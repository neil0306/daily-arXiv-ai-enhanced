<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 109]
- [cs.CV](#cs.CV) [Total: 169]
- [cs.SE](#cs.SE) [Total: 2]
- [cs.CY](#cs.CY) [Total: 2]
- [cs.AI](#cs.AI) [Total: 18]
- [physics.optics](#physics.optics) [Total: 1]
- [cs.CG](#cs.CG) [Total: 1]
- [cs.LG](#cs.LG) [Total: 45]
- [eess.SY](#eess.SY) [Total: 1]
- [cs.RO](#cs.RO) [Total: 5]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [eess.IV](#eess.IV) [Total: 7]
- [astro-ph.IM](#astro-ph.IM) [Total: 1]
- [eess.AS](#eess.AS) [Total: 2]
- [cs.SD](#cs.SD) [Total: 1]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.CR](#cs.CR) [Total: 2]
- [cs.IR](#cs.IR) [Total: 3]
- [cs.GR](#cs.GR) [Total: 10]
- [cs.PL](#cs.PL) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Decomposing Attention To Find Context-Sensitive Neurons](https://arxiv.org/abs/2510.03315)
*Alex Gibson*

Main category: cs.CL

TL;DR: The paper analyzes transformer language models, focusing on attention heads with spread-out patterns and weak content dependence. It shows that softmax denominators of these heads are stable with fixed token distribution, enabling linear approximation of combined outputs from multiple heads in GPT2-Small's first layer.


<details>
  <summary>Details</summary>
Motivation: To understand how transformer language models work, particularly analyzing attention mechanisms that appear stable and content-independent, and to develop methods for interpreting model behavior from weights alone.

Method: Sampling softmax denominators from calibration text to combine outputs of multiple stable attention heads in GPT2-Small's first layer, approximating their combined output as a linear summary of surrounding text.

Result: The method successfully uncovered hundreds of first layer neurons that respond to high-level contextual properties of surrounding text, including neurons that didn't activate on the calibration text used.

Conclusion: The approach enables interpretation of transformer models from weights and minimal calibration data, revealing meaningful neuron responses to contextual features without requiring extensive activation data.

Abstract: We study transformer language models, analyzing attention heads whose
attention patterns are spread out, and whose attention scores depend weakly on
content. We argue that the softmax denominators of these heads are stable when
the underlying token distribution is fixed. By sampling softmax denominators
from a "calibration text", we can combine together the outputs of multiple such
stable heads in the first layer of GPT2-Small, approximating their combined
output by a linear summary of the surrounding text. This approximation enables
a procedure where from the weights alone - and a single calibration text - we
can uncover hundreds of first layer neurons that respond to high-level
contextual properties of the surrounding text, including neurons that didn't
activate on the calibration text.

</details>


### [2] [Graph-S3: Enhancing Agentic textual Graph Retrieval with Synthetic Stepwise Supervision](https://arxiv.org/abs/2510.03323)
*Ge Chang,Jinbo Su,Jiacheng Liu,Pengfei Yang,Yuhao Shang,Huiwen Zheng,Hongli Ma,Yan Liang,Yuanchun Li,Yunxin Liu*

Main category: cs.CL

TL;DR: Graph-S³ is an agentic textual graph reasoning framework that uses LLM-based retrievers trained with synthetic stepwise supervision to improve graph retrieval for question answering, achieving significant performance gains over existing methods.


<details>
  <summary>Details</summary>
Motivation: Real-world data often exists as textual graphs, but current LLM-based graph QA systems struggle with graph retrieval - either using shallow embedding similarity or requiring excessive training costs. There's a need for more efficient and effective retrieval methods.

Method: Proposes Graph-S³ framework with: 1) LLM-based retriever trained with synthetic stepwise supervision, 2) Evaluation of each retrieval step using offline-extracted golden subgraphs instead of final answers, 3) Data synthesis pipeline for reward generation, 4) Two-stage training scheme for interactive graph exploration policy.

Result: Achieves average improvement of 8.1% in accuracy and 9.7% in F1 score across three datasets compared to seven strong baselines. Shows even higher advantage in complex multi-hop reasoning tasks.

Conclusion: Graph-S³ provides an effective solution for textual graph retrieval in LLM-based QA systems by using stepwise supervision and synthetic training data, significantly outperforming existing approaches while being more efficient.

Abstract: A significant portion of real-world data is inherently represented as textual
graphs, and integrating these graphs into large language models (LLMs) is
promising to enable complex graph-based question answering. However, a key
challenge in LLM-based textual graph QA systems lies in graph retrieval, i.e.,
how to retrieve relevant content from large graphs that is sufficiently
informative while remaining compact for the LLM context. Existing retrievers
suffer from poor performance since they either rely on shallow embedding
similarity or employ interactive retrieving policies that demand excessive data
labeling and training cost. To address these issues, we present Graph-$S^3$, an
agentic textual graph reasoning framework that employs an LLM-based retriever
trained with synthetic stepwise supervision. Instead of rewarding the agent
based on the final answers, which may lead to sparse and unstable training
signals, we propose to closely evaluate each step of the retriever based on
offline-extracted golden subgraphs. Our main techniques include a data
synthesis pipeline to extract the golden subgraphs for reward generation and a
two-stage training scheme to learn the interactive graph exploration policy
based on the synthesized rewards. Based on extensive experiments on three
common datasets in comparison with seven strong baselines, our approach
achieves an average improvement of 8.1\% in accuracy and 9.7\% in F$_1$ score.
The advantage is even higher in more complicated multi-hop reasoning tasks. Our
code will be open-sourced.

</details>


### [3] [Implicit Values Embedded in How Humans and LLMs Complete Subjective Everyday Tasks](https://arxiv.org/abs/2510.03384)
*Arjun Arunasalam,Madison Pickering,Z. Berkay Celik,Blase Ur*

Main category: cs.CL

TL;DR: This paper audits how six popular LLMs exhibit implicit values (like environmentalism, charity, diversity) when completing everyday tasks, comparing them to each other and to human crowdworkers.


<details>
  <summary>Details</summary>
Motivation: Despite AI assistants' promise for helping with everyday tasks, little is known about the implicit values these assistants display while completing subjective tasks, and how they compare to human values.

Method: The researchers audited how six popular LLMs complete 30 everyday tasks, comparing LLMs to each other and to 100 human crowdworkers from the US.

Result: LLMs often do not align with humans, nor with other LLMs, in the implicit values exhibited when completing everyday tasks.

Conclusion: There is significant misalignment between LLMs and humans in the implicit values displayed during task completion, highlighting a need for better value alignment in AI assistants.

Abstract: Large language models (LLMs) can underpin AI assistants that help users with
everyday tasks, such as by making recommendations or performing basic
computation. Despite AI assistants' promise, little is known about the implicit
values these assistants display while completing subjective everyday tasks.
Humans may consider values like environmentalism, charity, and diversity. To
what extent do LLMs exhibit these values in completing everyday tasks? How do
they compare with humans? We answer these questions by auditing how six popular
LLMs complete 30 everyday tasks, comparing LLMs to each other and to 100 human
crowdworkers from the US. We find LLMs often do not align with humans, nor with
other LLMs, in the implicit values exhibited.

</details>


### [4] [Morpheme Induction for Emergent Language](https://arxiv.org/abs/2510.03439)
*Brendon Boldt,David Mortensen*

Main category: cs.CL

TL;DR: CSAR is a greedy algorithm for morpheme induction from emergent language corpora using mutual information weighting and iterative selection-ablation.


<details>
  <summary>Details</summary>
Motivation: To develop an effective method for automatically inducing morphemes from emergent language data where parallel utterances and meanings are available.

Method: A greedy algorithm that weights morphemes by mutual information between forms and meanings, selects the highest-weighted pair, removes it from the corpus, and repeats the process (Count, Select, Ablate, Repeat).

Result: Validated on procedurally generated datasets showing effectiveness against baselines, performed reasonably on human language data, and enabled analysis of linguistic characteristics like synonymy and polysemy in emergent languages.

Conclusion: CSAR provides an effective approach for morpheme induction from emergent language corpora and can quantify linguistic properties of such languages.

Abstract: We introduce CSAR, an algorithm for inducing morphemes from emergent language
corpora of parallel utterances and meanings. It is a greedy algorithm that (1)
weights morphemes based on mutual information between forms and meanings, (2)
selects the highest-weighted pair, (3) removes it from the corpus, and (4)
repeats the process to induce further morphemes (i.e., Count, Select, Ablate,
Repeat). The effectiveness of CSAR is first validated on procedurally generated
datasets and compared against baselines for related tasks. Second, we validate
CSAR's performance on human language data to show that the algorithm makes
reasonable predictions in adjacent domains. Finally, we analyze a handful of
emergent languages, quantifying linguistic characteristics like degree of
synonymy and polysemy.

</details>


### [5] [Omni-Embed-Nemotron: A Unified Multimodal Retrieval Model for Text, Image, Audio, and Video](https://arxiv.org/abs/2510.03458)
*Mengyao Xu,Wenfei Zhou,Yauhen Babakhin,Gabriel Moreira,Ronay Ak,Radek Osmulski,Bo Liu,Even Oldridge,Benedikt Schifferer*

Main category: cs.CL

TL;DR: Omni-Embed-Nemotron is a unified multimodal retrieval embedding model that extends beyond text and images to support audio and video modalities, enabling both cross-modal and joint-modal retrieval using a single model.


<details>
  <summary>Details</summary>
Motivation: Existing text-based retrievers struggle with visually and semantically rich content in real-world documents like PDFs, slides, and videos, while recent work shows that preserving document layout using image-based representations can improve retrieval quality.

Method: The model builds on recent multimodal models like Qwen2.5-Omni and extends retrieval capabilities to support audio and video modalities, using a unified architecture that handles cross-modal and joint-modal retrieval.

Result: The model demonstrates effectiveness in text, image, and video retrieval, showing improved performance across multiple modalities.

Conclusion: Omni-Embed-Nemotron provides a comprehensive solution for multimodal retrieval, addressing the limitations of text-only approaches and enabling more effective handling of real-world multimodal content.

Abstract: We present Omni-Embed-Nemotron, a unified multimodal retrieval embedding
model developed to handle the increasing complexity of real-world information
needs. While Retrieval-Augmented Generation (RAG) has significantly advanced
language models by incorporating external knowledge, existing text-based
retrievers rely on clean, structured input and struggle with the visually and
semantically rich content found in real-world documents such as PDFs, slides,
or videos. Recent work such as ColPali has shown that preserving document
layout using image-based representations can improve retrieval quality.
Building on this, and inspired by the capabilities of recent multimodal models
such as Qwen2.5-Omni, we extend retrieval beyond text and images to also
support audio and video modalities. Omni-Embed-Nemotron enables both
cross-modal (e.g., text - video) and joint-modal (e.g., text - video+audio)
retrieval using a single model. We describe the architecture, training setup,
and evaluation results of Omni-Embed-Nemotron, and demonstrate its
effectiveness in text, image, and video retrieval.

</details>


### [6] [Searching for the Most Human-like Emergent Language](https://arxiv.org/abs/2510.03467)
*Brendon Boldt,David Mortensen*

Main category: cs.CL

TL;DR: The paper develops a signaling game-based environment with hyperparameter optimization to create emergent languages that closely resemble human language, using XferBench to measure similarity through transfer learning performance.


<details>
  <summary>Details</summary>
Motivation: To generate emergent languages that are statistically similar to human language, improving upon existing methods by focusing on transfer learning suitability as a measure of similarity.

Method: Design a signaling game-based emergent communication environment with hyperparameter optimization, using XferBench as the objective function to quantify statistical similarity to human language through transfer learning performance.

Result: Successfully generated state-of-the-art emergent languages with high similarity to human language, demonstrated the predictive power of entropy on transfer learning performance, and identified hyperparameters that produce more realistic emergent languages.

Conclusion: The approach effectively creates emergent languages similar to human language, with entropy serving as a key predictor of transfer learning performance, and specific hyperparameters identified for generating more realistic languages.

Abstract: In this paper, we design a signalling game-based emergent communication
environment to generate state-of-the-art emergent languages in terms of
similarity to human language. This is done with hyperparameter optimization,
using XferBench as the objective function. XferBench quantifies the statistical
similarity of emergent language to human language by measuring its suitability
for deep transfer learning to human language. Additionally, we demonstrate the
predictive power of entropy on the transfer learning performance of emergent
language as well as corroborate previous results on the entropy-minimization
properties of emergent communication systems. Finally, we report
generalizations regarding what hyperparameters produce more realistic emergent
languages, that is, ones which transfer better to human language.

</details>


### [7] [SEER: The Span-based Emotion Evidence Retrieval Benchmark](https://arxiv.org/abs/2510.03490)
*Aneesha Sampath,Oya Aran,Emily Mower Provost*

Main category: cs.CL

TL;DR: SEER Benchmark tests LLMs' ability to identify specific text spans that express emotion, focusing on emotion evidence detection rather than just emotion classification.


<details>
  <summary>Details</summary>
Motivation: Traditional emotion recognition assigns single labels to sentences, but applications like empathetic dialogue and clinical support need to know exactly how and where emotion is expressed in text.

Method: Created SEER Benchmark with 1200 real-world sentences annotated for emotion and emotion evidence. Includes two tasks: single-sentence evidence detection and cross-sentence evidence detection in 5-sentence passages. Evaluated 14 open-source LLMs.

Result: Some models approach average human performance on single-sentence inputs, but accuracy degrades in longer passages. Error analysis reveals overreliance on emotion keywords and false positives in neutral text.

Conclusion: LLMs struggle with span-level emotion evidence detection, especially in longer contexts, highlighting limitations in current emotion understanding capabilities.

Abstract: We introduce the SEER (Span-based Emotion Evidence Retrieval) Benchmark to
test Large Language Models' (LLMs) ability to identify the specific spans of
text that express emotion. Unlike traditional emotion recognition tasks that
assign a single label to an entire sentence, SEER targets the underexplored
task of emotion evidence detection: pinpointing which exact phrases convey
emotion. This span-level approach is crucial for applications like empathetic
dialogue and clinical support, which need to know how emotion is expressed, not
just what the emotion is. SEER includes two tasks: identifying emotion evidence
within a single sentence, and identifying evidence across a short passage of
five consecutive sentences. It contains new annotations for both emotion and
emotion evidence on 1200 real-world sentences. We evaluate 14 open-source LLMs
and find that, while some models approach average human performance on
single-sentence inputs, their accuracy degrades in longer passages. Our error
analysis reveals key failure modes, including overreliance on emotion keywords
and false positives in neutral text.

</details>


### [8] [ALHD: A Large-Scale and Multigenre Benchmark Dataset for Arabic LLM-Generated Text Detection](https://arxiv.org/abs/2510.03502)
*Ali Khairallah,Arkaitz Zubiaga*

Main category: cs.CL

TL;DR: ALHD is the first large-scale Arabic dataset for distinguishing human- and LLM-generated texts across news, social media, and reviews in both MSA and dialectal Arabic, with over 400K balanced samples.


<details>
  <summary>Details</summary>
Motivation: To address the need for comprehensive Arabic text detection capabilities to mitigate risks of misinformation, academic dishonesty, and cyber threats from LLM-generated content.

Method: Created a balanced dataset with 400K+ samples across three genres using three leading LLMs and multiple human sources, then benchmarked traditional classifiers, BERT-based models, and LLMs (zero-shot/few-shot).

Result: Fine-tuned BERT models achieved competitive performance, outperforming LLM-based models. However, models struggled with cross-genre generalization, particularly with news articles where LLM-generated texts closely resemble human writing style.

Conclusion: ALHD establishes a foundation for Arabic LLM-detection research, revealing challenges in cross-genre generalization and opening avenues for future work on detecting sophisticated LLM-generated content in Arabic.

Abstract: We introduce ALHD, the first large-scale comprehensive Arabic dataset
explicitly designed to distinguish between human- and LLM-generated texts. ALHD
spans three genres (news, social media, reviews), covering both MSA and
dialectal Arabic, and contains over 400K balanced samples generated by three
leading LLMs and originated from multiple human sources, which enables studying
generalizability in Arabic LLM-genearted text detection. We provide rigorous
preprocessing, rich annotations, and standardized balanced splits to support
reproducibility. In addition, we present, analyze and discuss benchmark
experiments using our new dataset, in turn identifying gaps and proposing
future research directions. Benchmarking across traditional classifiers,
BERT-based models, and LLMs (zero-shot and few-shot) demonstrates that
fine-tuned BERT models achieve competitive performance, outperforming LLM-based
models. Results are however not always consistent, as we observe challenges
when generalizing across genres; indeed, models struggle to generalize when
they need to deal with unseen patterns in cross-genre settings, and these
challenges are particularly prominent when dealing with news articles, where
LLM-generated texts resemble human texts in style, which opens up avenues for
future research. ALHD establishes a foundation for research related to Arabic
LLM-detection and mitigating risks of misinformation, academic dishonesty, and
cyber threats.

</details>


### [9] [TS-Reasoner: Aligning Time Series Foundation Models with LLM Reasoning](https://arxiv.org/abs/2510.03519)
*Fangxu Yu,Hongyu Zhao,Tianyi Zhou*

Main category: cs.CL

TL;DR: TS-Reasoner aligns time series foundation models (TSFMs) with large language models (LLMs) through two-stage training to enable effective time series reasoning, outperforming existing models with superior data efficiency.


<details>
  <summary>Details</summary>
Motivation: Existing TSFMs lack reasoning capabilities while LLMs struggle with numerical understanding of time series data. Integrating both models for effective time series reasoning remains challenging.

Method: Proposes TS-Reasoner with two-stage training: alignment pretraining using synthetic time series-text pairs, followed by instruction finetuning. Uses pretrained TSFM (frozen) and aligns its latent representations with LLM textual inputs.

Result: Outperforms prevailing LLMs, Vision Language Models, and Time Series LLMs on multiple benchmarks while using less than half the training data.

Conclusion: TS-Reasoner effectively bridges TSFMs and LLMs for time series reasoning tasks, achieving state-of-the-art performance with remarkable data efficiency through proper alignment and training strategies.

Abstract: Time series reasoning is crucial to decision-making in diverse domains,
including finance, energy usage, traffic, weather, and scientific discovery.
While existing time series foundation models (TSFMs) can capture low-level
dynamic patterns and provide accurate forecasting, further analysis usually
requires additional background knowledge and sophisticated reasoning, which are
lacking in most TSFMs but can be achieved through large language models (LLMs).
On the other hand, without expensive post-training, LLMs often struggle with
the numerical understanding of time series data. Although it is intuitive to
integrate the two types of models, developing effective training recipes that
align the two modalities for reasoning tasks is still an open challenge. To
this end, we propose TS-Reasoner that aligns the latent representations of
TSFMs with the textual inputs of LLMs for downstream understanding/reasoning
tasks. Specifically, we propose a simple yet effective method to curate
diverse, synthetic pairs of time series and textual captions for alignment
training. We then develop a two-stage training recipe that applies instruction
finetuning after the alignment pretraining. Unlike existing works that train an
LLM to take time series as inputs, we leverage a pretrained TSFM and freeze it
during training. Extensive experiments on several benchmarks demonstrate that
TS-Reasoner not only outperforms a wide range of prevailing LLMs, Vision
Language Models (VLMs), and Time Series LLMs, but also achieves this with
remarkable data efficiency, e.g., using less than half the training data.

</details>


### [10] [Identifying Financial Risk Information Using RAG with a Contrastive Insight](https://arxiv.org/abs/2510.03521)
*Ali Elahi*

Main category: cs.CL

TL;DR: The paper proposes a peer-aware comparative inference layer on top of RAG to address limitations in specialized reasoning tasks, particularly in finance, where standard RAG outputs generic information rather than context-specific insights.


<details>
  <summary>Details</summary>
Motivation: In specialized domains like finance, humans compare new problems against similar examples and highlight nuances, but standard RAG systems are not designed to retrieve comparable cases or related problems, resulting in generic outputs that lack context-specific insights.

Method: The authors propose a peer-aware comparative inference layer on top of RAG that uses a contrastive approach to enable comparison against similar cases and draw context-specific conclusions.

Result: The proposed contrastive approach outperforms baseline RAG in text generation metrics such as ROUGE and BERTScore when compared to human-generated equity research and risk analysis.

Conclusion: Adding a comparative inference layer to RAG systems improves their ability to generate context-specific insights in specialized domains, addressing the limitation of generic outputs in standard RAG implementations.

Abstract: In specialized domains, humans often compare new problems against similar
examples, highlight nuances, and draw conclusions instead of analyzing
information in isolation. When applying reasoning in specialized contexts with
LLMs on top of a RAG, the pipeline can capture contextually relevant
information, but it is not designed to retrieve comparable cases or related
problems.
  While RAG is effective at extracting factual information, its outputs in
specialized reasoning tasks often remain generic, reflecting broad facts rather
than context-specific insights. In finance, it results in generic risks that
are true for the majority of companies. To address this limitation, we propose
a peer-aware comparative inference layer on top of RAG.
  Our contrastive approach outperforms baseline RAG in text generation metrics
such as ROUGE and BERTScore in comparison with human-generated equity research
and risk.

</details>


### [11] [Sample, Align, Synthesize: Graph-Based Response Synthesis with ConGrs](https://arxiv.org/abs/2510.03527)
*Sayan Ghosh,Shahzaib Saqib Warraich,Dhruv Tarsadiya,Gregory Yauney,Swabha Swayamdipta*

Main category: cs.CL

TL;DR: Consensus Graphs (ConGrs) is a DAG-based method that synthesizes multiple LM responses using sequence alignment and targeted LM judges to improve factual precision, refusal rates, and reasoning accuracy.


<details>
  <summary>Details</summary>
Motivation: Existing methods cannot efficiently synthesize rich epistemic signals across different long-form language model responses to the same prompt.

Method: Construct Consensus Graphs using lightweight lexical sequence alignment from bioinformatics, supplemented by targeted usage of a secondary LM judge, with task-dependent decoding methods to synthesize final responses.

Result: Improves factual precision by up to 31% on biography generation, reduces reliance on LM judges by over 80%, increases abstention rates by up to 56% on refusal tasks, and improves reasoning accuracy by up to 6 points on MATH and AIME tasks.

Conclusion: ConGrs provide a flexible method for capturing variation in LM responses and using epistemic signals from response variation to synthesize more effective responses.

Abstract: Language models can be sampled multiple times to access the distribution
underlying their responses, but existing methods cannot efficiently synthesize
rich epistemic signals across different long-form responses. We introduce
Consensus Graphs (ConGrs), a flexible DAG-based data structure that represents
shared information, as well as semantic variation in a set of sampled LM
responses to the same prompt. We construct ConGrs using a light-weight lexical
sequence alignment algorithm from bioinformatics, supplemented by the targeted
usage of a secondary LM judge. Further, we design task-dependent decoding
methods to synthesize a single, final response from our ConGr data structure.
Our experiments show that synthesizing responses from ConGrs improves factual
precision on two biography generation tasks by up to 31% over an average
response and reduces reliance on LM judges by more than 80% compared to other
methods. We also use ConGrs for three refusal-based tasks requiring abstention
on unanswerable queries and find that abstention rate is increased by up to
56%. We apply our approach to the MATH and AIME reasoning tasks and find an
improvement over self-verification and majority vote baselines by up to 6
points of accuracy. We show that ConGrs provide a flexible method for capturing
variation in LM responses and using the epistemic signals provided by response
variation to synthesize more effective responses.

</details>


### [12] [Fine-Tuning on Noisy Instructions: Effects on Generalization and Performance](https://arxiv.org/abs/2510.03528)
*Ahmed Alajrami,Xingwei Tan,Nikolaos Aletras*

Main category: cs.CL

TL;DR: Instruction-tuning with perturbed instructions (removing stop words, shuffling words) can improve LLMs' resistance to noisy inputs and sometimes enhance downstream performance on benchmarks like MMLU, BBH, and GSM8K.


<details>
  <summary>Details</summary>
Motivation: LLMs are sensitive to minor variations in instruction phrasing, which affects their usability. This paper explores whether introducing perturbations during instruction-tuning can enhance models' robustness against noisy instructions.

Method: Introduce perturbations (removing stop words, shuffling words) in instruction-tuning data and evaluate the effects on LLMs' performance on original and perturbed versions of benchmarks (MMLU, BBH, GSM8K). Also assess learning dynamics and behavior shifts.

Result: Surprisingly, instruction-tuning on perturbed instructions can improve downstream performance in some cases. Models become more resilient to noisy user inputs.

Conclusion: Including perturbed instructions in instruction-tuning is important as it makes LLMs more resilient to noisy inputs, improving their robustness and potentially enhancing performance.

Abstract: Instruction-tuning plays a vital role in enhancing the task-solving abilities
of large language models (LLMs), improving their usability in generating
helpful responses on various tasks. However, previous work has demonstrated
that they are sensitive to minor variations in instruction phrasing. In this
paper, we explore whether introducing perturbations in instruction-tuning data
can enhance LLMs' resistance against noisy instructions. We focus on how
instruction-tuning with perturbations, such as removing stop words or shuffling
words, affects LLMs' performance on the original and perturbed versions of
widely-used benchmarks (MMLU, BBH, GSM8K). We further assess learning dynamics
and potential shifts in model behavior. Surprisingly, our results suggest that
instruction-tuning on perturbed instructions can, in some cases, improve
downstream performance. These findings highlight the importance of including
perturbed instructions in instruction-tuning, which can make LLMs more
resilient to noisy user inputs.

</details>


### [13] [TriMediQ: A Triplet-Structured Approach for Interactive Medical Question Answering](https://arxiv.org/abs/2510.03536)
*Zhaohan Meng,Zaiqiao Meng,Siwei Liu,Iadh Ounis*

Main category: cs.CL

TL;DR: TriMediQ improves LLM-based medical diagnosis by converting patient dialogue into structured triplets and building a knowledge graph, enabling multi-hop reasoning that boosts accuracy by up to 10.4% over baselines.


<details>
  <summary>Details</summary>
Motivation: Current LLMs perform well on static medical QA but struggle with iterative clinical dialogues where facts appear in unstructured sentences without clear connections, leading to unreliable reasoning.

Method: TriMediQ uses a frozen triplet generator to extract clinical triplets from patient responses, builds a knowledge graph, and employs a trainable projection module (graph encoder + projector) to capture relational information for enhanced reasoning.

Result: TriMediQ achieves up to 10.4% improvement in accuracy over five baselines on the iMedQA dataset, demonstrating superior performance in interactive medical QA benchmarks.

Conclusion: Converting patient responses into structured triplet-based graphs enables more accurate clinical reasoning in multi-turn settings, providing a viable solution for deploying LLM-based medical assistants in practical clinical scenarios.

Abstract: Large Language Models (LLMs) perform strongly in static and single-turn
medical Question Answer (QA) benchmarks, yet such settings diverge from the
iterative information gathering process required in practical clinical
consultations. The MEDIQ framework addresses this mismatch by recasting the
diagnosis as an interactive dialogue between a patient and an expert system,
but the reliability of LLMs drops dramatically when forced to reason with
dialogue logs, where clinical facts appear in sentences without clear links. To
bridge this gap, we introduce TriMediQ, a triplet-structured approach that
summarises patient responses into triplets and integrates them into a Knowledge
Graph (KG), enabling multi-hop reasoning. We introduce a frozen triplet
generator that extracts clinically relevant triplets, using prompts designed to
ensure factual consistency. In parallel, a trainable projection module,
comprising a graph encoder and a projector, captures relational information
from the KG to enhance expert reasoning. TriMediQ operates in two steps: (i)
the projection module fine-tuning with all LLM weights frozen; and (ii) using
the fine-tuned module to guide multi-hop reasoning during inference. We
evaluate TriMediQ on two interactive QA benchmarks, showing that it achieves up
to 10.4\% improvement in accuracy over five baselines on the iMedQA dataset.
These results demonstrate that converting patient responses into structured
triplet-based graphs enables more accurate clinical reasoning in multi-turn
settings, providing a solution for the deployment of LLM-based medical
assistants.

</details>


### [14] [What is a protest anyway? Codebook conceptualization is still a first-order concern in LLM-era classification](https://arxiv.org/abs/2510.03541)
*Andrew Halterman,Katherine A. Keith*

Main category: cs.CL

TL;DR: LLMs in computational social science can lead to conceptualization errors that bias downstream estimates, which cannot be fixed by just improving LLM accuracy or post-hoc corrections.


<details>
  <summary>Details</summary>
Motivation: To highlight that conceptualization steps before LLM prompting and using predictions in downstream inference have been overlooked in LLM-era computational social science, potentially leading to biased estimates.

Method: Using simulations to demonstrate that conceptualization-induced bias cannot be corrected solely by increasing LLM accuracy or post-hoc bias correction methods.

Result: The simulations show conceptualization errors create biases that persist despite improvements in LLM performance or statistical corrections.

Conclusion: Conceptualization remains a first-order concern in LLM-era CSS, and analysts should focus on proper conceptualization to achieve low-cost, unbiased, low-variance downstream estimates.

Abstract: Generative large language models (LLMs) are now used extensively for text
classification in computational social science (CSS). In this work, focus on
the steps before and after LLM prompting -- conceptualization of concepts to be
classified and using LLM predictions in downstream statistical inference --
which we argue have been overlooked in much of LLM-era CSS. We claim LLMs can
tempt analysts to skip the conceptualization step, creating conceptualization
errors that bias downstream estimates. Using simulations, we show that this
conceptualization-induced bias cannot be corrected for solely by increasing LLM
accuracy or post-hoc bias correction methods. We conclude by reminding CSS
analysts that conceptualization is still a first-order concern in the LLM-era
and provide concrete advice on how to pursue low-cost, unbiased, low-variance
downstream estimates.

</details>


### [15] [CCD-Bench: Probing Cultural Conflict in Large Language Model Decision-Making](https://arxiv.org/abs/2510.03553)
*Hasibur Rahman,Hanan Salam*

Main category: cs.CL

TL;DR: CCD-Bench is a new benchmark that evaluates how LLMs handle cross-cultural value conflicts, revealing models disproportionately favor certain cultural clusters and show superficial pluralism in reasoning.


<details>
  <summary>Details</summary>
Motivation: Current benchmarks focus on cultural knowledge, value prediction, or single-axis bias, but none assess how LLMs adjudicate when multiple culturally grounded values directly clash.

Method: Created CCD-Bench with 2,182 open-ended dilemmas across seven domains, paired with ten anonymized response options corresponding to GLOBE cultural clusters, using stratified Latin square design to mitigate ordering effects.

Result: Models disproportionately prefer Nordic Europe (20.2%) and Germanic Europe (12.4%), while underrepresented Eastern Europe and Middle East/North Africa (5.6-5.8%). Rationales show superficial pluralism, mainly recombining Future Orientation and Performance Orientation.

Conclusion: Current alignment pipelines promote consensus-oriented worldviews that underserve scenarios requiring power negotiation, rights-based reasoning, or gender-aware analysis, highlighting need for alignment strategies that substantively engage diverse worldviews.

Abstract: Although large language models (LLMs) are increasingly implicated in
interpersonal and societal decision-making, their ability to navigate explicit
conflicts between legitimately different cultural value systems remains largely
unexamined. Existing benchmarks predominantly target cultural knowledge
(CulturalBench), value prediction (WorldValuesBench), or single-axis bias
diagnostics (CDEval); none evaluate how LLMs adjudicate when multiple
culturally grounded values directly clash. We address this gap with CCD-Bench,
a benchmark that assesses LLM decision-making under cross-cultural value
conflict. CCD-Bench comprises 2,182 open-ended dilemmas spanning seven domains,
each paired with ten anonymized response options corresponding to the ten GLOBE
cultural clusters. These dilemmas are presented using a stratified Latin square
to mitigate ordering effects. We evaluate 17 non-reasoning LLMs. Models
disproportionately prefer Nordic Europe (mean 20.2 percent) and Germanic Europe
(12.4 percent), while options for Eastern Europe and the Middle East and North
Africa are underrepresented (5.6 to 5.8 percent). Although 87.9 percent of
rationales reference multiple GLOBE dimensions, this pluralism is superficial:
models recombine Future Orientation and Performance Orientation, and rarely
ground choices in Assertiveness or Gender Egalitarianism (both under 3
percent). Ordering effects are negligible (Cramer's V less than 0.10), and
symmetrized KL divergence shows clustering by developer lineage rather than
geography. These patterns suggest that current alignment pipelines promote a
consensus-oriented worldview that underserves scenarios demanding power
negotiation, rights-based reasoning, or gender-aware analysis. CCD-Bench shifts
evaluation beyond isolated bias detection toward pluralistic decision making
and highlights the need for alignment strategies that substantively engage
diverse worldviews.

</details>


### [16] [Reactive Transformer (RxT) -- Stateful Real-Time Processing for Event-Driven Reactive Language Models](https://arxiv.org/abs/2510.03561)
*Adam Filipek*

Main category: cs.CL

TL;DR: The Reactive Transformer (RxT) is a novel architecture that overcomes the stateless nature and quadratic complexity of standard Transformers for conversational AI by using an event-driven paradigm with fixed-size short-term memory.


<details>
  <summary>Details</summary>
Motivation: Standard Transformers have limitations in conversational AI due to their stateless nature and O(L²) computational complexity, requiring reprocessing of entire conversation history for each turn, which becomes prohibitively expensive in long dialogues.

Method: RxT processes each conversational turn as a discrete event, maintaining context in a fixed-size Short-Term Memory (STM) system. It uses a generator-decoder for response generation and a memory-encoder with Memory Attention network for asynchronous memory updates.

Result: RxT reduces conversation cost from quadratic O(N²·T) to linear O(N·T) scaling, achieves low latency, and enables real-time stateful conversations. Proof-of-concept experiments showed superior performance and constant-time inference latency compared to baseline models.

Conclusion: RxT provides an economically viable solution for long-form conversations by decoupling response generation from memory updates, fundamentally altering the scaling dynamics of conversational AI systems.

Abstract: The Transformer architecture has become the de facto standard for Large
Language Models (LLMs), demonstrating remarkable capabilities in language
understanding and generation. However, its application in conversational AI is
fundamentally constrained by its stateless nature and the quadratic
computational complexity ($O(L^2)$) with respect to sequence length $L$.
Current models emulate memory by reprocessing an ever-expanding conversation
history with each turn, leading to prohibitive costs and latency in long
dialogues. This paper introduces the Reactive Transformer (RxT), a novel
architecture designed to overcome these limitations by shifting from a
data-driven to an event-driven paradigm. RxT processes each conversational turn
as a discrete event in real-time, maintaining context in an integrated,
fixed-size Short-Term Memory (STM) system. The architecture features a distinct
operational cycle where a generator-decoder produces a response based on the
current query and the previous memory state, after which a memory-encoder and a
dedicated Memory Attention network asynchronously update the STM with a
representation of the complete interaction. This design fundamentally alters
the scaling dynamics, reducing the total user-facing cost of a conversation
from quadratic ($O(N^2 \cdot T)$) to linear ($O(N \cdot T)$) with respect to
the number of interactions $N$. By decoupling response generation from memory
updates, RxT achieves low latency, enabling truly real-time, stateful, and
economically viable long-form conversations. We validated our architecture with
a series of proof-of-concept experiments on synthetic data, demonstrating
superior performance and constant-time inference latency compared to a baseline
stateless model of comparable size.

</details>


### [17] [LLM, Reporting In! Medical Information Extraction Across Prompting, Fine-tuning and Post-correction](https://arxiv.org/abs/2510.03577)
*Ikram Belmadani,Parisa Nazari Hashemi,Thomas Sebbag,Benoit Favre,Guillaume Fortier,Solen Quiniou,Emmanuel Morin,Richard Dufour*

Main category: cs.CL

TL;DR: The paper presents three approaches for biomedical NER and event extraction in French using LLMs, with GPT-4.1 achieving best results through in-context learning with guideline summaries.


<details>
  <summary>Details</summary>
Motivation: To address biomedical NER and health event extraction in French under few-shot settings, leveraging LLMs to overcome limited training data.

Method: Three approaches: (1) GPT-4.1 with in-context learning using 10 examples and annotation guideline summary, (2) GLiNER fine-tuned on synthetic data with LLM verification, (3) LLaMA-3.1-8B fine-tuned on synthetic data. Event extraction uses same ICL strategy as NER.

Result: GPT-4.1 achieved macro-F1 of 61.53% for NER and 15.02% for event extraction, outperforming other methods.

Conclusion: Well-crafted prompting is crucial for maximizing performance in low-resource scenarios, with GPT-4.1 showing superior results through in-context learning with guideline integration.

Abstract: This work presents our participation in the EvalLLM 2025 challenge on
biomedical Named Entity Recognition (NER) and health event extraction in French
(few-shot setting). For NER, we propose three approaches combining large
language models (LLMs), annotation guidelines, synthetic data, and
post-processing: (1) in-context learning (ICL) with GPT-4.1, incorporating
automatic selection of 10 examples and a summary of the annotation guidelines
into the prompt, (2) the universal NER system GLiNER, fine-tuned on a synthetic
corpus and then verified by an LLM in post-processing, and (3) the open LLM
LLaMA-3.1-8B-Instruct, fine-tuned on the same synthetic corpus. Event
extraction uses the same ICL strategy with GPT-4.1, reusing the guideline
summary in the prompt. Results show GPT-4.1 leads with a macro-F1 of 61.53% for
NER and 15.02% for event extraction, highlighting the importance of
well-crafted prompting to maximize performance in very low-resource scenarios.

</details>


### [18] [Decoupling Task-Solving and Output Formatting in LLM Generation](https://arxiv.org/abs/2510.03595)
*Haikang Deng,Po-Nien Kung,Nanyun Peng*

Main category: cs.CL

TL;DR: Deco-G is a decoding framework that separates format adherence from task solving using a tractable probabilistic model for format compliance and LLMs for task instructions, achieving 1.0-6.0% performance gains with guaranteed format compliance.


<details>
  <summary>Details</summary>
Motivation: LLMs struggle with complex prompts that mix task-solving instructions with rigid formatting requirements, creating competing goals that reduce performance. Explicit separation of these aspects could improve adherence to instructions.

Method: Deco-G decouples format adherence from task solving using a separate tractable probabilistic model (TPM) for format compliance while prompting LLMs with only task instructions. It combines token probabilities from LLM with TPM format compliance likelihood. Key innovations include instruction-aware distillation, flexible trie-building algorithm, and HMM state pruning.

Result: Deco-G demonstrates effectiveness across mathematical reasoning, LLM-as-a-judge, and event argument extraction tasks, achieving 1.0% to 6.0% relative performance gains over regular prompting while guaranteeing format compliance.

Conclusion: Explicitly decoupling format adherence from task solving through the Deco-G framework significantly improves LLM performance on complex tasks with rigid formatting requirements, providing both performance gains and guaranteed format compliance.

Abstract: Large language models (LLMs) are increasingly adept at following instructions
containing task descriptions to solve complex problems, such as mathematical
reasoning and automatic evaluation (LLM-as-a-Judge). However, as prompts grow
more complex, models often struggle to adhere to all instructions. This
difficulty is especially common when instructive prompts intertwine reasoning
directives -- specifying what the model should solve -- with rigid formatting
requirements that dictate how the solution must be presented. The entanglement
creates competing goals for the model, suggesting that more explicit separation
of these two aspects could lead to improved performance. To this front, we
introduce Deco-G, a decoding framework that explicitly decouples format
adherence from task solving. Deco-G handles format compliance with a separate
tractable probabilistic model (TPM), while prompts LLMs with only task
instructions. At each decoding step, Deco-G combines next token probabilities
from the LLM with the TPM calculated format compliance likelihood to form the
output probability. To make this approach both practical and scalable for
modern instruction-tuned LLMs, we introduce three key innovations:
instruction-aware distillation, a flexible trie-building algorithm, and HMM
state pruning for computational efficiency. We demonstrate the effectiveness of
Deco-G across a wide range of tasks with diverse format requirements, including
mathematical reasoning, LLM-as-a-judge, and event argument extraction. Overall,
our approach yields 1.0% to 6.0% relative gain over regular prompting practice
with guaranteed format compliance.

</details>


### [19] [Can an LLM Induce a Graph? Investigating Memory Drift and Context Length](https://arxiv.org/abs/2510.03611)
*Raquib Bin Yousuf,Aadyant Khatri,Shengzhe Xu,Mandar Sharma,Naren Ramakrishnan*

Main category: cs.CL

TL;DR: LLMs show memory drift and forgetting at shorter context lengths in complex relational reasoning tasks compared to existing benchmarks, revealing limitations in structured knowledge abstraction from unstructured text.


<details>
  <summary>Details</summary>
Motivation: Current benchmarks use simplistic retrieval tasks that don't accurately reflect LLM performance in information-dense scenarios requiring complex reasoning.

Method: Evaluate LLMs on relational reasoning tasks requiring induction of structured knowledge (graphs) from noisy natural language text with long contexts and irrelevant information.

Result: LLMs exhibit memory drift and contextual forgetting at much shorter effective lengths than existing benchmarks suggest, even specialized reasoning models like OpenAI o1 remain vulnerable.

Conclusion: Significant limitations exist in LLMs' ability to abstract structured knowledge from unstructured input, highlighting need for architectural adaptations to improve long-range reasoning.

Abstract: Recently proposed evaluation benchmarks aim to characterize the effective
context length and the forgetting tendencies of large language models (LLMs).
However, these benchmarks often rely on simplistic 'needle in a haystack'
retrieval or continuation tasks that may not accurately reflect the performance
of these models in information-dense scenarios. Thus, rather than simple next
token prediction, we argue for evaluating these models on more complex
reasoning tasks that requires them to induce structured relational knowledge
from the text - such as graphs from potentially noisy natural language content.
While the input text can be viewed as generated in terms of a graph, its
structure is not made explicit and connections must be induced from distributed
textual cues, separated by long contexts and interspersed with irrelevant
information. Our findings reveal that LLMs begin to exhibit memory drift and
contextual forgetting at much shorter effective lengths when tasked with this
form of relational reasoning, compared to what existing benchmarks suggest.
With these findings, we offer recommendations for the optimal use of popular
LLMs for complex reasoning tasks. We further show that even models specialized
for reasoning, such as OpenAI o1, remain vulnerable to early memory drift in
these settings. These results point to significant limitations in the models'
ability to abstract structured knowledge from unstructured input and highlight
the need for architectural adaptations to improve long-range reasoning.

</details>


### [20] [Towards Unsupervised Speech Recognition at the Syllable-Level](https://arxiv.org/abs/2510.03639)
*Liming Wang,Junrui Ni,Kai-Wei Chang,Saurabhchand Bhati,David Harwath,Mark Hasegawa-Johnson,James R. Glass*

Main category: cs.CL

TL;DR: A syllable-level unsupervised speech recognition framework using masked language modeling that eliminates the need for G2P converters and addresses training instability in GAN-based methods, achieving significant CER reduction on LibriSpeech and effective generalization to Mandarin.


<details>
  <summary>Details</summary>
Motivation: To enable speech recognition for low-resource languages and multimodal learning from non-parallel data by overcoming limitations of existing phone-based approaches that rely on costly G2P converters and struggle with ambiguous phoneme boundaries.

Method: Syllable-level unsupervised speech recognition framework based on masked language modeling, avoiding G2P requirements and GAN-based training instability.

Result: Achieves up to 40% relative reduction in character error rate on LibriSpeech and generalizes effectively to Mandarin, which was particularly difficult for prior methods.

Conclusion: The syllable-level masked language modeling approach provides an effective solution for unsupervised speech recognition that eliminates dependency on G2P converters and addresses training stability issues, enabling better performance across different languages including challenging cases like Mandarin.

Abstract: Training speech recognizers with unpaired speech and text -- known as
unsupervised speech recognition (UASR) -- is a crucial step toward extending
ASR to low-resource languages in the long-tail distribution and enabling
multimodal learning from non-parallel data. However, existing approaches based
on phones often rely on costly resources such as grapheme-to-phoneme converters
(G2Ps) and struggle to generalize to languages with ambiguous phoneme
boundaries due to training instability. In this paper, we address both
challenges by introducing a syllable-level UASR framework based on masked
language modeling, which avoids the need for G2P and the instability of
GAN-based methods. Our approach achieves up to a 40\% relative reduction in
character error rate (CER) on LibriSpeech and generalizes effectively to
Mandarin, a language that has remained particularly difficult for prior
methods. Code will be released upon acceptance.

</details>


### [21] [UNIDOC-BENCH: A Unified Benchmark for Document-Centric Multimodal RAG](https://arxiv.org/abs/2510.03663)
*Xiangyu Peng,Cab Qin,Zeyuan Chen,Ran Xu,Caiming Xiong,Chien-Sheng Wu*

Main category: cs.CL

TL;DR: UniDoc-Bench is the first large-scale benchmark for multimodal retrieval-augmented generation (MM-RAG) using 70k real-world PDF pages across 8 domains, featuring 1,600 multimodal QA pairs and supporting comparisons across 4 retrieval paradigms.


<details>
  <summary>Details</summary>
Motivation: Current MM-RAG evaluations are fragmented and fail to capture document-centric multimodal use cases, lacking realistic benchmarks for real-world knowledge bases.

Method: Built from 70k PDF pages across 8 domains, extracting and linking evidence from text, tables, and figures to generate 1,600 multimodal QA pairs spanning factual retrieval, comparison, summarization, and logical reasoning. 20% validated by multiple annotators and expert adjudication.

Result: Multimodal text-image fusion RAG systems consistently outperform unimodal and joint multimodal embedding-based retrieval, showing neither text nor images alone are sufficient and current multimodal embeddings remain inadequate.

Conclusion: The benchmark provides unified evaluation protocol, reveals when visual context complements text, uncovers failure modes, and offers guidance for developing more robust MM-RAG pipelines.

Abstract: Multimodal retrieval-augmented generation (MM-RAG) is a key approach for
applying large language models (LLMs) and agents to real-world knowledge bases,
yet current evaluations are fragmented, focusing on either text or images in
isolation or on simplified multimodal setups that fail to capture
document-centric multimodal use cases. In this paper, we introduce
UniDoc-Bench, the first large-scale, realistic benchmark for MM-RAG built from
70k real-world PDF pages across eight domains. Our pipeline extracts and links
evidence from text, tables, and figures, then generates 1,600 multimodal QA
pairs spanning factual retrieval, comparison, summarization, and logical
reasoning queries. To ensure reliability, 20% of QA pairs are validated by
multiple annotators and expert adjudication. UniDoc-Bench supports
apples-to-apples comparison across four paradigms: (1) text-only, (2)
image-only, (3) multimodal text-image fusion, and (4) multimodal joint
retrieval -- under a unified protocol with standardized candidate pools,
prompts, and evaluation metrics. Our experiments show that multimodal
text-image fusion RAG systems consistently outperform both unimodal and jointly
multimodal embedding-based retrieval, indicating that neither text nor images
alone are sufficient and that current multimodal embeddings remain inadequate.
Beyond benchmarking, our analysis reveals when and how visual context
complements textual evidence, uncovers systematic failure modes, and offers
actionable guidance for developing more robust MM-RAG pipelines.

</details>


### [22] [Fine-Tuning Large Language Models with QLoRA for Offensive Language Detection in Roman Urdu-English Code-Mixed Text](https://arxiv.org/abs/2510.03683)
*Nisar Hussain,Amna Qasim,Gull Mehak,Muhammad Zain,Momina Hafeez,Grigori Sidorov*

Main category: cs.CL

TL;DR: Proposes QLoRA-based fine-tuning framework for offensive language detection in Roman Urdu-English code mixed text, achieving best performance with Meta LLaMA 3 8B (F1: 91.45) through English translation approach.


<details>
  <summary>Details</summary>
Motivation: Address challenges in processing code mixed languages like Roman Urdu due to unstated grammar, inconsistent spelling, and limited labeled data for offensive language detection.

Method: Translate Roman Urdu-English dataset to English using Google Translate, then fine-tune multiple LLMs (LLaMA 3 8B, Mistral 7B, LLaMA 2 7B, ModernBERT, RoBERTa) using QLoRA for memory-efficient adaptation on manually annotated offensive vs non-offensive content.

Result: Meta LLaMA 3 8B achieved highest F1 score of 91.45, followed by Mistral 7B at 89.66, outperforming traditional transformer baselines.

Conclusion: QLoRA enables effective fine-tuning of high-performing models for low-resource code mixed offensive language detection, demonstrating LLM potential for scalable Roman Urdu moderation and future multilingual systems.

Abstract: The use of derogatory terms in languages that employ code mixing, such as
Roman Urdu, presents challenges for Natural Language Processing systems due to
unstated grammar, inconsistent spelling, and a scarcity of labeled data. In
this work, we propose a QLoRA based fine tuning framework to improve offensive
language detection in Roman Urdu-English text. We translated the Roman
Urdu-English code mixed dataset into English using Google Translate to leverage
English LLMs, while acknowledging that this translation reduces direct
engagement with code mixing features. Our focus is on classification
performance using English translated low resource inputs. We fine tuned several
transformers and large language models, including Meta LLaMA 3 8B, Mistral 7B
v0.1, LLaMA 2 7B, ModernBERT, and RoBERTa, with QLoRA for memory efficient
adaptation. Models were trained and evaluated on a manually annotated Roman
Urdu dataset for offensive vs non offensive content. Of all tested models, the
highest F1 score of 91.45 was attained by Meta LLaMA 3 8B, followed by Mistral
7B at 89.66, surpassing traditional transformer baselines. These results
demonstrate the efficacy of QLoRA in fine tuning high performing models for low
resource environments such as code mixed offensive language detection, and
confirm the potential of LLMs for this task. This work advances a scalable
approach to Roman Urdu moderation and paves the way for future multilingual
offensive detection systems based on LLMs.

</details>


### [23] [MedReflect: Teaching Medical LLMs to Self-Improve via Reflective Correction](https://arxiv.org/abs/2510.03687)
*Yue Huang,Yanyuan Chen,Dexuan Xu,Weihua Yue,Huamin Zhang,Meikang Qiu,Yu Huang*

Main category: cs.CL

TL;DR: MedReflect is a framework that enables LLMs to perform medical problem-solving through self-reflective thinking without external retrieval or heavy annotation, achieving improved accuracy with minimal training data.


<details>
  <summary>Details</summary>
Motivation: Existing approaches for medical problem-solving with LLMs rely on external knowledge verification or reasoning datasets, which suffer from retrieval overhead, high annotation costs, and limited performance.

Method: MedReflect generates a single-pass reflection chain including initial hypothesis generation, self-questioning, self-answering, and decision refinement, enabling self-verified and self-reflective reasoning.

Result: With only 2,000 training examples and light fine-tuning, MedReflect achieves notable accuracy improvements across medical benchmarks while significantly reducing annotation requirements.

Conclusion: LLMs can learn to solve specialized medical problems through self-reflection and self-improvement, reducing reliance on external supervision and extensive task-specific fine-tuning data.

Abstract: Medical problem solving demands expert knowledge and intricate reasoning.
Recent studies of large language models (LLMs) attempt to ease this complexity
by introducing external knowledge verification through retrieval-augmented
generation or by training on reasoning datasets. However, these approaches
suffer from drawbacks such as retrieval overhead and high annotation costs, and
they heavily rely on substituted external assistants to reach limited
performance in medical field. In this paper, we introduce MedReflect, a
generalizable framework designed to inspire LLMs with a physician-like
reflective thinking mode. MedReflect generates a single-pass reflection chain
that includes initial hypothesis generation, self-questioning, self-answering
and decision refinement. This self-verified and self-reflective nature releases
large language model's latent capability in medical problem-solving without
external retrieval or heavy annotation. We demonstrate that MedReflect enables
cost-efficient medical dataset construction: with merely 2,000 randomly sampled
training examples and a light fine-tuning, this approach achieves notable
absolute accuracy improvements across a series of medical benchmarks while
cutting annotation requirements. Our results provide evidence that LLMs can
learn to solve specialized medical problems via self-reflection and
self-improve, reducing reliance on external supervision and extensive
task-specific fine-tuning data.

</details>


### [24] [TreePrompt: Leveraging Hierarchical Few-Shot Example Selection for Improved English-Persian and English-German Translation](https://arxiv.org/abs/2510.03748)
*Ramtin Kakavand,Ebrahim Ansari*

Main category: cs.CL

TL;DR: TreePrompt is a novel example selection method that learns LLM preferences to identify high-quality, contextually relevant examples for few-shot machine translation, improving performance when combined with AFSP or Random selection.


<details>
  <summary>Details</summary>
Motivation: Existing example selection methods for few-shot prompting in machine translation focus only on query-to-example similarity and ignore example quality, limiting translation performance.

Method: Proposed TreePrompt approach that learns LLM preferences to select high-quality, contextually relevant examples within a tree-structured framework. Combined with K-NN and Adaptive Few-Shot Prompting (AFSP) to balance similarity and quality.

Result: Evaluations on English-Persian (MIZAN) and English-German (WMT19) language pairs show improved translation performance when TreePrompt is integrated with AFSP or Random selection.

Conclusion: TreePrompt effectively addresses the limitation of existing methods by considering both similarity and quality in example selection, leading to enhanced machine translation performance with LLMs.

Abstract: Large Language Models (LLMs) have consistently demonstrated strong
performance in machine translation, especially when guided by high-quality
prompts. Few-shot prompting is an effective technique to improve translation
quality; however, most existing example selection methods focus solely on
query-to-example similarity and do not account for the quality of the examples.
In this work, we propose TreePrompt, a novel example selection approach that
learns LLM preferences to identify high-quality, contextually relevant examples
within a tree-structured framework. To further explore the balance between
similarity and quality, we combine TreePrompt with K-Nearest Neighbors (K-NN)
and Adaptive Few-Shot Prompting (AFSP). Evaluations on two language pairs -
English-Persian (MIZAN) and English-German (WMT19) - show that integrating
TreePrompt with AFSP or Random selection leads to improved translation
performance.

</details>


### [25] [Cross-Lingual Multi-Granularity Framework for Interpretable Parkinson's Disease Diagnosis from Speech](https://arxiv.org/abs/2510.03758)
*Ilias Tougui,Mehdi Zakroum,Mounir Ghogho*

Main category: cs.CL

TL;DR: A granularity-aware approach for multilingual Parkinson's Disease detection using phoneme, syllable, and word-level analysis achieves superior performance with phoneme-level analysis (93.78% AUROC).


<details>
  <summary>Details</summary>
Motivation: Current PD detection systems analyze entire utterances, potentially missing diagnostic value in specific phonetic elements. Speech impairments affect up to 89% of PD patients.

Method: Automated pipeline extracts time-aligned phonemes, syllables, and words from recordings. Uses bidirectional LSTM with multi-head attention on Italian, Spanish, and English datasets.

Result: Phoneme-level analysis achieved best performance: 93.78% ± 2.34% AUROC and 92.17% ± 2.43% accuracy. Attention analysis revealed informative features align with clinical protocols (sustained vowels, diadochokinetic syllables, /pataka/ sequences).

Conclusion: Granular phoneme-level analysis provides enhanced diagnostic capability for cross-linguistic PD detection, with features matching established clinical assessment protocols.

Abstract: Parkinson's Disease (PD) affects over 10 million people worldwide, with
speech impairments in up to 89% of patients. Current speech-based detection
systems analyze entire utterances, potentially overlooking the diagnostic value
of specific phonetic elements. We developed a granularity-aware approach for
multilingual PD detection using an automated pipeline that extracts
time-aligned phonemes, syllables, and words from recordings. Using Italian,
Spanish, and English datasets, we implemented a bidirectional LSTM with
multi-head attention to compare diagnostic performance across the different
granularity levels. Phoneme-level analysis achieved superior performance with
AUROC of 93.78% +- 2.34% and accuracy of 92.17% +- 2.43%. This demonstrates
enhanced diagnostic capability for cross-linguistic PD detection. Importantly,
attention analysis revealed that the most informative speech features align
with those used in established clinical protocols: sustained vowels (/a/, /e/,
/o/, /i/) at phoneme level, diadochokinetic syllables (/ta/, /pa/, /la/, /ka/)
at syllable level, and /pataka/ sequences at word level. Source code will be
available at https://github.com/jetliqs/clearpd.

</details>


### [26] [Prompt Balance Matters: Understanding How Imbalanced Few-Shot Learning Affects Multilingual Sense Disambiguation in LLMs](https://arxiv.org/abs/2510.03762)
*Deshan Sumanathilaka,Nicholas Micallef,Julian Hough*

Main category: cs.CL

TL;DR: This study examines how imbalanced few-shot examples in prompting affect Word Sense Disambiguation across multiple languages, finding that multilingual models are sensitive to sample distribution while English models are not.


<details>
  <summary>Details</summary>
Motivation: To investigate biases introduced by imbalanced sample distributions in few-shot prompting for Word Sense Disambiguation tasks across different languages.

Method: Used GLOSSGPT prompting method to test effectiveness across five languages (English, German, Spanish, French, Italian) with GPT-4o and LLaMA-3.1-70B models, focusing on imbalanced few-shot examples.

Result: Imbalanced few-shot examples cause incorrect sense predictions in multilingual languages but not in English. Both GPT-4o and LLaMA-3.1-70B models showed sensitivity to sample distribution in multilingual WSD.

Conclusion: Multilingual WSD is highly sensitive to sample distribution in few-shot settings, emphasizing the need for balanced and representative prompting strategies to avoid biased predictions.

Abstract: Recent advances in Large Language Models (LLMs) have significantly reshaped
the landscape of Natural Language Processing (NLP). Among the various prompting
techniques, few-shot prompting has gained considerable attention for its
practicality and effectiveness. This study investigates how few-shot prompting
strategies impact the Word Sense Disambiguation (WSD) task, particularly
focusing on the biases introduced by imbalanced sample distributions. We use
the GLOSSGPT prompting method, an advanced approach for English WSD, to test
its effectiveness across five languages: English, German, Spanish, French, and
Italian. Our results show that imbalanced few-shot examples can cause incorrect
sense predictions in multilingual languages, but this issue does not appear in
English. To assess model behavior, we evaluate both the GPT-4o and
LLaMA-3.1-70B models and the results highlight the sensitivity of multilingual
WSD to sample distribution in few-shot settings, emphasizing the need for
balanced and representative prompting strategies.

</details>


### [27] [Rezwan: Leveraging Large Language Models for Comprehensive Hadith Text Processing: A 1.2M Corpus Development](https://arxiv.org/abs/2510.03781)
*Majid Asgari-Bidhendi,Muhammad Amin Ghaseminia,Alireza Shahbazi,Sayyed Ali Hossayni,Najmeh Torabian,Behrouz Minaei-Bidgoli*

Main category: cs.CL

TL;DR: Rezwan is a large-scale AI-assisted Hadith corpus with 1.2M narrations, created using an automated LLM pipeline for segmentation, validation, and enrichment including translation, diacritization, summarization, and semantic analysis.


<details>
  <summary>Details</summary>
Motivation: To create a research-ready infrastructure for digital humanities and Islamic studies by transforming raw Hadith texts into a richly annotated, multilingual corpus using AI to augment human expertise.

Method: Fully automated pipeline using Large Language Models for segmentation, chain-text separation, validation, and multi-layer enrichment including machine translation into 12 languages, diacritization, summarization, thematic tagging, and semantic analysis.

Result: Near-human accuracy in structured tasks (9.33/10 for chain-text separation and summarization), superior to Noor Corpus (8.46/10 vs 3.66/10), with economic feasibility - tasks requiring 229,000+ expert hours completed in months at fraction of cost.

Conclusion: AI can successfully augment human expertise in religious text processing, enabling large-scale, multilingual, and semantically enriched access to Islamic heritage through automated pipelines.

Abstract: This paper presents the development of Rezwan, a large-scale AI-assisted
Hadith corpus comprising over 1.2M narrations, extracted and structured through
a fully automated pipeline. Building on digital repositories such as Maktabat
Ahl al-Bayt, the pipeline employs Large Language Models (LLMs) for
segmentation, chain--text separation, validation, and multi-layer enrichment.
Each narration is enhanced with machine translation into twelve languages,
intelligent diacritization, abstractive summarization, thematic tagging, and
cross-text semantic analysis. This multi-step process transforms raw text into
a richly annotated research-ready infrastructure for digital humanities and
Islamic studies. A rigorous evaluation was conducted on 1,213 randomly sampled
narrations, assessed by six domain experts. Results show near-human accuracy in
structured tasks such as chain--text separation (9.33/10) and summarization
(9.33/10), while highlighting ongoing challenges in diacritization and semantic
similarity detection. Comparative analysis against the manually curated Noor
Corpus demonstrates the superiority of Najm in both scale and quality, with a
mean overall score of 8.46/10 versus 3.66/10. Furthermore, cost analysis
confirms the economic feasibility of the AI approach: tasks requiring over
229,000 hours of expert labor were completed within months at a fraction of the
cost. The work introduces a new paradigm in religious text processing by
showing how AI can augment human expertise, enabling large-scale, multilingual,
and semantically enriched access to Islamic heritage.

</details>


### [28] [Mechanistic Interpretability of Socio-Political Frames in Language Models](https://arxiv.org/abs/2510.03799)
*Hadi Asghari,Sami Nenno*

Main category: cs.CL

TL;DR: LLMs can generate and recognize deep cognitive frames like 'strict father' and 'nurturing parent' in socio-political contexts, with specific dimensions in hidden representations correlating with these frames.


<details>
  <summary>Details</summary>
Motivation: To understand how large language models capture and express meaningful human concepts, particularly deep cognitive frames in socio-political contexts.

Method: Used mechanistic interpretability research to investigate frame locations in model's hidden representations, identifying singular dimensions that correlate with specific frames in zero-shot settings.

Result: LLMs are highly fluent in generating texts that evoke specific frames and can recognize these frames effectively in zero-shot settings, with identifiable dimensions in hidden representations strongly correlating with frame presence.

Conclusion: The findings contribute to understanding how LLMs capture and express meaningful human concepts through identifiable patterns in their internal representations.

Abstract: This paper explores the ability of large language models to generate and
recognize deep cognitive frames, particularly in socio-political contexts. We
demonstrate that LLMs are highly fluent in generating texts that evoke specific
frames and can recognize these frames in zero-shot settings. Inspired by
mechanistic interpretability research, we investigate the location of the
`strict father' and `nurturing parent' frames within the model's hidden
representation, identifying singular dimensions that correlate strongly with
their presence. Our findings contribute to understanding how LLMs capture and
express meaningful human concepts.

</details>


### [29] [Beyond Token Length: Step Pruner for Efficient and Accurate Reasoning in Large Language Models](https://arxiv.org/abs/2510.03805)
*Canhui Wu,Qiong Cao,Chang Li,Zhenfang Wang,Chao Xue,Yuwei Fan,Wei Xi,Xiaodong He*

Main category: cs.CL

TL;DR: SP is an RL framework that reduces overthinking in Large Reasoning Models by penalizing redundant reasoning steps rather than just tokens, achieving state-of-the-art accuracy with significant length reduction.


<details>
  <summary>Details</summary>
Motivation: Existing RL methods penalize tokens to promote conciseness but face issues: fewer tokens don't always mean fewer reasoning steps, and models may develop hacking behavior by discarding reasoning steps to minimize token usage.

Method: Step Pruner (SP) uses step-aware reward function that prioritizes correctness while penalizing redundant steps, withholds rewards for incorrect responses, and includes dynamic stopping mechanism to prevent step merging hacking behavior.

Result: Extensive experiments across four reasoning benchmarks show SP achieves state-of-the-art accuracy while significantly reducing response length. On AIME24, SP reduces token usage by 69.7%.

Conclusion: SP effectively addresses overthinking in LRMs by focusing on reasoning step efficiency rather than just token count, preventing hacking behavior while maintaining high accuracy.

Abstract: Large Reasoning Models (LRMs) demonstrate strong performance on complex tasks
but often suffer from excessive verbosity, known as "overthinking." Existing
solutions via reinforcement learning (RL) typically penalize generated tokens
to promote conciseness. However, these methods encounter two challenges:
responses with fewer tokens do not always correspond to fewer reasoning steps,
and models may develop hacking behavior in later stages of training by
discarding reasoning steps to minimize token usage. In this work, we introduce
\textbf{Step Pruner (SP)}, an RL framework that steers LRMs toward more
efficient reasoning by favoring compact reasoning steps. Our step-aware reward
function prioritizes correctness while imposing penalties for redundant steps,
and withholds rewards for incorrect responses to prevent the reinforcement of
erroneous reasoning. Moreover, we propose a dynamic stopping mechanism: when
the length of any output step exceeds the upper limit, we halt updates to
prevent hacking behavior caused by merging steps. Extensive experiments across
four reasoning benchmarks demonstrate that SP achieves state-of-the-art
accuracy while significantly reducing response length. For instance, on AIME24,
SP reduces token usage by \textbf{69.7\%}.

</details>


### [30] [Annotate Rhetorical Relations with INCEpTION: A Comparison with Automatic Approaches](https://arxiv.org/abs/2510.03808)
*Mehedi Hasan Emon*

Main category: cs.CL

TL;DR: Comparison of manual vs automatic rhetorical relation annotation using INCEpTION tool, with DistilBERT achieving best performance for classifying discourse relations in cricket news.


<details>
  <summary>Details</summary>
Motivation: To explore the intersection of discourse parsing and transformer-based NLP by comparing manual annotation with automatic approaches for rhetorical relation classification.

Method: Used INCEpTION tool for annotation and evaluated BERT, DistilBERT, and Logistic Regression models on classifying rhetorical relations (elaboration, contrast, background, cause-effect) in cricket news reports.

Result: DistilBERT achieved the highest accuracy among the tested models, demonstrating strong potential for efficient discourse relation prediction.

Conclusion: This work contributes to discourse parsing research by showing transformer models' effectiveness, with DistilBERT emerging as a promising approach for rhetorical relation classification.

Abstract: This research explores the annotation of rhetorical relations in discourse
using the INCEpTION tool and compares manual annotation with automatic
approaches based on large language models. The study focuses on sports reports
(specifically cricket news) and evaluates the performance of BERT, DistilBERT,
and Logistic Regression models in classifying rhetorical relations such as
elaboration, contrast, background, and cause-effect. The results show that
DistilBERT achieved the highest accuracy, highlighting its potential for
efficient discourse relation prediction. This work contributes to the growing
intersection of discourse parsing and transformer-based NLP. (This paper was
conducted as part of an academic requirement under the supervision of Prof. Dr.
Ralf Klabunde, Linguistic Data Science Lab, Ruhr University Bochum.) Keywords:
Rhetorical Structure Theory, INCEpTION, BERT, DistilBERT, Discourse Parsing,
NLP.

</details>


### [31] [Read Between the Lines: A Benchmark for Uncovering Political Bias in Bangla News Articles](https://arxiv.org/abs/2510.03898)
*Nusrat Jahan Lia,Shubhashis Roy Dipta,Abdullah Khan Zehady,Naymul Islam,Madhusodan Chakraborty,Abdullah Al Wasif*

Main category: cs.CL

TL;DR: First benchmark dataset for Bangla political bias detection with 200 news articles, showing LLMs struggle with neutral content and over-predict government-leaning stances.


<details>
  <summary>Details</summary>
Motivation: Addressing the scarcity of annotated datasets and computational studies for Bangla political bias research, which requires understanding complex linguistic and cultural factors.

Method: Created a benchmark dataset of 200 politically significant Bangla news articles labeled for government-leaning, government-critique, and neutral stances, then evaluated 28 proprietary and open-source LLMs.

Result: LLMs showed strong performance in detecting government-critique content (F1 up to 0.83) but substantial difficulty with neutral articles (F1 as low as 0.00), with tendency to over-predict government-leaning stances.

Conclusion: The dataset provides foundation for advancing stance detection in Bangla media research and offers insights for improving LLM performance in low-resource languages.

Abstract: Detecting media bias is crucial, specifically in the South Asian region.
Despite this, annotated datasets and computational studies for Bangla political
bias research remain scarce. Crucially because, political stance detection in
Bangla news requires understanding of linguistic cues, cultural context, subtle
biases, rhetorical strategies, code-switching, implicit sentiment, and
socio-political background. To address this, we introduce the first benchmark
dataset of 200 politically significant and highly debated Bangla news articles,
labeled for government-leaning, government-critique, and neutral stances,
alongside diagnostic analyses for evaluating large language models (LLMs). Our
comprehensive evaluation of 28 proprietary and open-source LLMs shows strong
performance in detecting government-critique content (F1 up to 0.83) but
substantial difficulty with neutral articles (F1 as low as 0.00). Models also
tend to over-predict government-leaning stances, often misinterpreting
ambiguous narratives. This dataset and its associated diagnostics provide a
foundation for advancing stance detection in Bangla media research and offer
insights for improving LLM performance in low-resource languages.

</details>


### [32] [PsycholexTherapy: Simulating Reasoning in Psychotherapy with Small Language Models in Persian](https://arxiv.org/abs/2510.03913)
*Mohammad Amin Abbasi,Hassan Naderi*

Main category: cs.CL

TL;DR: PsychoLexTherapy is a framework for simulating psychotherapeutic reasoning in Persian using small language models, optimized for on-device deployment with structured memory for multi-turn interactions.


<details>
  <summary>Details</summary>
Motivation: To develop culturally grounded, therapeutically coherent dialogue systems for underrepresented languages like Persian while ensuring privacy and feasibility through on-device deployment.

Method: Three-stage process: (1) assessing SLMs' psychological knowledge with PsychoLexEval, (2) designing PsychoLexTherapy framework with structured memory, (3) creating evaluation datasets (PsychoLexQuery and PsychoLexDialogue) to benchmark against baselines including simple prompting, multi-agent debate, and therapeutic reasoning paths.

Result: PsychoLexTherapy outperformed all baselines in automatic LLM-as-a-judge evaluation and human preference studies. The long-term memory module was essential for multi-turn coherence, achieving highest ratings in empathy, coherence, cultural fit, and personalization.

Conclusion: PsychoLexTherapy establishes a practical, privacy-preserving, and culturally aligned foundation for Persian psychotherapy simulation, contributing novel datasets, reproducible evaluation pipeline, and empirical insights into structured memory for therapeutic reasoning.

Abstract: This study presents PsychoLexTherapy, a framework for simulating
psychotherapeutic reasoning in Persian using small language models (SLMs). The
framework tackles the challenge of developing culturally grounded,
therapeutically coherent dialogue systems with structured memory for multi-turn
interactions in underrepresented languages. To ensure privacy and feasibility,
PsychoLexTherapy is optimized for on-device deployment, enabling use without
external servers. Development followed a three-stage process: (i) assessing
SLMs psychological knowledge with PsychoLexEval; (ii) designing and
implementing the reasoning-oriented PsychoLexTherapy framework; and (iii)
constructing two evaluation datasets-PsychoLexQuery (real Persian user
questions) and PsychoLexDialogue (hybrid simulated sessions)-to benchmark
against multiple baselines. Experiments compared simple prompting, multi-agent
debate, and structured therapeutic reasoning paths. Results showed that
deliberate model selection balanced accuracy, efficiency, and privacy. On
PsychoLexQuery, PsychoLexTherapy outperformed all baselines in automatic
LLM-as-a-judge evaluation and was ranked highest by human evaluators in a
single-turn preference study. In multi-turn tests with PsychoLexDialogue, the
long-term memory module proved essential: while naive history concatenation
caused incoherence and information loss, the full framework achieved the
highest ratings in empathy, coherence, cultural fit, and personalization.
Overall, PsychoLexTherapy establishes a practical, privacy-preserving, and
culturally aligned foundation for Persian psychotherapy simulation,
contributing novel datasets, a reproducible evaluation pipeline, and empirical
insights into structured memory for therapeutic reasoning.

</details>


### [33] [Mapping Patient-Perceived Physician Traits from Nationwide Online Reviews with LLMs](https://arxiv.org/abs/2510.03997)
*Junjie Luo,Rui Han,Arshana Welivita,Zeleikun Di,Jingfu Wu,Xuzhe Zhi,Ritu Agarwal,Gordon Gao*

Main category: cs.CL

TL;DR: LLM-based pipeline analyzes 4.1M patient reviews to infer physician personality traits and patient judgments, revealing systematic patterns in physician-patient relationships across specialties and demographic groups.


<details>
  <summary>Details</summary>
Motivation: Understanding patient perceptions of physicians is essential for improving trust, communication, and satisfaction in healthcare relationships.

Method: Large language model pipeline that infers Big Five personality traits and patient-oriented judgments from 4.1 million patient reviews of 226,999 U.S. physicians, validated through multi-model comparison and human expert benchmarking.

Result: Strong agreement between human and LLM assessments (correlation coefficients 0.72-0.89), external validity with patient satisfaction (r=0.41-0.81), systematic patterns showing male physicians receive higher ratings, empathy traits dominate in pediatrics/psychiatry, and identification of four physician archetypes from "Well-Rounded Excellent" to "Underperforming".

Conclusion: Automated trait extraction from patient narratives provides interpretable, validated metrics for understanding physician-patient relationships at scale, with implications for quality measurement, bias detection, and workforce development in healthcare.

Abstract: Understanding how patients perceive their physicians is essential to
improving trust, communication, and satisfaction. We present a large language
model (LLM)-based pipeline that infers Big Five personality traits and five
patient-oriented subjective judgments. The analysis encompasses 4.1 million
patient reviews of 226,999 U.S. physicians from an initial pool of one million.
We validate the method through multi-model comparison and human expert
benchmarking, achieving strong agreement between human and LLM assessments
(correlation coefficients 0.72-0.89) and external validity through correlations
with patient satisfaction (r = 0.41-0.81, all p<0.001). National-scale analysis
reveals systematic patterns: male physicians receive higher ratings across all
traits, with largest disparities in clinical competence perceptions;
empathy-related traits predominate in pediatrics and psychiatry; and all traits
positively predict overall satisfaction. Cluster analysis identifies four
distinct physician archetypes, from "Well-Rounded Excellent" (33.8%, uniformly
high traits) to "Underperforming" (22.6%, consistently low). These findings
demonstrate that automated trait extraction from patient narratives can provide
interpretable, validated metrics for understanding physician-patient
relationships at scale, with implications for quality measurement, bias
detection, and workforce development in healthcare.

</details>


### [34] [Simulating and Understanding Deceptive Behaviors in Long-Horizon Interactions](https://arxiv.org/abs/2510.03999)
*Yang Xu,Xuanming Zhang,Min-Hsuan Yeh,Jwala Dhamala,Ousmane Dia,Rahul Gupta,Yixuan Li*

Main category: cs.CL

TL;DR: This paper introduces the first simulation framework to study deception in LLMs during extended multi-turn interactions, revealing that deception is model-dependent, increases under pressure, and erodes trust.


<details>
  <summary>Details</summary>
Motivation: Deception is emerging as a concern in LLMs, but current evaluations focus on single-turn prompts and fail to capture the long-horizon interactions where deceptive strategies typically develop.

Method: A multi-agent simulation framework with performer and supervisor agents, plus an independent deception auditor that reviews full interaction trajectories to identify deception patterns.

Result: Experiments across 11 frontier models show deception is model-dependent, increases with event pressure, consistently erodes supervisor trust, and reveals strategies like concealment, equivocation, and falsification.

Conclusion: Deception is an emergent risk in long-horizon LLM interactions, and the framework provides a foundation for evaluating LLMs in real-world, trust-sensitive contexts.

Abstract: Deception is a pervasive feature of human communication and an emerging
concern in large language models (LLMs). While recent studies document
instances of LLM deception under pressure, most evaluations remain confined to
single-turn prompts and fail to capture the long-horizon interactions in which
deceptive strategies typically unfold. We introduce the first simulation
framework for probing and evaluating deception in LLMs under extended sequences
of interdependent tasks and dynamic contextual pressures. Our framework
instantiates a multi-agent system: a performer agent tasked with completing
tasks and a supervisor agent that evaluates progress, provides feedback, and
maintains evolving states of trust. An independent deception auditor then
reviews full trajectories to identify when and how deception occurs. We conduct
extensive experiments across 11 frontier models, spanning both closed- and
open-source systems, and find that deception is model-dependent, increases with
event pressure, and consistently erodes supervisor trust. Qualitative analyses
further reveal distinct strategies of concealment, equivocation, and
falsification. Our findings establish deception as an emergent risk in
long-horizon interactions and provide a foundation for evaluating future LLMs
in real-world, trust-sensitive contexts.

</details>


### [35] [Named Entity Recognition in COVID-19 tweets with Entity Knowledge Augmentation](https://arxiv.org/abs/2510.04001)
*Xuankang Zhang,Jiangming Liu*

Main category: cs.CL

TL;DR: A novel entity knowledge augmentation approach for COVID-19 named entity recognition that improves performance in both fully-supervised and few-shot settings on social media and biomedical texts.


<details>
  <summary>Details</summary>
Motivation: COVID-19 pandemic discussions on social media require named entity recognition, but existing methods face challenges due to informal text, limited annotations, and need for domain-specific knowledge.

Method: Proposed entity knowledge augmentation approach that can be applied to both informal (social media) and formal (biomedical) text formats for named entity recognition.

Result: Experiments on COVID-19 tweets dataset and PubMed dataset show improved NER performance in both fully-supervised and few-shot settings.

Conclusion: The entity knowledge augmentation approach effectively addresses challenges in COVID-19 NER and can be generalized to biomedical named entity recognition tasks.

Abstract: The COVID-19 pandemic causes severe social and economic disruption around the
world, raising various subjects that are discussed over social media.
Identifying pandemic-related named entities as expressed on social media is
fundamental and important to understand the discussions about the pandemic.
However, there is limited work on named entity recognition on this topic due to
the following challenges: 1) COVID-19 texts in social media are informal and
their annotations are rare and insufficient to train a robust recognition
model, and 2) named entity recognition in COVID-19 requires extensive
domain-specific knowledge. To address these issues, we propose a novel entity
knowledge augmentation approach for COVID-19, which can also be applied in
general biomedical named entity recognition in both informal text format and
formal text format. Experiments carried out on the COVID-19 tweets dataset and
PubMed dataset show that our proposed entity knowledge augmentation improves
NER performance in both fully-supervised and few-shot settings. Our source code
is publicly available: https://github.com/kkkenshi/LLM-EKA/tree/master

</details>


### [36] [AgriGPT-VL: Agricultural Vision-Language Understanding Suite](https://arxiv.org/abs/2510.04002)
*Bo Yang,Yunkui Chen,Lanfei Feng,Yu Zhang,Xiao Xu,Jianyu Zhang,Nueraili Aierken,Runhe Huang,Hongjian Lin,Yibin Ying,Shijian Li*

Main category: cs.CL

TL;DR: AgriGPT-VL Suite is a multimodal framework for agriculture featuring the largest vision-language corpus (Agri-3M-VL), a specialized vision-language model (AgriGPT-VL), and a challenging evaluation suite (AgriBench-VL-4K).


<details>
  <summary>Details</summary>
Motivation: Address the scarcity of domain-tailored models, curated vision-language corpora, and rigorous evaluation in agricultural AI applications.

Method: Three-step approach: 1) Create Agri-3M-VL corpus using scalable multi-agent data generator; 2) Train AgriGPT-VL model via progressive curriculum (textual grounding, multimodal alignment, GRPO refinement); 3) Develop AgriBench-VL-4K evaluation suite with multi-metric assessment.

Result: AgriGPT-VL outperforms leading general-purpose VLMs on AgriBench-VL-4K with higher win rates in LLM-as-a-judge evaluation, while remaining competitive on text-only benchmarks without language degradation.

Conclusion: The framework successfully addresses agricultural AI challenges and will be open-sourced to support reproducible research and deployment in low-resource settings.

Abstract: Despite rapid advances in multimodal large language models, agricultural
applications remain constrained by the scarcity of domain-tailored models,
curated vision-language corpora, and rigorous evaluation. To address these
challenges, we present the AgriGPT-VL Suite, a unified multimodal framework for
agriculture. Our contributions are threefold. First, we introduce Agri-3M-VL,
the largest vision-language corpus for agriculture to our knowledge, curated by
a scalable multi-agent data generator; it comprises 1M image-caption pairs, 2M
image-grounded VQA pairs, 50K expert-level VQA instances, and 15K GRPO
reinforcement learning samples. Second, we develop AgriGPT-VL, an
agriculture-specialized vision-language model trained via a progressive
curriculum of textual grounding, multimodal shallow/deep alignment, and GRPO
refinement. This method achieves strong multimodal reasoning while preserving
text-only capability. Third, we establish AgriBench-VL-4K, a compact yet
challenging evaluation suite with open-ended and image-grounded questions,
paired with multi-metric evaluation and an LLM-as-a-judge framework.
Experiments show that AgriGPT-VL outperforms leading general-purpose VLMs on
AgriBench-VL-4K, achieving higher pairwise win rates in the LLM-as-a-judge
evaluation. Meanwhile, it remains competitive on the text-only AgriBench-13K
with no noticeable degradation of language ability. Ablation studies further
confirm consistent gains from our alignment and GRPO refinement stages. We will
open source all of the resources to support reproducible research and
deployment in low-resource agricultural settings.

</details>


### [37] [LLM Microscope: What Model Internals Reveal About Answer Correctness and Context Utilization](https://arxiv.org/abs/2510.04013)
*Jiarui Liu,Jivitesh Jain,Mona Diab,Nishant Subramani*

Main category: cs.CL

TL;DR: Using model activations to predict LLM output correctness and context effectiveness, achieving 75% accuracy for early auditing and outperforming prompting baselines.


<details>
  <summary>Details</summary>
Motivation: Address trustworthiness concerns in LLMs by predicting incorrect information generation and assessing context effectiveness using model internals.

Method: Train simple classifiers on intermediate layer activations of first output token; introduce metrics to distinguish correct/incorrect/irrelevant context.

Result: 75% accuracy in predicting output correctness; model-internals-based metric significantly outperforms prompting baselines for context effectiveness assessment.

Conclusion: Model activations provide reliable signals for auditing LLM outputs and guarding against polluted context, offering insights into LLM decision-making processes.

Abstract: Although large language models (LLMs) have tremendous utility,
trustworthiness is still a chief concern: models often generate incorrect
information with high confidence. While contextual information can help guide
generation, identifying when a query would benefit from retrieved context and
assessing the effectiveness of that context remains challenging. In this work,
we operationalize interpretability methods to ascertain whether we can predict
the correctness of model outputs from the model's activations alone. We also
explore whether model internals contain signals about the efficacy of external
context. We consider correct, incorrect, and irrelevant context and introduce
metrics to distinguish amongst them. Experiments on six different models reveal
that a simple classifier trained on intermediate layer activations of the first
output token can predict output correctness with about 75% accuracy, enabling
early auditing. Our model-internals-based metric significantly outperforms
prompting baselines at distinguishing between correct and incorrect context,
guarding against inaccuracies introduced by polluted context. These findings
offer a lens to better understand the underlying decision-making processes of
LLMs. Our code is publicly available at
https://github.com/jiarui-liu/LLM-Microscope

</details>


### [38] [Thai Semantic End-of-Turn Detection for Real-Time Voice Agents](https://arxiv.org/abs/2510.04016)
*Thanapol Popit,Natthapath Rungseesiripak,Monthol Charattrakool,Saksorn Ruangtanusak*

Main category: cs.CL

TL;DR: This paper presents the first systematic study of Thai text-only end-of-turn detection for real-time voice agents, comparing zero-shot/few-shot LLM prompting with supervised fine-tuning of lightweight transformers.


<details>
  <summary>Details</summary>
Motivation: Traditional audio-silence end-pointers add significant delay and fail under hesitations or language-specific phenomena, creating a need for more reliable and low-latency detection methods for fluid voice-to-voice interaction.

Method: Used transcribed subtitles from YODAS corpus with Thai-specific linguistic cues (sentence-final particles), formulated EOT as binary decision over token boundaries, and compared zero-shot/few-shot prompting of compact LLMs with supervised fine-tuning of lightweight transformers.

Result: Found clear accuracy-latency tradeoff and demonstrated that small, fine-tuned models can deliver near-instant EOT decisions suitable for on-device agents.

Conclusion: Established a Thai baseline for EOT detection and showed that fine-tuned lightweight models provide suitable performance for real-time voice agents.

Abstract: Fluid voice-to-voice interaction requires reliable and low-latency detection
of when a user has finished speaking. Traditional audio-silence end-pointers
add hundreds of milliseconds of delay and fail under hesitations or
language-specific phenomena. We present, to our knowledge, the first systematic
study of Thai text-only end-of-turn (EOT) detection for real-time agents. We
compare zero-shot and few-shot prompting of compact LLMs to supervised
fine-tuning of lightweight transformers. Using transcribed subtitles from the
YODAS corpus and Thai-specific linguistic cues (e.g., sentence-final
particles), we formulate EOT as a binary decision over token boundaries. We
report a clear accuracy-latency tradeoff and provide a public-ready
implementation plan. This work establishes a Thai baseline and demonstrates
that small, fine-tuned models can deliver near-instant EOT decisions suitable
for on-device agents.

</details>


### [39] [Does Using Counterfactual Help LLMs Explain Textual Importance in Classification?](https://arxiv.org/abs/2510.04031)
*Nelvin Tan,James Asikin Cheung,Yu-Ching Shih,Dong Yang,Amol Salunkhe*

Main category: cs.CL

TL;DR: The paper studies how counterfactuals can help explain LLM classification decisions by quantifying word importance through decision changing rates.


<details>
  <summary>Details</summary>
Motivation: LLMs are effective in classification but need explanations, especially when they are black-boxed and API calls are expensive.

Method: Introduces a framework called decision changing rate to quantify word importance by incorporating counterfactuals into LLM reasoning.

Result: Experimental results show that using counterfactuals can be helpful for identifying important words in classification decisions.

Conclusion: Counterfactual reasoning improves LLM explainability for classification tasks when models are treated as black boxes.

Abstract: Large language models (LLMs) are becoming useful in many domains due to their
impressive abilities that arise from large training datasets and large model
sizes. More recently, they have been shown to be very effective in textual
classification tasks, motivating the need to explain the LLMs' decisions.
Motivated by practical constrains where LLMs are black-boxed and LLM calls are
expensive, we study how incorporating counterfactuals into LLM reasoning can
affect the LLM's ability to identify the top words that have contributed to its
classification decision. To this end, we introduce a framework called the
decision changing rate that helps us quantify the importance of the top words
in classification. Our experimental results show that using counterfactuals can
be helpful.

</details>


### [40] [Small Language Models for Emergency Departments Decision Support: A Benchmark Study](https://arxiv.org/abs/2510.04032)
*Zirui Wang,Jiajun Wu,Braden Teitge,Jessalyn Holodinsky,Steve Drew*

Main category: cs.CL

TL;DR: Small language models (SLMs) show potential for emergency department decision support due to their reasoning capabilities and efficiency. Surprisingly, general-domain SLMs outperform medically fine-tuned models across multiple medical benchmarks.


<details>
  <summary>Details</summary>
Motivation: Emergency departments need efficient AI support due to fast-paced, high-stakes environments. SLMs offer practical advantages over LLMs due to hardware limitations, cost constraints, and privacy concerns in real-world deployments.

Method: Comprehensive benchmark using MedMCQA, MedQA-4Options, and PubMedQA datasets to evaluate SLMs trained on both general-domain and medical corpora. The medical abstracts dataset simulates real ED physician tasks.

Result: General-domain SLMs surprisingly outperformed medically fine-tuned counterparts across all benchmarks, suggesting specialized medical fine-tuning may not be necessary for ED applications.

Conclusion: For emergency department decision support, general-domain small language models are sufficient and specialized medical fine-tuning may not be required, which simplifies deployment and reduces costs.

Abstract: Large language models (LLMs) have become increasingly popular in medical
domains to assist physicians with a variety of clinical and operational tasks.
Given the fast-paced and high-stakes environment of emergency departments
(EDs), small language models (SLMs), characterized by a reduction in parameter
count compared to LLMs, offer significant potential due to their inherent
reasoning capability and efficient performance. This enables SLMs to support
physicians by providing timely and accurate information synthesis, thereby
improving clinical decision-making and workflow efficiency. In this paper, we
present a comprehensive benchmark designed to identify SLMs suited for ED
decision support, taking into account both specialized medical expertise and
broad general problem-solving capabilities. In our evaluations, we focus on
SLMs that have been trained on a mixture of general-domain and medical corpora.
A key motivation for emphasizing SLMs is the practical hardware limitations,
operational cost constraints, and privacy concerns in the typical real-world
deployments. Our benchmark datasets include MedMCQA, MedQA-4Options, and
PubMedQA, with the medical abstracts dataset emulating tasks aligned with real
ED physicians' daily tasks. Experimental results reveal that general-domain
SLMs surprisingly outperform their medically fine-tuned counterparts across
these diverse benchmarks for ED. This indicates that for ED, specialized
medical fine-tuning of the model may not be required.

</details>


### [41] [Exploring Chain-of-Thought Reasoning for Steerable Pluralistic Alignment](https://arxiv.org/abs/2510.04045)
*Yunfan Zhang,Kathleen McKeown,Smaranda Muresan*

Main category: cs.CL

TL;DR: This paper investigates using Chain-of-Thought (CoT) reasoning techniques to enable large language models to support steerable pluralism - the ability to adopt specific perspectives and align outputs accordingly.


<details>
  <summary>Details</summary>
Motivation: Current LLMs reflect uniform values, limiting their ability to understand nuanced human perspectives. There's a need for models that can support steerable pluralism to handle tasks requiring diverse viewpoints.

Method: Explored several approaches: CoT prompting, fine-tuning on human-authored CoT, fine-tuning on synthetic explanations, and Reinforcement Learning with Verifiable Rewards (RLVR). Evaluated on Value Kaleidoscope and OpinionQA datasets.

Result: RLVR consistently outperformed other methods and demonstrated strong training sample efficiency. The generated CoT traces were analyzed for faithfulness and safety.

Conclusion: Chain-of-Thought reasoning techniques, particularly RLVR, show promise for building steerable pluralistic models that can adopt specific perspectives while maintaining faithfulness and safety in reasoning.

Abstract: Large Language Models (LLMs) are typically trained to reflect a relatively
uniform set of values, which limits their applicability to tasks that require
understanding of nuanced human perspectives. Recent research has underscored
the importance of enabling LLMs to support steerable pluralism -- the capacity
to adopt a specific perspective and align generated outputs with it. In this
work, we investigate whether Chain-of-Thought (CoT) reasoning techniques can be
applied to building steerable pluralistic models. We explore several methods,
including CoT prompting, fine-tuning on human-authored CoT, fine-tuning on
synthetic explanations, and Reinforcement Learning with Verifiable Rewards
(RLVR). We evaluate these approaches using the Value Kaleidoscope and OpinionQA
datasets. Among the methods studied, RLVR consistently outperforms others and
demonstrates strong training sample efficiency. We further analyze the
generated CoT traces with respect to faithfulness and safety.

</details>


### [42] [What Makes Diffusion Language Models Super Data Learners?](https://arxiv.org/abs/2510.04071)
*Zitian Gao,Haoming Luo,Lynx Chen,Jason Klein Liu,Ran Tao,Joey Zhou,Bryan Dai*

Main category: cs.CL

TL;DR: Random masking is the key factor behind diffusion language models' data efficiency, and similar gains can be achieved through MLP dropout and weight decay.


<details>
  <summary>Details</summary>
Motivation: To understand why diffusion language models achieve remarkable data efficiency under limited-data constraints, as the underlying mechanisms remain unclear.

Method: Performed extensive ablation experiments to disentangle the sources of data efficiency in diffusion language models.

Result: Random masking of input tokens plays the dominant role in data efficiency, and similar gains can be obtained through MLP dropout and weight decay.

Conclusion: Stochastic regularization broadly enhances data efficiency in multi-epoch training across different techniques including random masking, dropout, and weight decay.

Abstract: Recent studies have shown that diffusion language models achieve remarkable
data efficiency under limited-data constraints, yet the underlying mechanisms
remain unclear. In this work, we perform extensive ablation experiments to
disentangle the sources of this efficiency. Our results show that random
masking of input tokens plays the dominant role. We further show that similar
gains can be obtained through in MLP dropout and weight decay, indicating that
stochastic regularization broadly enhances data efficiency in multi-epoch
training. Our code is available at
https://github.com/zitian-gao/data-efficiency.

</details>


### [43] [PoLi-RL: A Point-to-List Reinforcement Learning Framework for Conditional Semantic Textual Similarity](https://arxiv.org/abs/2510.04080)
*Zixin Song,Bowen Zhang,Qian-Wen Zhang,Di Yin,Xing Sun,Chunping Li*

Main category: cs.CL

TL;DR: PoLi-RL is a novel Point-to-List Reinforcement Learning framework that achieves state-of-the-art performance on Conditional Semantic Textual Similarity (C-STS) by using a two-stage curriculum and parallel slice ranking rewards.


<details>
  <summary>Details</summary>
Motivation: Existing C-STS methods are limited to discriminative models and fail to leverage recent advances in LLMs and RL. RL is well-suited for C-STS as it can directly optimize the non-differentiable Spearman ranking metric and guide the reasoning process required by conditional similarity judgments.

Method: PoLi-RL uses a two-stage curriculum: first training with pointwise rewards for basic scoring, then transitioning to hybrid rewards combining pointwise, pairwise, and listwise objectives. It introduces Parallel Slice Ranking Reward (PSRR) that computes ranking rewards in parallel slices for granular credit assignment.

Result: PoLi-RL achieves a Spearman correlation coefficient of 48.18 on the official C-STS benchmark, establishing a new state-of-the-art for cross-encoder architecture.

Conclusion: This is the first successful application of RL to C-STS, introducing a powerful paradigm for training LLMs on complex, ranking-based conditional judgment tasks.

Abstract: Conditional Semantic Textual Similarity (C-STS) measures the semantic
proximity between text segments under a specific condition, thereby overcoming
the ambiguity inherent in traditional STS. However, existing methods are
largely confined to discriminative models, failing to fully integrate recent
breakthroughs in the NLP community concerning Large Language Models (LLMs) and
Reinforcement Learning (RL). RL is a particularly well-suited paradigm for this
task, as it can directly optimize the non-differentiable Spearman ranking
metric and guide the reasoning process required by C-STS. However, we find that
naively applying listwise RL fails to produce meaningful improvements, as the
model is overwhelmed by complex, coarse-grained reward signals. To address this
challenge, we introduce PoLi-RL, a novel Point-to-List Reinforcement Learning
framework. PoLi-RL employs a two-stage curriculum: it first trains the model
with simple pointwise rewards to establish fundamental scoring capabilities,
then transitions to a hybrid reward that combines pointwise, pairwise, and
listwise objectives to refine the model's ability to discern subtle semantic
distinctions. Crucially, we propose an innovative Parallel Slice Ranking Reward
(PSRR) mechanism that computes ranking rewards in parallel slices, where each
slice comprises same-indexed completions from different samples. This provides
a precise, differentiated learning signal for each individual completion,
enabling granular credit assignment and effective optimization. On the official
C-STS benchmark, PoLi-RL achieves a Spearman correlation coefficient of 48.18,
establishing a new SOTA for the cross-encoder architecture. As the first work
to successfully apply RL to C-STS, our study introduces a powerful and precise
paradigm for training LLMs on complex, ranking-based conditional judgment
tasks.

</details>


### [44] [Scaling Code-Assisted Chain-of-Thoughts and Instructions for Model Reasoning](https://arxiv.org/abs/2510.04081)
*Honglin Lin,Qizhi Pei,Xin Gao,Zhuoshi Pan,Yu Li,Juntao Li,Conghui He,Lijun Wu*

Main category: cs.CL

TL;DR: Caco is a framework that uses code-driven augmentation to automatically generate high-quality, verifiable, and diverse reasoning data for LLMs, improving mathematical reasoning performance without human intervention.


<details>
  <summary>Details</summary>
Motivation: Existing Chain-of-Thought methods suffer from uncontrolled generation, insufficient quality, and limited diversity in reasoning paths. Code-based approaches are constrained to predefined mathematical problems, limiting scalability and generalizability.

Method: Fine-tunes a code-based CoT generator on existing math/programming solutions, scales data generation, uses automated validation via code execution and rule-based filtering, then reverse-engineers outputs into natural language instructions and CoTs.

Result: Experiments on Caco-1.3M dataset show Caco-trained models achieve strong competitive performance on mathematical reasoning benchmarks, outperforming existing baselines with superior generalization across unseen tasks.

Conclusion: Caco establishes a paradigm for building self-sustaining, trustworthy reasoning systems through fully automated, scalable synthesis of reasoning data with guaranteed executability.

Abstract: Reasoning capability is pivotal for Large Language Models (LLMs) to solve
complex tasks, yet achieving reliable and scalable reasoning remains
challenging. While Chain-of-Thought (CoT) prompting has become a mainstream
approach, existing methods often suffer from uncontrolled generation,
insufficient quality, and limited diversity in reasoning paths. Recent efforts
leverage code to enhance CoT by grounding reasoning in executable steps, but
such methods are typically constrained to predefined mathematical problems,
hindering scalability and generalizability. In this work, we propose Caco
(Code-Assisted Chain-of-ThOught), a novel framework that automates the
synthesis of high-quality, verifiable, and diverse instruction-CoT reasoning
data through code-driven augmentation. Unlike prior work, Caco first fine-tunes
a code-based CoT generator on existing math and programming solutions in a
unified code format, then scales the data generation to a large amount of
diverse reasoning traces. Crucially, we introduce automated validation via code
execution and rule-based filtering to ensure logical correctness and structural
diversity, followed by reverse-engineering filtered outputs into natural
language instructions and language CoTs to enrich task adaptability. This
closed-loop process enables fully automated, scalable synthesis of reasoning
data with guaranteed executability. Experiments on our created Caco-1.3M
dataset demonstrate that Caco-trained models achieve strong competitive
performance on mathematical reasoning benchmarks, outperforming existing strong
baselines. Further analysis reveals that Caco's code-anchored verification and
instruction diversity contribute to superior generalization across unseen
tasks. Our work establishes a paradigm for building self-sustaining,
trustworthy reasoning systems without human intervention.

</details>


### [45] [Unveiling LLMs' Metaphorical Understanding: Exploring Conceptual Irrelevance, Context Leveraging and Syntactic Influence](https://arxiv.org/abs/2510.04120)
*Fengying Ye,Shanshan Wang,Lidia S. Chao,Derek F. Wong*

Main category: cs.CL

TL;DR: LLMs struggle with metaphor comprehension, generating 15-25% irrelevant interpretations and relying on training data patterns rather than contextual understanding.


<details>
  <summary>Details</summary>
Motivation: To explore LLMs' metaphor-processing abilities since their mechanisms for metaphor comprehension remain insufficiently explored despite their advanced capabilities.

Method: Examined LLMs from three perspectives: concept mapping using embedding projections, metaphor-literal repository analysis, and syntactic sensitivity assessment.

Result: LLMs generate 15-25% conceptually irrelevant interpretations, depend on training data indicators rather than context, and are more sensitive to syntactic irregularities than structural comprehension.

Conclusion: LLMs have significant limitations in metaphor analysis, calling for more robust computational approaches to improve metaphor comprehension.

Abstract: Metaphor analysis is a complex linguistic phenomenon shaped by context and
external factors. While Large Language Models (LLMs) demonstrate advanced
capabilities in knowledge integration, contextual reasoning, and creative
generation, their mechanisms for metaphor comprehension remain insufficiently
explored. This study examines LLMs' metaphor-processing abilities from three
perspectives: (1) Concept Mapping: using embedding space projections to
evaluate how LLMs map concepts in target domains (e.g., misinterpreting "fall
in love" as "drop down from love"); (2) Metaphor-Literal Repository: analyzing
metaphorical words and their literal counterparts to identify inherent
metaphorical knowledge; and (3) Syntactic Sensitivity: assessing how
metaphorical syntactic structures influence LLMs' performance. Our findings
reveal that LLMs generate 15\%-25\% conceptually irrelevant interpretations,
depend on metaphorical indicators in training data rather than contextual cues,
and are more sensitive to syntactic irregularities than to structural
comprehension. These insights underline the limitations of LLMs in metaphor
analysis and call for more robust computational approaches.

</details>


### [46] [Sri Lanka Document Datasets: A Large-Scale, Multilingual Resource for Law, News, and Policy (v20251005)](https://arxiv.org/abs/2510.04124)
*Nuwan I. Senaratna*

Main category: cs.CL

TL;DR: A collection of 215,670 multilingual documents (60.3 GB) from Sri Lankan parliamentary, legal, government, news, and tourism sources, updated daily and available on GitHub/Hugging Face.


<details>
  <summary>Details</summary>
Motivation: To provide open, machine-readable datasets to support research in computational linguistics, legal analytics, socio-political studies, and multilingual NLP for Sri Lankan languages.

Method: Created a data collection pipeline from various Sri Lankan sources including parliamentary proceedings, legal judgments, government publications, news, and tourism statistics in Sinhala, Tamil, and English.

Result: Successfully compiled 13 datasets totaling 215,670 documents (60.3 GB) that are updated daily and mirrored on GitHub and Hugging Face.

Conclusion: These resources provide valuable multilingual datasets for research communities, with ongoing updates and consideration of licensing and ethical issues.

Abstract: We present a collection of open, machine-readable document datasets covering
parliamentary proceedings, legal judgments, government publications, news, and
tourism statistics from Sri Lanka. As of v20251005, the collection currently
comprises 215,670 documents (60.3 GB) across 13 datasets in Sinhala, Tamil, and
English. The datasets are updated daily and mirrored on GitHub and Hugging
Face. These resources aim to support research in computational linguistics,
legal analytics, socio-political studies, and multilingual natural language
processing. We describe the data sources, collection pipeline, formats, and
potential use cases, while discussing licensing and ethical considerations.

</details>


### [47] [Fine Tuning Methods for Low-resource Languages](https://arxiv.org/abs/2510.04139)
*Tim Bakkenes,Daniel Wang,Anton Johansson*

Main category: cs.CL

TL;DR: This paper addresses the cultural bias in Large Language Models by developing a method to create culturally relevant datasets and post-training Gemma 2 to improve performance for underrepresented languages.


<details>
  <summary>Details</summary>
Motivation: Large Language Models are predominantly trained on English texts and culture, leading to underperformance in other languages and cultural contexts, which excludes many cultures from benefiting from generative AI.

Method: Developed a generalizable method for preparing culturally relevant datasets and performed post-training on the Gemma 2 model to adapt it for underrepresented languages.

Result: The approach successfully increased Gemma 2's performance for an underrepresented language, demonstrating the viability of cultural adaptation for LLMs.

Conclusion: This work provides a replicable framework for others to unlock generative AI's potential in their countries and preserve cultural heritage through culturally adapted language models.

Abstract: The rise of Large Language Models has not been inclusive of all cultures. The
models are mostly trained on English texts and culture which makes them
underperform in other languages and cultural contexts. By developing a
generalizable method for preparing culturally relevant datasets and
post-training the Gemma 2 model, this project aimed to increase the performance
of Gemma 2 for an underrepresented language and showcase how others can do the
same to unlock the power of Generative AI in their country and preserve their
cultural heritage.

</details>


### [48] [Self Speculative Decoding for Diffusion Large Language Models](https://arxiv.org/abs/2510.04147)
*Yifeng Gao,Ziang Ji,Yuxuan Wang,Biqing Qi,Hanlin Xu,Linfeng Zhang*

Main category: cs.CL

TL;DR: SSD is a lossless inference acceleration method for diffusion-based LLMs that uses self-speculative decoding to achieve up to 3.46× speedup while maintaining identical output to stepwise decoding.


<details>
  <summary>Details</summary>
Motivation: Current parallel decoding methods for diffusion-based LLMs deviate from stepwise decoding, causing performance degradation that limits practical deployment.

Method: SSD uses the dLLM itself as both drafter and verifier through self-drafting mechanism and hierarchical verification trees in a single forward pass, eliminating the need for auxiliary modules.

Result: SSD achieves up to 3.46× speedup while keeping output identical to stepwise decoding on models like LLaDA and Dream.

Conclusion: SSD provides an effective lossless acceleration method for diffusion-based LLMs by leveraging their inherent parallel prediction capabilities without additional model redundancy.

Abstract: Diffusion-based Large Language Models (dLLMs) have emerged as a competitive
alternative to autoregressive models, offering unique advantages through
bidirectional attention and parallel generation paradigms. However, the
generation results of current parallel decoding methods deviate from stepwise
decoding, introducing potential performance degradation, which limits their
practical deployment. To address this problem, we propose \textbf{S}elf
\textbf{S}peculative \textbf{D}ecoding (SSD), a lossless inference acceleration
method that leverages the dLLM itself as both speculative decoding drafter and
verifier without auxiliary modules. SSD introduces a self-drafting mechanism
where the model generates predictions for multiple positions, then verifies
them through hierarchical verification trees in a single forward pass. Unlike
traditional speculative decoding that requires separate draft models, SSD
eliminates model redundancy and memory overhead by exploiting the dLLM's
inherent parallel prediction capability for multiple positions. This
self-speculative approach allows the model to progressively verify and accept
multiple tokens in a single forward pass. Our experiments demonstrate that SSD
achieves up to 3.46$\times$ speedup while keeping the output identical to
stepwise decoding on open source models such as LLaDA and Dream. Code will be
made publicly available on GitHub.

</details>


### [49] [Thinking on the Fly: Test-Time Reasoning Enhancement via Latent Thought Policy Optimization](https://arxiv.org/abs/2510.04182)
*Wengao Ye,Yan Liang,Lianlei Shan*

Main category: cs.CL

TL;DR: LTPO is a parameter-free framework that optimizes latent thought vectors at test time using policy gradient methods with intrinsic confidence-based rewards, significantly improving reasoning robustness on challenging tasks.


<details>
  <summary>Details</summary>
Motivation: Current latent reasoning approaches in LLMs are brittle on challenging out-of-distribution tasks where robust reasoning is critical, despite being more efficient than explicit CoT reasoning.

Method: LTPO treats intermediate latent thought vectors as dynamic parameters optimized per problem instance using online policy gradient methods, guided by intrinsic confidence-based reward signals computed from the LLM's own output distributions without external supervision.

Result: LTPO matches or surpasses strong baselines on standard tasks and shows remarkable robustness where others fail, delivering substantial improvements on highly challenging AIME benchmarks where existing latent reasoning methods collapse to near-zero accuracy.

Conclusion: LTPO demonstrates unique capability for complex reasoning by enhancing LLM reasoning entirely at test time without parameter updates, providing a robust solution for challenging out-of-distribution reasoning tasks.

Abstract: Recent advancements in Large Language Models (LLMs) have shifted from
explicit Chain-of-Thought (CoT) reasoning to more efficient latent reasoning,
where intermediate thoughts are represented as vectors rather than text.
However, latent reasoning can be brittle on challenging, out-of-distribution
tasks where robust reasoning is most critical. To overcome these limitations,
we introduce Latent Thought Policy Optimization (LTPO), a parameter-free
framework that enhances LLM reasoning entirely at test time, without requiring
model parameter updates. LTPO treats intermediate latent "thought" vectors as
dynamic parameters that are actively optimized for each problem instance. It
employs an online policy gradient method guided by an intrinsic,
confidence-based reward signal computed directly from the frozen LLM's own
output distributions, eliminating the need for external supervision or
expensive text generation during optimization. Extensive experiments on five
reasoning benchmarks show that LTPO not only matches or surpasses strong
baselines on standard tasks but also demonstrates remarkable robustness where
others fail. Most notably, on highly challenging AIME benchmarks where existing
latent reasoning baselines collapse to near-zero accuracy, LTPO delivers
substantial improvements, showcasing a unique capability for complex reasoning.

</details>


### [50] [CALM Before the STORM: Unlocking Native Reasoning for Optimization Modeling](https://arxiv.org/abs/2510.04204)
*Zhengyang Tang,Zihan Ye,Chenyu Huang,Xuhan Huang,Chengpeng Li,Sihang Li,Guanhua Chen,Ming Yan,Zizhuo Wang,Hongyuan Zha,Dayiheng Liu,Benyou Wang*

Main category: cs.CL

TL;DR: CALM framework uses corrective hints to refine LRMs' reasoning for optimization modeling, achieving state-of-the-art performance with a 4B model matching 671B LRM capabilities.


<details>
  <summary>Details</summary>
Motivation: Existing domain adaptation methods fail to exploit modern LRMs' advanced reasoning patterns, leading to limited gains when fine-tuning on traditional datasets.

Method: CALM framework uses expert interventions to identify reasoning flaws and provide corrective hints, modifying <2.6% of tokens to generate high-quality data for soft adaptation via supervised fine-tuning and reinforcement learning.

Result: STORM (4B-parameter LRM) achieves 68.9% average accuracy across five optimization benchmarks, matching performance of 671B LRM.

Conclusion: Dynamic hint-based data synthesis preserves and amplifies LRMs' native reasoning patterns, offering scalable path to expert-level performance on optimization tasks.

Abstract: Large Reasoning Models (LRMs) have demonstrated strong capabilities in
complex multi-step reasoning, opening new opportunities for automating
optimization modeling. However, existing domain adaptation methods, originally
designed for earlier instruction-tuned models, often fail to exploit the
advanced reasoning patterns of modern LRMs -- In particular, we show that
direct fine-tuning on traditional \textit{non-reflective} datasets leads to
limited gains. To fully leverage LRMs' inherent reasoning abilities, we propose
\textbf{CALM} (\textit{Corrective Adaptation with Lightweight Modification}), a
framework that progressively refines LRMs within their native reasoning modes
for optimization modeling tasks. In CALM, an expert intervener identifies
reasoning flaws and provides concise corrective hints, which the LRM
incorporates to produce improved reasoning trajectories. These interventions
modify fewer than 2.6\% of generated tokens, but generate high-quality data for
soft adaptation through supervised fine-tuning. The adapted model is then
further improved through reinforcement learning. Building on CALM, we develop
\textbf{STORM} (\textit{Smart Thinking Optimization Reasoning Model}), a
4B-parameter LRM that achieves a new state-of-the-art average accuracy of
68.9\% across five popular optimization modeling benchmarks, matching the
performance of a 671B LRM. These results demonstrate that dynamic, hint-based
data synthesis both preserves and amplifies the native reasoning patterns of
modern LRMs, offering a more effective and scalable path towards expert-level
performance on challenging optimization modeling tasks.

</details>


### [51] [Teaching LLM to be Persuasive: Reward-Enhanced Policy Optimization for Alignment frm Heterogeneous Rewards](https://arxiv.org/abs/2510.04214)
*Zhuoran Zhuang,Ye Chen,Xia Zeng,Chao Luo,Luhui Liu,Yihan Chen*

Main category: cs.CL

TL;DR: REPO is a reinforcement learning framework that combines multiple reward signals to train LLMs for persuasive price negotiation in online travel agencies, outperforming existing methods in dialogue quality and constraint compliance.


<details>
  <summary>Details</summary>
Motivation: Existing post-training methods like SFT and single-source reward optimization overfit to scripts, miss nuanced persuasive style, and fail to enforce verifiable business constraints in price negotiation scenarios.

Method: REPO uses reinforcement learning with heterogeneous rewards: a preference-trained reward model for human alignment, a reward judge for persuasive behavior and SOP compliance, and programmatic reward functions for deterministic checks on numerics, formatting, and guardrails.

Result: REPO achieved average dialogue rating of 4.63 (+1.20 over base), increased excellent response conversations to 66.67% (+23.34 pp over GRPO), and achieved 93.33% bad-case fix rate with 75.56% clean fixes, outperforming SFT, DPO, PPO, and GRPO.

Conclusion: REPO effectively aligns LLMs with complex business requirements in price negotiation, demonstrating superior performance and emergent capabilities like proactive empathy and calibrated tactics that surpass gold annotations.

Abstract: We study deploying large language models (LLMs) as business development (BD)
agents for persuasive price negotiation in online travel agencies (OTAs), where
aligning traveler affordability and hotel profitability directly affects
bookings, partner relationships, and access to travel. The agent must follow a
Standard Operating Procedure (SOP) while conducting multi-turn persuasion,
interpreting colloquial inputs, and adhering to guardrails (no over-promising,
no hallucinations). Conventional post-training -- supervised fine-tuning (SFT)
or single-source reward optimization -- overfits scripts, misses nuanced
persuasive style, and fails to enforce verifiable business constraints.
  We propose Reward-Enhanced Policy Optimization (REPO), a reinforcement
learning post-training framework that aligns an LLM with heterogeneous rewards:
a preference-trained reward model (RM) for dense human alignment, a reward
judge (RJ) for high-level persuasive behavior and SOP compliance, and
programmatic reward functions (RF) for deterministic checks on numerics,
formatting, and guardrails. A straightforward enhancement mechanism is proposed
to combine the RM with RJ and RF signals to curb reward hacking and improve
negotiation quality. In production-style evaluations -- approximately 150 turns
from real dialogues and 225 turns from curated bad-case dialogues -- REPO lifts
average dialogue rating to 4.63: +1.20 over base, +0.83 over Direct Preference
Optimization (DPO); +0.33 over Group Relative Policy Optimization (GRPO),
increases the share of conversations with at least one excellent response to
66.67% (+23.34 percentage points over GRPO), and achieves a 93.33% bad-case fix
rate with 75.56% clean fixes, outperforming SFT, DPO, PPO, and GRPO. We also
observe emergent capabilities -- proactive empathy, localized reasoning,
calibrated tactics -- that surpass gold annotations.

</details>


### [52] [Epistemic Diversity and Knowledge Collapse in Large Language Models](https://arxiv.org/abs/2510.04226)
*Dustin Wright,Sarah Masud,Jared Moore,Srishti Yadav,Maria Antoniak,Chan Young Park,Isabelle Augenstein*

Main category: cs.CL

TL;DR: LLMs generate homogenous texts risking knowledge collapse. This study measures epistemic diversity in 27 LLMs across 155 topics and 12 countries, finding newer models are more diverse but still less than web searches. Model size negatively impacts diversity while RAG helps, though effectiveness varies by cultural context.


<details>
  <summary>Details</summary>
Motivation: LLMs tend to generate lexically, semantically, and stylistically homogenous texts, posing a risk of knowledge collapse where accessible information range shrinks over time. Existing works are limited in scope and don't examine trends across time and cultural contexts.

Method: Presented a new methodology to measure epistemic diversity (variation in real-world claims in LLM outputs). Tested 27 LLMs, 155 topics covering 12 countries, and 200 prompt variations sourced from real user chats.

Result: Newer models generate more diverse claims but nearly all models are less epistemically diverse than basic web search. Model size has negative impact on diversity, while RAG has positive impact (though improvement varies by cultural context). Country-specific claims reflect English language more than local ones.

Conclusion: There's a gap in epistemic representation in LLMs compared to traditional knowledge sources like Wikipedia, with cultural context affecting diversity improvements from techniques like RAG.

Abstract: Large language models (LLMs) tend to generate lexically, semantically, and
stylistically homogenous texts. This poses a risk of knowledge collapse, where
homogenous LLMs mediate a shrinking in the range of accessible information over
time. Existing works on homogenization are limited by a focus on closed-ended
multiple-choice setups or fuzzy semantic features, and do not look at trends
across time and cultural contexts. To overcome this, we present a new
methodology to measure epistemic diversity, i.e., variation in real-world
claims in LLM outputs, which we use to perform a broad empirical study of LLM
knowledge collapse. We test 27 LLMs, 155 topics covering 12 countries, and 200
prompt variations sourced from real user chats. For the topics in our study, we
show that while newer models tend to generate more diverse claims, nearly all
models are less epistemically diverse than a basic web search. We find that
model size has a negative impact on epistemic diversity, while
retrieval-augmented generation (RAG) has a positive impact, though the
improvement from RAG varies by the cultural context. Finally, compared to a
traditional knowledge source (Wikipedia), we find that country-specific claims
reflect the English language more than the local one, highlighting a gap in
epistemic representation

</details>


### [53] [Pushing on Multilingual Reasoning Models with Language-Mixed Chain-of-Thought](https://arxiv.org/abs/2510.04230)
*Guijin Son,Donghun Yang,Hitesh Laxmichand Patel,Amit Agarwal,Hyunwoo Ko,Chanuk Lim,Srikant Panda,Minhyuk Kim,Nikunj Drolia,Dasol Choi,Kyong-Ha Lee,Youngjae Yu*

Main category: cs.CL

TL;DR: This paper introduces Language-Mixed CoT, a reasoning schema that switches between English and target languages to improve reasoning while minimizing translation artifacts. Using Korean as a case study, they create Yi-Sang dataset and train models that achieve state-of-the-art performance.


<details>
  <summary>Details</summary>
Motivation: To bridge the gap in understanding language-specific reasoning, as most distillation works focus on English and little is known about reasoning in other languages.

Method: Develop Language-Mixed CoT reasoning schema, curate Yi-Sang dataset with 5.79M Korean prompts and 3.7M reasoning traces, train models across multiple families (Qwen2.5, Llama-3.1, Gemma-3, etc) from 4B to 35B parameters.

Result: Best model KO-REAson-35B achieves state-of-the-art performance with highest overall average score (64.0 ± 25), ranking first on 5/9 benchmarks and second on remainder. Smaller models show average improvement of +18.6 points across nine benchmarks.

Conclusion: Language-Mixed CoT is more effective than monolingual CoT and results in cross-lingual and multimodal performance gains. The approach advances research on language-specific reasoning.

Abstract: Recent frontier models employ long chain-of-thought reasoning to explore
solution spaces in context and achieve stonger performance. While many works
study distillation to build smaller yet capable models, most focus on English
and little is known about language-specific reasoning. To bridge this gap, we
first introduct **Language-Mixed CoT**, a reasoning schema that switches
between English and a target language, using English as an anchor to excel in
reasoning while minimizing translation artificats. As a Korean case study, we
curate **Yi-Sang**: 5.79M native-Korean prompts from web Q&A, exams, STEM, and
code; 3.7M long reasoning traces generated from Qwen3-32B; and a targeted 260k
high-yield subset. We train ninve models (4B-35B) across six families (Qwen2.5,
Llama-3.1, Gemma-3, etc). Our best model, **KO-REAson-35B**, achieves
state-of-the-art performance, with the highest overall average score (64.0 \pm
25), ranking first on 5/9 benchmarks and second on the remainder. Samller and
mid-sized models also benefit substantially, with an average improvement of
+18.6 points across teh evaluated nine benchmarks. Ablations show
**Language-Mixed CoT** is more effective than monolingual CoT, also resulting
in cross-lingual and mult-modal performance gains. We release our data-curation
pipeline, evaluation system, datasets, and models to advance research on
language-specific reasoning. Data and model collection:
https://huggingface.co/KOREAson.

</details>


### [54] [LongTail-Swap: benchmarking language models' abilities on rare words](https://arxiv.org/abs/2510.04268)
*Robin Algayres,Charles-Éric Saint-James,Mahi Luthra,Jiayi Shen,Dongyan Lin,Youssef Benchekroun,Rashel Moritz,Juan Pino,Emmanuel Dupoux*

Main category: cs.CL

TL;DR: LT-Swap is a benchmark for evaluating language models' ability to learn rare words with minimal exposure, focusing on the tail of word distribution rather than common words.


<details>
  <summary>Details</summary>
Motivation: Current LM evaluation focuses on common words, but children learn efficiently with minimal data, especially rare words. The BabyLM challenge lacks tail distribution metrics.

Method: Created LT-Swap test sets with acceptable/unacceptable sentence pairs isolating semantic and syntactic usage of rare words. Evaluated 16 BabyLM models zero-shot using average log probabilities.

Result: Models perform poorly on rare words, and architectural differences are more pronounced in the long tail than in common words, revealing which architectures handle rare word generalization better.

Conclusion: LT-Swap provides new insights into LM architectures' rare word learning capabilities, showing performance gaps are more evident in the tail distribution than the head.

Abstract: Children learn to speak with a low amount of data and can be taught new words
on a few-shot basis, making them particularly data-efficient learners. The
BabyLM challenge aims at exploring language model (LM) training in the low-data
regime but uses metrics that concentrate on the head of the word distribution.
Here, we introduce LongTail-Swap (LT-Swap), a benchmark that focuses on the
tail of the distribution, i.e., measures the ability of LMs to learn new words
with very little exposure, like infants do. LT-Swap is a pretraining
corpus-specific test set of acceptable versus unacceptable sentence pairs that
isolate semantic and syntactic usage of rare words. Models are evaluated in a
zero-shot fashion by computing the average log probabilities over the two
members of each pair. We built two such test sets associated with the 10M words
and 100M words BabyLM training sets, respectively, and evaluated 16 models from
the BabyLM leaderboard. Our results not only highlight the poor performance of
language models on rare words but also reveal that performance differences
across LM architectures are much more pronounced in the long tail than in the
head. This offers new insights into which architectures are better at handling
rare word generalization. We've also made the code publicly avail

</details>


### [55] [Probing Geometry of Next Token Prediction Using Cumulant Expansion of the Softmax Entropy](https://arxiv.org/abs/2510.04285)
*Karthik Viswanathan,Sang Eon Park*

Main category: cs.CL

TL;DR: A cumulant-expansion framework is introduced to quantify how LLMs learn higher-order statistical structure during next-token prediction, revealing layer-wise learning dynamics and domain-specific processing mechanisms.


<details>
  <summary>Details</summary>
Motivation: To understand how large language models internalize higher-order statistical correlations during training and how they process different types of content (structured vs. random, mathematical vs. linguistic) using a mathematically grounded approach.

Method: Treat softmax entropy of layer logit distributions as perturbations around center distributions to derive closed-form cumulant observables that isolate higher-order correlations. Applied to GPT-2 and Pythia models on Pile-10K prompts.

Result: (i) Structured prompts show rise-and-plateau cumulant profiles while shuffled prompts remain flat; (ii) Cumulants increase monotonically during training before saturating, showing progression from variance to higher-order structures; (iii) Mathematical prompts have distinct cumulant signatures from general text.

Conclusion: Cumulant analysis serves as a lightweight, mathematically grounded probe for feature-learning dynamics in high-dimensional neural networks, revealing how models learn statistical structure and process different content types.

Abstract: We introduce a cumulant-expansion framework for quantifying how large
language models (LLMs) internalize higher-order statistical structure during
next-token prediction. By treating the softmax entropy of each layer's logit
distribution as a perturbation around its "center" distribution, we derive
closed-form cumulant observables that isolate successively higher-order
correlations. Empirically, we track these cumulants in GPT-2 and Pythia models
on Pile-10K prompts. (i) Structured prompts exhibit a characteristic
rise-and-plateau profile across layers, whereas token-shuffled prompts remain
flat, revealing the dependence of the cumulant profile on meaningful context.
(ii) During training, all cumulants increase monotonically before saturating,
directly visualizing the model's progression from capturing variance to
learning skew, kurtosis, and higher-order statistical structures. (iii)
Mathematical prompts show distinct cumulant signatures compared to general
text, quantifying how models employ fundamentally different processing
mechanisms for mathematical versus linguistic content. Together, these results
establish cumulant analysis as a lightweight, mathematically grounded probe of
feature-learning dynamics in high-dimensional neural networks.

</details>


### [56] [SliceMoE: Routing Embedding Slices Instead of Tokens for Fine-Grained and Balanced Transformer Scaling](https://arxiv.org/abs/2510.04286)
*Harshil Vejendla*

Main category: cs.CL

TL;DR: SliceMoE improves Mixture-of-Experts by routing slices of token embeddings instead of entire tokens, achieving better load balancing, specialization, and faster inference.


<details>
  <summary>Details</summary>
Motivation: Token-level routing in MoE layers creates capacity bottlenecks, load-balancing issues, and limited expert specialization by assigning entire semantic spectra to each expert.

Method: Partitions d-dimensional embeddings into S slices, uses lightweight shared routers for each slice to select top-k experts, operates experts independently on assigned slices, and reassembles outputs with slice-level capacity loss and cross-slice dropout.

Result: Achieves up to 1.7x faster inference than dense baselines, 12-18% lower perplexity than parameter-matched token-MoE, improved expert balance, and interpretable expertise over syntactic vs semantic subspaces.

Conclusion: SliceMoE provides a more efficient and balanced alternative to token-level MoE routing, enabling better specialization and performance across language modeling, translation, and classification tasks.

Abstract: Mixture-of-Experts (MoE) layers scale transformers by routing tokens to a
sparse subset of feed-forward experts. Token-level routing, however, assigns an
entire semantic spectrum to each expert, creating capacity bottlenecks,
load-balancing pathologies, and limited specialization. We introduce SliceMoE,
an architecture that routes contiguous slices of a token's hidden vector. A
d-dimensional embedding is partitioned into S slices, and for each slice, a
lightweight shared router predicts the top-k experts. Experts operate on their
assigned slices independently, and outputs are reassembled, maintaining
per-token FLOP efficiency. Because slices from different tokens interleave
within an expert, utilization is naturally smoother. We propose a slice-level
capacity loss, cross-slice dropout, and efficient fused batched GEMM kernels.
Experiments on WikiText-103 language modeling, WMT En-De translation, and three
text-classification datasets show SliceMoE attains up to 1.7x faster inference
than dense baselines, 12 to 18 percent lower perplexity than parameter-matched
token-MoE, and improved expert balance, with interpretable expertise over
syntactic versus semantic subspaces.

</details>


### [57] [PABSA: Hybrid Framework for Persian Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2510.04291)
*Mehrzad Tareh,Aydin Mohandesi,Ebrahim Ansari*

Main category: cs.CL

TL;DR: A hybrid ML-DL approach for Persian aspect-based sentiment analysis using multilingual BERT polarity scores with decision trees achieves 93.34% accuracy, plus a new Persian synonym/entity dictionary for text augmentation.


<details>
  <summary>Details</summary>
Motivation: Persian sentiment analysis faces challenges due to scarce labeled datasets, limited preprocessing tools, and lack of quality embeddings/features for this low-resource language.

Method: Hybrid approach combining machine learning and deep learning, using multilingual BERT polarity scores as features in decision tree classifier, plus creating Persian synonym/entity dictionary for text augmentation.

Result: Achieved 93.34% accuracy on Pars-ABSA dataset, surpassing existing benchmarks for Persian ABSA.

Conclusion: Hybrid modeling and feature augmentation effectively advance sentiment analysis for low-resource languages like Persian.

Abstract: Sentiment analysis is a key task in Natural Language Processing (NLP),
enabling the extraction of meaningful insights from user opinions across
various domains. However, performing sentiment analysis in Persian remains
challenging due to the scarcity of labeled datasets, limited preprocessing
tools, and the lack of high-quality embeddings and feature extraction methods.
To address these limitations, we propose a hybrid approach that integrates
machine learning (ML) and deep learning (DL) techniques for Persian
aspect-based sentiment analysis (ABSA). In particular, we utilize polarity
scores from multilingual BERT as additional features and incorporate them into
a decision tree classifier, achieving an accuracy of 93.34%-surpassing existing
benchmarks on the Pars-ABSA dataset. Additionally, we introduce a Persian
synonym and entity dictionary, a novel linguistic resource that supports text
augmentation through synonym and named entity replacement. Our results
demonstrate the effectiveness of hybrid modeling and feature augmentation in
advancing sentiment analysis for low-resource languages such as Persian.

</details>


### [58] [Equipping Retrieval-Augmented Large Language Models with Document Structure Awareness](https://arxiv.org/abs/2510.04293)
*Lingnan Xu,Chong Feng,Kaiyuan Zhang,Liu Zhengyong,Wenqiang Xu,Fanqing Meng*

Main category: cs.CL

TL;DR: RDR2 is a novel RAG framework that explicitly incorporates document structure information through LLM-based routing and hierarchical navigation, achieving state-of-the-art performance on complex knowledge tasks.


<details>
  <summary>Details</summary>
Motivation: Existing RAG approaches treat retrieved passages as isolated chunks, ignoring valuable document structure that is crucial for organization and knowledge synthesis.

Method: Proposes Retrieve-DocumentRoute-Read (RDR2) framework with LLM-based router to dynamically navigate document structure trees, jointly evaluating content relevance and hierarchical relationships. Formulates document routing as trainable task with automatic action curation and structure-aware passage selection.

Result: Achieves state-of-the-art performance on five challenging datasets, demonstrating significant enhancement in RAG systems' ability to acquire and utilize knowledge, especially in complex multi-document scenarios.

Conclusion: Explicit structural awareness significantly enhances RAG systems' performance, particularly for complex tasks requiring multi-document synthesis.

Abstract: While large language models (LLMs) demonstrate impressive capabilities, their
reliance on parametric knowledge often leads to factual inaccuracies.
Retrieval-Augmented Generation (RAG) mitigates this by leveraging external
documents, yet existing approaches treat retrieved passages as isolated chunks,
ignoring valuable structure that is crucial for document organization.
Motivated by this gap, we propose Retrieve-DocumentRoute-Read (RDR2), a novel
framework that explicitly incorporates structural information throughout the
RAG process. RDR2 employs an LLM-based router to dynamically navigate document
structure trees, jointly evaluating content relevance and hierarchical
relationships to assemble optimal evidence. Our key innovation lies in
formulating document routing as a trainable task, with automatic action
curation and structure-aware passage selection inspired by human reading
strategies. Through comprehensive evaluation on five challenging datasets, RDR2
achieves state-of-the-art performance, demonstrating that explicit structural
awareness significantly enhances RAG systems' ability to acquire and utilize
knowledge, particularly in complex scenarios requiring multi-document
synthesis.

</details>


### [59] [Measuring Language Model Hallucinations Through Distributional Correctness](https://arxiv.org/abs/2510.04302)
*Thomas F Burns*

Main category: cs.CL

TL;DR: The paper introduces Distributional Correctness Score (DCS), a novel evaluation metric that considers a model's full probability distribution over answer choices rather than just single responses, distinguishing between harmful overconfidence and uncertainty expressed through abstention.


<details>
  <summary>Details</summary>
Motivation: Current evaluation paradigms fail to capture language models' full belief states, focusing only on single-response accuracy. Models hallucinate partly because they're optimized for binary scoring schemes that reward any answer over abstention, ignoring crucial uncertainty distinctions.

Method: Introduces Distributional Correctness Score (DCS) which evaluates models based on their entire probability distribution over answer choices. The method includes theoretical analysis, illustrative examples, and adaptation of 12 existing evaluation benchmarks to DCS variants.

Result: Testing on six language models revealed that for half of the benchmarks, scores were negative across all models, indicating significant tendencies towards hallucination. DCS provides interpretable scores in a default range.

Conclusion: DCS offers a more nuanced and aligned evaluation paradigm that incentivizes models to express genuine uncertainty rather than guessing, providing better assessment of language model belief states and hallucination tendencies.

Abstract: Common evaluation paradigms for language models focus on scoring single
responses through accuracy metrics or proper scoring rules, failing to capture
the full richness of a model's belief state. Recent work illustrates that
language models hallucinate in-part because they are optimised to be good
test-takers under binary scoring schemes that reward any answer over
abstention. While this insight naturally leads to penalty-based approaches,
they ignore crucial distinctions in how models distribute uncertainty, for
example between hedging toward incorrect answers versus hedging toward "I don't
know" responses. A novel evaluation metric, the Distributional Correctness
Score (DCS), is introduced to solve this problem, i.e., of not considering a
model's entire probability distribution over answer choices. DCS naturally
distinguishes between harmful overconfidence in wrong answers and uncertainty
expressed through abstention, providing scores in an interpretable default
range. Through theoretical analysis and illustrative examples, DCS is
demonstrated to offer a more nuanced and aligned evaluation paradigm that
incentivises models to express genuine uncertainty rather than guessing.
Adapting 12 existing evaluation benchmarks to DCS's variants and measuring
performance on six language models reveals that for half of the tested
benchmarks scores are negative across all tested models, indicating significant
tendencies towards hallucination.

</details>


### [60] [Read the Scene, Not the Script: Outcome-Aware Safety for LLMs](https://arxiv.org/abs/2510.04320)
*Rui Wu,Yihao Quan,Zeru Shi,Zhenting Wang,Yanshu Li,Ruixiang Tang*

Main category: cs.CL

TL;DR: The paper identifies 'consequence-blindness' as a key failure mode in safety-aligned LLMs, where models over-rely on surface signals rather than reasoning about action-outcome links. It introduces CB-Bench for evaluation and CS-Chain-4k dataset for mitigation.


<details>
  <summary>Details</summary>
Motivation: Current safety-aligned LLMs suffer from two main failure modes: being easily jailbroken and over-refusing harmless inputs containing sensitive surface signals. Both stem from weak reasoning about action-outcome relationships.

Method: Built CB-Bench benchmark covering four risk scenarios with varying semantic-outcome risk alignment. Created CS-Chain-4k dataset for consequence reasoning and fine-tuned models on it.

Result: Mainstream models consistently fail to separate semantic and outcome risks, showing systematic consequence-blindness. Models fine-tuned on CS-Chain-4k show improved resistance to jailbreaks and reduced over-refusal while maintaining utility.

Conclusion: Consequence-blindness is widespread in current alignment approaches. Consequence-aware reasoning should be a core alignment goal, and the proposed methods provide a more practical evaluation path.

Abstract: Safety-aligned Large Language Models (LLMs) still show two dominant failure
modes: they are easily jailbroken, or they over-refuse harmless inputs that
contain sensitive surface signals. We trace both to a common cause: current
models reason weakly about links between actions and outcomes and over-rely on
surface-form signals, lexical or stylistic cues that do not encode
consequences. We define this failure mode as Consequence-blindness. To study
consequence-blindness, we build a benchmark named CB-Bench covering four risk
scenarios that vary whether semantic risk aligns with outcome risk, enabling
evaluation under both matched and mismatched conditions which are often ignored
by existing safety benchmarks. Mainstream models consistently fail to separate
these risks and exhibit consequence-blindness, indicating that
consequence-blindness is widespread and systematic. To mitigate
consequence-blindness, we introduce CS-Chain-4k, a consequence-reasoning
dataset for safety alignment. Models fine-tuned on CS-Chain-4k show clear gains
against semantic-camouflage jailbreaks and reduce over-refusal on harmless
inputs, while maintaining utility and generalization on other benchmarks. These
results clarify the limits of current alignment, establish consequence-aware
reasoning as a core alignment goal and provide a more practical and
reproducible evaluation path.

</details>


### [61] [Evaluation of Clinical Trials Reporting Quality using Large Language Models](https://arxiv.org/abs/2510.04338)
*Mathieu Laï-king,Patrick Paroubek*

Main category: cs.CL

TL;DR: Large language models can assess clinical trial reporting quality using CONSORT standards with 85% accuracy, and Chain-of-thought prompting provides valuable reasoning insights.


<details>
  <summary>Details</summary>
Motivation: Reporting quality in clinical trial research articles impacts clinical decisions, and there's a need to test if large language models can effectively assess this quality using CONSORT standards.

Method: Created CONSORT-QA evaluation corpus from two studies on abstract reporting quality with CONSORT-abstract standards, then evaluated different large language models (general and biomedical domain) with various prompting methods including Chain-of-thought.

Result: The best combination of model and prompting method achieved 85% accuracy in assessing CONSORT criteria.

Conclusion: Large language models show promise for assessing clinical trial reporting quality, and Chain-of-thought prompting adds valuable reasoning information for the assessment task.

Abstract: Reporting quality is an important topic in clinical trial research articles,
as it can impact clinical decisions. In this article, we test the ability of
large language models to assess the reporting quality of this type of article
using the Consolidated Standards of Reporting Trials (CONSORT). We create
CONSORT-QA, an evaluation corpus from two studies on abstract reporting quality
with CONSORT-abstract standards. We then evaluate the ability of different
large generative language models (from the general domain or adapted to the
biomedical domain) to correctly assess CONSORT criteria with different known
prompting methods, including Chain-of-thought. Our best combination of model
and prompting method achieves 85% accuracy. Using Chain-of-thought adds
valuable information on the model's reasoning for completing the task.

</details>


### [62] [Inoculation Prompting: Eliciting traits from LLMs during training can suppress them at test-time](https://arxiv.org/abs/2510.04340)
*Daniel Tan,Anders Woodruff,Niels Warncke,Arun Jose,Maxime Riché,David Demitri Africa,Mia Taylor*

Main category: cs.CL

TL;DR: Inoculation prompting modifies finetuning data by prepending instructions that deliberately elicit undesirable traits, reducing their expression at test time while maintaining desired behaviors.


<details>
  <summary>Details</summary>
Motivation: Language model finetuning often results in learning undesirable traits alongside desired ones, creating a need for selective learning methods.

Method: Prepend short system-prompt instructions to finetuning data that deliberately elicit undesirable traits, then evaluate without these instructions at test time.

Result: Inoculated models show much lower expression of undesirable traits across multiple settings including emergent misalignment, backdoor injections, and subliminal learning.

Conclusion: Inoculation is an effective technique for selective learning that reduces generalization of undesirable traits by making them less surprising during training.

Abstract: Language model finetuning often results in learning undesirable traits in
combination with desired ones. To address this, we propose inoculation
prompting: modifying finetuning data by prepending a short system-prompt
instruction that deliberately elicits the undesirable trait. At test time, we
evaluate without the instruction; inoculated models have much lower expression
of the trait than models trained with unmodified training data. Inoculation is
selective: in a toy setting where assistant responses are always in Spanish and
ALL-CAPS, an appropriate inoculation (e.g., ``You always speak in Spanish.'')
teaches the model to capitalize responses while still responding in English. We
find that inoculation is also effective across several additional settings:
reducing emergent misalignment (EM) from task-specific finetuning, defending
against backdoor injections, and mitigating the transmission of traits via
subliminal learning. Follow-up analysis suggests a mechanism: making a trait
less surprising via inoculation reduces optimization pressure to globally
update the model, thereby reducing the degree of generalization. Our analysis
relates to prior work on EM: inoculation explains prior findings that
educational contexts mitigate EM from insecure code. Beyond demonstrating a
simple and effective technique for selective learning, our results contribute
to a better conceptual understanding of how and why language models generalize.

</details>


### [63] [Unmasking Backdoors: An Explainable Defense via Gradient-Attention Anomaly Scoring for Pre-trained Language Models](https://arxiv.org/abs/2510.04347)
*Anindya Sundar Das,Kangjie Chen,Monowar Bhuyan*

Main category: cs.CL

TL;DR: The paper analyzes backdoor attacks in pre-trained language models and proposes an inference-time defense using attention and gradient anomaly scores to detect and mitigate these attacks.


<details>
  <summary>Details</summary>
Motivation: Pre-trained language models are vulnerable to backdoor attacks where triggers in training data can cause targeted misclassifications when activated, despite their general success in NLP tasks.

Method: The authors investigate internal model behavior and propose an inference-time defense that constructs anomaly scores by combining token-level attention and gradient information to detect poisoned inputs.

Result: Extensive experiments on text classification tasks show the method significantly reduces attack success rates compared to existing baselines across diverse backdoor attack scenarios.

Conclusion: The proposed defense effectively mitigates backdoor attacks through attention and gradient analysis, with interpretability-driven analysis providing insights into trigger localization and defense robustness.

Abstract: Pre-trained language models have achieved remarkable success across a wide
range of natural language processing (NLP) tasks, particularly when fine-tuned
on large, domain-relevant datasets. However, they remain vulnerable to backdoor
attacks, where adversaries embed malicious behaviors using trigger patterns in
the training data. These triggers remain dormant during normal usage, but, when
activated, can cause targeted misclassifications. In this work, we investigate
the internal behavior of backdoored pre-trained encoder-based language models,
focusing on the consistent shift in attention and gradient attribution when
processing poisoned inputs; where the trigger token dominates both attention
and gradient signals, overriding the surrounding context. We propose an
inference-time defense that constructs anomaly scores by combining token-level
attention and gradient information. Extensive experiments on text
classification tasks across diverse backdoor attack scenarios demonstrate that
our method significantly reduces attack success rates compared to existing
baselines. Furthermore, we provide an interpretability-driven analysis of the
scoring mechanism, shedding light on trigger localization and the robustness of
the proposed defense.

</details>


### [64] [Improving Consistency in Retrieval-Augmented Systems with Group Similarity Rewards](https://arxiv.org/abs/2510.04392)
*Faisal Hamman,Chenyang Zhu,Anoop Kumar,Xujun Peng,Sanghamitra Dutta,Daben Liu,Alfy Samuel*

Main category: cs.CL

TL;DR: The paper addresses inconsistency issues in RAG systems by proposing Con-RAG, which uses PS-GRPO reinforcement learning to train generators for consistent outputs across semantically equivalent queries, with a scalable approximation method for efficient training.


<details>
  <summary>Details</summary>
Motivation: RAG systems deployed in high-stakes domains often produce inconsistent outputs for semantically equivalent queries, undermining trust and reliability. This work focuses on improving information consistency across retriever and generator components.

Method: Proposes PS-GRPO (Paraphrased Set Group Relative Policy Optimization), an RL approach that uses multiple rollouts across paraphrased sets with group similarity rewards. Also introduces a scalable approximation method for efficient training.

Result: Con-RAG significantly improves both consistency and accuracy across short-form, multi-hop, and long-form QA benchmarks, even without explicit ground-truth supervision.

Conclusion: The work provides practical solutions for evaluating and building reliable RAG systems for safety-critical deployments by addressing inconsistency sources through principled evaluation and effective training methods.

Abstract: RAG systems are increasingly deployed in high-stakes domains where users
expect outputs to be consistent across semantically equivalent queries.
However, existing systems often exhibit significant inconsistencies due to
variability in both the retriever and generator (LLM), undermining trust and
reliability. In this work, we focus on information consistency, i.e., the
requirement that outputs convey the same core content across semantically
equivalent inputs. We introduce a principled evaluation framework that
decomposes RAG consistency into retriever-level, generator-level, and
end-to-end components, helping identify inconsistency sources. To improve
consistency, we propose Paraphrased Set Group Relative Policy Optimization
(PS-GRPO), an RL approach that leverages multiple rollouts across paraphrased
set to assign group similarity rewards. We leverage PS-GRPO to achieve
Information Consistent RAG (Con-RAG), training the generator to produce
consistent outputs across paraphrased queries and remain robust to
retrieval-induced variability. Because exact reward computation over paraphrase
sets is computationally expensive, we also introduce a scalable approximation
method that retains effectiveness while enabling efficient, large-scale
training. Empirical evaluations across short-form, multi-hop, and long-form QA
benchmarks demonstrate that Con-RAG significantly improves both consistency and
accuracy over strong baselines, even in the absence of explicit ground-truth
supervision. Our work provides practical solutions for evaluating and building
reliable RAG systems for safety-critical deployments.

</details>


### [65] [Time Is Effort: Estimating Human Post-Editing Time for Grammar Error Correction Tool Evaluation](https://arxiv.org/abs/2510.04394)
*Ankit Vadehra,Bill Johnson,Gene Saunders,Pascal Poupart*

Main category: cs.CL

TL;DR: This paper introduces PEET (Post-Editing Effort in Time), a human-focused evaluation metric for Grammar Error Correction tools that measures time savings in post-editing tasks.


<details>
  <summary>Details</summary>
Motivation: To quantify how much effort GEC Tools can save users in text editing workflows, addressing the need for human-centric evaluation of tool usability.

Method: Created the first large-scale dataset of post-editing time annotations and corrections for English GEC test datasets (BEA19 and CoNLL14), then developed PEET scorer to estimate post-editing time-to-correct.

Result: Quantified time savings by GEC Tools, found that determining correction need and edits like paraphrasing/punctuation most impact PE time, and PEET correlates well with human technical effort judgments.

Conclusion: PEET provides a new human-centric direction for evaluating GEC tool usability, with dataset and code publicly released for further research.

Abstract: Text editing can involve several iterations of revision. Incorporating an
efficient Grammar Error Correction (GEC) tool in the initial correction round
can significantly impact further human editing effort and final text quality.
This raises an interesting question to quantify GEC Tool usability: How much
effort can the GEC Tool save users? We present the first large-scale dataset of
post-editing (PE) time annotations and corrections for two English GEC test
datasets (BEA19 and CoNLL14). We introduce Post-Editing Effort in Time (PEET)
for GEC Tools as a human-focused evaluation scorer to rank any GEC Tool by
estimating PE time-to-correct. Using our dataset, we quantify the amount of
time saved by GEC Tools in text editing. Analyzing the edit type indicated that
determining whether a sentence needs correction and edits like paraphrasing and
punctuation changes had the greatest impact on PE time. Finally, comparison
with human rankings shows that PEET correlates well with technical effort
judgment, providing a new human-centric direction for evaluating GEC tool
usability. We release our dataset and code at:
https://github.com/ankitvad/PEET_Scorer.

</details>


### [66] [SECA: Semantically Equivalent and Coherent Attacks for Eliciting LLM Hallucinations](https://arxiv.org/abs/2510.04398)
*Buyun Liang,Liangzu Peng,Jinqi Luo,Darshan Thaker,Kwan Ho Ryan Chan,René Vidal*

Main category: cs.CL

TL;DR: SECA is a method for eliciting hallucinations in LLMs through realistic prompt modifications that preserve meaning and coherence, achieving higher attack success rates than existing methods.


<details>
  <summary>Details</summary>
Motivation: Current adversarial attacks for hallucination elicitation produce unrealistic prompts that don't reflect real-world scenarios, limiting practical insights into LLM reliability issues.

Method: Formulates realistic attacks as constrained optimization under semantic equivalence and coherence constraints, using a constraint-preserving zeroth-order method to search for adversarial prompts.

Result: SECA achieves higher attack success rates on open-ended multiple-choice question answering tasks with almost no constraint violations compared to existing methods.

Conclusion: LLMs are sensitive to realistic and plausible prompt variations, highlighting reliability concerns even with semantically equivalent inputs.

Abstract: Large Language Models (LLMs) are increasingly deployed in high-risk domains.
However, state-of-the-art LLMs often produce hallucinations, raising serious
concerns about their reliability. Prior work has explored adversarial attacks
for hallucination elicitation in LLMs, but it often produces unrealistic
prompts, either by inserting gibberish tokens or by altering the original
meaning. As a result, these approaches offer limited insight into how
hallucinations may occur in practice. While adversarial attacks in computer
vision often involve realistic modifications to input images, the problem of
finding realistic adversarial prompts for eliciting LLM hallucinations has
remained largely underexplored. To address this gap, we propose Semantically
Equivalent and Coherent Attacks (SECA) to elicit hallucinations via realistic
modifications to the prompt that preserve its meaning while maintaining
semantic coherence. Our contributions are threefold: (i) we formulate finding
realistic attacks for hallucination elicitation as a constrained optimization
problem over the input prompt space under semantic equivalence and coherence
constraints; (ii) we introduce a constraint-preserving zeroth-order method to
effectively search for adversarial yet feasible prompts; and (iii) we
demonstrate through experiments on open-ended multiple-choice question
answering tasks that SECA achieves higher attack success rates while incurring
almost no constraint violations compared to existing methods. SECA highlights
the sensitivity of both open-source and commercial gradient-inaccessible LLMs
to realistic and plausible prompt variations. Code is available at
https://github.com/Buyun-Liang/SECA.

</details>


### [67] [Large Language Models Preserve Semantic Isotopies in Story Continuations](https://arxiv.org/abs/2510.04400)
*Marc Cavazza*

Main category: cs.CL

TL;DR: LLM-generated texts preserve semantic isotopies when completing stories within token limits, maintaining structural and semantic properties.


<details>
  <summary>Details</summary>
Motivation: To investigate whether Large Language Models preserve semantic isotopies in generated text, extending previous research on distributional and structural semantics.

Method: Used 10,000 ROCStories prompts completed by five LLMs, validated GPT-4o's isotopy extraction on linguistic benchmarks, then analyzed structural (coverage, density, spread) and semantic properties of isotopies in generated stories.

Result: LLM completion within token horizons preserves semantic isotopies across multiple properties.

Conclusion: Large Language Models maintain semantic isotopies when generating text completions, indicating preservation of semantic coherence in their outputs.

Abstract: In this work, we explore the relevance of textual semantics to Large Language
Models (LLMs), extending previous insights into the connection between
distributional semantics and structural semantics. We investigate whether
LLM-generated texts preserve semantic isotopies. We design a story continuation
experiment using 10,000 ROCStories prompts completed by five LLMs. We first
validate GPT-4o's ability to extract isotopies from a linguistic benchmark,
then apply it to the generated stories. We then analyze structural (coverage,
density, spread) and semantic properties of isotopies to assess how they are
affected by completion. Results show that LLM completion within a given token
horizon preserves semantic isotopies across multiple properties.

</details>


### [68] [Good Intentions Beyond ACL: Who Does NLP for Social Good, and Where?](https://arxiv.org/abs/2510.04434)
*Grace LeFevre,Qingcheng Zeng,Adam Leif,Jason Jewell,Denis Peskoff,Rob Voigt*

Main category: cs.CL

TL;DR: This paper maps the NLP for Social Good (NLP4SG) landscape, revealing that ACL authors are more likely to publish NLP4SG work outside ACL venues, and most NLP4SG publications come from non-ACL authors in non-ACL venues.


<details>
  <summary>Details</summary>
Motivation: To understand the distribution and patterns of NLP for Social Good research across different author communities and publication venues, particularly examining ACL vs non-ACL contributions.

Method: Author- and venue-level analysis of NLP4SG publications, quantifying proportions of work addressing social good concerns within and beyond the ACL community, using UN Sustainable Development Goals as framework.

Result: Two key findings: 1) ACL authors are dramatically more likely to publish NLP4SG work in non-ACL venues, 2) Majority of NLP4SG publications come from non-ACL authors publishing outside ACL venues.

Conclusion: The findings highlight agenda-setting implications for the ACL community regarding NLP4SG, suggesting potential venue-specific barriers or preferences that affect where social good research is published.

Abstract: The social impact of Natural Language Processing (NLP) is increasingly
important, with a rising community focus on initiatives related to NLP for
Social Good (NLP4SG). Indeed, in recent years, almost 20% of all papers in the
ACL Anthology address topics related to social good as defined by the UN
Sustainable Development Goals (Adauto et al., 2023). In this study, we take an
author- and venue-level perspective to map the landscape of NLP4SG, quantifying
the proportion of work addressing social good concerns both within and beyond
the ACL community, by both core ACL contributors and non-ACL authors. With this
approach we discover two surprising facts about the landscape of NLP4SG. First,
ACL authors are dramatically more likely to do work addressing social good
concerns when publishing in venues outside of ACL. Second, the vast majority of
publications using NLP techniques to address concerns of social good are done
by non-ACL authors in venues outside of ACL. We discuss the implications of
these findings on agenda-setting considerations for the ACL community related
to NLP4SG.

</details>


### [69] [On the Role of Unobserved Sequences on Sample-based Uncertainty Quantification for LLMs](https://arxiv.org/abs/2510.04439)
*Lucie Kunitomo-Jacquin,Edison Marrese-Taylor,Ken Fukuda*

Main category: cs.CL

TL;DR: This paper argues that accounting for unobserved sequences is crucial for improving LLM uncertainty quantification methods that rely on entropy estimation.


<details>
  <summary>Details</summary>
Motivation: To enhance safety in LLM applications by improving uncertainty quantification methods that currently focus only on observed sequences, which may miss important uncertainty signals from unobserved potential outputs.

Method: The paper advocates for and experimentally demonstrates the importance of considering the probability of unobserved sequences in entropy-based uncertainty quantification methods for LLMs.

Result: Experimental results show that unobserved sequences play a crucial role in uncertainty quantification, and their inclusion significantly enhances the accuracy of uncertainty estimates.

Conclusion: Future research should integrate the probability of unobserved sequences to improve LLM uncertainty quantification methods for better detection of hallucinations in safety-critical applications.

Abstract: Quantifying uncertainty in large language models (LLMs) is important for
safety-critical applications because it helps spot incorrect answers, known as
hallucinations. One major trend of uncertainty quantification methods is based
on estimating the entropy of the distribution of the LLM's potential output
sequences. This estimation is based on a set of output sequences and associated
probabilities obtained by querying the LLM several times. In this paper, we
advocate and experimentally show that the probability of unobserved sequences
plays a crucial role, and we recommend future research to integrate it to
enhance such LLM uncertainty quantification methods.

</details>


### [70] [Mitigating Forgetting Between Supervised and Reinforcement Learning Yields Stronger Reasoners](https://arxiv.org/abs/2510.04454)
*Xiangchi Yuan,Xiang Chen,Tong Yu,Dachuan Shi,Can Jin,Wenke Lee,Saayan Mitra*

Main category: cs.CL

TL;DR: A plug-and-play framework that dynamically integrates SFT into RL by selecting challenging examples for SFT, reducing data requirements while achieving state-of-the-art reasoning performance.


<details>
  <summary>Details</summary>
Motivation: RL algorithms struggle to expand reasoning boundaries as they learn from their own trajectories rather than external knowledge, while SFT requires large-scale data and risks overfitting. Combining SFT and RL faces challenges of data inefficiency, algorithm-specific designs, and catastrophic forgetting.

Method: Dynamically integrates SFT into RL by selecting challenging examples for SFT, reduces SFT data requirements, remains agnostic to RL/SFT algorithm choice, mitigates catastrophic forgetting by selecting high-entropy tokens for loss calculation and freezing critical RL parameters.

Result: Achieves state-of-the-art reasoning performance using only 1.5% of SFT data and 20.4% of RL data compared to prior state-of-the-art methods.

Conclusion: Provides an efficient and plug-and-play solution for combining SFT and RL in reasoning post-training, addressing key challenges in data efficiency and catastrophic forgetting.

Abstract: Large Language Models (LLMs) show strong reasoning abilities, often amplified
by Chain-of-Thought (CoT) prompting and reinforcement learning (RL). Although
RL algorithms can substantially improve reasoning, they struggle to expand
reasoning boundaries because they learn from their own reasoning trajectories
rather than acquiring external knowledge. Supervised fine-tuning (SFT) offers
complementary benefits but typically requires large-scale data and risks
overfitting. Recent attempts to combine SFT and RL face three main challenges:
data inefficiency, algorithm-specific designs, and catastrophic forgetting. We
propose a plug-and-play framework that dynamically integrates SFT into RL by
selecting challenging examples for SFT. This approach reduces SFT data
requirements and remains agnostic to the choice of RL or SFT algorithm. To
mitigate catastrophic forgetting of RL-acquired skills during SFT, we select
high-entropy tokens for loss calculation and freeze parameters identified as
critical for RL. Our method achieves state-of-the-art (SoTA) reasoning
performance using only 1.5% of the SFT data and 20.4% of the RL data used by
prior SoTA, providing an efficient and plug-and-play solution for combining SFT
and RL in reasoning post-training.

</details>


### [71] [Compressed Convolutional Attention: Efficient Attention in a Compressed Latent Space](https://arxiv.org/abs/2510.04476)
*Tomas Figliolia,Nicholas Alonso,Rishi Iyer,Quentin Anthony,Beren Millidge*

Main category: cs.CL

TL;DR: CCA and CCGQA are novel attention methods that compress queries, keys, and values into a shared latent space, reducing parameters, KV-cache, and FLOPs simultaneously while maintaining performance.


<details>
  <summary>Details</summary>
Motivation: Multi-headed Attention's quadratic compute and linearly growing KV-cache make long-context transformers expensive to train and serve. Prior methods like GQA and MLA only address cache size but leave compute unchanged.

Method: CCA down-projects queries, keys, and values into a shared latent space and performs attention operations there. CCGQA combines CCA with head-sharing for further optimization.

Result: CCGQA outperforms GQA and MLA at equal KV-cache compression, achieves 8x KV-cache compression with no performance drop, reduces prefill latency by 1.7x at 16k sequence length, and accelerates backward by 1.3x on H100 GPUs.

Conclusion: CCA and CCGQA provide a superior compute-bandwidth Pareto frontier, enabling users to tune compression toward FLOP or memory limits without sacrificing quality, making long-context transformers more efficient.

Abstract: Multi-headed Attention's (MHA) quadratic compute and linearly growing
KV-cache make long-context transformers expensive to train and serve. Prior
works such as Grouped Query Attention (GQA) and Multi-Latent Attention (MLA)
shrink the cache, speeding decode, but leave compute, which determines prefill
and training speed, largely unchanged. We introduce Compressed Convolutional
Attention (CCA), a novel attention method which down-projects queries, keys,
and values and performs the entire attention operation inside the shared latent
space. This simple design dramatically cuts parameters, KV-cache, and FLOPs all
at once by the desired compression factor. Because CCA is orthogonal to
head-sharing, we combine the two to form Compressed Convolutional Grouped Query
Attention (CCGQA), which further tightens the compute-bandwidth Pareto frontier
so that users can tune compression toward either FLOP or memory limits without
sacrificing quality. Experiments show that CCGQA consistently outperforms both
GQA and MLA at equal KV-cache compression on dense and MoE models.
Additionally, we show that CCGQA outperforms all other attention methods on MoE
models with half the KV-cache of GQA and MLA, achieving an 8x KV-cache
compression with no drop in performance compared to standard MHA. CCA and CCGQA
also dramatically reduce the FLOP cost of attention which leads to
substantially faster training and prefill than existing methods. On H100 GPUs,
our fused CCA/CCGQA kernel reduces prefill latency by about 1.7x at a sequence
length of 16k relative to MHA, and accelerates backward by about 1.3x.

</details>


### [72] [Psychological Steering in LLMs: An Evaluation of Effectiveness and Trustworthiness](https://arxiv.org/abs/2510.04484)
*Amin Banayeeanzade,Ala N. Tak,Fatemeh Bahrani,Anahita Bolourani,Leonardo Blas,Emilio Ferrara,Jonathan Gratch,Sai Praneeth Karimireddy*

Main category: cs.CL

TL;DR: PsySET is a psychological benchmark for evaluating LLM steering effectiveness and trustworthiness across emotion and personality domains, revealing that prompting is effective but limited, while vector injections offer finer control with slight quality trade-offs.


<details>
  <summary>Details</summary>
Motivation: To enable rich, human-centered interactions in socially interactive settings by controlling LLMs' emotional states and personality traits, requiring evaluation of steering effectiveness and trustworthiness.

Method: Developed PsySET benchmark spanning four LLM families with various steering strategies including prompting, fine-tuning, and representation engineering, assessing safety, truthfulness, fairness, and ethics.

Result: Prompting is consistently effective but limited in intensity control; vector injections achieve finer controllability with slight output quality reduction. Idiosyncratic effects observed - even positive emotions like joy can degrade robustness and increase bias, while anger elevates toxicity but strengthens leakage resistance.

Conclusion: The framework establishes the first holistic evaluation of emotion and personality steering, offering insights into interpretability and reliability for socially interactive applications, highlighting complex trade-offs between controllability and trustworthiness.

Abstract: The ability to control LLMs' emulated emotional states and personality traits
is essential for enabling rich, human-centered interactions in socially
interactive settings. We introduce PsySET, a Psychologically-informed benchmark
to evaluate LLM Steering Effectiveness and Trustworthiness across the emotion
and personality domains. Our study spans four models from different LLM
families paired with various steering strategies, including prompting,
fine-tuning, and representation engineering. Our results indicate that
prompting is consistently effective but limited in intensity control, whereas
vector injections achieve finer controllability while slightly reducing output
quality. Moreover, we explore the trustworthiness of steered LLMs by assessing
safety, truthfulness, fairness, and ethics, highlighting potential side effects
and behavioral shifts. Notably, we observe idiosyncratic effects; for instance,
even a positive emotion like joy can degrade robustness to adversarial
factuality, lower privacy awareness, and increase preferential bias. Meanwhile,
anger predictably elevates toxicity yet strengthens leakage resistance. Our
framework establishes the first holistic evaluation of emotion and personality
steering, offering insights into its interpretability and reliability for
socially interactive applications.

</details>


### [73] [GenQuest: An LLM-based Text Adventure Game for Language Learners](https://arxiv.org/abs/2510.04498)
*Qiao Wang,Adnan Labib,Robert Swier,Michael Hofmeyr,Zheng Yuan*

Main category: cs.CL

TL;DR: GenQuest is an LLM-powered text adventure game for EFL learning that uses interactive storytelling with adaptive content and vocabulary assistance.


<details>
  <summary>Details</summary>
Motivation: To create an immersive language learning tool that combines interactive storytelling with personalized language instruction for EFL learners.

Method: Uses LLMs to generate dynamic choose-your-own-adventure narratives with branching decision points, proficiency-level content adaptation, and in-context vocabulary explanations.

Result: Pilot study with Chinese university EFL students showed promising vocabulary gains and positive user perceptions, though participants suggested improvements to narrative length/quality and requested multi-modal content.

Conclusion: GenQuest demonstrates the potential of LLM-driven interactive storytelling for language learning, with identified areas for enhancement including narrative refinement and multi-modal integration.

Abstract: GenQuest is a generative text adventure game that leverages Large Language
Models (LLMs) to facilitate second language learning through immersive,
interactive storytelling. The system engages English as a Foreign Language
(EFL) learners in a collaborative "choose-your-own-adventure" style narrative,
dynamically generated in response to learner choices. Game mechanics such as
branching decision points and story milestones are incorporated to maintain
narrative coherence while allowing learner-driven plot development. Key
pedagogical features include content generation tailored to each learner's
proficiency level, and a vocabulary assistant that provides in-context
explanations of learner-queried text strings, ranging from words and phrases to
sentences. Findings from a pilot study with university EFL students in China
indicate promising vocabulary gains and positive user perceptions. Also
discussed are suggestions from participants regarding the narrative length and
quality, and the request for multi-modal content such as illustrations.

</details>


### [74] [GRACE: Generative Representation Learning via Contrastive Policy Optimization](https://arxiv.org/abs/2510.04506)
*Jiashuo Sun,Shixuan Liu,Zhaochen Su,Xianrui Zhong,Pengcheng Jiang,Bowen Jin,Peiran Li,Weijia Shi,Jiawei Han*

Main category: cs.CL

TL;DR: GRACE is a novel framework that treats contrastive signals as rewards to guide a generative policy, enabling LLMs to produce interpretable rationales and high-quality embeddings through policy gradient optimization.


<details>
  <summary>Details</summary>
Motivation: Current methods for training LLMs as text encoders discard generative and reasoning capabilities in favor of static embeddings, treating models as black boxes without transparency.

Method: Uses policy gradient optimization with a multi-component reward function that maximizes similarity between positive pairs and minimizes similarity with negatives. The LLM produces explicit, human-interpretable rationales that are encoded into embeddings via mean pooling.

Result: On MTEB benchmark, supervised setting improves overall score by 11.5% over base models, and unsupervised variant adds 6.9%, while preserving general capabilities. Achieves broad cross-category gains.

Conclusion: GRACE unifies representation learning with generation to produce stronger embeddings and transparent rationales, transforming LLMs from opaque encoders into interpretable agents with inspectable reasoning processes.

Abstract: Prevailing methods for training Large Language Models (LLMs) as text encoders
rely on contrastive losses that treat the model as a black box function,
discarding its generative and reasoning capabilities in favor of static
embeddings. We introduce GRACE (Generative Representation Learning via
Contrastive Policy Optimization), a novel framework that reimagines contrastive
signals not as losses to be minimized, but as rewards that guide a generative
policy. In GRACE, the LLM acts as a policy that produces explicit,
human-interpretable rationales--structured natural language explanations of its
semantic understanding. These rationales are then encoded into high-quality
embeddings via mean pooling. Using policy gradient optimization, we train the
model with a multi-component reward function that maximizes similarity between
query positive pairs and minimizes similarity with negatives. This transforms
the LLM from an opaque encoder into an interpretable agent whose reasoning
process is transparent and inspectable. On MTEB benchmark, GRACE yields broad
cross category gains: averaged over four backbones, the supervised setting
improves overall score by 11.5% over base models, and the unsupervised variant
adds 6.9%, while preserving general capabilities. This work treats contrastive
objectives as rewards over rationales, unifying representation learning with
generation to produce stronger embeddings and transparent rationales. The
model, data and code are available at https://github.com/GasolSun36/GRACE.

</details>


### [75] [Fine-grained auxiliary learning for real-world product recommendation](https://arxiv.org/abs/2510.04551)
*Mario Almagro,Diego Ortego,David Jimenez*

Main category: cs.CL

TL;DR: ALC is an auxiliary learning strategy that improves recommendation coverage by learning fine-grained embeddings using hardest negatives in training batches.


<details>
  <summary>Details</summary>
Motivation: Real-world recommendation systems require high coverage (automated recommendations) but existing models often overlook this production requirement when determining relevance through similarity thresholds.

Method: Proposes ALC with two training objectives that leverage hardest negatives in batches to create discriminative training signals between positive and negative items. Validated with three extreme multi-label classification approaches on two datasets.

Result: Demonstrates state-of-the-art coverage rates when combined with a recent threshold-consistent margin loss on LF-AmazonTitles-131K and proprietary Tech and Durables datasets.

Conclusion: ALC effectively boosts recommendation coverage through fine-grained embedding learning, addressing production system requirements for automated recommendations.

Abstract: Product recommendation is the task of recovering the closest items to a given
query within a large product corpora. Generally, one can determine if
top-ranked products are related to the query by applying a similarity
threshold; exceeding it deems the product relevant, otherwise manual revision
is required. Despite being a well-known problem, the integration of these
models in real-world systems is often overlooked. In particular, production
systems have strong coverage requirements, i.e., a high proportion of
recommendations must be automated. In this paper we propose ALC , an Auxiliary
Learning strategy that boosts Coverage through learning fine-grained
embeddings. Concretely, we introduce two training objectives that leverage the
hardest negatives in the batch to build discriminative training signals between
positives and negatives. We validate ALC using three extreme multi-label
classification approaches in two product recommendation datasets;
LF-AmazonTitles-131K and Tech and Durables (proprietary), demonstrating
state-of-the-art coverage rates when combined with a recent
threshold-consistent margin loss.

</details>


### [76] [Can LLMs Detect Ambiguous Plural Reference? An Analysis of Split-Antecedent and Mereological Reference](https://arxiv.org/abs/2510.04581)
*Dang Anh,Rick Nouwen,Massimo Poesio*

Main category: cs.CL

TL;DR: LLMs show partial awareness of plural reference ambiguity but struggle with human-like interpretation and ambiguity detection without explicit instruction.


<details>
  <summary>Details</summary>
Motivation: To study how LLMs represent and interpret plural reference in ambiguous and unambiguous contexts, comparing their performance to human preferences.

Method: Designed experiments using next-token prediction tasks for pronoun production, pronoun interpretation, and ambiguity detection with different prompting strategies.

Result: LLMs are sometimes aware of possible referents of ambiguous pronouns but don't consistently follow human reference patterns, especially when interpretations aren't explicitly mentioned. They struggle with ambiguity detection without direct instruction.

Conclusion: LLMs exhibit inconsistencies across experiments and have limitations in handling plural reference ambiguity compared to human performance, particularly in detecting ambiguity without explicit guidance.

Abstract: Our goal is to study how LLMs represent and interpret plural reference in
ambiguous and unambiguous contexts. We ask the following research questions:
(1) Do LLMs exhibit human-like preferences in representing plural reference?
(2) Are LLMs able to detect ambiguity in plural anaphoric expressions and
identify possible referents? To address these questions, we design a set of
experiments, examining pronoun production using next-token prediction tasks,
pronoun interpretation, and ambiguity detection using different prompting
strategies. We then assess how comparable LLMs are to humans in formulating and
interpreting plural reference. We find that LLMs are sometimes aware of
possible referents of ambiguous pronouns. However, they do not always follow
human reference when choosing between interpretations, especially when the
possible interpretation is not explicitly mentioned. In addition, they struggle
to identify ambiguity without direct instruction. Our findings also reveal
inconsistencies in the results across different types of experiments.

</details>


### [77] [Robustness assessment of large audio language models in multiple-choice evaluation](https://arxiv.org/abs/2510.04584)
*Fernando López,Santosh Kesiraju,Jordi Luque*

Main category: cs.CL

TL;DR: This paper analyzes the instability of multiple-choice question answering (MCQA) evaluation for large audio language models, showing that subtle changes like choice ordering and paraphrasing significantly affect results, and proposes a more robust evaluation protocol.


<details>
  <summary>Details</summary>
Motivation: Current MCQA evaluation frameworks for large audio language models report single accuracy numbers but are highly sensitive to subtle variations like choice ordering and paraphrasing, leading to unreliable assessments.

Method: Conducted systematic study across three benchmarks (MMAU, MMAR, MMSU) and four models, testing sensitivity to choice ordering, question paraphrasing, and choice paraphrasing.

Result: Found that models are highly sensitive to choice ordering, question paraphrasing, and choice paraphrasing, with substantial performance variations across different evaluation conditions.

Conclusion: Proposed a simpler evaluation protocol and metric that accounts for subtle variations to provide more detailed and reliable evaluation of large audio language models within MCQA frameworks.

Abstract: Recent advances in large audio language models (LALMs) have primarily been
assessed using a multiple-choice question answering (MCQA) framework. However,
subtle changes, such as shifting the order of choices, result in substantially
different results. Existing MCQA frameworks do not account for this variability
and report a single accuracy number per benchmark or category. We dive into the
MCQA evaluation framework and conduct a systematic study spanning three
benchmarks (MMAU, MMAR and MMSU) and four models: Audio Flamingo 2, Audio
Flamingo 3, Qwen2.5-Omni-7B-Instruct, and Kimi-Audio-7B-Instruct. Our findings
indicate that models are sensitive not only to the ordering of choices, but
also to the paraphrasing of the question and the choices. Finally, we propose a
simpler evaluation protocol and metric that account for subtle variations and
provide a more detailed evaluation report of LALMs within the MCQA framework.

</details>


### [78] [FedSRD: Sparsify-Reconstruct-Decompose for Communication-Efficient Federated Large Language Models Fine-Tuning](https://arxiv.org/abs/2510.04601)
*Guochen Yan,Luyuan Xie,Qingni Shen,Yuejian Fang,Zhonghai Wu*

Main category: cs.CL

TL;DR: FedSRD is a communication-efficient federated learning framework that addresses the bottleneck of LoRA parameter transmission in heterogeneous networks through sparsification, reconstruction, and decomposition techniques.


<details>
  <summary>Details</summary>
Motivation: Current LLM training is unsustainable due to exhausted high-quality data sources, and federated learning with LoRA faces communication overhead challenges in heterogeneous network conditions.

Method: FedSRD uses importance-aware sparsification to reduce uploaded LoRA parameters, server-side reconstruction and aggregation in full-rank space to mitigate conflicts, and decomposition into sparse low-rank format for efficient broadcasting.

Result: Experimental results on 10 benchmarks show up to 90% reduction in communication costs while improving model performance on heterogeneous client data.

Conclusion: FedSRD provides an effective solution for communication-efficient federated fine-tuning of LLMs, enabling sustainable AI development on decentralized web infrastructure.

Abstract: The current paradigm of training large language models (LLMs) on publicly
available Web data is becoming unsustainable, with high-quality data sources in
specialized domains nearing exhaustion. Federated Learning (FL) emerges as a
practical solution for the next generation of AI on a decentralized Web,
enabling privacy-preserving collaborative fine-tuning by leveraging private
data distributed across a global client base. While Low-Rank Adaptation (LoRA)
is the standard for efficient fine-tuning, its application in federated
settings presents a critical challenge: communication overhead remains a
significant bottleneck across the Web's heterogeneous network conditions. The
structural redundancy within LoRA parameters not only incurs a heavy
communication burden but also introduces conflicts when aggregating client
updates. To address this, we propose FedSRD, a Sparsify-Reconstruct-Decompose
framework designed for communication-efficient FL. We first introduce an
importance-aware sparsification method that preserves the structural integrity
of LoRA updates to reduce the uploaded parameter count. The server then
reconstructs and aggregates these updates in a full-rank space to mitigate
conflicts. Finally, it decomposes the global update into a sparse low-rank
format for broadcast, ensuring a symmetrically efficient cycle. We also propose
an efficient variant, FedSRD-e, to reduce computational overhead. Experimental
results on 10 benchmarks demonstrate that our framework significantly reduces
communication costs by up to 90\% while even improving model performance on
heterogeneous client data.

</details>


### [79] [Contrastive Learning Using Graph Embeddings for Domain Adaptation of Language Models in the Process Industry](https://arxiv.org/abs/2510.04631)
*Anastasia Zhukova,Jonas Lührs,Christian E. Matt,Bela Gipp*

Main category: cs.CL

TL;DR: SciNCL, a graph-aware contrastive learning method, is applied to process industry text logs structured as sparse knowledge graphs, achieving significant performance improvements over state-of-the-art text encoders while being much smaller in size.


<details>
  <summary>Details</summary>
Motivation: To enhance language models for process industry applications by incorporating knowledge from sparse knowledge graphs found in text logs, which contain crucial operational information that might be overlooked by standard text encoders.

Method: Applied SciNCL (graph-aware neighborhood contrastive learning) methodology to process industry domain, using triplets derived from knowledge graphs to fine-tune language models.

Result: Fine-tuned models outperformed state-of-the-art mE5-large text encoder by 9.8-14.3% on proprietary process industry text embedding benchmark (PITEB) while being 3-5 times smaller in size.

Conclusion: Graph-aware contrastive learning effectively enhances language models for process industry applications, demonstrating superior performance with smaller model sizes by leveraging knowledge from sparse graph structures in operational text logs.

Abstract: Recent trends in NLP utilize knowledge graphs (KGs) to enhance pretrained
language models by incorporating additional knowledge from the graph structures
to learn domain-specific terminology or relationships between documents that
might otherwise be overlooked. This paper explores how SciNCL, a graph-aware
neighborhood contrastive learning methodology originally designed for
scientific publications, can be applied to the process industry domain, where
text logs contain crucial information about daily operations and are often
structured as sparse KGs. Our experiments demonstrate that language models
fine-tuned with triplets derived from GE outperform a state-of-the-art
mE5-large text encoder by 9.8-14.3% (5.4-8.0p) on the proprietary process
industry text embedding benchmark (PITEB) while being 3-5 times smaller in
size.

</details>


### [80] [Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study](https://arxiv.org/abs/2510.04641)
*Ayan Majumdar,Feihao Chen,Jinghui Li,Xiaozhen Wang*

Main category: cs.CL

TL;DR: This paper presents a comprehensive evaluation framework for assessing LLMs' ability to detect demographic-targeted social biases in English texts, revealing that fine-tuned smaller models show promise but gaps persist in detecting multi-demographic biases.


<details>
  <summary>Details</summary>
Motivation: Large web-scraped text corpora contain harmful demographic-targeted social biases, creating regulatory needs for data auditing and scalable bias-detection methods. Current methods are narrow in scope and practitioners lack holistic understanding of LLMs' capabilities for automated bias detection.

Method: Developed a comprehensive evaluation framework framing bias detection as multi-label task using demographic-focused taxonomy. Systematically evaluated models across scales and techniques including prompting, in-context learning, and fine-tuning using twelve datasets spanning diverse content types and demographics.

Result: Fine-tuned smaller models show promise for scalable bias detection, but analyses expose persistent gaps across demographic axes and multi-demographic targeted biases.

Conclusion: There is a need for more effective and scalable auditing frameworks to address the limitations in detecting multi-demographic biases and gaps across demographic axes.

Abstract: Large-scale web-scraped text corpora used to train general-purpose AI models
often contain harmful demographic-targeted social biases, creating a regulatory
need for data auditing and developing scalable bias-detection methods. Although
prior work has investigated biases in text datasets and related detection
methods, these studies remain narrow in scope. They typically focus on a single
content type (e.g., hate speech), cover limited demographic axes, overlook
biases affecting multiple demographics simultaneously, and analyze limited
techniques. Consequently, practitioners lack a holistic understanding of the
strengths and limitations of recent large language models (LLMs) for automated
bias detection. In this study, we present a comprehensive evaluation framework
aimed at English texts to assess the ability of LLMs in detecting
demographic-targeted social biases. To align with regulatory requirements, we
frame bias detection as a multi-label task using a demographic-focused
taxonomy. We then conduct a systematic evaluation with models across scales and
techniques, including prompting, in-context learning, and fine-tuning. Using
twelve datasets spanning diverse content types and demographics, our study
demonstrates the promise of fine-tuned smaller models for scalable detection.
However, our analyses also expose persistent gaps across demographic axes and
multi-demographic targeted biases, underscoring the need for more effective and
scalable auditing frameworks.

</details>


### [81] [FT-MDT: Extracting Decision Trees from Medical Texts via a Novel Low-rank Adaptation Method](https://arxiv.org/abs/2510.04655)
*Yuheng Li,Jiechao Gao,Wei Han,Wenwen Ouyang,Wei Zhu,Hui Yi Leong*

Main category: cs.CL

TL;DR: PI-LoRA is a novel low-rank adaptation method that automatically extracts medical decision trees from clinical texts by integrating gradient path information for better rank allocation, achieving state-of-the-art performance with reduced complexity.


<details>
  <summary>Details</summary>
Motivation: Current medical decision tree construction methods rely heavily on manual annotation, which is time-consuming and laborious. There's a need for automated extraction from clinical guidelines and textbooks to build clinical decision support systems.

Method: Proposed PI-LoRA (Path-Integrated LoRA) that integrates gradient path information to capture synergistic effects between modules, enabling effective rank allocation where critical modules get appropriate ranks while less important ones are pruned.

Result: Extensive experiments show PI-LoRA significantly outperforms existing parameter-efficient fine-tuning approaches for Text2MDT task, achieving better accuracy with substantially reduced model complexity and state-of-the-art results.

Conclusion: PI-LoRA provides an efficient and accurate method for extracting medical decision trees from clinical texts, maintaining lightweight architecture suitable for clinical decision support systems with limited computational resources.

Abstract: Knowledge of the medical decision process, which can be modeled as medical
decision trees (MDTs), is critical to building clinical decision support
systems. However, current MDT construction methods rely heavily on
time-consuming and laborious manual annotation. To address this challenge, we
propose PI-LoRA (Path-Integrated LoRA), a novel low-rank adaptation method for
automatically extracting MDTs from clinical guidelines and textbooks. We
integrate gradient path information to capture synergistic effects between
different modules, enabling more effective and reliable rank allocation. This
framework ensures that the most critical modules receive appropriate rank
allocations while less important ones are pruned, resulting in a more efficient
and accurate model for extracting medical decision trees from clinical texts.
Extensive experiments on medical guideline datasets demonstrate that our
PI-LoRA method significantly outperforms existing parameter-efficient
fine-tuning approaches for the Text2MDT task, achieving better accuracy with
substantially reduced model complexity. The proposed method achieves
state-of-the-art results while maintaining a lightweight architecture, making
it particularly suitable for clinical decision support systems where
computational resources may be limited.

</details>


### [82] [FocusMed: A Large Language Model-based Framework for Enhancing Medical Question Summarization with Focus Identification](https://arxiv.org/abs/2510.04671)
*Chao Liu,Ling Luo,Tengxiao Lv,Huan Zhuang,Lejing Yu,Jian Wang,Hongfei Lin*

Main category: cs.CL

TL;DR: This paper proposes a core focus guidance framework for medical question summarization that improves focus identification and reduces hallucinations in LLMs.


<details>
  <summary>Details</summary>
Motivation: Consumer health questions are inefficient due to redundancy and non-professional terms, and existing methods struggle with poor focus identification and model hallucination.

Method: A three-step framework: 1) prompt template for core focus extraction, 2) fine-tuning dataset construction with CHQ-FAQ pairs, 3) multi-dimensional quality evaluation and selection mechanism.

Result: Achieves state-of-the-art performance on two MQS datasets across all evaluation metrics, with significant improvement in focus identification and hallucination mitigation.

Conclusion: The proposed framework effectively enhances LLMs' ability to generate faithful medical question summaries by guiding focus identification and reducing hallucinations.

Abstract: With the rapid development of online medical platforms, consumer health
questions (CHQs) are inefficient in diagnosis due to redundant information and
frequent non-professional terms. The medical question summary (MQS) task aims
to transform CHQs into streamlined doctors' frequently asked questions (FAQs),
but existing methods still face challenges such as poor identification of
question focus and model hallucination. This paper explores the potential of
large language models (LLMs) in the MQS task and finds that direct fine-tuning
is prone to focus identification bias and generates unfaithful content. To this
end, we propose an optimization framework based on core focus guidance. First,
a prompt template is designed to drive the LLMs to extract the core focus from
the CHQs that is faithful to the original text. Then, a fine-tuning dataset is
constructed in combination with the original CHQ-FAQ pairs to improve the
ability to identify the focus of the question. Finally, a multi-dimensional
quality evaluation and selection mechanism is proposed to comprehensively
improve the quality of the summary from multiple dimensions. We conduct
comprehensive experiments on two widely-adopted MQS datasets using three
established evaluation metrics. The proposed framework achieves
state-of-the-art performance across all measures, demonstrating a significant
boost in the model's ability to identify critical focus of questions and a
notable mitigation of hallucinations. The source codes are freely available at
https://github.com/DUT-LiuChao/FocusMed.

</details>


### [83] [Multi-Agent Tool-Integrated Policy Optimization](https://arxiv.org/abs/2510.04678)
*Zhanfeng Mo,Xingxuan Li,Yuntao Chen,Lidong Bing*

Main category: cs.CL

TL;DR: MATPO enables reinforcement learning training of multi-agent tool-integrated frameworks within a single LLM, outperforming single-agent baselines by 18.38% and improving robustness to noisy tool outputs.


<details>
  <summary>Details</summary>
Motivation: Existing single-agent approaches for tool-integrated planning suffer from limited context length and noisy tool responses, while multi-agent frameworks lack effective reinforcement learning training methods.

Method: Multi-Agent Tool-Integrated Policy Optimization (MATPO) trains distinct planner and worker roles within a single LLM instance using role-specific prompts and a principled credit assignment mechanism across rollouts.

Result: MATPO consistently outperforms single-agent baselines by 18.38% average relative improvement on GAIA-text, WebWalkerQA, and FRAMES datasets, and shows greater robustness to noisy tool outputs.

Conclusion: Unifying multiple agent roles within a single LLM is effective for multi-agent RL training, providing practical insights for stable and efficient training while eliminating the need for memory-intensive multiple LLM deployments.

Abstract: Large language models (LLMs) increasingly rely on multi-turn tool-integrated
planning for knowledge-intensive and complex reasoning tasks. Existing
implementations typically rely on a single agent, but they suffer from limited
context length and noisy tool responses. A natural solution is to adopt a
multi-agent framework with planner- and worker-agents to manage context.
However, no existing methods support effective reinforcement learning
post-training of tool-integrated multi-agent frameworks. To address this gap,
we propose Multi-Agent Tool-Integrated Policy Optimization (MATPO), which
enables distinct roles (planner and worker) to be trained within a single LLM
instance using role-specific prompts via reinforcement learning. MATPO is
derived from a principled credit assignment mechanism across planner and worker
rollouts. This design eliminates the need to deploy multiple LLMs, which would
be memory-intensive, while preserving the benefits of specialization.
Experiments on GAIA-text, WebWalkerQA, and FRAMES show that MATPO consistently
outperforms single-agent baselines by an average of 18.38% relative improvement
in performance and exhibits greater robustness to noisy tool outputs. Our
findings highlight the effectiveness of unifying multiple agent roles within a
single LLM and provide practical insights for stable and efficient multi-agent
RL training.

</details>


### [84] [TiTok: Transfer Token-level Knowledge via Contrastive Excess to Transplant LoRA](https://arxiv.org/abs/2510.04682)
*Chanjoo Jung,Jaehyung Kim*

Main category: cs.CL

TL;DR: TiTok enables LoRA parameter transfer across different LLMs through token-level knowledge distillation without needing additional models or training data.


<details>
  <summary>Details</summary>
Motivation: Current PEFT methods like LoRA create model-dependent parameters that can't be transferred between different base models, and existing transfer methods either depend on training data or require complex additional models.

Method: TiTok uses contrastive excess between source models with and without LoRA to capture task-relevant information at token level, enabling selective filtering of synthetic data for knowledge transfer.

Result: Experiments on three benchmarks show consistent effectiveness with average performance gains of +4~8% compared to baselines across multiple transfer settings.

Conclusion: TiTok provides an effective framework for LoRA transplantation through token-level knowledge transfer without additional model overhead or data dependency.

Abstract: Large Language Models (LLMs) are widely applied in real world scenarios, but
fine-tuning them comes with significant computational and storage costs.
Parameter-Efficient Fine-Tuning (PEFT) methods such as LoRA mitigate these
costs, but the adapted parameters are dependent on the base model and cannot be
transferred across different backbones. One way to address this issue is
through knowledge distillation, but its effectiveness inherently depends on
training data. Recent work such as TransLoRA avoids this by generating
synthetic data, but this adds complexity because it requires training an
additional discriminator model. In this paper, we propose TiTok, a new
framework that enables effective LoRA Transplantation through Token-level
knowledge transfer. Specifically, TiTok captures task-relevant information
through a contrastive excess between a source model with and without LoRA. This
excess highlights informative tokens and enables selective filtering of
synthetic data, all without additional models or overhead. Through experiments
on three benchmarks across multiple transfer settings, our experiments show
that the proposed method is consistently effective, achieving average
performance gains of +4~8% compared to baselines overall.

</details>


### [85] [Multilingual Routing in Mixture-of-Experts](https://arxiv.org/abs/2510.04694)
*Lucas Bandarkar,Chenyuan Yang,Mohsen Fayyaz,Junlin Hu,Nanyun Peng*

Main category: cs.CL

TL;DR: MoE models route tokens language-specifically in early/late layers but show cross-lingual routing alignment in middle layers. Performance correlates with routing similarity to English, and interventions promoting English-activated experts in middle layers boost multilingual performance by 1-2%.


<details>
  <summary>Details</summary>
Motivation: To understand how MoE architectures handle multilingual data and their sparse routing dynamics across different languages.

Method: Analyzed expert routing patterns using parallel multilingual datasets, examined layer-wise phenomena, and introduced inference-time interventions that steer routers by promoting middle-layer task experts frequently activated in English.

Result: Found strong correlation between language performance and routing similarity to English in middle layers. Interventions increasing cross-lingual routing alignment consistently improved multilingual performance by 1-2% across tasks, models, and languages.

Conclusion: MoE generalization is limited by the model's ability to leverage language-universal experts across all languages, with middle layers playing a crucial role in cross-lingual processing.

Abstract: Mixture-of-Experts (MoE) architectures have become the key to scaling modern
LLMs, yet little is understood about how their sparse routing dynamics respond
to multilingual data. In this work, we analyze expert routing patterns using
parallel multilingual datasets and present highly interpretable layer-wise
phenomena. We find that MoE models route tokens in language-specific ways in
the early and late decoder layers but exhibit significant cross-lingual routing
alignment in middle layers, mirroring parameter-sharing trends observed in
dense LLMs. In particular, we reveal a clear, strong correlation between a
model's performance in a given language and how similarly its tokens are routed
to English in these layers. Extending beyond correlation, we explore
inference-time interventions that induce higher cross-lingual routing
alignment. We introduce a method that steers the router by promoting
middle-layer task experts frequently activated in English, and it successfully
increases multilingual performance. These 1-2% gains are remarkably consistent
across two evaluation tasks, three models, and 15+ languages, especially given
that these simple interventions override routers of extensively trained,
state-of-the-art LLMs. In comparison, interventions outside of the middle
layers or targeting multilingual-specialized experts only yield performance
degradation. Altogether, we present numerous findings that explain how MoEs
process non-English text and demonstrate that generalization is limited by the
model's ability to leverage language-universal experts in all languages.

</details>


### [86] [JSON Whisperer: Efficient JSON Editing with LLMs](https://arxiv.org/abs/2510.04717)
*Sarel Duanis,Asnat Greenstein-Messica,Eliya Habba*

Main category: cs.CL

TL;DR: JSON Whisperer enables LLMs to generate RFC 6902 diff patches instead of regenerating entire JSON documents, reducing computational costs by 31% while maintaining edit quality.


<details>
  <summary>Details</summary>
Motivation: Current LLM approaches for JSON editing regenerate entire structures for each edit, which is computationally inefficient.

Method: Introduces JSON Whisperer framework with EASE (Explicitly Addressed Sequence Encoding) that transforms arrays into dictionaries with stable keys to handle index shift challenges in patch-based editing.

Result: Patch generation with EASE reduces token usage by 31% while maintaining edit quality within 5% of full regeneration, with particular gains for complex instructions and list manipulations.

Conclusion: JSON Whisperer with EASE provides an efficient alternative to full document regeneration for JSON editing tasks, significantly reducing computational overhead while preserving edit quality.

Abstract: Large language models (LLMs) can modify JSON documents through natural
language commands, but current approaches regenerate entire structures for each
edit, resulting in computational inefficiency. We present JSON Whisperer, a
framework that enables LLMs to generate RFC 6902 diff patches-expressing only
the necessary modifications-rather than complete documents. We identify two key
challenges in patch-based editing: (1) LLMs often miss related updates when
generating isolated patches, and (2) array manipulations require tracking index
shifts across operations, which LLMs handle poorly. To address these issues, we
introduce EASE (Explicitly Addressed Sequence Encoding), which transforms
arrays into dictionaries with stable keys, eliminating index arithmetic
complexities. Our evaluation shows that patch generation with EASE reduces
token usage by 31% while maintaining edit quality within 5% of full
regeneration with particular gains for complex instructions and list
manipulations. The dataset is available at:
https://github.com/emnlp2025/JSON-Whisperer/

</details>


### [87] [A Low-Resource Speech-Driven NLP Pipeline for Sinhala Dyslexia Assistance](https://arxiv.org/abs/2510.04750)
*Peshala Perera,Deshan Sumanathilaka*

Main category: cs.CL

TL;DR: An assistive system for Sinhala-speaking adults with dyslexia that uses speech-to-text, error detection, text correction, and text-to-speech technologies to create a multimodal feedback loop.


<details>
  <summary>Details</summary>
Motivation: Dyslexia in adults is under-researched, especially in non-English contexts like Sinhala, a low-resource language with limited accessibility tools.

Method: Integrated system using Whisper for speech-to-text, SinBERT for dyslexic error identification, combined mT5 and Mistral models for text correction, and gTTS for text-to-speech conversion.

Result: Achieved 0.66 transcription accuracy, 0.7 correction accuracy, and 0.65 overall system accuracy despite limited Sinhala datasets.

Conclusion: Demonstrates feasibility of inclusive NLP technologies for underrepresented languages and provides practical assistive solution for Sinhala-speaking adults with dyslexia.

Abstract: Dyslexia in adults remains an under-researched and under-served area,
particularly in non-English-speaking contexts, despite its significant impact
on personal and professional lives. This work addresses that gap by focusing on
Sinhala, a low-resource language with limited tools for linguistic
accessibility. We present an assistive system explicitly designed for
Sinhala-speaking adults with dyslexia. The system integrates Whisper for
speech-to-text conversion, SinBERT, an open-sourced fine-tuned BERT model
trained for Sinhala to identify common dyslexic errors, and a combined mT5 and
Mistral-based model to generate corrected text. Finally, the output is
converted back to speech using gTTS, creating a complete multimodal feedback
loop. Despite the challenges posed by limited Sinhala-language datasets, the
system achieves 0.66 transcription accuracy and 0.7 correction accuracy with
0.65 overall system accuracy. These results demonstrate both the feasibility
and effectiveness of the approach. Ultimately, this work highlights the
importance of inclusive Natural Language Processing (NLP) technologies in
underrepresented languages and showcases a practical

</details>


### [88] [ModernBERT + ColBERT: Enhancing biomedical RAG through an advanced re-ranking retriever](https://arxiv.org/abs/2510.04757)
*Eduardo Martínez Rivera,Filippo Menolascina*

Main category: cs.CL

TL;DR: A two-stage retrieval architecture combining ModernBERT for initial retrieval and ColBERTv2 for re-ranking improves biomedical RAG performance, achieving state-of-the-art accuracy on MIRAGE benchmark.


<details>
  <summary>Details</summary>
Motivation: Address the trade-off between general-purpose retrievers struggling with domain nuances and in-domain models having prohibitive computational costs in biomedical RAG systems.

Method: Two-stage retrieval: lightweight ModernBERT bidirectional encoder for initial candidate retrieval + ColBERTv2 late-interaction model for fine-grained re-ranking, fine-tuned on 10k PubMedQA question-passage pairs.

Result: ColBERT re-ranker improved Recall@3 by 4.2 percentage points. Achieved state-of-the-art average accuracy of 0.4448 on MIRAGE benchmark, outperforming MedCPT (0.4436).

Conclusion: Joint fine-tuning of retriever and re-ranker is critical for performance; without alignment, re-ranker can degrade results. The architecture effectively balances efficiency and accuracy in biomedical retrieval.

Abstract: Retrieval-Augmented Generation (RAG) is a powerful technique for enriching
Large Language Models (LLMs) with external knowledge, allowing for factually
grounded responses, a critical requirement in high-stakes domains such as
healthcare. However, the efficacy of RAG systems is fundamentally restricted by
the performance of their retrieval module, since irrelevant or semantically
misaligned documents directly compromise the accuracy of the final generated
response. General-purpose dense retrievers can struggle with the nuanced
language of specialised domains, while the high accuracy of in-domain models is
often achieved at prohibitive computational costs. In this work, we aim to
address this trade-off by developing and evaluating a two-stage retrieval
architecture that combines a lightweight ModernBERT bidirectional encoder for
efficient initial candidate retrieval with a ColBERTv2 late-interaction model
for fine-grained re-ranking. We conduct comprehensive evaluations of our
retriever module performance and RAG system performance in the biomedical
context, fine-tuning the IR module using 10k question-passage pairs from
PubMedQA. Our analysis of the retriever module confirmed the positive impact of
the ColBERT re-ranker, which improved Recall@3 by up to 4.2 percentage points
compared to its retrieve-only counterpart. When integrated into the biomedical
RAG, our IR module leads to a state-of-the-art average accuracy of 0.4448 on
the five tasks of the MIRAGE question-answering benchmark, outperforming strong
baselines such as MedCPT (0.4436). Our ablation studies reveal that this
performance is critically dependent on a joint fine-tuning process that aligns
the retriever and re-ranker; otherwise, the re-ranker might degrade the
performance.

</details>


### [89] [Are BabyLMs Deaf to Gricean Maxims? A Pragmatic Evaluation of Sample-efficient Language Models](https://arxiv.org/abs/2510.04764)
*Raha Askari,Sina Zarrieß,Özge Alacam,Judith Sieker*

Main category: cs.CL

TL;DR: The paper introduces a benchmark to test language models' ability to distinguish Gricean maxim violations, comparing BabyLMs trained on <10M and <100M tokens with children and a large LLM.


<details>
  <summary>Details</summary>
Motivation: Implicit meanings are crucial for human communication, and understanding Gricean maxim violations is essential for language models to interpret pragmatic inferences beyond literal words.

Method: Created a novel benchmark based on Surian et al.'s study to test language models' sensitivity to Gricean maxim violations, comparing BabyLMs across five maxims with children and a large LLM.

Result: Models trained on <100M tokens outperform those on <10M tokens but still fall short of child-level and LLM competence. Modest data improvements lead to better pragmatic behavior and finer-grained differentiation.

Conclusion: While increased training data improves some pragmatic capabilities, current smaller models still lag behind human children and large language models in understanding Gricean maxim violations.

Abstract: Implicit meanings are integral to human communication, making it essential
for language models to be capable of identifying and interpreting them. Grice
(1975) proposed a set of conversational maxims that guide cooperative dialogue,
noting that speakers may deliberately violate these principles to express
meanings beyond literal words, and that listeners, in turn, recognize such
violations to draw pragmatic inferences.
  Building on Surian et al. (1996)'s study of children's sensitivity to
violations of Gricean maxims, we introduce a novel benchmark to test whether
language models pretrained on less than 10M and less than 100M tokens can
distinguish maxim-adhering from maxim-violating utterances. We compare these
BabyLMs across five maxims and situate their performance relative to children
and a Large Language Model (LLM) pretrained on 3T tokens.
  We find that overall, models trained on less than 100M tokens outperform
those trained on less than 10M, yet fall short of child-level and LLM
competence. Our results suggest that modest data increases improve some aspects
of pragmatic behavior, leading to finer-grained differentiation between
pragmatic dimensions.

</details>


### [90] [Hybrid Architectures for Language Models: Systematic Analysis and Design Insights](https://arxiv.org/abs/2510.04800)
*Sangmin Bae,Bilge Acun,Haroun Habeeb,Seungyeon Kim,Chien-Yu Lin,Liang Luo,Junjie Wang,Carole-Jean Wu*

Main category: cs.CL

TL;DR: This paper presents a systematic evaluation of hybrid language model architectures combining self-attention with Mamba-style state space models, comparing inter-layer and intra-layer fusion strategies across multiple performance metrics.


<details>
  <summary>Details</summary>
Motivation: While hybrid architectures show promising performance for long-context tasks, there has been no systematic comparison of hybridization strategies or analysis of the key factors behind their effectiveness.

Method: The authors conduct holistic evaluation of hybrid architectures based on inter-layer (sequential) and intra-layer (parallel) fusion, assessing language modeling performance, long-context capabilities, scaling analysis, and training/inference efficiency.

Result: The study identifies the most critical elements for each hybridization strategy and proposes optimal design recipes for both hybrid models by investigating the core characteristics of their computational primitives.

Conclusion: The comprehensive analysis provides practical guidance and valuable insights for developing hybrid language models, facilitating the optimization of architectural configurations.

Abstract: Recent progress in large language models demonstrates that hybrid
architectures--combining self-attention mechanisms with structured state space
models like Mamba--can achieve a compelling balance between modeling quality
and computational efficiency, particularly for long-context tasks. While these
hybrid models show promising performance, systematic comparisons of
hybridization strategies and analyses on the key factors behind their
effectiveness have not been clearly shared to the community. In this work, we
present a holistic evaluation of hybrid architectures based on inter-layer
(sequential) or intra-layer (parallel) fusion. We evaluate these designs from a
variety of perspectives: language modeling performance, long-context
capabilities, scaling analysis, and training and inference efficiency. By
investigating the core characteristics of their computational primitive, we
identify the most critical elements for each hybridization strategy and further
propose optimal design recipes for both hybrid models. Our comprehensive
analysis provides practical guidance and valuable insights for developing
hybrid language models, facilitating the optimization of architectural
configurations.

</details>


### [91] [How I Built ASR for Endangered Languages with a Spoken Dictionary](https://arxiv.org/abs/2510.04832)
*Christopher Bartley,Anton Ragni*

Main category: cs.CL

TL;DR: This paper shows that only 40 minutes of short-form pronunciation data is needed to build usable ASR for endangered languages like Manx Gaelic and Cornish, with less than 50% WER, lowering the barrier for language preservation efforts.


<details>
  <summary>Details</summary>
Motivation: Nearly half of the world's languages are endangered, but standard ASR pipelines require utterance-level supervised data that most endangered languages lack. Existing speech data for languages like Manx Gaelic (2,200 speakers) since 1948 remains unsupported by modern systems.

Method: The authors explore minimal data requirements for ASR by using short-form pronunciation resources as an alternative to standard utterance-level data. They test this approach on Manx Gaelic and replicate it on Cornish (600 speakers).

Result: Using only 40 minutes of short-form pronunciation data produces usable ASR for Manx Gaelic with less than 50% Word Error Rate (WER). The approach is successfully replicated on Cornish, another critically endangered language.

Conclusion: The barrier to building ASR for endangered languages is much lower than previously thought, requiring far less data and different formats than standard pipelines demand. This gives hope to language communities that cannot meet arbitrary data requirements imposed by conventional methods.

Abstract: Nearly half of the world's languages are endangered. Speech technologies such
as Automatic Speech Recognition (ASR) are central to revival efforts, yet most
languages remain unsupported because standard pipelines expect utterance-level
supervised data. Speech data often exist for endangered languages but rarely
match these formats. Manx Gaelic ($\sim$2,200 speakers), for example, has had
transcribed speech since 1948, yet remains unsupported by modern systems. In
this paper, we explore how little data, and in what form, is needed to build
ASR for critically endangered languages. We show that a short-form
pronunciation resource is a viable alternative, and that 40 minutes of such
data produces usable ASR for Manx ($<$50\% WER). We replicate our approach,
applying it to Cornish ($\sim$600 speakers), another critically endangered
language. Results show that the barrier to entry, in quantity and form, is far
lower than previously thought, giving hope to endangered language communities
that cannot afford to meet the requirements arbitrarily imposed upon them.

</details>


### [92] [Instability in Downstream Task Performance During LLM Pretraining](https://arxiv.org/abs/2510.04848)
*Yuto Nishida,Masaru Isonuma,Yusuke Oda*

Main category: cs.CL

TL;DR: LLM training checkpoints show unstable downstream task performance. Checkpoint averaging and ensemble methods improve stability without modifying training.


<details>
  <summary>Details</summary>
Motivation: Downstream metrics fluctuate substantially during LLM training, making it difficult to identify the best-performing checkpoint.

Method: Analyze performance stability in LLM training, then investigate checkpoint averaging and ensemble methods to aggregate neighboring checkpoints.

Result: Task scores frequently fluctuate throughout training. Checkpoint averaging and ensemble methods reduce performance volatility and improve stability.

Conclusion: Post-hoc checkpoint integration methods effectively improve downstream performance stability without requiring training procedure changes.

Abstract: When training large language models (LLMs), it is common practice to track
downstream task performance throughout the training process and select the
checkpoint with the highest validation score. However, downstream metrics often
exhibit substantial fluctuations, making it difficult to identify the
checkpoint that truly represents the best-performing model. In this study, we
empirically analyze the stability of downstream task performance in an LLM
trained on diverse web-scale corpora. We find that task scores frequently
fluctuate throughout training, both at the aggregate and example levels. To
address this instability, we investigate two post-hoc checkpoint integration
methods: checkpoint averaging and ensemble, motivated by the hypothesis that
aggregating neighboring checkpoints can reduce performance volatility. We
demonstrate both empirically and theoretically that these methods improve
downstream performance stability without requiring any changes to the training
procedure.

</details>


### [93] [When Models Lie, We Learn: Multilingual Span-Level Hallucination Detection with PsiloQA](https://arxiv.org/abs/2510.04849)
*Elisei Rykov,Kseniia Petrushina,Maksim Savkin,Valerii Olisov,Artem Vazhentsev,Kseniia Titova,Alexander Panchenko,Vasily Konovalov,Julia Belikova*

Main category: cs.CL

TL;DR: PsiloQA is a large-scale multilingual dataset for span-level hallucination detection across 14 languages, created via automated pipeline using GPT-4o, enabling comprehensive evaluation of detection methods.


<details>
  <summary>Details</summary>
Motivation: Existing hallucination benchmarks are limited to sequence-level detection and English-only, lacking fine-grained multilingual supervision needed for comprehensive evaluation of LLM hallucinations.

Method: Automated three-stage pipeline: 1) Generate question-answer pairs from Wikipedia using GPT-4o, 2) Elicit potentially hallucinated answers from diverse LLMs in no-context setting, 3) Automatically annotate hallucinated spans using GPT-4o by comparing against golden answers and retrieved context.

Result: Encoder-based models achieve strongest performance across languages. PsiloQA demonstrates effective cross-lingual generalization and supports robust knowledge transfer to other benchmarks, while being significantly more cost-efficient than human-annotated datasets.

Conclusion: PsiloQA advances development of scalable, fine-grained hallucination detection in multilingual settings, providing comprehensive evaluation framework for LLM safety and reliability.

Abstract: Hallucination detection remains a fundamental challenge for the safe and
reliable deployment of large language models (LLMs), especially in applications
requiring factual accuracy. Existing hallucination benchmarks often operate at
the sequence level and are limited to English, lacking the fine-grained,
multilingual supervision needed for a comprehensive evaluation. In this work,
we introduce PsiloQA, a large-scale, multilingual dataset annotated with
span-level hallucinations across 14 languages. PsiloQA is constructed through
an automated three-stage pipeline: generating question-answer pairs from
Wikipedia using GPT-4o, eliciting potentially hallucinated answers from diverse
LLMs in a no-context setting, and automatically annotating hallucinated spans
using GPT-4o by comparing against golden answers and retrieved context. We
evaluate a wide range of hallucination detection methods -- including
uncertainty quantification, LLM-based tagging, and fine-tuned encoder models --
and show that encoder-based models achieve the strongest performance across
languages. Furthermore, PsiloQA demonstrates effective cross-lingual
generalization and supports robust knowledge transfer to other benchmarks, all
while being significantly more cost-efficient than human-annotated datasets.
Our dataset and results advance the development of scalable, fine-grained
hallucination detection in multilingual settings.

</details>


### [94] [Detecting Distillation Data from Reasoning Models](https://arxiv.org/abs/2510.04850)
*Hengxiang Zhang,Hyeong Kyu Choi,Yixuan Li,Hongxin Wei*

Main category: cs.CL

TL;DR: The paper proposes Token Probability Deviation (TBD), a method to detect distillation data contamination by analyzing probability patterns of generated tokens, achieving strong performance with 0.918 AUC.


<details>
  <summary>Details</summary>
Motivation: Reasoning distillation can cause benchmark contamination when evaluation data is included in distillation datasets, inflating performance metrics of distilled models.

Method: Token Probability Deviation (TBD) quantifies how far generated tokens' probabilities deviate from a high reference probability, leveraging that distilled models produce near-deterministic tokens for seen questions but more low-probability tokens for unseen questions.

Result: The method achieves competitive detection performance with 0.918 AUC and 0.470 TPR@1% FPR on the S1 dataset, showing lower scores for seen questions than unseen questions.

Conclusion: TBD is an effective approach for detecting distillation data contamination by analyzing token probability patterns, addressing the challenge of partial data availability in distillation scenarios.

Abstract: Reasoning distillation has emerged as an efficient and powerful paradigm for
enhancing the reasoning capabilities of large language models. However,
reasoning distillation may inadvertently cause benchmark contamination, where
evaluation data included in distillation datasets can inflate performance
metrics of distilled models. In this work, we formally define the task of
distillation data detection, which is uniquely challenging due to the partial
availability of distillation data. Then, we propose a novel and effective
method Token Probability Deviation (TBD), which leverages the probability
patterns of the generated output tokens. Our method is motivated by the
analysis that distilled models tend to generate near-deterministic tokens for
seen questions, while producing more low-probability tokens for unseen
questions. Our key idea behind TBD is to quantify how far the generated tokens'
probabilities deviate from a high reference probability. In effect, our method
achieves competitive detection performance by producing lower scores for seen
questions than for unseen questions. Extensive experiments demonstrate the
effectiveness of our method, achieving an AUC of 0.918 and a TPR@1% FPR of
0.470 on the S1 dataset.

</details>


### [95] [SocialHarmBench: Revealing LLM Vulnerabilities to Socially Harmful Requests](https://arxiv.org/abs/2510.04891)
*Punya Syon Pandey,Hai Son Le,Devansh Bhardwaj,Rada Mihalcea,Zhijing Jin*

Main category: cs.CL

TL;DR: SocialHarmBench is a dataset of 585 prompts across 7 sociopolitical categories and 34 countries that reveals LLMs' vulnerabilities in politically sensitive contexts, with open-weight models showing up to 98% attack success rates in areas like propaganda and political manipulation.


<details>
  <summary>Details</summary>
Motivation: Existing safety benchmarks rarely test LLM vulnerabilities in high-stakes sociopolitical domains like political manipulation, propaganda, surveillance, and disinformation generation, despite the real-world consequences of failures in these areas.

Method: Created SocialHarmBench - a dataset of 585 prompts spanning 7 sociopolitical categories and 34 countries, then evaluated LLMs' responses to surface vulnerabilities in politically charged contexts.

Result: Open-weight models showed high vulnerability to harmful compliance, with Mistral-7B reaching 97-98% attack success rates in historical revisionism, propaganda, and political manipulation. LLMs were most fragile with 21st-century/pre-20th-century contexts and prompts from Latin America, USA, and UK regions.

Conclusion: Current LLM safeguards fail to generalize to high-stakes sociopolitical settings, exposing systematic biases and raising concerns about LLM reliability in preserving human rights and democratic values.

Abstract: Large language models (LLMs) are increasingly deployed in contexts where
their failures can have direct sociopolitical consequences. Yet, existing
safety benchmarks rarely test vulnerabilities in domains such as political
manipulation, propaganda and disinformation generation, or surveillance and
information control. We introduce SocialHarmBench, a dataset of 585 prompts
spanning 7 sociopolitical categories and 34 countries, designed to surface
where LLMs most acutely fail in politically charged contexts. Our evaluations
reveal several shortcomings: open-weight models exhibit high vulnerability to
harmful compliance, with Mistral-7B reaching attack success rates as high as
97% to 98% in domains such as historical revisionism, propaganda, and political
manipulation. Moreover, temporal and geographic analyses show that LLMs are
most fragile when confronted with 21st-century or pre-20th-century contexts,
and when responding to prompts tied to regions such as Latin America, the USA,
and the UK. These findings demonstrate that current safeguards fail to
generalize to high-stakes sociopolitical settings, exposing systematic biases
and raising concerns about the reliability of LLMs in preserving human rights
and democratic values. We share the SocialHarmBench benchmark at
https://huggingface.co/datasets/psyonp/SocialHarmBench.

</details>


### [96] [Do LLMs Align with My Task? Evaluating Text-to-SQL via Dataset Alignment](https://arxiv.org/abs/2510.04919)
*Davood Rafiei,Morgan Lindsay Heisler,Weiwei Zhang,Mohammadreza Pourreza,Yong Zhang*

Main category: cs.CL

TL;DR: Structural alignment between training data and target queries is a strong predictor of SFT success in NL2SQL tasks, with high alignment leading to substantial performance gains and low alignment yielding marginal improvements.


<details>
  <summary>Details</summary>
Motivation: Variability in training data hinders LLMs' generalization across domains in NL2SQL tasks, and understanding how data alignment impacts model performance is crucial for effective fine-tuning.

Method: Estimate alignment by comparing distributions of structural SQL features across training set, target data, and model predictions before SFT, using comprehensive experiments on three cross-domain NL2SQL benchmarks and multiple model families.

Result: Structural alignment strongly predicts fine-tuning success - high alignment yields substantial accuracy and SQL generation improvements, while low alignment provides marginal or no gains.

Conclusion: Alignment-aware data selection is essential for effective fine-tuning and generalization in NL2SQL tasks, as structural alignment between training and target data determines SFT success.

Abstract: Supervised Fine-Tuning (SFT) is an effective method for adapting Large
Language Models (LLMs) on downstream tasks. However, variability in training
data can hinder a model's ability to generalize across domains. This paper
studies the problem of dataset alignment for Natural Language to SQL (NL2SQL or
text to SQL), examining how well SFT training data matches the structural
characteristics of target queries and how this alignment impacts model
performance. We hypothesize that alignment can be accurately estimated by
comparing the distributions of structural SQL features across the training set,
target data, and the model's predictions prior to SFT. Through comprehensive
experiments on three large cross-domain NL2SQL benchmarks and multiple model
families, we show that structural alignment is a strong predictor of
fine-tuning success. When alignment is high, SFT yields substantial gains in
accuracy and SQL generation quality; when alignment is low, improvements are
marginal or absent. These findings highlight the importance of alignment-aware
data selection for effective fine-tuning and generalization in NL2SQL tasks.

</details>


### [97] [The Geometry of Truth: Layer-wise Semantic Dynamics for Hallucination Detection in Large Language Models](https://arxiv.org/abs/2510.04933)
*Amir Hameed Mir*

Main category: cs.CL

TL;DR: LSD is a geometric framework that detects LLM hallucinations by analyzing semantic evolution across transformer layers, achieving high accuracy with single forward pass efficiency.


<details>
  <summary>Details</summary>
Motivation: Address LLM hallucination risks in high-stakes domains by developing an intrinsic detection method that doesn't require multiple sampling or external verification.

Method: Uses margin-based contrastive learning to align hidden activations with ground-truth embeddings, revealing semantic drift patterns across transformer layers.

Result: Achieves F1-score of 0.92, AUROC of 0.96, and clustering accuracy of 0.89 on TruthfulQA and synthetic datasets, with 5-20x speedup over sampling methods.

Conclusion: LSD provides scalable, model-agnostic real-time hallucination monitoring and offers insights into the geometry of factual consistency in LLMs.

Abstract: Large Language Models (LLMs) often produce fluent yet factually incorrect
statements-a phenomenon known as hallucination-posing serious risks in
high-stakes domains. We present Layer-wise Semantic Dynamics (LSD), a geometric
framework for hallucination detection that analyzes the evolution of
hidden-state semantics across transformer layers. Unlike prior methods that
rely on multiple sampling passes or external verification sources, LSD operates
intrinsically within the model's representational space. Using margin-based
contrastive learning, LSD aligns hidden activations with ground-truth
embeddings derived from a factual encoder, revealing a distinct separation in
semantic trajectories: factual responses preserve stable alignment, while
hallucinations exhibit pronounced semantic drift across depth. Evaluated on the
TruthfulQA and synthetic factual-hallucination datasets, LSD achieves an
F1-score of 0.92, AUROC of 0.96, and clustering accuracy of 0.89, outperforming
SelfCheckGPT and Semantic Entropy baselines while requiring only a single
forward pass. This efficiency yields a 5-20x speedup over sampling-based
methods without sacrificing precision or interpretability. LSD offers a
scalable, model-agnostic mechanism for real-time hallucination monitoring and
provides new insights into the geometry of factual consistency within large
language models.

</details>


### [98] [A First Context-Free Grammar Applied to Nawatl Corpora Augmentation](https://arxiv.org/abs/2510.04945)
*Juan-José Guzmán-Landa,Juan-Manuel Torres-Moreno,Miguel Figueroa-Saavedra,Ligia Quintana-Torres,Martha-Lorena Avendaño-Garrido,Graham Ranger*

Main category: cs.CL

TL;DR: A context-free grammar (CFG) is developed for Nawatl language to generate artificial sentences and expand corpora for language model training, showing preliminary improvements over some LLMs.


<details>
  <summary>Details</summary>
Motivation: Nawatl is a low-resource language with virtually no digital corpora available for machine learning, making it difficult to train language models effectively.

Method: Develop a context-free grammar (CFG) for Nawatl to generate grammatically correct artificial sentences, expanding the existing π-yalli corpus for training algorithms like FastText.

Result: Preliminary results show comparative improvements over some LLMs when using the grammar-expanded corpus, but more effective grammars are needed for significant improvement.

Conclusion: CFG-based corpus expansion is a viable approach for low-resource languages like Nawatl, but more sophisticated grammars are required to achieve substantial performance gains in language model training.

Abstract: In this article we introduce a context-free grammar (CFG) for the Nawatl
language. Nawatl (or Nahuatl) is an Amerindian language of the $\pi$-language
type, i.e. a language with few digital resources, in which the corpora
available for machine learning are virtually non-existent. The objective here
is to generate a significant number of grammatically correct artificial
sentences, in order to increase the corpora available for language model
training. We want to show that a grammar enables us significantly to expand a
corpus in Nawatl which we call $\pi$-\textsc{yalli}. The corpus, thus enriched,
enables us to train algorithms such as FastText and to evaluate them on
sentence-level semantic tasks. Preliminary results show that by using the
grammar, comparative improvements are achieved over some LLMs. However, it is
observed that to achieve more significant improvement, grammars that model the
Nawatl language even more effectively are required.

</details>


### [99] [Mind Your Tone: Investigating How Prompt Politeness Affects LLM Accuracy (short paper)](https://arxiv.org/abs/2510.04950)
*Om Dobariya,Akhil Kumar*

Main category: cs.CL

TL;DR: Study shows impolite prompts surprisingly outperform polite ones in LLM accuracy, with Very Rude prompts achieving 84.8% accuracy vs 80.8% for Very Polite prompts.


<details>
  <summary>Details</summary>
Motivation: To investigate how varying levels of prompt politeness affect model accuracy on multiple-choice questions, as the role of politeness and tone in LLM performance remains underexplored.

Method: Created 50 base questions across math, science, and history, each rewritten into five tone variants (Very Polite, Polite, Neutral, Rude, Very Rude), yielding 250 prompts. Evaluated using ChatGPT 4o with paired sample t-tests for statistical significance.

Result: Impolite prompts consistently outperformed polite ones, with accuracy ranging from 80.8% (Very Polite) to 84.8% (Very Rude). This contradicts earlier studies that associated rudeness with poorer outcomes.

Conclusion: Newer LLMs may respond differently to tonal variation than earlier models. Findings highlight the importance of studying pragmatic aspects of prompting and raise questions about social dimensions of human-AI interaction.

Abstract: The wording of natural language prompts has been shown to influence the
performance of large language models (LLMs), yet the role of politeness and
tone remains underexplored. In this study, we investigate how varying levels of
prompt politeness affect model accuracy on multiple-choice questions. We
created a dataset of 50 base questions spanning mathematics, science, and
history, each rewritten into five tone variants: Very Polite, Polite, Neutral,
Rude, and Very Rude, yielding 250 unique prompts. Using ChatGPT 4o, we
evaluated responses across these conditions and applied paired sample t-tests
to assess statistical significance. Contrary to expectations, impolite prompts
consistently outperformed polite ones, with accuracy ranging from 80.8% for
Very Polite prompts to 84.8% for Very Rude prompts. These findings differ from
earlier studies that associated rudeness with poorer outcomes, suggesting that
newer LLMs may respond differently to tonal variation. Our results highlight
the importance of studying pragmatic aspects of prompting and raise broader
questions about the social dimensions of human-AI interaction.

</details>


### [100] [AWARE, Beyond Sentence Boundaries: A Contextual Transformer Framework for Identifying Cultural Capital in STEM Narratives](https://arxiv.org/abs/2510.04983)
*Khalid Mehtab Khan,Anagha Kulkarni*

Main category: cs.CL

TL;DR: AWARE framework improves cultural capital theme detection in student reflections through domain, context, and class overlap awareness, outperforming baselines by 2.1% in Macro-F1.


<details>
  <summary>Details</summary>
Motivation: Cultural capital themes in student reflections are valuable for equitable learning but hard to detect with standard NLP models due to narrative context and domain-specific language.

Method: AWARE framework with three components: Domain Awareness (vocabulary adaptation), Context Awareness (essay-level embeddings), and Class Overlap Awareness (multi-label classification).

Result: AWARE outperforms strong baseline by 2.1 percentage points in Macro-F1 and shows considerable improvements across all cultural capital themes.

Conclusion: Provides robust methodology for text classification tasks where meaning depends on narrative context, generalizable beyond cultural capital detection.

Abstract: Identifying cultural capital (CC) themes in student reflections can offer
valuable insights that help foster equitable learning environments in
classrooms. However, themes such as aspirational goals or family support are
often woven into narratives, rather than appearing as direct keywords. This
makes them difficult to detect for standard NLP models that process sentences
in isolation. The core challenge stems from a lack of awareness, as standard
models are pre-trained on general corpora, leaving them blind to the
domain-specific language and narrative context inherent to the data. To address
this, we introduce AWARE, a framework that systematically attempts to improve a
transformer model's awareness for this nuanced task. AWARE has three core
components: 1) Domain Awareness, adapting the model's vocabulary to the
linguistic style of student reflections; 2) Context Awareness, generating
sentence embeddings that are aware of the full essay context; and 3) Class
Overlap Awareness, employing a multi-label strategy to recognize the
coexistence of themes in a single sentence. Our results show that by making the
model explicitly aware of the properties of the input, AWARE outperforms a
strong baseline by 2.1 percentage points in Macro-F1 and shows considerable
improvements across all themes. This work provides a robust and generalizable
methodology for any text classification task in which meaning depends on the
context of the narrative.

</details>


### [101] [Resource-Efficient Fine-Tuning of LLaMA-3.2-3B for Medical Chain-of-Thought Reasoning](https://arxiv.org/abs/2510.05003)
*Imran Mansha*

Main category: cs.CL

TL;DR: Resource-efficient fine-tuning of LLaMA-3.2-3B using LoRA and QLoRA techniques for medical chain-of-thought reasoning, achieving 60% memory reduction while maintaining reasoning capability.


<details>
  <summary>Details</summary>
Motivation: LLMs require significant computational resources for fine-tuning, making it challenging to deploy them in low-resource research environments, particularly for medical applications.

Method: Parameter-efficient tuning techniques (LoRA and QLoRA) applied to LLaMA-3.2-3B model on publicly available medical reasoning datasets under constrained GPU and memory settings.

Result: Achieved improved reasoning coherence and factual accuracy with up to 60% memory reduction compared to standard full fine-tuning, while retaining strong reasoning capability in medical question-answering tasks.

Conclusion: Lightweight adaptations can effectively balance efficiency and domain specialization for medical AI systems, providing practical deployment strategies for low-resource environments.

Abstract: Large Language Models (LLMs) such as GPT-4 and LLaMA have demonstrated
remarkable reasoning abilities but require significant computational resources
for fine-tuning. This paper presents a resource-efficient fine-tuning approach
for LLaMA-3.2-3B to enhance medical chain-of-thought reasoning while operating
under constrained GPU and memory settings. Using parameter-efficient tuning
techniques such as LoRA and QLoRA, we adapt the base model on publicly
available medical reasoning datasets. The model achieves improved reasoning
coherence and factual accuracy while reducing memory usage by up to 60%
compared to standard full fine-tuning. Experimental evaluation demonstrates
that lightweight adaptations can retain strong reasoning capability in medical
question-answering tasks. This work highlights practical strategies for
deploying LLMs in low-resource research environments and provides insights into
balancing efficiency and domain specialization for medical AI systems.

</details>


### [102] [Imperceptible Jailbreaking against Large Language Models](https://arxiv.org/abs/2510.05025)
*Kuofeng Gao,Yiming Li,Chao Du,Xin Wang,Xingjun Ma,Shu-Tao Xia,Tianyu Pang*

Main category: cs.CL

TL;DR: The paper introduces imperceptible jailbreak attacks using invisible Unicode variation selectors that alter tokenization while keeping prompts visually identical, achieving high success rates against aligned LLMs.


<details>
  <summary>Details</summary>
Motivation: Current jailbreaking attacks on vision use imperceptible perturbations, while text attacks require visible modifications. The authors aim to create imperceptible text jailbreaks that exploit Unicode variation selectors.

Method: Proposed a chain-of-search pipeline to generate adversarial suffixes using invisible variation selectors that alter tokenization without visible changes to the prompt.

Result: Achieved high attack success rates against four aligned LLMs and demonstrated generalization to prompt injection attacks, all without producing visible modifications.

Conclusion: Imperceptible jailbreaks using Unicode variation selectors are effective and pose a significant security threat to LLMs, as they bypass visual detection while successfully inducing harmful responses.

Abstract: Jailbreaking attacks on the vision modality typically rely on imperceptible
adversarial perturbations, whereas attacks on the textual modality are
generally assumed to require visible modifications (e.g., non-semantic
suffixes). In this paper, we introduce imperceptible jailbreaks that exploit a
class of Unicode characters called variation selectors. By appending invisible
variation selectors to malicious questions, the jailbreak prompts appear
visually identical to original malicious questions on screen, while their
tokenization is "secretly" altered. We propose a chain-of-search pipeline to
generate such adversarial suffixes to induce harmful responses. Our experiments
show that our imperceptible jailbreaks achieve high attack success rates
against four aligned LLMs and generalize to prompt injection attacks, all
without producing any visible modifications in the written prompt. Our code is
available at https://github.com/sail-sg/imperceptible-jailbreaks.

</details>


### [103] [A Set of Quebec-French Corpus of Regional Expressions and Terms](https://arxiv.org/abs/2510.05026)
*David Beauchemin,Yan Tremblay,Mohamed Amine Youssef,Richard Khoury*

Main category: cs.CL

TL;DR: The paper introduces two new benchmark datasets (QFrCoRE and QFrCoRT) for testing dialect understanding in Quebec French using regional idioms, and shows these benchmarks effectively measure LLM dialect proficiency.


<details>
  <summary>Details</summary>
Motivation: To combine idiom understanding and dialect understanding by using regional idioms as a test case for dialect proficiency, specifically focusing on Quebec French.

Method: Created two benchmark datasets: QFrCoRE (4,633 idiomatic phrases) and QFrCoRT (171 regional idiomatic words) for Quebec French, with a replicable methodology for other dialects. Tested 94 LLMs on these benchmarks.

Result: Experiments demonstrated that the regional idiom benchmarks are reliable tools for measuring a model's proficiency in specific dialects.

Conclusion: Regional idioms serve as effective benchmarks for evaluating dialect understanding in language models, and the proposed methodology can be replicated for other dialects.

Abstract: The tasks of idiom understanding and dialect understanding are both
well-established benchmarks in natural language processing. In this paper, we
propose combining them, and using regional idioms as a test of dialect
understanding. Towards this end, we propose two new benchmark datasets for the
Quebec dialect of French: QFrCoRE, which contains 4,633 instances of idiomatic
phrases, and QFrCoRT, which comprises 171 regional instances of idiomatic
words. We explain how to construct these corpora, so that our methodology can
be replicated for other dialects. Our experiments with 94 LLM demonstrate that
our regional idiom benchmarks are a reliable tool for measuring a model's
proficiency in a specific dialect.

</details>


### [104] [Guided Query Refinement: Multimodal Hybrid Retrieval with Test-Time Optimization](https://arxiv.org/abs/2510.05038)
*Omri Uzan,Asaf Yehudai,Roi pony,Eyal Shnarch,Ariel Gera*

Main category: cs.CL

TL;DR: GQR is a test-time optimization method that enhances vision-centric document retrieval by refining query embeddings using guidance from a complementary text retriever, achieving better performance with significantly improved efficiency.


<details>
  <summary>Details</summary>
Motivation: Vision-centric multimodal retrieval models face deployment challenges due to large representation sizes and modality gaps, while existing hybrid methods fail to exploit rich interactions between different retrieval models.

Method: Guided Query Refinement (GQR) - a test-time optimization that refines a primary retriever's query embedding using guidance from a complementary retriever's scores, enabling better interaction between representation spaces.

Result: GQR allows vision-centric models to match performance of models with significantly larger representations while being 14x faster and requiring 54x less memory, pushing the Pareto frontier for performance and efficiency.

Conclusion: GQR effectively bridges the modality gap and addresses scalability issues in multimodal retrieval through intelligent query refinement at test time.

Abstract: Multimodal encoders have pushed the boundaries of visual document retrieval,
matching textual query tokens directly to image patches and achieving
state-of-the-art performance on public benchmarks. Recent models relying on
this paradigm have massively scaled the sizes of their query and document
representations, presenting obstacles to deployment and scalability in
real-world pipelines. Furthermore, purely vision-centric approaches may be
constrained by the inherent modality gap still exhibited by modern
vision-language models. In this work, we connect these challenges to the
paradigm of hybrid retrieval, investigating whether a lightweight dense text
retriever can enhance a stronger vision-centric model. Existing hybrid methods,
which rely on coarse-grained fusion of ranks or scores, fail to exploit the
rich interactions within each model's representation space. To address this, we
introduce Guided Query Refinement (GQR), a novel test-time optimization method
that refines a primary retriever's query embedding using guidance from a
complementary retriever's scores. Through extensive experiments on visual
document retrieval benchmarks, we demonstrate that GQR allows vision-centric
models to match the performance of models with significantly larger
representations, while being up to 14x faster and requiring 54x less memory.
Our findings show that GQR effectively pushes the Pareto frontier for
performance and efficiency in multimodal retrieval. We release our code at
https://github.com/IBM/test-time-hybrid-retrieval

</details>


### [105] [COLE: a Comprehensive Benchmark for French Language Understanding Evaluation](https://arxiv.org/abs/2510.05046)
*David Beauchemin,Yan Tremblay,Mohamed Amine Youssef,Richard Khoury*

Main category: cs.CL

TL;DR: COLE is a new French NLU benchmark with 23 diverse tasks, benchmarking 94 LLMs to analyze the state of French NLU, revealing performance gaps between closed/open models and identifying challenging frontiers.


<details>
  <summary>Details</summary>
Motivation: To address the need for more comprehensive evaluation of French Natural Language Understanding capabilities, particularly focusing on linguistic phenomena specific to French.

Method: Created COLE benchmark with 23 diverse NLU tasks covering sentiment analysis, paraphrase detection, grammatical judgment, reasoning, etc. Benchmarked 94 large language models on this comprehensive evaluation framework.

Result: Identified significant performance gap between closed- and open-weights models. Found key challenging frontiers including zero-shot extractive QA, fine-grained word sense disambiguation, and understanding of regional language variations.

Conclusion: COLE is released as a public resource to foster further progress in French language modeling, providing an extensive analysis of current French NLU capabilities and highlighting areas needing improvement.

Abstract: To address the need for a more comprehensive evaluation of French Natural
Language Understanding (NLU), we introduce COLE, a new benchmark composed of 23
diverse task covering a broad range of NLU capabilities, including sentiment
analysis, paraphrase detection, grammatical judgment, and reasoning, with a
particular focus on linguistic phenomena relevant to the French language. We
benchmark 94 large language models (LLM), providing an extensive analysis of
the current state of French NLU. Our results highlight a significant
performance gap between closed- and open-weights models and identify key
challenging frontiers for current LLMs, such as zero-shot extractive
question-answering (QA), fine-grained word sense disambiguation, and
understanding of regional language variations. We release COLE as a public
resource to foster further progress in French language modelling.

</details>


### [106] [SwiReasoning: Switch-Thinking in Latent and Explicit for Pareto-Superior Reasoning LLMs](https://arxiv.org/abs/2510.05069)
*Dachuan Shi,Abedelkadir Asi,Keying Li,Xiangchi Yuan,Leyan Pan,Wenke Lee,Wen Xiao*

Main category: cs.CL

TL;DR: SwiReasoning is a training-free framework that dynamically switches between explicit and latent reasoning using entropy-based confidence estimation, improving accuracy and token efficiency in LLM reasoning tasks.


<details>
  <summary>Details</summary>
Motivation: Latent reasoning in LLMs faces challenges: 1) broad search distribution diffuses probability mass and hurts accuracy, 2) overthinking wastes tokens and degrades efficiency, especially in training-free settings.

Method: SwiReasoning dynamically switches between explicit and latent reasoning guided by block-wise confidence estimated from entropy trends, and limits maximum thinking-block switches to curb overthinking.

Result: On mathematics and STEM benchmarks, SwiReasoning improves average accuracy by 1.5%-2.8% across different LLMs, and improves token efficiency by 56%-79% under constrained budgets.

Conclusion: SwiReasoning effectively balances exploration and exploitation in LLM reasoning, promoting timely convergence while significantly improving both accuracy and token efficiency.

Abstract: Recent work shows that, beyond discrete reasoning through explicit
chain-of-thought steps, which are limited by the boundaries of natural
languages, large language models (LLMs) can also reason continuously in latent
space, allowing richer information per step and thereby improving token
efficiency. Despite this promise, latent reasoning still faces two challenges,
especially in training-free settings: 1) purely latent reasoning broadens the
search distribution by maintaining multiple implicit paths, which diffuses
probability mass, introduces noise, and impedes convergence to a single
high-confidence solution, thereby hurting accuracy; and 2) overthinking
persists even without explicit text, wasting tokens and degrading efficiency.
To address these issues, we introduce SwiReasoning, a training-free framework
for LLM reasoning which features two key innovations: 1) SwiReasoning
dynamically switches between explicit and latent reasoning, guided by
block-wise confidence estimated from entropy trends in next-token
distributions, to balance exploration and exploitation and promote timely
convergence. 2) By limiting the maximum number of thinking-block switches,
SwiReasoning curbs overthinking and improves token efficiency across varying
problem difficulties. On widely used mathematics and STEM benchmarks,
SwiReasoning consistently improves average accuracy by 1.5%-2.8% across
reasoning LLMs of different model families and scales. Furthermore, under
constrained budgets, SwiReasoning improves average token efficiency by 56%-79%,
with larger gains as budgets tighten.

</details>


### [107] [Slm-mux: Orchestrating small language models for reasoning](https://arxiv.org/abs/2510.05077)
*Chenyu Wang,Zishen Wan,Hao Kang,Emma Chen,Zhiqiang Xie,Tushar Krishna,Vijay Janapa Reddi,Yilun Du*

Main category: cs.CL

TL;DR: A three-stage approach called SLM-MUX that orchestrates multiple small language models (SLMs) to achieve higher accuracy than individual models, with optimization strategies for model selection and test-time scaling.


<details>
  <summary>Details</summary>
Motivation: Small language models are efficient and excel at specific tasks, but existing orchestration methods perform poorly with SLMs compared to frontier models. The goal is to create systems where multiple SLMs can work together effectively.

Method: Three-stage approach: 1) SLM-MUX multi-model architecture for coordinating SLMs, 2) Model selection search to find complementary SLMs, 3) Test-time scaling tailored for SLM-MUX.

Result: Achieved up to 13.4% improvement on MATH, 8.8% on GPQA, and 7.0% on GSM8K compared to existing methods. With just two SLMs, outperformed Qwen 2.5 72B on GPQA and GSM8K, and matched its performance on MATH.

Conclusion: SLMs can be effectively orchestrated into more accurate and efficient systems through the proposed SLM-MUX approach with proper optimization strategies.

Abstract: With the rapid development of language models, the number of small language
models (SLMs) has grown significantly. Although they do not achieve
state-of-the-art accuracy, they are more efficient and often excel at specific
tasks. This raises a natural question: can multiple SLMs be orchestrated into a
system where each contributes effectively, achieving higher accuracy than any
individual model? Existing orchestration methods have primarily targeted
frontier models (e.g., GPT-4) and perform suboptimally when applied to SLMs. To
address this gap, we propose a three-stage approach for orchestrating SLMs.
First, we introduce SLM-MUX, a multi-model architecture that effectively
coordinates multiple SLMs. Building on this, we develop two optimization
strategies: (i) a model selection search that identifies the most complementary
SLMs from a given pool, and (ii) test-time scaling tailored to SLM-MUX. Our
approach delivers strong results: Compared to existing orchestration methods,
our approach achieves up to 13.4% improvement on MATH, 8.8% on GPQA, and 7.0%
on GSM8K. With just two SLMS, SLM-MUX outperforms Qwen 2.5 72B on GPQA and
GSM8K, and matches its performance on MATH. We further provide theoretical
analyses to substantiate the advantages of our method. In summary, we
demonstrate that SLMs can be effectively orchestrated into more accurate and
efficient systems through the proposed approach.

</details>


### [108] [TeachLM: Post-Training LLMs for Education Using Authentic Learning Data](https://arxiv.org/abs/2510.05087)
*Janos Perczel,Jin Chow,Dorottya Demszky*

Main category: cs.CL

TL;DR: TeachLM is an LLM fine-tuned for teaching using authentic student-tutor interaction data, enabling better pedagogical dialogue and evaluation through synthetic student generation.


<details>
  <summary>Details</summary>
Motivation: Current LLMs lack high-quality educational training data and have limited ability to encode complex pedagogical strategies through prompt engineering alone.

Method: Parameter-efficient fine-tuning of state-of-the-art LLMs on 100,000 hours of anonymized student-tutor interactions, creating an authentic student model for synthetic dialogue generation.

Result: Fine-tuning on authentic learning data doubled student talk time, improved questioning style, increased dialogue turns by 50%, and enabled greater personalization of instruction.

Conclusion: TeachLM demonstrates that fine-tuning on authentic educational data significantly enhances LLMs' conversational and pedagogical capabilities for teaching applications.

Abstract: The promise of generative AI to revolutionize education is constrained by the
pedagogical limits of large language models (LLMs). A major issue is the lack
of access to high-quality training data that reflect the learning of actual
students. Prompt engineering has emerged as a stopgap, but the ability of
prompts to encode complex pedagogical strategies in rule-based natural language
is inherently limited. To address this gap we introduce TeachLM - an LLM
optimized for teaching through parameter-efficient fine-tuning of
state-of-the-art models. TeachLM is trained on a dataset comprised of 100,000
hours of one-on-one, longitudinal student-tutor interactions maintained by
Polygence, which underwent a rigorous anonymization process to protect privacy.
We use parameter-efficient fine-tuning to develop an authentic student model
that enables the generation of high-fidelity synthetic student-tutor dialogues.
Building on this capability, we propose a novel multi-turn evaluation protocol
that leverages synthetic dialogue generation to provide fast, scalable, and
reproducible assessments of the dialogical capabilities of LLMs. Our
evaluations demonstrate that fine-tuning on authentic learning data
significantly improves conversational and pedagogical performance - doubling
student talk time, improving questioning style, increasing dialogue turns by
50%, and greater personalization of instruction.

</details>


### [109] [Finish First, Perfect Later: Test-Time Token-Level Cross-Validation for Diffusion Large Language Models](https://arxiv.org/abs/2510.05090)
*Runchu Tian,Junxia Cui,Xueqiang Xu,Feng Yao,Jingbo Shang*

Main category: cs.CL

TL;DR: Tolerator is a training-free decoding strategy for diffusion LLMs that enables token revision through cross-validation, addressing the limitation of irreversible token acceptance in vanilla diffusion decoding.


<details>
  <summary>Details</summary>
Motivation: Vanilla decoding in discrete diffusion LLMs suffers from irreversible token acceptance where early mistakes persist throughout decoding, harming output quality. This motivates the need for a method that allows token revision.

Method: Two-stage process: (1) sequence fill-up, (2) iterative refinement by remasking and decoding a subset of tokens while using remaining tokens as context, enabling cross-validation and correction of previously accepted tokens.

Result: Consistent improvements over baselines on five benchmarks covering language understanding, code generation, and mathematics under the same computational budget.

Conclusion: Decoding algorithms are crucial to realizing the full potential of diffusion large language models, and Tolerator demonstrates that enabling token revision through cross-validation significantly improves output quality.

Abstract: Diffusion large language models (dLLMs) have recently emerged as a promising
alternative to autoregressive (AR) models, offering advantages such as
accelerated parallel decoding and bidirectional context modeling. However, the
vanilla decoding strategy in discrete dLLMs suffers from a critical limitation:
once a token is accepted, it can no longer be revised in subsequent steps. As a
result, early mistakes persist across iterations, harming both intermediate
predictions and final output quality. To address this issue, we propose
Tolerator (Token-Level Cross-Validation Refinement), a training-free decoding
strategy that leverages cross-validation among predicted tokens. Unlike
existing methods that follow a single progressive unmasking procedure,
Tolerator introduces a two-stage process: (i) sequence fill-up and (ii)
iterative refinement by remasking and decoding a subset of tokens while
treating the remaining as context. This design enables previously accepted
tokens to be reconsidered and corrected when necessary, leading to more
reliable diffusion decoding outputs. We evaluate Tolerator on five standard
benchmarks covering language understanding, code generation, and mathematics.
Experiments show that our method achieves consistent improvements over the
baselines under the same computational budget. These findings suggest that
decoding algorithms are crucial to realizing the full potential of diffusion
large language models. Code and data are publicly available.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [110] [SoC-DT: Standard-of-Care Aligned Digital Twins for Patient-Specific Tumor Dynamics](https://arxiv.org/abs/2510.03287)
*Moinak Bhattacharya,Gagandeep Singh,Prateek Prasanna*

Main category: cs.CV

TL;DR: SoC-DT is a differentiable framework that combines reaction-diffusion tumor growth models with standard-of-care interventions and patient-specific factors to predict post-treatment tumor structure on imaging.


<details>
  <summary>Details</summary>
Motivation: Accurate prediction of tumor trajectories under standard-of-care therapies is a major unmet need in oncology, as conventional models fail to capture tumor dynamics under heterogeneous therapeutic paradigms.

Method: SoC-DT unifies reaction-diffusion tumor growth models with discrete SoC interventions (surgery, chemotherapy, radiotherapy) and incorporates genomic and demographic personalization. It uses an IMEX-SoC solver for stability, positivity, and scalability.

Result: SoC-DT consistently outperforms classical PDE baselines and purely data-driven neural models in predicting tumor dynamics on both synthetic data and real-world glioma data.

Conclusion: SoC-DT establishes a principled foundation for patient-specific digital twins in oncology by bridging mechanistic interpretability with modern differentiable solvers, enabling biologically consistent tumor dynamics estimation.

Abstract: Accurate prediction of tumor trajectories under standard-of-care (SoC)
therapies remains a major unmet need in oncology. This capability is essential
for optimizing treatment planning and anticipating disease progression.
Conventional reaction-diffusion models are limited in scope, as they fail to
capture tumor dynamics under heterogeneous therapeutic paradigms. There is
hence a critical need for computational frameworks that can realistically
simulate SoC interventions while accounting for inter-patient variability in
genomics, demographics, and treatment regimens. We introduce Standard-of-Care
Digital Twin (SoC-DT), a differentiable framework that unifies
reaction-diffusion tumor growth models, discrete SoC interventions (surgery,
chemotherapy, radiotherapy) along with genomic and demographic personalization
to predict post-treatment tumor structure on imaging. An implicit-explicit
exponential time-differencing solver, IMEX-SoC, is also proposed, which ensures
stability, positivity, and scalability in SoC treatment situations. Evaluated
on both synthetic data and real world glioma data, SoC-DT consistently
outperforms classical PDE baselines and purely data-driven neural models in
predicting tumor dynamics. By bridging mechanistic interpretability with modern
differentiable solvers, SoC-DT establishes a principled foundation for
patient-specific digital twins in oncology, enabling biologically consistent
tumor dynamics estimation. Code will be made available upon acceptance.

</details>


### [111] [Visualizing Celebrity Dynamics in Video Content: A Proposed Approach Using Face Recognition Timestamp Data](https://arxiv.org/abs/2510.03292)
*Doğanay Demir,İlknur Durgar Elkahlout*

Main category: cs.CV

TL;DR: A hybrid framework combining distributed multi-GPU inference with interactive visualization for analyzing celebrity dynamics in video content, providing comprehensive insights through various charts and graphs.


<details>
  <summary>Details</summary>
Motivation: In the video-dominated era, understanding video structure and celebrity dynamics is crucial for entertainment analytics, content strategy, and audience engagement.

Method: Uses distributed multi-GPU inference with optimized ONNX models, heterogeneous batch processing, and high-throughput parallelism to generate timestamped appearance records, then transforms them into interactive visualizations including frequency charts, network graphs, heatmaps, and co-appearance matrices.

Result: Enables scalable processing of large video volumes and provides multi-dimensional insights into celebrity prominence, screen-time distribution, temporal dynamics, co-appearance relationships, and intensity across episodes and seasons.

Conclusion: Bridges distributed recognition with structured visual analytics, opening new possibilities for entertainment analytics, content creation strategies, and audience engagement studies through interactive exploration of video content dynamics.

Abstract: In an era dominated by video content, understanding its structure and
dynamics has become increasingly important. This paper presents a hybrid
framework that combines a distributed multi-GPU inference system with an
interactive visualization platform for analyzing celebrity dynamics in video
episodes. The inference framework efficiently processes large volumes of video
data by leveraging optimized ONNX models, heterogeneous batch inference, and
high-throughput parallelism, ensuring scalable generation of timestamped
appearance records. These records are then transformed into a comprehensive
suite of visualizations, including appearance frequency charts, duration
analyses, pie charts, co-appearance matrices, network graphs, stacked area
charts, seasonal comparisons, and heatmaps. Together, these visualizations
provide multi-dimensional insights into video content, revealing patterns in
celebrity prominence, screen-time distribution, temporal dynamics,
co-appearance relationships, and intensity across episodes and seasons. The
interactive nature of the system allows users to dynamically explore data,
identify key moments, and uncover evolving relationships between individuals.
By bridging distributed recognition with structured, visually-driven analytics,
this work enables new possibilities for entertainment analytics, content
creation strategies, and audience engagement studies.

</details>


### [112] [Domain-Robust Marine Plastic Detection Using Vision Models](https://arxiv.org/abs/2510.03294)
*Saanvi Kataria*

Main category: cs.CV

TL;DR: This study benchmarks deep learning models for cross-domain underwater plastic debris detection, finding that lightweight CNNs like MobileNetV2 outperform larger models and zero-shot approaches in generalization.


<details>
  <summary>Details</summary>
Motivation: Marine plastic pollution requires reliable automated detection, but vision systems suffer from domain shift when applied to new underwater imagery.

Method: Benchmarked CNN models (MobileNetV2, ResNet-18, EfficientNet-B0) and vision transformers (DeiT-Tiny, ViT-B16) trained on labeled underwater data, plus zero-shot models CLIP ViT-L14 and Gemini 2.0 Flash, evaluated on cross-domain test sets.

Result: MobileNetV2 achieved best cross-domain performance (F1 0.97). Fine-tuned models had high Precision (~99%) but varying Recall. Zero-shot CLIP had higher Recall (~80%) but lower Precision (~56%), while Gemini showed inverse pattern.

Conclusion: Compact CNNs with supervised training generalize effectively for cross-domain underwater detection, while large pretrained vision-language models provide complementary strengths.

Abstract: Marine plastic pollution is a pressing environmental threat, making reliable
automation for underwater debris detection essential. However, vision systems
trained on one dataset often degrade on new imagery due to domain shift. This
study benchmarks models for cross-domain robustness, training convolutional
neural networks - CNNs (MobileNetV2, ResNet-18, EfficientNet-B0) and vision
transformers (DeiT-Tiny, ViT-B16) on a labeled underwater dataset and then
evaluates them on a balanced cross-domain test set built from plastic-positive
images drawn from a different source and negatives from the training domain.
Two zero-shot models were assessed, CLIP ViT-L14 and Google's Gemini 2.0 Flash,
that leverage pretraining to classify images without fine-tuning. Results show
the lightweight MobileNetV2 delivers the strongest cross-domain performance (F1
0.97), surpassing larger models. All fine-tuned models achieved high Precision
(around 99%), but differ in Recall, indicating varying sensitivity to plastic
instances. Zero-shot CLIP is comparatively sensitive (Recall around 80%) yet
prone to false positives (Precision around 56%), whereas Gemini exhibits the
inverse profile (Precision around 99%, Recall around 81%). Error analysis
highlights recurring confusions with coral textures, suspended particulates,
and specular glare. Overall, compact CNNs with supervised training can
generalize effectively for cross-domain underwater detection, while large
pretrained vision-language models provide complementary strengths.

</details>


### [113] [Multimodal Arabic Captioning with Interpretable Visual Concept Integration](https://arxiv.org/abs/2510.03295)
*Passant Elchafei,Amany Fashwan*

Main category: cs.CV

TL;DR: VLCAP is an Arabic image captioning framework that combines CLIP-based visual label retrieval with multimodal text generation, using interpretable Arabic visual concepts to create culturally coherent captions.


<details>
  <summary>Details</summary>
Motivation: To develop an Arabic image captioning system that grounds generation in interpretable visual concepts rather than relying solely on end-to-end approaches, enabling culturally appropriate and contextually accurate Arabic captions.

Method: Uses three multilingual encoders (mCLIP, AraCLIP, Jina V4) for visual label retrieval from a hybrid vocabulary, then transforms top-k labels into Arabic prompts for vision-language models (Qwen-VL and Gemini Pro Vision) to generate captions.

Result: mCLIP + Gemini Pro Vision achieved best BLEU-1 (5.34%) and cosine similarity (60.01%), while AraCLIP + Qwen-VL obtained highest LLM-judge score (36.33%) across six encoder-decoder configurations.

Conclusion: The interpretable pipeline successfully enables culturally coherent and contextually accurate Arabic image captions through grounded visual concept retrieval and multimodal generation.

Abstract: We present VLCAP, an Arabic image captioning framework that integrates
CLIP-based visual label retrieval with multimodal text generation. Rather than
relying solely on end-to-end captioning, VLCAP grounds generation in
interpretable Arabic visual concepts extracted with three multilingual
encoders, mCLIP, AraCLIP, and Jina V4, each evaluated separately for label
retrieval. A hybrid vocabulary is built from training captions and enriched
with about 21K general domain labels translated from the Visual Genome dataset,
covering objects, attributes, and scenes. The top-k retrieved labels are
transformed into fluent Arabic prompts and passed along with the original image
to vision-language models. In the second stage, we tested Qwen-VL and Gemini
Pro Vision for caption generation, resulting in six encoder-decoder
configurations. The results show that mCLIP + Gemini Pro Vision achieved the
best BLEU-1 (5.34%) and cosine similarity (60.01%), while AraCLIP + Qwen-VL
obtained the highest LLM-judge score (36.33%). This interpretable pipeline
enables culturally coherent and contextually accurate Arabic captions.

</details>


### [114] [Convolutional Neural Nets vs Vision Transformers: A SpaceNet Case Study with Balanced vs Imbalanced Regimes](https://arxiv.org/abs/2510.03297)
*Akshar Gothi*

Main category: cs.CV

TL;DR: Comparison of EfficientNet-B0 (CNN) and ViT-Base (Vision Transformer) on SpaceNet dataset under imbalanced and balanced label distributions, showing both achieve high accuracy but CNNs maintain efficiency advantages.


<details>
  <summary>Details</summary>
Motivation: To conduct a controlled comparison between convolutional neural networks and vision transformers on satellite imagery, specifically examining performance under different label distribution regimes.

Method: Used SpaceNet dataset with two splits: naturally imbalanced five-class and balanced-resampled (700 images per class). Applied matched preprocessing (224x224, ImageNet normalization), lightweight augmentations, and 40-epoch training on single NVIDIA P100 GPU.

Result: On imbalanced split: EfficientNet-B0 reached 93% test accuracy with strong macro-F1 and lower latency; ViT-Base was competitive at 93% but with larger parameters and runtime. On balanced split: Both models performed strongly with EfficientNet-B0 reaching 99% accuracy while ViT-Base remained competitive.

Conclusion: Balancing label distributions narrows architecture performance gaps, but CNNs retain efficiency advantages in terms of model size and latency compared to vision transformers.

Abstract: We present a controlled comparison of a convolutional neural network
(EfficientNet-B0) and a Vision Transformer (ViT-Base) on SpaceNet under two
label-distribution regimes: a naturally imbalanced five-class split and a
balanced-resampled split with 700 images per class (70:20:10 train/val/test).
With matched preprocessing (224x224, ImageNet normalization), lightweight
augmentations, and a 40-epoch budget on a single NVIDIA P100, we report
accuracy, macro-F1, balanced accuracy, per-class recall, and deployment metrics
(model size and latency). On the imbalanced split, EfficientNet-B0 reaches 93%
test accuracy with strong macro-F1 and lower latency; ViT-Base is competitive
at 93% with a larger parameter count and runtime. On the balanced split, both
models are strong; EfficientNet-B0 reaches 99% while ViT-Base remains
competitive, indicating that balancing narrows architecture gaps while CNNs
retain an efficiency edge. We release manifests, logs, and per-image
predictions to support reproducibility.

</details>


### [115] [A Comprehensive Review on Artificial Intelligence Empowered Solutions for Enhancing Pedestrian and Cyclist Safety](https://arxiv.org/abs/2510.03314)
*Shucheng Zhang,Yan Shi,Bingzhang Wang,Yuang Zhang,Muhammad Monjurul Karim,Kehua Chen,Chenxi Liu,Mehrdad Nasri,Yinhai Wang*

Main category: cs.CV

TL;DR: This paper provides a comprehensive review of camera-based AI sensing systems for vulnerable road user (VRU) safety, covering detection, tracking, trajectory prediction, and intent recognition tasks from the past five years.


<details>
  <summary>Details</summary>
Motivation: Existing surveys on AI for VRU safety mainly focus on detection, leaving gaps in other vision-based tasks essential for comprehensive VRU protection. Conventional infrastructure measures are inadequate in dynamic urban environments.

Method: Systematic review of recent progress in camera-based AI sensing systems, examining four core tasks: detection/classification, tracking/reidentification, trajectory prediction, and intent recognition/prediction.

Result: The survey identifies emerging research trends and provides a foundational reference for developing next-generation sensing systems to enhance VRU safety in intelligent transportation systems.

Conclusion: The paper highlights four major open challenges from data, model, and deployment perspectives, aiming to link visual AI advances with practical considerations for real-world implementation of VRU protection systems.

Abstract: Ensuring the safety of vulnerable road users (VRUs), such as pedestrians and
cyclists, remains a critical global challenge, as conventional
infrastructure-based measures often prove inadequate in dynamic urban
environments. Recent advances in artificial intelligence (AI), particularly in
visual perception and reasoning, open new opportunities for proactive and
context-aware VRU protection. However, existing surveys on AI applications for
VRUs predominantly focus on detection, offering limited coverage of other
vision-based tasks that are essential for comprehensive VRU understanding and
protection. This paper presents a state-of-the-art review of recent progress in
camera-based AI sensing systems for VRU safety, with an emphasis on
developments from the past five years and emerging research trends. We
systematically examine four core tasks, namely detection and classification,
tracking and reidentification, trajectory prediction, and intent recognition
and prediction, which together form the backbone of AI-empowered proactive
solutions for VRU protection in intelligent transportation systems. To guide
future research, we highlight four major open challenges from the perspectives
of data, model, and deployment. By linking advances in visual AI with practical
considerations for real-world implementation, this survey aims to provide a
foundational reference for the development of next-generation sensing systems
to enhance VRU safety.

</details>


### [116] [The View From Space: Navigating Instrumentation Differences with EOFMs](https://arxiv.org/abs/2510.03316)
*Ryan P. Demilt,Nicholas LaHaye,Karis Tenneson*

Main category: cs.CV

TL;DR: Earth Observation Foundation Models (EOFMs) are sensitive to sensor architecture differences, which affects their representation spaces and highlights limitations in current model design.


<details>
  <summary>Details</summary>
Motivation: To understand how diverse sensor architectures impact the internal representations of EOFMs, as most current models are trained on single modalities but applied across different modalities.

Method: Analyzed the representation space sensitivity of EOFMs to different sensor architectures through empirical investigation.

Result: Found that EOFM representation spaces are highly sensitive to sensor architecture, revealing significant differences in how models process data from different sensors.

Conclusion: Understanding sensor architecture sensitivity provides crucial insights for improving EOFM design, guiding model developers and users toward more robust remote-sensing applications.

Abstract: Earth Observation Foundation Models (EOFMs) have exploded in prevalence as
tools for processing the massive volumes of remotely sensed and other earth
observation data, and for delivering impact on the many essential earth
monitoring tasks. An emerging trend posits using the outputs of pre-trained
models as 'embeddings' which summarize high dimensional data to be used for
generic tasks such as similarity search and content-specific queries. However,
most EOFM models are trained only on single modalities of data and then applied
or benchmarked by matching bands across different modalities. It is not clear
from existing work what impact diverse sensor architectures have on the
internal representations of the present suite of EOFMs. We show in this work
that the representation space of EOFMs is highly sensitive to sensor
architecture and that understanding this difference gives a vital perspective
on the pitfalls of current EOFM design and signals for how to move forward as
model developers, users, and a community guided by robust remote-sensing
science.

</details>


### [117] [Photorealistic Inpainting for Perturbation-based Explanations in Ecological Monitoring](https://arxiv.org/abs/2510.03317)
*Günel Aghakishiyeva,Jiayi Zhou,Saagar Arya,James David Poling,Holly R. Houliston,Jamie N. Womble,David W. Johnston,Brinnae Bent*

Main category: cs.CV

TL;DR: An inpainting-guided explanation method for ecological vision models that creates photorealistic, mask-localized edits to reveal morphological cues driving predictions in species recognition tasks.


<details>
  <summary>Details</summary>
Motivation: Address opacity in automated ecological monitoring models to build trust and enable field adoption by providing interpretable explanations that preserve scene context.

Method: Uses inpainting-guided perturbation with Segment-Anything-Model-refined masks for object removal/replacement and background replacement interventions on a YOLOv9 seal detector.

Result: Produces photorealistic explanations that localize diagnostic structures, avoid deletion artifacts, and provide domain-relevant insights validated by expert review and quantitative metrics.

Conclusion: The approach supports expert validation and enables more trustworthy deployment of AI in ecology by providing interpretable, ecologically plausible explanations.

Abstract: Ecological monitoring is increasingly automated by vision models, yet opaque
predictions limit trust and field adoption. We present an inpainting-guided,
perturbation-based explanation technique that produces photorealistic,
mask-localized edits that preserve scene context. Unlike masking or blurring,
these edits stay in-distribution and reveal which fine-grained morphological
cues drive predictions in tasks such as species recognition and trait
attribution. We demonstrate the approach on a YOLOv9 detector fine-tuned for
harbor seal detection in Glacier Bay drone imagery, using
Segment-Anything-Model-refined masks to support two interventions: (i) object
removal/replacement (e.g., replacing seals with plausible ice/water or boats)
and (ii) background replacement with original animals composited onto new
scenes. Explanations are assessed by re-scoring perturbed images (flip rate,
confidence drop) and by expert review for ecological plausibility and
interpretability. The resulting explanations localize diagnostic structures,
avoid deletion artifacts common to traditional perturbations, and yield
domain-relevant insights that support expert validation and more trustworthy
deployment of AI in ecology.

</details>


### [118] [Advances in Medical Image Segmentation: A Comprehensive Survey with a Focus on Lumbar Spine Applications](https://arxiv.org/abs/2510.03318)
*Ahmed Kabil,Ghada Khoriba,Mina Yousef,Essam A. Rashed*

Main category: cs.CV

TL;DR: This paper provides a comprehensive survey of medical image segmentation methods, covering both traditional techniques and modern deep learning approaches, with a special focus on emerging trends and a case study on lumbar spine segmentation.


<details>
  <summary>Details</summary>
Motivation: Medical image segmentation is crucial for diagnostics, treatment planning, and monitoring medical conditions, but there's a need to bridge the gap between traditional methods and modern deep learning approaches while addressing current challenges in the field.

Method: The survey systematically reviews thresholding, edge detection, region-based segmentation, clustering algorithms, model-based techniques, and deep learning architectures including CNNs, FCNs, U-Net variants, attention mechanisms, semi-supervised learning, GANs, and Transformer-based models.

Result: The paper identifies emerging trends such as hybrid architectures, cross-modality learning, federated/distributed learning, and active learning strategies that address challenges like limited labeled datasets, computational complexity, and model generalizability.

Conclusion: Despite significant progress, critical challenges remain including dataset bias, domain adaptation, interpretability of deep learning models, and integration into real-world clinical workflows.

Abstract: Medical Image Segmentation (MIS) stands as a cornerstone in medical image
analysis, playing a pivotal role in precise diagnostics, treatment planning,
and monitoring of various medical conditions. This paper presents a
comprehensive and systematic survey of MIS methodologies, bridging the gap
between traditional image processing techniques and modern deep learning
approaches. The survey encompasses thresholding, edge detection, region-based
segmentation, clustering algorithms, and model-based techniques while also
delving into state-of-the-art deep learning architectures such as Convolutional
Neural Networks (CNNs), Fully Convolutional Networks (FCNs), and the widely
adopted U-Net and its variants. Moreover, integrating attention mechanisms,
semi-supervised learning, generative adversarial networks (GANs), and
Transformer-based models is thoroughly explored. In addition to covering
established methods, this survey highlights emerging trends, including hybrid
architectures, cross-modality learning, federated and distributed learning
frameworks, and active learning strategies, which aim to address challenges
such as limited labeled datasets, computational complexity, and model
generalizability across diverse imaging modalities. Furthermore, a specialized
case study on lumbar spine segmentation is presented, offering insights into
the challenges and advancements in this relatively underexplored anatomical
region. Despite significant progress in the field, critical challenges persist,
including dataset bias, domain adaptation, interpretability of deep learning
models, and integration into real-world clinical workflows.

</details>


### [119] [DECOR: Deep Embedding Clustering with Orientation Robustness](https://arxiv.org/abs/2510.03328)
*Fiona Victoria Stanley Jothiraj,Arunaggiri Pandian Karunanidhi,Seth A. Eichmeyer*

Main category: cs.CV

TL;DR: DECOR is a deep clustering framework that groups wafer defect patterns into consistent clusters while being robust to orientation variations, outperforming existing methods on the MixedWM38 dataset.


<details>
  <summary>Details</summary>
Motivation: Early detection of wafer defects is critical for semiconductor manufacturing yield optimization, but raw wafer data is complex, unlabeled, imbalanced, and can contain multiple defects per wafer, requiring reliable clustering methods under imperfect data conditions.

Method: DECOR (deep clustering with orientation robustness) framework that explicitly accounts for orientation variations in wafer maps to ensure spatially similar defects are consistently clustered regardless of rotation or alignment.

Result: DECOR outperforms existing clustering baseline methods on the MixedWM38 dataset and demonstrates ability to discover clusters without manual tuning.

Conclusion: DECOR provides a reliable and scalable solution for automated visual inspection systems in semiconductor manufacturing by handling orientation variations and imperfect data conditions effectively.

Abstract: In semiconductor manufacturing, early detection of wafer defects is critical
for product yield optimization. However, raw wafer data from wafer quality
tests are often complex, unlabeled, imbalanced and can contain multiple defects
on a single wafer, making it crucial to design clustering methods that remain
reliable under such imperfect data conditions. We introduce DECOR, a deep
clustering with orientation robustness framework that groups complex defect
patterns from wafer maps into consistent clusters. We evaluate our method on
the open source MixedWM38 dataset, demonstrating its ability to discover
clusters without manual tuning. DECOR explicitly accounts for orientation
variations in wafer maps, ensuring that spatially similar defects are
consistently clustered regardless of its rotation or alignment. Experiments
indicate that our method outperforms existing clustering baseline methods, thus
providing a reliable and scalable solution in automated visual inspection
systems.

</details>


### [120] [Error correction in multiclass image classification of facial emotion on unbalanced samples](https://arxiv.org/abs/2510.03337)
*Andrey A. Lebedev,Victor B. Kazantsev,Sergey V. Stasenko*

Main category: cs.CV

TL;DR: This paper proposes an error correction method for multi-class facial emotion classification using LSTM with attention mechanism, focusing on handling class imbalance by training on subsets and correcting excluded classes.


<details>
  <summary>Details</summary>
Motivation: To address the problem of class imbalance in facial emotion recognition where some emotions significantly outnumber others, which is common in real-world applications like anti-fraud systems.

Method: Uses LSTM neural network with attention mechanism to focus on key facial areas. Trains model on subsets of six emotion classes and performs error correction for the excluded seventh class.

Result: Error correction was possible for all classes with varying success rates. Some classes were better restored than others. Test results showed improved quality metrics for small classes.

Conclusion: The proposed method is effective for facial expression analysis and stable classification under imbalanced class distributions, particularly promising for detecting rare events in applications like anti-fraud systems.

Abstract: This paper considers the problem of error correction in multi-class
classification of face images on unbalanced samples. The study is based on the
analysis of a data frame containing images labeled by seven different emotional
states of people of different ages. Particular attention is paid to the problem
of class imbalance, in which some emotions significantly prevail over others.
To solve the classification problem, a neural network model based on LSTM with
an attention mechanism focusing on key areas of the face that are informative
for emotion recognition is used. As part of the experiments, the model is
trained on all possible configurations of subsets of six classes with
subsequent error correction for the seventh class, excluded at the training
stage. The results show that correction is possible for all classes, although
the degree of success varies: some classes are better restored, others are
worse. In addition, on the test sample, when correcting some classes, an
increase in key quality metrics for small classes was recorded, which indicates
the promise of the proposed approach in solving applied problems related to the
search for rare events, for example, in anti-fraud systems. Thus, the proposed
method can be effectively applied in facial expression analysis systems and in
tasks requiring stable classification under skewed class distribution.

</details>


### [121] [OpusAnimation: Code-Based Dynamic Chart Generation](https://arxiv.org/abs/2510.03341)
*Bozheng Li,Miao Yang,Zhenhan Chen,Jiawang Cao,Mushui Liu,Yi Lu,Yongliang Wu,Bin Zhang,Yangguang Ji,Licheng Tang,Jay Wu,Wenbo Zhu*

Main category: cs.CV

TL;DR: The paper introduces DCG-Bench, the first benchmark for evaluating multi-modal large language models (MLLMs) on dynamic chart generation tasks, and proposes a two-stage training method with Joint-Code-Visual Reward optimization that achieves state-of-the-art performance.


<details>
  <summary>Details</summary>
Motivation: While MLLMs have improved on static chart generation, their potential for dynamic chart generation and understanding remains underexplored, creating a research gap that needs to be addressed.

Method: Created DCG-8K dataset with instruction-code-video triplets and QA pairs, then used a two-stage training recipe with Joint-Code-Visual Reward for group relative policy optimization to train Qwen2.5-VL-DCG-3B model.

Result: The proposed model beats the best open-sourced MLLM with 8.31% average performance gain across three tasks and shows comparable performance to proprietary models despite having only 3B parameters.

Conclusion: The research successfully bridges the gap in dynamic chart generation evaluation and demonstrates the effectiveness of the proposed training approach, with code and dataset to be made publicly available.

Abstract: Dynamic Chart Generation (DCG) involves producing code-rendered animated
visualizations as charts. While recent advances in multi-modal large language
models (MLLMs) have significantly improved their capability on static chart
generation and comprehension, MLLMs' potential for handling dynamic chart
generation and understanding remains underexplored. To bridge this research
gap, we introduce DCG-Bench (Dynamic Chart Generation Benchmark), the first
benchmark evaluating MLLM's capability on dynamic chart generation tasks from
three dimensions: Simple Text-to-Chart, Detailed Text-to-Chart, and
Video-to-Chart tasks. We construct DCG-8K, a high-quality DCG dataset with
annotations covering instruction-code-video triplets and QA pairs for both code
and video evaluation. Based on DCG-8K, we explored a two-stage training recipe,
proposing Joint-Code-Visual Reward for group relative policy optimization to
construct expert MLLM Qwen2.5-VL-DCG-3B for the DCG task. Our benchmarking
result reveals shortcomings of existing MLLMs in the visual-to-chart task, and
our model beats the best open-sourced MLLM with an average 8.31% performance
gain across three tasks, and shows on par performance against proprietary
models with only 3B parameters, proving the effectiveness of our training
recipe. Our code and dataset will be publicly available.

</details>


### [122] [Visual Odometry with Transformers](https://arxiv.org/abs/2510.03348)
*Vlardimir Yugay,Duy-Kien Nguyen,Theo Gevers,Cees G. M. Snoek,Martin R. Oswald*

Main category: cs.CV

TL;DR: VoT is an end-to-end Visual odometry Transformer that directly predicts camera motion from monocular video sequences without traditional components like bundle adjustment or dense 3D reconstruction.


<details>
  <summary>Details</summary>
Motivation: Current monocular visual odometry methods rely on complex pipelines with pre-trained components and optimization modules, requiring camera calibration and hyperparameter tuning, and struggle in unseen real-world scenarios. Existing large-scale 3D models have limitations in handling long videos and providing accurate per-frame estimates.

Method: VoT processes sequences of monocular frames by extracting features and modeling global relationships through temporal and spatial attention. It directly predicts camera motion without estimating dense geometry and uses only camera poses for supervision. The framework is modular and allows integration of various pre-trained encoders.

Result: VoT scales effectively with larger datasets, benefits from stronger pre-trained backbones, generalizes across diverse camera motions and calibration settings, outperforms traditional methods, and runs more than 3 times faster.

Conclusion: Monocular visual odometry can be effectively addressed in an end-to-end manner, eliminating the need for handcrafted components like bundle adjustment, feature matching, camera calibration, or dense 3D reconstruction.

Abstract: Modern monocular visual odometry methods typically combine pre-trained deep
learning components with optimization modules, resulting in complex pipelines
that rely heavily on camera calibration and hyperparameter tuning, and often
struggle in unseen real-world scenarios. Recent large-scale 3D models trained
on massive amounts of multi-modal data have partially alleviated these
challenges, providing generalizable dense reconstruction and camera pose
estimation. Still, they remain limited in handling long videos and providing
accurate per-frame estimates, which are required for visual odometry. In this
work, we demonstrate that monocular visual odometry can be addressed
effectively in an end-to-end manner, thereby eliminating the need for
handcrafted components such as bundle adjustment, feature matching, camera
calibration, or dense 3D reconstruction. We introduce VoT, short for Visual
odometry Transformer, which processes sequences of monocular frames by
extracting features and modeling global relationships through temporal and
spatial attention. Unlike prior methods, VoT directly predicts camera motion
without estimating dense geometry and relies solely on camera poses for
supervision. The framework is modular and flexible, allowing seamless
integration of various pre-trained encoders as feature extractors. Experimental
results demonstrate that VoT scales effectively with larger datasets, benefits
substantially from stronger pre-trained backbones, generalizes across diverse
camera motions and calibration settings, and outperforms traditional methods
while running more than 3 times faster. The code will be released.

</details>


### [123] [Inference-Time Search using Side Information for Diffusion-based Image Reconstruction](https://arxiv.org/abs/2510.03352)
*Mahdi Farahbakhsh,Vishnu Teja Kunde,Dileep Kalathil,Krishna Narayanan,Jean-Francois Chamberland*

Main category: cs.CV

TL;DR: A novel inference-time search algorithm that uses side information to guide diffusion models for solving inverse problems, improving reconstruction quality without reward-hacking artifacts.


<details>
  <summary>Details</summary>
Motivation: Existing diffusion-based approaches for inverse problems overlook side information that could significantly improve reconstruction quality, especially in severely ill-posed settings.

Method: Proposed an inference-time search algorithm that guides sampling using side information in a manner that balances exploration and exploitation, avoiding gradient-based guidance issues.

Result: Consistently improves qualitative and quantitative performance on various inverse problems including box inpainting, super-resolution, and multiple deblurring tasks, outperforming reward gradient-based guidance baselines.

Conclusion: The approach provides more accurate and reliable reconstructions and can be seamlessly integrated into existing diffusion-based image reconstruction pipelines.

Abstract: Diffusion models have emerged as powerful priors for solving inverse
problems. However, existing approaches typically overlook side information that
could significantly improve reconstruction quality, especially in severely
ill-posed settings. In this work, we propose a novel inference-time search
algorithm that guides the sampling process using the side information in a
manner that balances exploration and exploitation. This enables more accurate
and reliable reconstructions, providing an alternative to the gradient-based
guidance that is prone to reward-hacking artifacts. Our approach can be
seamlessly integrated into a wide range of existing diffusion-based image
reconstruction pipelines. Through extensive experiments on a number of inverse
problems, such as box inpainting, super-resolution, and various deblurring
tasks including motion, Gaussian, nonlinear, and blind deblurring, we show that
our approach consistently improves the qualitative and quantitative performance
of diffusion-based image reconstruction algorithms. We also show the superior
performance of our approach with respect to other baselines, including reward
gradient-based guidance algorithms. The code is available at
\href{https://github.com/mhdfb/sideinfo-search-reconstruction}{this
repository}.

</details>


### [124] [Sonar Image Datasets: A Comprehensive Survey of Resources, Challenges, and Applications](https://arxiv.org/abs/2510.03353)
*Larissa S. Gomes,Gustavo P. Almeida,Bryan U. Moreira,Marco Quiroz,Breno Xavier,Lucas Soares,Stephanie L. Brião,Felipe G. Oliveira,Paulo L. J. Drews-Jr*

Main category: cs.CV

TL;DR: This paper provides a comprehensive review of publicly available sonar image datasets across various modalities (SSS, FLS, SAS, MBES, DIDSON) to address the data scarcity bottleneck in underwater acoustic data analysis.


<details>
  <summary>Details</summary>
Motivation: The scarcity of publicly available, well-annotated sonar image datasets creates a significant bottleneck for developing robust machine learning models in underwater exploration, autonomous navigation, and ecosystem monitoring.

Method: Conducted a comprehensive review and mapping of publicly accessible sonar datasets across various modalities, analyzed applications (classification, detection, segmentation, 3D reconstruction), and synthesized findings into a master table and chronological timeline.

Result: Created a clear and accessible comparison of dataset characteristics, sizes, and annotation details, incorporating state-of-the-art advancements and newly released datasets.

Conclusion: This review serves as a base guide for researchers to start or advance in underwater acoustic data analysis by cataloging existing resources, contextualizing them, identifying gaps, and providing a clear roadmap.

Abstract: Sonar images are relevant for advancing underwater exploration, autonomous
navigation, and ecosystem monitoring. However, the progress depends on data
availability. The scarcity of publicly available, well-annotated sonar image
datasets creates a significant bottleneck for the development of robust machine
learning models. This paper presents a comprehensive and concise review of the
current landscape of sonar image datasets, seeking not only to catalog existing
resources but also to contextualize them, identify gaps, and provide a clear
roadmap, serving as a base guide for researchers of any kind who wish to start
or advance in the field of underwater acoustic data analysis. We mapped
publicly accessible datasets across various sonar modalities, including Side
Scan Sonar (SSS), Forward-Looking Sonar (FLS), Synthetic Aperture Sonar (SAS),
Multibeam Echo Sounder (MBES), and Dual-Frequency Identification Sonar
(DIDSON). An analysis was conducted on applications such as classification,
detection, segmentation, and 3D reconstruction. This work focuses on
state-of-the-art advancements, incorporating newly released datasets. The
findings are synthesized into a master table and a chronological timeline,
offering a clear and accessible comparison of characteristics, sizes, and
annotation details datasets.

</details>


### [125] [Learned Display Radiance Fields with Lensless Cameras](https://arxiv.org/abs/2510.03356)
*Ziyang Chen,Yuta Itoh,Kaan Akşit*

Main category: cs.CV

TL;DR: A lensless camera and neural representation algorithm for display calibration without specialized hardware, enabling light field reconstruction from multiple viewpoints.


<details>
  <summary>Details</summary>
Motivation: Display calibration requires specialized equipment and dark rooms, making it inaccessible to most users. The goal is to eliminate hardware requirements for display characterization.

Method: Co-design of a lensless camera with Implicit Neural Representation algorithm to capture display characteristics from various viewpoints, reconstructing light fields from a 46.6° × 37.6° viewing cone.

Result: The pipeline enables efficient reconstruction of light fields emitted from displays across a wide viewing angle, providing display characterization capabilities.

Conclusion: This emerging pipeline represents initial steps toward effortless display calibration and characterization, potentially making the process more accessible without specialized hardware.

Abstract: Calibrating displays is a basic and regular task that content creators must
perform to maintain optimal visual experience, yet it remains a troublesome
issue. Measuring display characteristics from different viewpoints often
requires specialized equipment and a dark room, making it inaccessible to most
users. To avoid specialized hardware requirements in display calibrations, our
work co-designs a lensless camera and an Implicit Neural Representation based
algorithm for capturing display characteristics from various viewpoints. More
specifically, our pipeline enables efficient reconstruction of light fields
emitted from a display from a viewing cone of 46.6{\deg} X 37.6{\deg}. Our
emerging pipeline paves the initial steps towards effortless display
calibration and characterization.

</details>


### [126] [Provenance Networks: End-to-End Exemplar-Based Explainability](https://arxiv.org/abs/2510.03361)
*Ali Kayyam,Anusha Madan Gopal,M. Anthony Lewis*

Main category: cs.CV

TL;DR: Provenance networks are neural models that provide end-to-end explainability by linking predictions to supporting training examples, embedding interpretability directly into the architecture.


<details>
  <summary>Details</summary>
Motivation: Address model opaqueness, hallucination, and lack of transparency in deep learning by providing training-data-driven explainability and improving trustworthiness.

Method: Learn to connect each prediction to relevant training examples through a learned KNN-like approach, jointly optimizing the primary task and explainability objectives.

Result: Enables systematic investigation of memorization vs. generalization trade-offs, verification of training set inclusion, detection of mislabeled data, enhanced resilience to perturbations, and identification of similar inputs.

Conclusion: Provenance networks offer complementary explainability with computational costs, but improve transparency, robustness, and trustworthiness in neural models by addressing critical deep learning challenges.

Abstract: We introduce provenance networks, a novel class of neural models designed to
provide end-to-end, training-data-driven explainability. Unlike conventional
post-hoc methods, provenance networks learn to link each prediction directly to
its supporting training examples as part of the model's normal operation,
embedding interpretability into the architecture itself. Conceptually, the
model operates similarly to a learned KNN, where each output is justified by
concrete exemplars weighted by relevance in the feature space. This approach
facilitates systematic investigations of the trade-off between memorization and
generalization, enables verification of whether a given input was included in
the training set, aids in the detection of mislabeled or anomalous data points,
enhances resilience to input perturbations, and supports the identification of
similar inputs contributing to the generation of a new data point. By jointly
optimizing the primary task and the explainability objective, provenance
networks offer insights into model behavior that traditional deep networks
cannot provide. While the model introduces additional computational cost and
currently scales to moderately sized datasets, it provides a complementary
approach to existing explainability techniques. In particular, it addresses
critical challenges in modern deep learning, including model opaqueness,
hallucination, and the assignment of credit to data contributors, thereby
improving transparency, robustness, and trustworthiness in neural models.

</details>


### [127] [Unified Unsupervised Anomaly Detection via Matching Cost Filtering](https://arxiv.org/abs/2510.03363)
*Zhe Zhang,Mingxiu Cai,Gaochang Wu,Jing Zhang,Lingqiao Liu,Dacheng Tao,Tianyou Chai,Xiatian Zhu*

Main category: cs.CV

TL;DR: The paper proposes Unified Cost Filtering (UCF), a post-hoc framework that refines anomaly cost volumes in unsupervised anomaly detection by mitigating matching noise through multi-layer attention guidance, achieving state-of-the-art results across unimodal and multimodal settings.


<details>
  <summary>Details</summary>
Motivation: Existing unsupervised anomaly detection methods suffer from overlooked matching noise and remain isolated between unimodal and multimodal approaches, limiting detection ability and knowledge transfer.

Method: UCF constructs anomaly cost volume by matching test samples against normal samples, then applies a learnable filtering module with multi-layer attention guidance to reduce matching noise and highlight subtle anomalies.

Result: Comprehensive experiments on 22 benchmarks show UCF consistently enhances various UAD methods, achieving new state-of-the-art results in both unimodal (RGB) and multimodal (RGB-3D, RGB-Text) scenarios.

Conclusion: UCF provides a unified framework that effectively addresses matching noise in unsupervised anomaly detection, demonstrating strong performance across diverse modalities and enabling knowledge transfer between unimodal and multimodal approaches.

Abstract: Unsupervised anomaly detection (UAD) aims to identify image- and pixel-level
anomalies using only normal training data, with wide applications such as
industrial inspection and medical analysis, where anomalies are scarce due to
privacy concerns and cold-start constraints. Existing methods, whether
reconstruction-based (restoring normal counterparts) or embedding-based
(pretrained representations), fundamentally conduct image- or feature-level
matching to generate anomaly maps. Nonetheless, matching noise has been largely
overlooked, limiting their detection ability. Beyond earlier focus on unimodal
RGB-based UAD, recent advances expand to multimodal scenarios, e.g., RGB--3D
and RGB--Text, enabled by point cloud sensing and vision--language models.
Despite shared challenges, these lines remain largely isolated, hindering a
comprehensive understanding and knowledge transfer. In this paper, we advocate
unified UAD for both unimodal and multimodal settings in the matching
perspective. Under this insight, we present Unified Cost Filtering (UCF), a
generic post-hoc refinement framework for refining anomaly cost volume of any
UAD model. The cost volume is constructed by matching a test sample against
normal samples from the same or different modalities, followed by a learnable
filtering module with multi-layer attention guidance from the test sample,
mitigating matching noise and highlighting subtle anomalies. Comprehensive
experiments on 22 diverse benchmarks demonstrate the efficacy of UCF in
enhancing a variety of UAD methods, consistently achieving new state-of-the-art
results in both unimodal (RGB) and multimodal (RGB--3D, RGB--Text) UAD
scenarios. Code and models will be released at
https://github.com/ZHE-SAPI/CostFilter-AD.

</details>


### [128] [Visual Language Model as a Judge for Object Detection in Industrial Diagrams](https://arxiv.org/abs/2510.03376)
*Sanjukta Ghosh*

Main category: cs.CV

TL;DR: A framework using Visual Language Models (VLMs) to automatically evaluate and refine object detection in industrial diagrams like P&IDs, addressing the lack of quality assessment methods in digitalization.


<details>
  <summary>Details</summary>
Motivation: Industrial diagrams are crucial for digital twins and automation, but current object detection methods lack automated quality evaluation, creating a gap in the digitalization process.

Method: Employ Visual Language Models (VLMs) to assess object detection results by identifying missing or inconsistent detections using multimodal capabilities.

Result: The framework enables automated quality assessment and improves overall detection performance on complex industrial diagrams.

Conclusion: VLMs provide an effective solution for automated quality evaluation and refinement of object detection in industrial diagram digitalization.

Abstract: Industrial diagrams such as piping and instrumentation diagrams (P&IDs) are
essential for the design, operation, and maintenance of industrial plants.
Converting these diagrams into digital form is an important step toward
building digital twins and enabling intelligent industrial automation. A
central challenge in this digitalization process is accurate object detection.
Although recent advances have significantly improved object detection
algorithms, there remains a lack of methods to automatically evaluate the
quality of their outputs. This paper addresses this gap by introducing a
framework that employs Visual Language Models (VLMs) to assess object detection
results and guide their refinement. The approach exploits the multimodal
capabilities of VLMs to identify missing or inconsistent detections, thereby
enabling automated quality assessment and improving overall detection
performance on complex industrial diagrams.

</details>


### [129] [Spatial-ViLT: Enhancing Visual Spatial Reasoning through Multi-Task Learning](https://arxiv.org/abs/2510.03441)
*Chashi Mahiul Islam,Oteo Mamo,Samuel Jacob Chacko,Xiuwen Liu,Weikuan Yu*

Main category: cs.CV

TL;DR: SpatialViLT enhances vision-language models by integrating spatial features like depth maps and 3D coordinates through multi-task learning, achieving state-of-the-art spatial reasoning performance.


<details>
  <summary>Details</summary>
Motivation: Address limitations of current VLMs in spatial reasoning for 3D scenes and complex object configurations, which is crucial for advanced multimodal understanding and real-world applications.

Method: Introduces SpatialViLT with spatial feature integration (depth maps, 3D coordinates, edge maps) via multi-task learning. Proposes two variants: SpatialViLT and MaskedSpatialViLT, plus SpatialEnsemble combining both approaches.

Result: Achieves state-of-the-art accuracy on Visual Spatial Reasoning (VSR) dataset, excelling in directional, topological, and proximity relation categories.

Conclusion: Represents significant advancement in spatial intelligence for AI systems, enhancing multimodal reasoning capabilities for complex spatial understanding.

Abstract: Vision-language models (VLMs) have advanced multimodal reasoning but still
face challenges in spatial reasoning for 3D scenes and complex object
configurations. To address this, we introduce SpatialViLT, an enhanced VLM that
integrates spatial features like depth maps, 3D coordinates, and edge maps
through a multi-task learning framework. This approach enriches multimodal
embeddings with spatial understanding. We propose two variants: SpatialViLT and
MaskedSpatialViLT, focusing on full and masked object regions, respectively.
Additionally, SpatialEnsemble combines both approaches, achieving
state-of-the-art accuracy. Our models excel in spatial reasoning categories
such as directional, topological, and proximity relations, as demonstrated on
the challenging Visual Spatial Reasoning (VSR) dataset. This work represents a
significant step in enhancing the spatial intelligence of AI systems, crucial
for advanced multimodal understanding and real-world applications.

</details>


### [130] [Denoising of Two-Phase Optically Sectioned Structured Illumination Reconstructions Using Encoder-Decoder Networks](https://arxiv.org/abs/2510.03452)
*Allison Davis,Yezhi Shen,Xiaoyu Ji,Fengqing Zhu*

Main category: cs.CV

TL;DR: Encoder-decoder networks (asymmetrical DAE and U-Net) trained on synthetic data effectively reduce artifacts in two-phase optical-sectioning structured illumination microscopy, improving image clarity without requiring clean ground-truth data.


<details>
  <summary>Details</summary>
Motivation: Two-phase optical-sectioning SI suffers from residual artifacts due to reduced acquisition time, and conventional denoising methods struggle with these artifacts. Supervised deep learning approaches are limited by the lack of clean ground-truth data for training.

Method: Used encoder-decoder networks (asymmetrical denoising autoencoder and U-Net) trained on synthetic data pairs created by applying real artifact fields to synthetic images, then evaluated on real OS-SI images.

Result: Both networks improved image clarity, with each network excelling against different types of artifacts. The approach successfully enabled supervised denoising of OS-SI images.

Conclusion: Synthetic training enables effective supervised denoising of OS-SI images, and encoder-decoder networks show potential for streamlining reconstruction workflows in structured illumination microscopy.

Abstract: Structured illumination (SI) enhances image resolution and contrast by
projecting patterned light onto a sample. In two-phase optical-sectioning SI
(OS-SI), reduced acquisition time introduces residual artifacts that
conventional denoising struggles to suppress. Deep learning offers an
alternative to traditional methods; however, supervised training is limited by
the lack of clean, optically sectioned ground-truth data. We investigate
encoder-decoder networks for artifact reduction in two-phase OS-SI, using
synthetic training pairs formed by applying real artifact fields to synthetic
images. An asymmetrical denoising autoencoder (DAE) and a U-Net are trained on
the synthetic data, then evaluated on real OS-SI images. Both networks improve
image clarity, with each excelling against different artifact types. These
results demonstrate that synthetic training enables supervised denoising of
OS-SI images and highlight the potential of encoder-decoder networks to
streamline reconstruction workflows.

</details>


### [131] [PEaRL: Pathway-Enhanced Representation Learning for Gene and Pathway Expression Prediction from Histology](https://arxiv.org/abs/2510.03455)
*Sejuti Majumder,Saarthak Kapse,Moinak Bhattacharya,Xuan Xu,Alisa Yurovsky,Prateek Prasanna*

Main category: cs.CV

TL;DR: PEaRL is a multimodal framework that integrates histopathology with spatial transcriptomics using pathway activation scores instead of individual genes, improving prediction accuracy and biological interpretability.


<details>
  <summary>Details</summary>
Motivation: Existing multimodal approaches rely on a small set of highly variable genes, limiting predictive scope and overlooking coordinated biological programs that shape tissue phenotypes.

Method: PEaRL represents transcriptomics through pathway activation scores computed with ssGSEA, encodes biologically coherent pathway signals with a transformer, and aligns them with histology features via contrastive learning.

Result: Across three cancer ST datasets (breast, skin, and lymph node), PEaRL consistently outperforms SOTA methods, yielding up to 58.9% and 20.4% increase in Pearson correlation coefficient for gene- and pathway-level expression prediction.

Conclusion: Grounded transcriptomic representation in pathways produces more biologically faithful and interpretable multimodal models, advancing computational pathology beyond gene-level embeddings.

Abstract: Integrating histopathology with spatial transcriptomics (ST) provides a
powerful opportunity to link tissue morphology with molecular function. Yet
most existing multimodal approaches rely on a small set of highly variable
genes, which limits predictive scope and overlooks the coordinated biological
programs that shape tissue phenotypes. We present PEaRL (Pathway Enhanced
Representation Learning), a multimodal framework that represents
transcriptomics through pathway activation scores computed with ssGSEA. By
encoding biologically coherent pathway signals with a transformer and aligning
them with histology features via contrastive learning, PEaRL reduces
dimensionality, improves interpretability, and strengthens cross-modal
correspondence. Across three cancer ST datasets (breast, skin, and lymph node),
PEaRL consistently outperforms SOTA methods, yielding higher accuracy for both
gene- and pathway-level expression prediction (up to 58.9 percent and 20.4
percent increase in Pearson correlation coefficient compared to SOTA). These
results demonstrate that grounding transcriptomic representation in pathways
produces more biologically faithful and interpretable multimodal models,
advancing computational pathology beyond gene-level embeddings.

</details>


### [132] [DuPLUS: Dual-Prompt Vision-Language Framework for Universal Medical Image Segmentation and Prognosis](https://arxiv.org/abs/2510.03483)
*Numan Saeed,Tausifa Jan Saleem,Fadillah Maani,Muhammad Ridzuan,Hu Wang,Mohammad Yaqub*

Main category: cs.CV

TL;DR: DuPLUS is a universal medical image analysis framework using hierarchical semantic prompts and dual-prompt mechanism that outperforms state-of-the-art models across multiple modalities and datasets, while enabling EHR integration for prognosis.


<details>
  <summary>Details</summary>
Motivation: Address limitations of task-specific models lacking generalizability and existing universal approaches with simplistic conditioning and poor medical semantic understanding.

Method: Novel vision-language framework with hierarchical semantic prompts for fine-grained control, dual-prompt mechanism, and parameter-efficient fine-tuning for rapid adaptation.

Result: Outperforms state-of-the-art on 8/10 datasets across 3 imaging modalities and 30+ organs/tumors; achieves CI of 0.69 for head and neck cancer prognosis with EHR integration.

Conclusion: DuPLUS establishes a versatile and clinically relevant solution for medical image analysis with strong generalizability and extensibility capabilities.

Abstract: Deep learning for medical imaging is hampered by task-specific models that
lack generalizability and prognostic capabilities, while existing 'universal'
approaches suffer from simplistic conditioning and poor medical semantic
understanding. To address these limitations, we introduce DuPLUS, a deep
learning framework for efficient multi-modal medical image analysis. DuPLUS
introduces a novel vision-language framework that leverages hierarchical
semantic prompts for fine-grained control over the analysis task, a capability
absent in prior universal models. To enable extensibility to other medical
tasks, it includes a hierarchical, text-controlled architecture driven by a
unique dual-prompt mechanism. For segmentation, DuPLUS is able to generalize
across three imaging modalities, ten different anatomically various medical
datasets, encompassing more than 30 organs and tumor types. It outperforms the
state-of-the-art task specific and universal models on 8 out of 10 datasets. We
demonstrate extensibility of its text-controlled architecture by seamless
integration of electronic health record (EHR) data for prognosis prediction,
and on a head and neck cancer dataset, DuPLUS achieved a Concordance Index (CI)
of 0.69. Parameter-efficient fine-tuning enables rapid adaptation to new tasks
and modalities from varying centers, establishing DuPLUS as a versatile and
clinically relevant solution for medical image analysis. The code for this work
is made available at: https://anonymous.4open.science/r/DuPLUS-6C52

</details>


### [133] [Real-Time Threaded Houbara Detection and Segmentation for Wildlife Conservation using Mobile Platforms](https://arxiv.org/abs/2510.03501)
*Lyes Saad Saoud,Loic Lesobre,Enrico Sorato,Irfan Hussain*

Main category: cs.CV

TL;DR: A mobile-optimized two-stage framework combining YOLOv10 detection and MobileSAM segmentation with threading for real-time animal detection and segmentation in wildlife conservation.


<details>
  <summary>Details</summary>
Motivation: Real-time animal detection and segmentation in natural environments are vital for wildlife conservation through non-invasive monitoring, but remain challenging due to limited computational resources and cryptic species appearance.

Method: Proposes a mobile-optimized two-stage deep learning framework that integrates a Threading Detection Model (TDM) to parallelize YOLOv10-based detection and MobileSAM-based segmentation, executing both concurrently for efficient resource use.

Result: On the cryptic Houbara Bustard, achieves mAP50 of 0.9627, mAP75 of 0.7731, mAP95 of 0.7178, and MobileSAM mIoU of 0.7421. YOLOv10 operates at 43.7 ms per frame, confirming real-time readiness. Introduces a curated Houbara dataset of 40,000 annotated images.

Conclusion: The proposed threading-based approach successfully enables real-time animal detection and segmentation for wildlife conservation, with high accuracy and efficiency demonstrated on the Houbara Bustard species.

Abstract: Real-time animal detection and segmentation in natural environments are vital
for wildlife conservation, enabling non-invasive monitoring through remote
camera streams. However, these tasks remain challenging due to limited
computational resources and the cryptic appearance of many species. We propose
a mobile-optimized two-stage deep learning framework that integrates a
Threading Detection Model (TDM) to parallelize YOLOv10-based detection and
MobileSAM-based segmentation. Unlike prior YOLO+SAM pipelines, our approach
improves real-time performance by reducing latency through threading. YOLOv10
handles detection while MobileSAM performs lightweight segmentation, both
executed concurrently for efficient resource use. On the cryptic Houbara
Bustard, a conservation-priority species, our model achieves mAP50 of 0.9627,
mAP75 of 0.7731, mAP95 of 0.7178, and a MobileSAM mIoU of 0.7421. YOLOv10
operates at 43.7 ms per frame, confirming real-time readiness. We introduce a
curated Houbara dataset of 40,000 annotated images to support model training
and evaluation across diverse conditions. The code and dataset used in this
study are publicly available on GitHub at
https://github.com/LyesSaadSaoud/mobile-houbara-detseg. For interactive demos
and additional resources, visit
https://lyessaadsaoud.github.io/LyesSaadSaoud-Threaded-YOLO-SAM-Houbara.

</details>


### [134] [Platonic Transformers: A Solid Choice For Equivariance](https://arxiv.org/abs/2510.03511)
*Mohammad Mohaiminul Islam,Rishabh Anand,David R. Wessels,Friso de Kruiff,Thijs P. Kuipers,Rex Ying,Clara I. Sánchez,Sharvaree Vadgama,Georg Bökman,Erik J. Bekkers*

Main category: cs.CV

TL;DR: The Platonic Transformer introduces geometric inductive biases into Transformers using Platonic solid symmetry groups, achieving equivariance to continuous translations and Platonic symmetries without increasing computational cost.


<details>
  <summary>Details</summary>
Motivation: Transformers lack geometric symmetry biases common in scientific domains, while existing equivariant methods sacrifice efficiency and flexibility with complex designs.

Method: Defines attention relative to reference frames from Platonic solid symmetry groups, creating a principled weight-sharing scheme that enables equivariance while preserving standard Transformer architecture and computational cost.

Result: Achieves competitive performance across computer vision (CIFAR-10), 3D point clouds (ScanObjectNN), and molecular property prediction (QM9, OMol25) benchmarks by leveraging geometric constraints at no additional cost.

Conclusion: The Platonic Transformer resolves the trade-off between geometric equivariance and Transformer efficiency, demonstrating that geometric biases can be incorporated without sacrificing computational performance.

Abstract: While widespread, Transformers lack inductive biases for geometric symmetries
common in science and computer vision. Existing equivariant methods often
sacrifice the efficiency and flexibility that make Transformers so effective
through complex, computationally intensive designs. We introduce the Platonic
Transformer to resolve this trade-off. By defining attention relative to
reference frames from the Platonic solid symmetry groups, our method induces a
principled weight-sharing scheme. This enables combined equivariance to
continuous translations and Platonic symmetries, while preserving the exact
architecture and computational cost of a standard Transformer. Furthermore, we
show that this attention is formally equivalent to a dynamic group convolution,
which reveals that the model learns adaptive geometric filters and enables a
highly scalable, linear-time convolutional variant. Across diverse benchmarks
in computer vision (CIFAR-10), 3D point clouds (ScanObjectNN), and molecular
property prediction (QM9, OMol25), the Platonic Transformer achieves
competitive performance by leveraging these geometric constraints at no
additional cost.

</details>


### [135] [Domain Generalization for Semantic Segmentation: A Survey](https://arxiv.org/abs/2510.03540)
*Manuel Schwonberg,Hanno Gottschalk*

Main category: cs.CV

TL;DR: This survey provides a comprehensive overview of domain generalized semantic segmentation, highlighting the paradigm shift towards foundation-model-based approaches and their significant impact on performance.


<details>
  <summary>Details</summary>
Motivation: Deep neural networks struggle with generalization to unknown domains, and domain generalization (DG) addresses this challenge by enabling models to perform well across multiple unseen target domains without access to target domain data.

Method: The survey clusters and reviews existing DG approaches for semantic segmentation, identifying the emerging trend towards foundation-model-based methods.

Result: Extensive performance comparisons reveal that foundation models have a significant influence on domain generalization performance in semantic segmentation.

Conclusion: This survey aims to advance domain generalization research and inspire new research directions in the field.

Abstract: The generalization of deep neural networks to unknown domains is a major
challenge despite their tremendous progress in recent years. For this reason,
the dynamic area of domain generalization (DG) has emerged. In contrast to
unsupervised domain adaptation, there is no access to or knowledge about the
target domains, and DG methods aim to generalize across multiple different
unseen target domains. Domain generalization is particularly relevant for the
task semantic segmentation which is used in several areas such as biomedicine
or automated driving. This survey provides a comprehensive overview of the
rapidly evolving topic of domain generalized semantic segmentation. We cluster
and review existing approaches and identify the paradigm shift towards
foundation-model-based domain generalization. Finally, we provide an extensive
performance comparison of all approaches, which highlights the significant
influence of foundation models on domain generalization. This survey seeks to
advance domain generalization research and inspire scientists to explore new
research directions.

</details>


### [136] [From Scope to Script: An Automated Report Generation Model for Gastrointestinal Endoscopy](https://arxiv.org/abs/2510.03543)
*Evandros Kaklamanos,Kristjana Kristinsdottir,Jonathan Huang,Dustin Carlson,Rajesh Keswani,John Pandolfino,Mozziyar Etemadi*

Main category: cs.CV

TL;DR: A transformer-based automated report generation model for endoscopic procedures that reduces documentation burden on gastroenterologists.


<details>
  <summary>Details</summary>
Motivation: Endoscopic procedures create significant documentation burden, contributing to inefficiencies in clinical workflows and physician burnout.

Method: Two-stage training framework: pre-training transformer-based vision encoder and text decoder on image/text caption pairs, then fine-tuning on images/report pairs to generate clinical findings.

Result: The model streamlines documentation process and reduces physician workload.

Conclusion: The approach shows promise for improving patient care by automating report generation for endoscopic procedures.

Abstract: Endoscopic procedures such as esophagogastroduodenoscopy (EGD) and
colonoscopy play a critical role in diagnosing and managing gastrointestinal
(GI) disorders. However, the documentation burden associated with these
procedures place significant strain on gastroenterologists, contributing to
inefficiencies in clinical workflows and physician burnout. To address this
challenge, we propose a novel automated report generation model that leverages
a transformer-based vision encoder and text decoder within a two-stage training
framework. In the first stage, both components are pre-trained on image/text
caption pairs to capture generalized vision-language features, followed by
fine-tuning on images/report pairs to generate clinically meaningful findings.
Our approach not only streamlines the documentation process but also holds
promise for reducing physician workload and improving patient care.

</details>


### [137] [SketchPlan: Diffusion Based Drone Planning From Human Sketches](https://arxiv.org/abs/2510.03545)
*Sixten Norelius,Aaron O. Feldman,Mac Schwager*

Main category: cs.CV

TL;DR: SketchPlan is a diffusion-based planner that converts 2D hand-drawn sketches over depth images into 3D flight paths for drone navigation, achieving zero-shot sim-to-real transfer.


<details>
  <summary>Details</summary>
Motivation: To enable intuitive drone navigation through hand-drawn sketches while overcoming the gap between ideal 2D projections and real human sketches.

Method: Uses a two-component system: SketchAdapter maps human sketches to 2D paths, and DiffPath (diffusion model) infers 3D trajectories from 2D projections and depth images. Trained on 32k synthetic flight paths with 872 human-labeled sketches.

Result: Achieved 100% success in low/medium clutter and 40% in unseen high-clutter environments, outperforming ablations by 20-60% in task completion. Demonstrated effective zero-shot sim-to-real transfer.

Conclusion: The modular design with mixed training data (human-labeled and auto-labeled) significantly improves human intent interpretation and 3D path inference capabilities for drone navigation.

Abstract: We propose SketchPlan, a diffusion-based planner that interprets 2D
hand-drawn sketches over depth images to generate 3D flight paths for drone
navigation. SketchPlan comprises two components: a SketchAdapter that learns to
map the human sketches to projected 2D paths, and DiffPath, a diffusion model
that infers 3D trajectories from 2D projections and a first person view depth
image. Our model achieves zero-shot sim-to-real transfer, generating accurate
and safe flight paths in previously unseen real-world environments. To train
the model, we build a synthetic dataset of 32k flight paths using a diverse set
of photorealistic 3D Gaussian Splatting scenes. We automatically label the data
by computing 2D projections of the 3D flight paths onto the camera plane, and
use this to train the DiffPath diffusion model. However, since real human 2D
sketches differ significantly from ideal 2D projections, we additionally label
872 of the 3D flight paths with real human sketches and use this to train the
SketchAdapter to infer the 2D projection from the human sketch. We demonstrate
SketchPlan's effectiveness in both simulated and real-world experiments, and
show through ablations that training on a mix of human labeled and auto-labeled
data together with a modular design significantly boosts its capabilities to
correctly interpret human intent and infer 3D paths. In real-world drone tests,
SketchPlan achieved 100\% success in low/medium clutter and 40\% in unseen
high-clutter environments, outperforming key ablations by 20-60\% in task
completion.

</details>


### [138] [Unmasking Puppeteers: Leveraging Biometric Leakage to Disarm Impersonation in AI-based Videoconferencing](https://arxiv.org/abs/2510.03548)
*Danial Samadi Vahdati,Tai Duc Nguyen,Ekta Prashnani,Koki Nagano,David Luebke,Orazio Gallo,Matthew Stamm*

Main category: cs.CV

TL;DR: A biometric-based defense system that detects identity hijacking in AI-based talking-head videoconferencing by analyzing pose-expression latents rather than reconstructed RGB video.


<details>
  <summary>Details</summary>
Motivation: AI talking-head systems transmit compact pose-expression latents that can be puppeteered to hijack identities, and existing deepfake detectors fail because every frame is synthetic.

Method: A pose-conditioned, large-margin contrastive encoder that isolates persistent identity cues from transmitted latents while canceling transient pose and expression, followed by cosine similarity testing.

Result: The method consistently outperforms existing puppeteering defenses, operates in real-time, and shows strong generalization to out-of-distribution scenarios across multiple talking-head generation models.

Conclusion: The proposed biometric leakage defense effectively detects identity swaps by analyzing pose-expression latents directly, providing real-time protection against puppeteering attacks in talking-head videoconferencing systems.

Abstract: AI-based talking-head videoconferencing systems reduce bandwidth by sending a
compact pose-expression latent and re-synthesizing RGB at the receiver, but
this latent can be puppeteered, letting an attacker hijack a victim's likeness
in real time. Because every frame is synthetic, deepfake and synthetic video
detectors fail outright. To address this security problem, we exploit a key
observation: the pose-expression latent inherently contains biometric
information of the driving identity. Therefore, we introduce the first
biometric leakage defense without ever looking at the reconstructed RGB video:
a pose-conditioned, large-margin contrastive encoder that isolates persistent
identity cues inside the transmitted latent while cancelling transient pose and
expression. A simple cosine test on this disentangled embedding flags illicit
identity swaps as the video is rendered. Our experiments on multiple
talking-head generation models show that our method consistently outperforms
existing puppeteering defenses, operates in real-time, and shows strong
generalization to out-of-distribution scenarios.

</details>


### [139] [Streaming Drag-Oriented Interactive Video Manipulation: Drag Anything, Anytime!](https://arxiv.org/abs/2510.03550)
*Junbao Zhou,Yuan Zhou,Kesen Zhao,Qingshan Xu,Beier Zhu,Richang Hong,Hanwang Zhang*

Main category: cs.CV

TL;DR: REVEL enables interactive drag-based video manipulation anytime on any content, unifying translation, deformation, and rotation effects. DragStream addresses latent distribution drift and context interference through adaptive self-rectification and spatial-frequency optimization.


<details>
  <summary>Details</summary>
Motivation: Current autoregressive video diffusion models lack fine-grained streaming control over outputs, making it difficult to ensure consistent alignment with user expectations through interactive manipulation.

Method: Proposes DragStream with two key components: 1) adaptive distribution self-rectification using neighboring frames' statistics to constrain latent embedding drift, and 2) spatial-frequency selective optimization to exploit contextual information while mitigating interference through selective visual cue propagation.

Result: Extensive experiments demonstrate DragStream's effectiveness in enabling streaming, fine-grained drag-based video manipulation that can be seamlessly integrated into existing autoregressive video diffusion models.

Conclusion: REVEL and DragStream successfully bridge the gap in interactive video manipulation, providing versatile drag operations for editing and animating video frames with translation, deformation, and rotation effects while maintaining natural visual outcomes.

Abstract: Achieving streaming, fine-grained control over the outputs of autoregressive
video diffusion models remains challenging, making it difficult to ensure that
they consistently align with user expectations. To bridge this gap, we propose
\textbf{stReaming drag-oriEnted interactiVe vidEo manipuLation (REVEL)}, a new
task that enables users to modify generated videos \emph{anytime} on
\emph{anything} via fine-grained, interactive drag. Beyond DragVideo and
SG-I2V, REVEL unifies drag-style video manipulation as editing and animating
video frames with both supporting user-specified translation, deformation, and
rotation effects, making drag operations versatile. In resolving REVEL, we
observe: \emph{i}) drag-induced perturbations accumulate in latent space,
causing severe latent distribution drift that halts the drag process;
\emph{ii}) streaming drag is easily disturbed by context frames, thereby
yielding visually unnatural outcomes. We thus propose a training-free approach,
\textbf{DragStream}, comprising: \emph{i}) an adaptive distribution
self-rectification strategy that leverages neighboring frames' statistics to
effectively constrain the drift of latent embeddings; \emph{ii}) a
spatial-frequency selective optimization mechanism, allowing the model to fully
exploit contextual information while mitigating its interference via
selectively propagating visual cues along generation. Our method can be
seamlessly integrated into existing autoregressive video diffusion models, and
extensive experiments firmly demonstrate the effectiveness of our DragStream.

</details>


### [140] [GAS-MIL: Group-Aggregative Selection Multi-Instance Learning for Ensemble of Foundation Models in Digital Pathology Image Analysis](https://arxiv.org/abs/2510.03555)
*Peiran Quan,Zifan Gu,Zhuo Zhao,Qin Zhou,Donghan M. Yang,Ruichen Rong,Yang Xie,Guanghua Xiao*

Main category: cs.CV

TL;DR: GAS-MIL is an ensemble framework that efficiently integrates multiple foundation models for computational pathology without requiring manual feature selection or extensive fine-tuning, achieving superior performance across multiple cancer datasets.


<details>
  <summary>Details</summary>
Motivation: Foundation models provide powerful feature extractors for computational pathology, but adapting and benchmarking individual models for specific diagnostic tasks is time-consuming and resource-intensive due to their scale and diversity.

Method: Group-Aggregative Selection Multi-Instance Learning (GAS-MIL) - a flexible ensemble framework that seamlessly integrates features from multiple foundation models while preserving their complementary strengths.

Result: Across three cancer datasets (prostate, ovarian, and breast), GAS-MIL consistently achieves superior or on-par performance relative to individual foundation models and established multi-instance learning methods.

Conclusion: GAS-MIL enables efficient integration of heterogeneous foundation models, streamlines model deployment for pathology, and provides a scalable foundation for future multimodal and precision oncology applications.

Abstract: Foundation models (FMs) have transformed computational pathology by providing
powerful, general-purpose feature extractors. However, adapting and
benchmarking individual FMs for specific diagnostic tasks is often
time-consuming and resource-intensive, especially given their scale and
diversity. To address this challenge, we introduce Group-Aggregative Selection
Multi-Instance Learning (GAS-MIL), a flexible ensemble framework that
seamlessly integrates features from multiple FMs, preserving their
complementary strengths without requiring manual feature selection or extensive
task-specific fine-tuning. Across classification tasks in three cancer
datasets-prostate (PANDA), ovarian (UBC-OCEAN), and breast (TCGA-BrCa)-GAS-MIL
consistently achieves superior or on-par performance relative to individual FMs
and established MIL methods, demonstrating its robustness and generalizability.
By enabling efficient integration of heterogeneous FMs, GAS-MIL streamlines
model deployment for pathology and provides a scalable foundation for future
multimodal and precision oncology applications.

</details>


### [141] [Real-Time Assessment of Bystander Situation Awareness in Drone-Assisted First Aid](https://arxiv.org/abs/2510.03558)
*Shen Chang,Renran Tian,Nicole Adams,Nan Kong*

Main category: cs.CV

TL;DR: A real-time situational awareness assessment framework for drone-assisted naloxone delivery using graph embeddings and transformers, achieving high-performance prediction and temporal segmentation accuracy.


<details>
  <summary>Details</summary>
Motivation: To address the critical need for real-time situational awareness assessment in human-autonomy teaming during opioid overdose emergencies, enabling bystanders to effectively administer naloxone before EMS arrival.

Method: Proposed a video-based real-time SA assessment framework using graph embeddings and transformer models, integrating visual perception and comprehension cues including geometric, kinematic, and interaction graph features.

Result: Achieved high-performance SA prediction with strong temporal segmentation accuracy, outperforming FINCH baseline by 9% in Mean over Frames (MoF) and 5% in Intersection over Union (IoU).

Conclusion: The framework supports development of adaptive drone systems that can effectively guide bystanders in opioid overdose emergencies, improving emergency response outcomes and saving lives.

Abstract: Rapid naloxone delivery via drones offers a promising solution for responding
to opioid overdose emergencies (OOEs), by extending lifesaving interventions to
medically untrained bystanders before emergency medical services (EMS) arrive.
Recognizing the critical role of bystander situational awareness (SA) in
human-autonomy teaming (HAT), we address a key research gap in real-time SA
assessment by introducing the Drone-Assisted Naloxone Delivery Simulation
Dataset (DANDSD). This pioneering dataset captures HAT during simulated OOEs,
where college students without medical training act as bystanders tasked with
administering intranasal naloxone to a mock overdose victim. Leveraging this
dataset, we propose a video-based real-time SA assessment framework that
utilizes graph embeddings and transformer models to assess bystander SA in real
time. Our approach integrates visual perception and comprehension cues--such as
geometric, kinematic, and interaction graph features--and achieves
high-performance SA prediction. It also demonstrates strong temporal
segmentation accuracy, outperforming the FINCH baseline by 9% in Mean over
Frames (MoF) and 5% in Intersection over Union (IoU). This work supports the
development of adaptive drone systems capable of guiding bystanders
effectively, ultimately improving emergency response outcomes and saving lives.

</details>


### [142] [Evaluating OCR performance on food packaging labels in South Africa](https://arxiv.org/abs/2510.03570)
*Mayimunah Nagayi,Alice Khan,Tamryn Frank,Rina Swart,Clement Nyirenda*

Main category: cs.CV

TL;DR: Evaluation of four OCR systems (Tesseract, EasyOCR, PaddleOCR, TrOCR) on food packaging images shows Tesseract has best accuracy, EasyOCR offers good multilingual balance, PaddleOCR has high coverage but is slow, while TrOCR performs worst despite GPU acceleration.


<details>
  <summary>Details</summary>
Motivation: Accurate OCR for food packaging is important for compliance and nutrition monitoring but challenging due to multilingual text, dense layouts, varied fonts, glare, and curved surfaces.

Method: Used dataset of 231 products (1,628 images) processed by four OCR models to assess speed and coverage, with ground truth subset of 113 images (60 products) for accuracy evaluation using metrics including CER, WER, BLEU, ROUGE-L, F1, coverage, and execution time.

Result: Tesseract achieved lowest CER (0.912) and highest BLEU (0.245). EasyOCR provided good balance between accuracy and multilingual support. PaddleOCR achieved near complete coverage but was slower due to CPU-only operation. TrOCR produced weakest results despite GPU acceleration.

Conclusion: Results provide packaging-specific benchmark, establish baseline, and highlight directions for layout-aware methods and text localization.

Abstract: This study evaluates four open-source Optical Character Recognition (OCR)
systems which are Tesseract, EasyOCR, PaddleOCR, and TrOCR on real world food
packaging images. The aim is to assess their ability to extract ingredient
lists and nutrition facts panels. Accurate OCR for packaging is important for
compliance and nutrition monitoring but is challenging due to multilingual
text, dense layouts, varied fonts, glare, and curved surfaces. A dataset of 231
products (1,628 images) was processed by all four models to assess speed and
coverage, and a ground truth subset of 113 images (60 products) was created for
accuracy evaluation. Metrics include Character Error Rate (CER), Word Error
Rate (WER), BLEU, ROUGE-L, F1, coverage, and execution time. On the ground
truth subset, Tesseract achieved the lowest CER (0.912) and the highest BLEU
(0.245). EasyOCR provided a good balance between accuracy and multilingual
support. PaddleOCR achieved near complete coverage but was slower because it
ran on CPU only due to GPU incompatibility, and TrOCR produced the weakest
results despite GPU acceleration. These results provide a packaging-specific
benchmark, establish a baseline, and highlight directions for layout-aware
methods and text localization.

</details>


### [143] [FrameOracle: Learning What to See and How Much to See in Videos](https://arxiv.org/abs/2510.03584)
*Chaoyu Li,Tianzhi Li,Fei Tao,Zhenyu Zhao,Ziqian Wu,Maozheng Zhao,Juntong Song,Cheng Niu,Pooyan Fazli*

Main category: cs.CV

TL;DR: FrameOracle is a lightweight plug-and-play module that intelligently selects relevant frames and determines optimal frame count for video understanding, reducing input frames by 35-78% while maintaining or improving accuracy.


<details>
  <summary>Details</summary>
Motivation: Current frame sampling methods (uniform/fixed-budget) fail to adapt to information density and task complexity variations, causing inefficiency and information loss in video understanding.

Method: Four-stage curriculum training using weak proxy signals initially, then strong supervision from FrameOracle-41K dataset with keyframe annotations. Predicts both relevant frames and optimal frame count.

Result: Reduces 16-frame inputs to 10.4 frames (35% reduction) without accuracy loss. With 64-frame candidates, reduces to 13.9 frames (78% reduction) while improving accuracy by 1.4%. Achieves SOTA efficiency-accuracy trade-offs.

Conclusion: FrameOracle enables scalable video understanding through adaptive frame selection, significantly reducing computational costs while maintaining or enhancing performance across multiple VLMs and benchmarks.

Abstract: Vision-language models (VLMs) have advanced video understanding, but their
performance is limited by the number of input frames they can process. Existing
frame sampling strategies, such as uniform or fixed-budget selection, often
fail to adapt to variations in information density or task complexity,
resulting in inefficiency and information loss. To address this, we present
FrameOracle, a lightweight and plug-and-play module that predicts both (1)
which frames are most relevant to a given query and (2) how many frames are
needed. FrameOracle is trained using a four-stage curriculum, with the first
three stages relying on weak proxy signals such as cross-modal similarity. In
the final stage, it leverages stronger supervision from a new dataset we
introduce, FrameOracle-41K, the first large-scale VideoQA collection to provide
keyframe annotations specifying the minimal set of frames required to answer
each question. Extensive experiments across five VLMs and six benchmarks
demonstrate that FrameOracle reduces 16-frame inputs to an average of 10.4
frames without any loss in accuracy. When starting from 64-frame candidates, it
reduces the input to an average of 13.9 frames while improving accuracy by
1.4%, achieving state-of-the-art efficiency-accuracy trade-offs for scalable
video understanding.

</details>


### [144] [A Hybrid Co-Finetuning Approach for Visual Bug Detection in Video Games](https://arxiv.org/abs/2510.03591)
*Faliu Yi,Sherif Abdelfattah,Wei Huang,Adrian Brown*

Main category: cs.CV

TL;DR: Proposes a hybrid Co-FineTuning (CFT) method for visual bug detection in video games that combines labeled and unlabeled data from target and co-domain games to reduce dependency on extensive labeled datasets.


<details>
  <summary>Details</summary>
Motivation: Manual visual bug detection in games is resource-intensive and costly, while supervised models require extensive labeled data which is challenging due to infrequent occurrence of visual bugs.

Method: Hybrid Co-FineTuning (CFT) method that integrates labeled samples from target game and co-domain games with unlabeled data to enhance feature representation learning.

Result: Superior performance compared to conventional baselines across multiple gaming environments, maintains competitive performance with only 50% of labeled data from target game.

Conclusion: CFT method effectively reduces dependency on labeled examples, demonstrates enhanced scalability and adaptability for efficient visual bug detection across various game titles.

Abstract: Manual identification of visual bugs in video games is a resource-intensive
and costly process, often demanding specialized domain knowledge. While
supervised visual bug detection models offer a promising solution, their
reliance on extensive labeled datasets presents a significant challenge due to
the infrequent occurrence of such bugs. To overcome this limitation, we propose
a hybrid Co-FineTuning (CFT) method that effectively integrates both labeled
and unlabeled data. Our approach leverages labeled samples from the target game
and diverse co-domain games, additionally incorporating unlabeled data to
enhance feature representation learning. This strategy maximizes the utility of
all available data, substantially reducing the dependency on labeled examples
from the specific target game. The developed framework demonstrates enhanced
scalability and adaptability, facilitating efficient visual bug detection
across various game titles. Our experimental results show the robustness of the
proposed method for game visual bug detection, exhibiting superior performance
compared to conventional baselines across multiple gaming environments.
Furthermore, CFT maintains competitive performance even when trained with only
50% of the labeled data from the target game.

</details>


### [145] [Exploring the Hierarchical Reasoning Model for Small Natural-Image Classification Without Augmentation](https://arxiv.org/abs/2510.03598)
*Alexander V. Mantzaris*

Main category: cs.CV

TL;DR: HRM with Transformer-style modules performs well on MNIST but overfits and generalizes poorly on CIFAR datasets, being outperformed by simple CNNs in raw training regimes without data augmentation.


<details>
  <summary>Details</summary>
Motivation: To evaluate if the Hierarchical Reasoning Model (HRM) with specific architectural choices can serve as a practical image classifier under deliberately raw training conditions.

Method: Used HRM with two Transformer-style modules, DEQ-style one-step training, deep supervision, Rotary Position Embeddings, and RMSNorm. Evaluated on MNIST, CIFAR-10, and CIFAR-100 without data augmentation using identical optimizer with one-epoch warmup and cosine-floor decay.

Result: HRM achieved ~98% on MNIST but performed poorly on natural images: 65.0% on CIFAR-10 vs 77.2% for CNN baseline, and 29.7% on CIFAR-100 vs 45.3% for CNN. HRM trained ~30x slower per epoch and showed significant overfitting.

Conclusion: HRM is not competitive with simple convolutional architectures for small-resolution image classification without augmentation due to insufficient image-specific inductive bias, though modifications could potentially improve performance.

Abstract: This paper asks whether the Hierarchical Reasoning Model (HRM) with the two
Transformer-style modules $(f_L,f_H)$, one step (DEQ-style) training, deep
supervision, Rotary Position Embeddings, and RMSNorm can serve as a practical
image classifier. It is evaluated on MNIST, CIFAR-10, and CIFAR-100 under a
deliberately raw regime: no data augmentation, identical optimizer family with
one-epoch warmup then cosine-floor decay, and label smoothing. HRM optimizes
stably and performs well on MNIST ($\approx 98\%$ test accuracy), but on small
natural images it overfits and generalizes poorly: on CIFAR-10, HRM reaches
65.0\% after 25 epochs, whereas a two-stage Conv--BN--ReLU baseline attains
77.2\% while training $\sim 30\times$ faster per epoch; on CIFAR-100, HRM
achieves only 29.7\% test accuracy despite 91.5\% train accuracy, while the
same CNN reaches 45.3\% test with 50.5\% train accuracy. Loss traces and error
analyses indicate healthy optimization but insufficient image-specific
inductive bias for HRM in this regime. It is concluded that, for
small-resolution image classification without augmentation, HRM is not
competitive with even simple convolutional architectures as the HRM currently
exist but this does not exclude possibilities that modifications to the model
may allow it to improve greatly.

</details>


### [146] [Unsupervised Transformer Pre-Training for Images: Self-Distillation, Mean Teachers, and Random Crops](https://arxiv.org/abs/2510.03606)
*Mattia Scardecchia*

Main category: cs.CV

TL;DR: Survey of DINOv2's self-supervised learning approach, comparing it with other methods and highlighting its emergent properties and limitations.


<details>
  <summary>Details</summary>
Motivation: Recent SSL advances like DINOv2 have surpassed weakly supervised methods on benchmarks, prompting examination of its core ideas and performance.

Method: Analyzes DINOv2's multi-crop view augmentation and self-distillation with mean teacher, tracing their development from previous work.

Result: DINOv2 establishes new state-of-the-art, outperforming WSL methods like OpenCLIP on most benchmarks with remarkable emergent properties in transformer features.

Conclusion: Discusses DINOv2's limitations, impact, and future research directions in self-supervised learning.

Abstract: Recent advances in self-supervised learning (SSL) have made it possible to
learn general-purpose visual features that capture both the high-level
semantics and the fine-grained spatial structure of images. Most notably, the
recent DINOv2 has established a new state of the art by surpassing weakly
supervised methods (WSL) like OpenCLIP on most benchmarks. In this survey, we
examine the core ideas behind its approach, multi-crop view augmentation and
self-distillation with a mean teacher, and trace their development in previous
work. We then compare the performance of DINO and DINOv2 with other SSL and WSL
methods across various downstream tasks, and highlight some remarkable emergent
properties of their learned features with transformer backbones. We conclude by
briefly discussing DINOv2's limitations, its impact, and future research
directions.

</details>


### [147] [Diffusion-Classifier Synergy: Reward-Aligned Learning via Mutual Boosting Loop for FSCIL](https://arxiv.org/abs/2510.03608)
*Ruitao Wu,Yifan Zhao,Guangyao Chen,Jia Li*

Main category: cs.CV

TL;DR: DCS is a novel framework that creates a mutual boosting loop between diffusion models and FSCIL classifiers using reward-aligned learning to generate semantically aligned and diverse images for few-shot class-incremental learning.


<details>
  <summary>Details</summary>
Motivation: Address the challenges of FSCIL where models struggle with generalization due to limited data and the stability-plasticity dilemma, while overcoming issues with direct diffusion model application like semantic misalignment.

Method: Uses a dynamic multi-faceted reward function derived from classifier state to guide diffusion model at feature level (semantic coherence/diversity via prototype-anchored MMD and variance matching) and logits level (exploratory generation and inter-class discriminability via confidence recalibration and cross-session confusion-aware mechanisms).

Result: Achieves state-of-the-art performance on FSCIL benchmarks, significantly enhancing both knowledge retention and new class learning.

Conclusion: The co-evolutionary process between diffusion model and classifier through reward-aligned learning effectively addresses FSCIL challenges and demonstrates superior performance.

Abstract: Few-Shot Class-Incremental Learning (FSCIL) challenges models to sequentially
learn new classes from minimal examples without forgetting prior knowledge, a
task complicated by the stability-plasticity dilemma and data scarcity. Current
FSCIL methods often struggle with generalization due to their reliance on
limited datasets. While diffusion models offer a path for data augmentation,
their direct application can lead to semantic misalignment or ineffective
guidance. This paper introduces Diffusion-Classifier Synergy (DCS), a novel
framework that establishes a mutual boosting loop between diffusion model and
FSCIL classifier. DCS utilizes a reward-aligned learning strategy, where a
dynamic, multi-faceted reward function derived from the classifier's state
directs the diffusion model. This reward system operates at two levels: the
feature level ensures semantic coherence and diversity using prototype-anchored
maximum mean discrepancy and dimension-wise variance matching, while the logits
level promotes exploratory image generation and enhances inter-class
discriminability through confidence recalibration and cross-session
confusion-aware mechanisms. This co-evolutionary process, where generated
images refine the classifier and an improved classifier state yields better
reward signals, demonstrably achieves state-of-the-art performance on FSCIL
benchmarks, significantly enhancing both knowledge retention and new class
learning.

</details>


### [148] [MonitorVLM:A Vision Language Framework for Safety Violation Detection in Mining Operations](https://arxiv.org/abs/2510.03666)
*Jiang Wu,Sichao Wu,Yinsong Ma,Guangyuan Yu,Haoyuan Xu,Lifang Zheng,Jingliang Duan*

Main category: cs.CV

TL;DR: MonitorVLM is a vision-language framework that automatically detects safety violations in mining surveillance videos using domain-specific datasets, clause filtering, and behavior magnification to improve detection accuracy and efficiency.


<details>
  <summary>Details</summary>
Motivation: Traditional manual safety inspections in mining are labor-intensive, error-prone, and insufficient for large-scale dynamic environments, creating an urgent need for automated intelligent safety monitoring systems.

Method: MonitorVLM uses three innovations: (1) domain-specific violation dataset with 9,000 VQA samples across 40 mining regulations, (2) clause filter module that selects Top-K relevant clauses to reduce latency, and (3) behavior magnifier module that enhances worker regions for better action recognition.

Result: MonitorVLM significantly outperforms baseline models with 22.01% precision improvement, 34.22% recall improvement, and 28.37% F1 score improvement over 72B unfine-tuned baseline. The clause filter reduces inference latency by 13.56% while maintaining accuracy.

Conclusion: The study demonstrates the potential of multimodal large models to enhance occupational safety monitoring in mining and other high-risk industries through automated violation detection and reporting.

Abstract: Industrial accidents, particularly in high-risk domains such as surface and
underground mining, are frequently caused by unsafe worker behaviors.
Traditional manual inspection remains labor-intensive, error-prone, and
insufficient for large-scale, dynamic environments, highlighting the urgent
need for intelligent and automated safety monitoring. In this paper, we present
MonitorVLM, a novel vision--language framework designed to detect safety
violations directly from surveillance video streams. MonitorVLM introduces
three key innovations: (1) a domain-specific violation dataset comprising 9,000
vision--question--answer (VQA) samples across 40 high-frequency mining
regulations, enriched with augmentation and auxiliary detection cues; (2) a
clause filter (CF) module that dynamically selects the Top-$K$ most relevant
clauses, reducing inference latency by 13.56\% while maintaining accuracy; and
(3) a behavior magnifier (BM) module that enhances worker regions to improve
fine-grained action recognition, yielding additional gains of 3.45% in
precision and 8.62% in recall. Experimental results demonstrate that MonitorVLM
significantly outperforms baseline vision--language models, achieving
improvements of 22.01% in precision, 34.22\% in recall, and 28.37% in F1 score
over the 72B unfine-tuned baseline. A lightweight web-based interface further
integrates MonitorVLM into practical workflows, enabling automatic violation
reporting with video timestamping. This study highlights the potential of
multimodal large models to enhance occupational safety monitoring in mining and
beyond.

</details>


### [149] [A Novel Cloud-Based Diffusion-Guided Hybrid Model for High-Accuracy Accident Detection in Intelligent Transportation Systems](https://arxiv.org/abs/2510.03675)
*Siva Sai,Saksham Gupta,Vinay Chamola,Rajkumar Buyya*

Main category: cs.CV

TL;DR: A hybrid model combining diffusion models with guidance classification for improved accident detection in ITS, achieving 97.32% accuracy.


<details>
  <summary>Details</summary>
Motivation: To overcome limitations of conventional classification approaches in ITS by leveraging diffusion models' ability to understand complex data distributions for better accident detection.

Method: Hybrid model integrating ExceptionNet outputs with diffusion techniques, using image tensors as conditioning, multiple conditional modules with time and image embeddings, and cloud-based implementation for scalability.

Result: Achieved 97.32% accuracy in image-based accident detection, outperforming baseline models on a publicly available dataset.

Conclusion: The proposed diffusion-based approach provides a robust and effective framework for accident detection in intelligent transportation systems.

Abstract: The integration of Diffusion Models into Intelligent Transportation Systems
(ITS) is a substantial improvement in the detection of accidents. We present a
novel hybrid model integrating guidance classification with diffusion
techniques. By leveraging fine-tuned ExceptionNet architecture outputs as input
for our proposed diffusion model and processing image tensors as our
conditioning, our approach creates a robust classification framework. Our model
consists of multiple conditional modules, which aim to modulate the linear
projection of inputs using time embeddings and image covariate embeddings,
allowing the network to adapt its behavior dynamically throughout the diffusion
process. To address the computationally intensive nature of diffusion models,
our implementation is cloud-based, enabling scalable and efficient processing.
Our strategy overcomes the shortcomings of conventional classification
approaches by leveraging diffusion models inherent capacity to effectively
understand complicated data distributions. We investigate important diffusion
characteristics, such as timestep schedulers, timestep encoding techniques,
timestep count, and architectural design changes, using a thorough ablation
study, and have conducted a comprehensive evaluation of the proposed model
against the baseline models on a publicly available dataset. The proposed
diffusion model performs best in image-based accident detection with an
accuracy of 97.32%.

</details>


### [150] [SAMSOD: Rethinking SAM Optimization for RGB-T Salient Object Detection](https://arxiv.org/abs/2510.03689)
*Zhengyi Liu,Xinrui Wang,Xianyong Fang,Zhengzheng Tu,Linbo Wang*

Main category: cs.CV

TL;DR: SAMSOD model improves RGB-T salient object detection by addressing modality imbalance and gradient conflicts through unimodal supervision, gradient deconfliction, and decoupled adapters for high/low activation neurons.


<details>
  <summary>Details</summary>
Motivation: Existing methods ignore the imbalance convergence between RGB and thermal modalities and the gradient differences between high- and low-activation regions, limiting performance improvement.

Method: Proposes SAMSOD with unimodal supervision for non-dominant modality learning, gradient deconfliction to reduce conflicting gradients, and two decoupled adapters to separately mask high- and low-activation neurons to enhance background learning.

Result: Demonstrates effectiveness through fundamental experiments on RGB-T SOD benchmarks and generalizability tests on scribble-supervised RGB-T SOD, RGB-D SOD datasets, and RGB-D rail surface defect detection.

Conclusion: The proposed SAMSOD method effectively addresses modality imbalance and gradient conflicts, showing strong performance across multiple SOD tasks and datasets.

Abstract: RGB-T salient object detection (SOD) aims to segment attractive objects by
combining RGB and thermal infrared images. To enhance performance, the Segment
Anything Model has been fine-tuned for this task. However, the imbalance
convergence of two modalities and significant gradient difference between high-
and low- activations are ignored, thereby leaving room for further performance
enhancement. In this paper, we propose a model called \textit{SAMSOD}, which
utilizes unimodal supervision to enhance the learning of non-dominant modality
and employs gradient deconfliction to reduce the impact of conflicting
gradients on model convergence. The method also leverages two decoupled
adapters to separately mask high- and low-activation neurons, emphasizing
foreground objects by enhancing background learning. Fundamental experiments on
RGB-T SOD benchmark datasets and generalizability experiments on scribble
supervised RGB-T SOD, fully supervised RGB-D SOD datasets and full-supervised
RGB-D rail surface defect detection all demonstrate the effectiveness of our
proposed method.

</details>


### [151] [Referring Expression Comprehension for Small Objects](https://arxiv.org/abs/2510.03701)
*Kanoko Goto,Takumi Hirose,Mahiro Ukai,Shuhei Kurita,Nakamasa Inoue*

Main category: cs.CV

TL;DR: The paper introduces SOREC dataset for small object referring expression comprehension and proposes PIZA adapter for progressive zooming to improve small object localization.


<details>
  <summary>Details</summary>
Motivation: Localizing extremely small objects in referring expression comprehension remains challenging despite advances in vision-language learning, especially for real-world applications like autonomous driving.

Method: Created SOREC dataset with 100K expression-bounding box pairs for small objects in driving scenarios, and proposed PIZA adapter module for parameter-efficient fine-tuning that enables progressive zooming for small object localization.

Result: Applied PIZA to GroundingDINO and demonstrated significant improvement in accuracy on the SOREC dataset.

Conclusion: The proposed dataset and method effectively address the challenge of small object localization in REC tasks, with publicly available resources for further research.

Abstract: Referring expression comprehension (REC) aims to localize the target object
described by a natural language expression. Recent advances in vision-language
learning have led to significant performance improvements in REC tasks.
However, localizing extremely small objects remains a considerable challenge
despite its importance in real-world applications such as autonomous driving.
To address this issue, we introduce a novel dataset and method for REC
targeting small objects. First, we present the small object REC (SOREC)
dataset, which consists of 100,000 pairs of referring expressions and
corresponding bounding boxes for small objects in driving scenarios. Second, we
propose the progressive-iterative zooming adapter (PIZA), an adapter module for
parameter-efficient fine-tuning that enables models to progressively zoom in
and localize small objects. In a series of experiments, we apply PIZA to
GroundingDINO and demonstrate a significant improvement in accuracy on the
SOREC dataset. Our dataset, codes and pre-trained models are publicly available
on the project page.

</details>


### [152] [Artery-Vein Segmentation from Fundus Images using Deep Learning](https://arxiv.org/abs/2510.03717)
*Sharan SK,Subin Sahayam,Umarani Jayaraman,Lakshmi Priya A*

Main category: cs.CV

TL;DR: Proposes Attention-WNet, a deep learning model combining attention mechanisms with WNet for retinal artery-vein segmentation, achieving state-of-the-art performance on HRF and DRIVE datasets.


<details>
  <summary>Details</summary>
Motivation: Retinal artery-vein segmentation is crucial for analyzing retinal vessels to identify biomarkers for eye diseases and systemic vascular conditions like stroke and myocardial infarction.

Method: Developed Attention-WNet by incorporating attention mechanisms into the WNet deep learning model for improved artery-vein segmentation.

Result: Outperformed other state-of-the-art models on publicly available HRF and DRIVE datasets.

Conclusion: The attention-enhanced WNet model provides an effective approach for retinal artery-vein segmentation with superior performance compared to existing methods.

Abstract: Segmenting of clinically important retinal blood vessels into arteries and
veins is a prerequisite for retinal vessel analysis. Such analysis can provide
potential insights and bio-markers for identifying and diagnosing various
retinal eye diseases. Alteration in the regularity and width of the retinal
blood vessels can act as an indicator of the health of the vasculature system
all over the body. It can help identify patients at high risk of developing
vasculature diseases like stroke and myocardial infarction. Over the years,
various Deep Learning architectures have been proposed to perform retinal
vessel segmentation. Recently, attention mechanisms have been increasingly used
in image segmentation tasks. The work proposes a new Deep Learning approach for
artery-vein segmentation. The new approach is based on the Attention mechanism
that is incorporated into the WNet Deep Learning model, and we call the model
as Attention-WNet. The proposed approach has been tested on publicly available
datasets such as HRF and DRIVE datasets. The proposed approach has outperformed
other state-of-art models available in the literature.

</details>


### [153] [Person-Centric Annotations of LAION-400M: Auditing Bias and Its Transfer to Models](https://arxiv.org/abs/2510.03721)
*Leander Girrbach,Stephan Alaniz,Genevieve Smith,Trevor Darrell,Zeynep Akata*

Main category: cs.CV

TL;DR: The paper creates demographic annotations for LAION-400M dataset, revealing significant biases and harmful associations in vision-language models, with 60-70% of gender bias explained by direct data co-occurrences.


<details>
  <summary>Details</summary>
Motivation: To understand how training data composition contributes to demographic biases in vision-language models, addressing the lack of demographic annotations in web-scale datasets like LAION-400M.

Method: Created person-centric annotations for LAION-400M using validated automatic labeling pipelines combining object detection, multimodal captioning, and finetuned classifiers, generating over 276 million bounding boxes and demographic labels.

Result: Uncovered demographic imbalances and harmful associations, including disproportionate linking of men and individuals perceived as Black or Middle Eastern with crime-related and negative content. Found that 60-70% of gender bias in CLIP and Stable Diffusion can be linearly explained by direct co-occurrences in the data.

Conclusion: Established the first large-scale empirical link between dataset composition and downstream model bias, providing resources to study and mitigate demographic biases in vision-language models.

Abstract: Vision-language models trained on large-scale multimodal datasets show strong
demographic biases, but the role of training data in producing these biases
remains unclear. A major barrier has been the lack of demographic annotations
in web-scale datasets such as LAION-400M. We address this gap by creating
person-centric annotations for the full dataset, including over 276 million
bounding boxes, perceived gender and race/ethnicity labels, and automatically
generated captions. These annotations are produced through validated automatic
labeling pipelines combining object detection, multimodal captioning, and
finetuned classifiers. Using them, we uncover demographic imbalances and
harmful associations, such as the disproportionate linking of men and
individuals perceived as Black or Middle Eastern with crime-related and
negative content. We also show that 60-70% of gender bias in CLIP and Stable
Diffusion can be linearly explained by direct co-occurrences in the data. Our
resources establish the first large-scale empirical link between dataset
composition and downstream model bias.

</details>


### [154] [Mapping Rio de Janeiro's favelas: general-purpose vs. satellite-specific neural networks](https://arxiv.org/abs/2510.03725)
*Thomas Hallopeau,Joris Guérin,Laurent Demagistri,Youssef Fouzai,Renata Gracie,Vanderlei Pascoal De Matos,Helen Gurgel,Nadine Dessay*

Main category: cs.CV

TL;DR: Comparison of generic vs specialized pretrained neural networks for favela detection in Rio de Janeiro, examining whether task specificity or data volume yields better performance.


<details>
  <summary>Details</summary>
Motivation: Deep learning methods for informal settlement detection haven't fully utilized recent pretrained neural networks' potential, creating a need to compare different pretraining approaches.

Method: Compare two types of pretrained networks: 1) Generic networks pretrained on large diverse datasets, 2) Specialized network pretrained on satellite imagery.

Result: The paper investigates but does not specify the actual performance results in this abstract.

Conclusion: The research aims to determine whether task specificity (specialized satellite imagery pretraining) or data volume (generic large dataset pretraining) provides superior performance for urban informal settlement detection.

Abstract: While deep learning methods for detecting informal settlements have already
been developed, they have not yet fully utilized the potential offered by
recent pretrained neural networks. We compare two types of pretrained neural
networks for detecting the favelas of Rio de Janeiro: 1. Generic networks
pretrained on large diverse datasets of unspecific images, 2. A specialized
network pretrained on satellite imagery. While the latter is more specific to
the target task, the former has been pretrained on significantly more images.
Hence, this research investigates whether task specificity or data volume
yields superior performance in urban informal settlement detection.

</details>


### [155] [LoRA Patching: Exposing the Fragility of Proactive Defenses against Deepfakes](https://arxiv.org/abs/2510.03747)
*Zuomin Qu,Yimao Guo,Qianyue Hu,Wei Lu*

Main category: cs.CV

TL;DR: LoRA patching bypasses proactive Deepfake defenses by injecting plug-and-play patches into generators, using adaptive gating and multi-modal feature alignment to defeat state-of-the-art protections with minimal data.


<details>
  <summary>Details</summary>
Motivation: Current proactive Deepfake defenses that embed adversarial perturbations in facial images lack robustness and reliability, creating a security vulnerability that needs to be exposed and addressed.

Method: Proposes Low-Rank Adaptation (LoRA) patching with learnable gating mechanism to prevent gradient explosions, and Multi-Modal Feature Alignment (MMFA) loss for semantic-level feature alignment. Also introduces defensive LoRA patching as a countermeasure.

Result: Successfully defeats multiple proactive defenses with only 1,000 facial examples and a single epoch of fine-tuning, demonstrating critical weaknesses in current defense paradigms.

Conclusion: Reveals fundamental vulnerabilities in existing Deepfake defense strategies and underscores the urgent need for more robust protection mechanisms against manipulation attacks.

Abstract: Deepfakes pose significant societal risks, motivating the development of
proactive defenses that embed adversarial perturbations in facial images to
prevent manipulation. However, in this paper, we show that these preemptive
defenses often lack robustness and reliability. We propose a novel approach,
Low-Rank Adaptation (LoRA) patching, which injects a plug-and-play LoRA patch
into Deepfake generators to bypass state-of-the-art defenses. A learnable
gating mechanism adaptively controls the effect of the LoRA patch and prevents
gradient explosions during fine-tuning. We also introduce a Multi-Modal Feature
Alignment (MMFA) loss, encouraging the features of adversarial outputs to align
with those of the desired outputs at the semantic level. Beyond bypassing, we
present defensive LoRA patching, embedding visible warnings in the outputs as a
complementary solution to mitigate this newly identified security
vulnerability. With only 1,000 facial examples and a single epoch of
fine-tuning, LoRA patching successfully defeats multiple proactive defenses.
These results reveal a critical weakness in current paradigms and underscore
the need for more robust Deepfake defense strategies. Our code is available at
https://github.com/ZOMIN28/LoRA-Patching.

</details>


### [156] [The Overlooked Value of Test-time Reference Sets in Visual Place Recognition](https://arxiv.org/abs/2510.03751)
*Mubariz Zaffar,Liangliang Nan,Sebastian Scherer,Julian F. P. Kooij*

Main category: cs.CV

TL;DR: Proposes Reference-Set-Finetuning (RSF) to improve Visual Place Recognition by finetuning models on test-time reference sets (maps) to bridge domain gaps, achieving ~2.3% average improvement in Recall@1 on challenging datasets.


<details>
  <summary>Details</summary>
Motivation: Current VPR methods struggle when test environments differ significantly from training datasets, creating a domain gap that limits performance on challenging benchmarks.

Method: Reference-Set-Finetuning (RSF) - finetuning VPR models on the test-time reference set (map) which contains images and poses of the target domain, available before query processing.

Result: RSF boosts State-of-the-Art performance by ~2.3% average increase in Recall@1 on challenging datasets while maintaining generalization across diverse test datasets.

Conclusion: Test-time reference set finetuning is an effective complementary approach that significantly improves VPR performance on challenging benchmarks with domain gaps.

Abstract: Given a query image, Visual Place Recognition (VPR) is the task of retrieving
an image of the same place from a reference database with robustness to
viewpoint and appearance changes. Recent works show that some VPR benchmarks
are solved by methods using Vision-Foundation-Model backbones and trained on
large-scale and diverse VPR-specific datasets. Several benchmarks remain
challenging, particularly when the test environments differ significantly from
the usual VPR training datasets. We propose a complementary, unexplored source
of information to bridge the train-test domain gap, which can further improve
the performance of State-of-the-Art (SOTA) VPR methods on such challenging
benchmarks. Concretely, we identify that the test-time reference set, the
"map", contains images and poses of the target domain, and must be available
before the test-time query is received in several VPR applications. Therefore,
we propose to perform simple Reference-Set-Finetuning (RSF) of VPR models on
the map, boosting the SOTA (~2.3% increase on average for Recall@1) on these
challenging datasets. Finetuned models retain generalization, and RSF works
across diverse test datasets.

</details>


### [157] [Adaptively Sampling-Reusing-Mixing Decomposed Gradients to Speed Up Sharpness Aware Minimization](https://arxiv.org/abs/2510.03763)
*Jiaxin Deng,Junbiao Pang*

Main category: cs.CV

TL;DR: ARSAM accelerates Sharpness-Aware Minimization (SAM) by decomposing SAM's gradient into SGD gradient and PSF (Projection of Second-order gradient onto First-order gradient), then adaptively reusing and mixing these components to reduce computational cost while maintaining generalization.


<details>
  <summary>Details</summary>
Motivation: SAM improves model generalization but doubles computational cost compared to SGD due to requiring twice the gradient calculations per step. This motivates the need for an efficient alternative that preserves SAM's benefits.

Method: Decompose SAM's gradient into SGD gradient and PSF, then adaptively sample, reuse, and mix these decomposed gradients. Specifically, reuse PSF and timely update PSF to maintain model generalization while reducing computations.

Result: ARSAM achieves comparable accuracies to SAM across diverse architectures while providing ~40% speedup on CIFAR-10/100. It also accelerates various challenging tasks like human pose estimation and model quantization without performance loss.

Conclusion: ARSAM successfully accelerates SAM optimization while maintaining its generalization benefits, demonstrating broad practicality across different tasks and architectures.

Abstract: Sharpness-Aware Minimization (SAM) improves model generalization but doubles
the computational cost of Stochastic Gradient Descent (SGD) by requiring twice
the gradient calculations per optimization step. To mitigate this, we propose
Adaptively sampling-Reusing-mixing decomposed gradients to significantly
accelerate SAM (ARSAM). Concretely, we firstly discover that SAM's gradient can
be decomposed into the SGD gradient and the Projection of the Second-order
gradient onto the First-order gradient (PSF). Furthermore, we observe that the
SGD gradient and PSF dynamically evolve during training, emphasizing the
growing role of the PSF to achieve a flat minima. Therefore, ARSAM is proposed
to the reused PSF and the timely updated PSF still maintain the model's
generalization ability. Extensive experiments show that ARSAM achieves
state-of-the-art accuracies comparable to SAM across diverse network
architectures. On CIFAR-10/100, ARSAM is comparable to SAM while providing a
speedup of about 40\%. Moreover, ARSAM accelerates optimization for the various
challenge tasks (\textit{e.g.}, human pose estimation, and model quantization)
without sacrificing performance, demonstrating its broad practicality.% The
code is publicly accessible at: https://github.com/ajiaaa/ARSAM.

</details>


### [158] [CoPA: Hierarchical Concept Prompting and Aggregating Network for Explainable Diagnosis](https://arxiv.org/abs/2510.03767)
*Yiheng Dong,Yi Lin,Xin Yang*

Main category: cs.CV

TL;DR: CoPA introduces a framework that enhances concept bottleneck models by extracting concept representations from multiple layers of visual encoders and using them as prompts to guide concept-related visual cues, improving concept and disease prediction performance.


<details>
  <summary>Details</summary>
Motivation: Current concept-based methods for clinical diagnostics have limitations in concept capture capabilities - they only use features from the final layer, neglect shallow/multiscale features, and lack effective guidance for concept encoding, hindering fine-grained concept extraction.

Method: CoPA framework uses Concept-aware Embedding Generator (CEG) to extract concept representations from each layer of visual encoder, and Concept Prompt Tuning (CPT) that uses these representations as prompts to amplify critical concept-related visual cues. Visual representations from all layers are aggregated to align with textual concept representations.

Result: Extensive experiments show CoPA outperforms state-of-the-art methods on three public datasets, effectively capturing and utilizing valuable concept-wise information in images to improve concept and disease prediction performance.

Conclusion: The proposed CoPA framework successfully addresses limitations of existing concept-based methods by capturing multilayer concepts under prompt guidance, demonstrating superior performance in clinical diagnostic applications.

Abstract: The transparency of deep learning models is essential for clinical
diagnostics. Concept Bottleneck Model provides clear decision-making processes
for diagnosis by transforming the latent space of black-box models into
human-understandable concepts. However, concept-based methods still face
challenges in concept capture capabilities. These methods often rely on encode
features solely from the final layer, neglecting shallow and multiscale
features, and lack effective guidance in concept encoding, hindering
fine-grained concept extraction. To address these issues, we introduce Concept
Prompting and Aggregating (CoPA), a novel framework designed to capture
multilayer concepts under prompt guidance. This framework utilizes the
Concept-aware Embedding Generator (CEG) to extract concept representations from
each layer of the visual encoder. Simultaneously, these representations serve
as prompts for Concept Prompt Tuning (CPT), steering the model towards
amplifying critical concept-related visual cues. Visual representations from
each layer are aggregated to align with textual concept representations. With
the proposed method, valuable concept-wise information in the images is
captured and utilized effectively, thus improving the performance of concept
and disease prediction. Extensive experimental results demonstrate that CoPA
outperforms state-of-the-art methods on three public datasets. Code is
available at https://github.com/yihengd/CoPA.

</details>


### [159] [Efficiency vs. Efficacy: Assessing the Compression Ratio-Dice Score Relationship through a Simple Benchmarking Framework for Cerebrovascular 3D Segmentation](https://arxiv.org/abs/2510.03769)
*Shimaa Elbana,Ahmad Kamal,Shahd Ahmed Ali,Ahmad Al-Kabbany*

Main category: cs.CV

TL;DR: ZFP compression technique enables substantial data reduction (up to 22.89:1 ratio) for 3D medical imaging datasets while maintaining high cerebrovascular segmentation quality comparable to uncompressed baseline.


<details>
  <summary>Details</summary>
Motivation: Address the challenges of increasing size and complexity of 3D medical imaging datasets that hinder collaborative research and transferability in cerebrovascular segmentation for intracranial aneurysm detection.

Method: Apply ZFP compression in both error tolerance and fixed-rate modes to a large-scale 3D medical dataset with ground-truth vascular segmentations, then compare segmentation quality on compressed volumes against uncompressed baseline using Dice coefficient.

Result: ZFP achieved significant data reduction (up to 22.89:1 ratio) while maintaining high segmentation fidelity with mean Dice coefficient of 0.87656, nearly identical to uncompressed baseline (Dice ≈ 0.8774).

Conclusion: ZFP is a viable and powerful tool for enabling more efficient and accessible research on large-scale medical datasets, fostering broader collaboration across the research community.

Abstract: The increasing size and complexity of medical imaging datasets, particularly
in 3D formats, present significant barriers to collaborative research and
transferability. This study investigates whether the ZFP compression technique
can mitigate these challenges without compromising the performance of automated
cerebrovascular segmentation, a critical first step in intracranial aneurysm
detection. We apply ZFP in both its error tolerance and fixed-rate modes to a
large scale, and one of the most recent, datasets in the literature, 3D medical
dataset containing ground-truth vascular segmentations. The segmentation
quality on the compressed volumes is rigorously compared to the uncompressed
baseline (Dice approximately equals 0.8774). Our findings reveal that ZFP can
achieve substantial data reduction--up to a 22.89:1 ratio in error tolerance
mode--while maintaining a high degree of fidelity, with the mean Dice
coefficient remaining high at 0.87656. These results demonstrate that ZFP is a
viable and powerful tool for enabling more efficient and accessible research on
large-scale medical datasets, fostering broader collaboration across the
community.

</details>


### [160] [MambaCAFU: Hybrid Multi-Scale and Multi-Attention Model with Mamba-Based Fusion for Medical Image Segmentation](https://arxiv.org/abs/2510.03786)
*T-Mai Bui,Fares Bougourzi,Fadi Dornaika,Vinh Truong Hoang*

Main category: cs.CV

TL;DR: A hybrid medical image segmentation architecture combining CNNs, Transformers, and Mamba-based attention to capture multi-scale dependencies, achieving state-of-the-art performance with balanced efficiency.


<details>
  <summary>Details</summary>
Motivation: Existing medical segmentation models are task-specific with varying performance across modalities and anatomical regions, while clinical settings require both accuracy and efficiency.

Method: Three-branch encoder integrating CNNs, Transformers, and Mamba-based Attention Fusion (MAF) with multi-scale attention-based CNN decoder and co-attention gates for enhanced feature selection.

Result: Outperforms state-of-the-art methods in accuracy and generalization across multiple benchmark datasets while maintaining comparable computational complexity.

Conclusion: The architecture effectively balances efficiency and effectiveness, offering a practical and scalable solution for diverse medical imaging tasks.

Abstract: In recent years, deep learning has shown near-expert performance in
segmenting complex medical tissues and tumors. However, existing models are
often task-specific, with performance varying across modalities and anatomical
regions. Balancing model complexity and performance remains challenging,
particularly in clinical settings where both accuracy and efficiency are
critical. To address these issues, we propose a hybrid segmentation
architecture featuring a three-branch encoder that integrates CNNs,
Transformers, and a Mamba-based Attention Fusion (MAF) mechanism to capture
local, global, and long-range dependencies. A multi-scale attention-based CNN
decoder reconstructs fine-grained segmentation maps while preserving contextual
consistency. Additionally, a co-attention gate enhances feature selection by
emphasizing relevant spatial and semantic information across scales during both
encoding and decoding, improving feature interaction and cross-scale
communication. Extensive experiments on multiple benchmark datasets show that
our approach outperforms state-of-the-art methods in accuracy and
generalization, while maintaining comparable computational complexity. By
effectively balancing efficiency and effectiveness, our architecture offers a
practical and scalable solution for diverse medical imaging tasks. Source code
and trained models will be publicly released upon acceptance to support
reproducibility and further research.

</details>


### [161] [Road Damage and Manhole Detection using Deep Learning for Smart Cities: A Polygonal Annotation Approach](https://arxiv.org/abs/2510.03797)
*Rasel Hossen,Diptajoy Mistry,Mushiur Rahman,Waki As Sami Atikur Rahman Hridoy,Sajib Saha,Muhammad Ibrahim*

Main category: cs.CV

TL;DR: Deep learning approach using YOLOv9 with polygonal annotations for automated road damage and manhole detection, achieving 78.1% overall accuracy with strong performance on road damage classes.


<details>
  <summary>Details</summary>
Motivation: Manual monitoring of road damages is time-consuming, costly, and error-prone, especially in developing countries where urban infrastructure maintenance is critical for smart city development.

Method: Used YOLOv9 algorithm with polygonal annotations (instead of traditional bounding boxes) for precise localization, trained on a novel dataset of 1000+ images from Dhaka, Bangladesh with three classes: Broken, Not Broken, and Manhole.

Result: Achieved 78.1% overall image-level accuracy. Strong performance for Broken (86.7% F1-score) and Not Broken (89.2% F1-score) classes, but poor Manhole detection (18.2% F1-score) due to class imbalance.

Conclusion: The approach provides an efficient and scalable solution for monitoring urban infrastructure in developing countries, though manhole detection needs improvement through better class balancing.

Abstract: Urban safety and infrastructure maintenance are critical components of smart
city development. Manual monitoring of road damages is time-consuming, highly
costly, and error-prone. This paper presents a deep learning approach for
automated road damage and manhole detection using the YOLOv9 algorithm with
polygonal annotations. Unlike traditional bounding box annotation, we employ
polygonal annotations for more precise localization of road defects. We develop
a novel dataset comprising more than one thousand images which are mostly
collected from Dhaka, Bangladesh. This dataset is used to train a YOLO-based
model for three classes, namely Broken, Not Broken, and Manhole. We achieve
78.1% overall image-level accuracy. The YOLOv9 model demonstrates strong
performance for Broken (86.7% F1-score) and Not Broken (89.2% F1-score)
classes, with challenges in Manhole detection (18.2% F1-score) due to class
imbalance. Our approach offers an efficient and scalable solution for
monitoring urban infrastructure in developing countries.

</details>


### [162] [Contrastive-SDE: Guiding Stochastic Differential Equations with Contrastive Learning for Unpaired Image-to-Image Translation](https://arxiv.org/abs/2510.03821)
*Venkata Narendra Kotyada,Revanth Eranki,Nagesh Bhattu Sristy*

Main category: cs.CV

TL;DR: Proposes Contrastive-SDE, a method combining contrastive learning with score-based diffusion models for unpaired image-to-image translation, achieving comparable performance to state-of-the-art with faster convergence and no label supervision.


<details>
  <summary>Details</summary>
Motivation: Leverage the strengths of score-based diffusion models (high-fidelity generation) and contrastive learning (semantic consistency without paired data) for unpaired image-to-image translation, addressing the challenge of learning mappings between domains without aligned samples.

Method: Uses time-dependent contrastive learning with SimCLR, treating an image and its domain-invariant feature as positive pairs. The learned contrastive model then guides inference of a pretrained stochastic differential equation (SDE) for translation.

Result: Achieves comparable results to state-of-the-art on several metrics across three unpaired I2I tasks. Converges significantly faster and requires no label supervision or classifier training.

Conclusion: Contrastive-SDE provides an efficient alternative for unpaired image-to-image translation, combining the benefits of contrastive learning and diffusion models while eliminating the need for supervision and reducing training time.

Abstract: Unpaired image-to-image translation involves learning mappings between source
domain and target domain in the absence of aligned or corresponding samples.
Score based diffusion models have demonstrated state-of-the-art performance in
generative tasks. Their ability to approximate complex data distributions
through stochastic differential equations (SDEs) enables them to generate
high-fidelity and diverse outputs, making them particularly well-suited for
unpaired I2I settings. In parallel, contrastive learning provides a powerful
framework for learning semantic similarities without the need for explicit
supervision or paired data. By pulling together representations of semantically
similar samples and pushing apart dissimilar ones, contrastive methods are
inherently aligned with the objectives of unpaired translation. Its ability to
selectively enforce semantic consistency at the feature level makes contrastive
learning particularly effective for guiding generation in unpaired scenarios.
In this work, we propose a time-dependent contrastive learning approach where a
model is trained with SimCLR by considering an image and its domain invarient
feature as a positive pair, enabling the preservation of domain-invariant
features and the discarding of domain-specific ones. The learned contrastive
model then guides the inference of a pretrained SDE for the I2I translation
task. We empirically compare Contrastive-SDE with several baselines across
three common unpaired I2I tasks, using four metrics for evaluation.
Constrastive-SDE achieves comparable results to the state-of-the-art on several
metrics. Furthermore, we observe that our model converges significantly faster
and requires no label supervision or classifier training, making it a more
efficient alternative for this task.

</details>


### [163] [LIBERO-PRO: Towards Robust and Fair Evaluation of Vision-Language-Action Models Beyond Memorization](https://arxiv.org/abs/2510.03827)
*Xueyang Zhou,Yangming Xu,Guiyao Tie,Yongchao Chen,Guowen Zhang,Duanfeng Chu,Pan Zhou,Lichao Sun*

Main category: cs.CV

TL;DR: LIBERO-PRO extends the LIBERO benchmark to systematically evaluate VLA models under perturbations, revealing that models achieving 90%+ accuracy in standard settings collapse to 0% when tested on manipulated objects, initial states, instructions, and environments, exposing reliance on memorization rather than genuine understanding.


<details>
  <summary>Details</summary>
Motivation: Current LIBERO benchmark settings lead to inflated performance estimates and prevent fair model comparison due to models memorizing action sequences and environment layouts rather than demonstrating true task comprehension.

Method: Extended LIBERO benchmark (LIBERO-PRO) that systematically evaluates model performance under perturbations across four dimensions: manipulated objects, initial states, task instructions, and environments.

Result: Models achieving over 90% accuracy in standard LIBERO evaluation collapse to 0.0% accuracy under the generalized LIBERO-PRO setting, revealing models' reliance on rote memorization rather than genuine understanding.

Conclusion: Current evaluation practices are severely flawed, and the community should adopt robust assessments of model generalization and comprehension rather than misleading methodologies that inflate performance estimates.

Abstract: LIBERO has emerged as a widely adopted benchmark for evaluating
Vision-Language-Action (VLA) models; however, its current training and
evaluation settings are problematic, often leading to inflated performance
estimates and preventing fair model comparison. To address these issues, we
introduce LIBERO-PRO, an extended LIBERO benchmark that systematically
evaluates model performance under reasonable perturbations across four
dimensions: manipulated objects, initial states, task instructions, and
environments. Experimental results reveal that, although existing models
achieve over 90% accuracy under the standard LIBERO evaluation, their
performance collapses to 0.0% under our generalized setting. Crucially, this
discrepancy exposes the models' reliance on rote memorization of action
sequences and environment layouts from the training set, rather than genuine
task understanding or environmental perception. For instance, models persist in
executing grasping actions when the target object is replaced with irrelevant
items, and their outputs remain unchanged even when given corrupted
instructions or even messy tokens. These findings expose the severe flaws in
current evaluation practices, and we call on the community to abandon
misleading methodologies in favor of robust assessments of model generalization
and comprehension. Our code is available at:
https://github.com/Zxy-MLlab/LIBERO-PRO.

</details>


### [164] [Mirage: Unveiling Hidden Artifacts in Synthetic Images with Large Vision-Language Models](https://arxiv.org/abs/2510.03840)
*Pranav Sharma,Shivank Garg,Durga Toshniwal*

Main category: cs.CV

TL;DR: The paper introduces Mirage, a dataset of AI-generated images with visible artifacts where current detectors fail, and investigates using Large Vision-Language Models for explainable AI image detection.


<details>
  <summary>Details</summary>
Motivation: There's a growing discrepancy where AI-generated images are hard for standard detectors to identify but remain distinguishable by humans. The authors want to address this gap and explore whether LVLMs can serve as effective detectors.

Method: Created the Mirage dataset with diverse AI-generated images exhibiting visible artifacts. Tested Large Vision-Language Models on both Mirage and existing benchmark datasets for AI image detection.

Result: LVLMs are highly effective at detecting AI-generated images with visible artifacts but their performance declines significantly when images lack such visual cues.

Conclusion: While LVLMs show promise for explainable AI image detection, their effectiveness is limited to images with visible artifacts, highlighting the need for more robust detection methods.

Abstract: Recent advances in image generation models have led to models that produce
synthetic images that are increasingly difficult for standard AI detectors to
identify, even though they often remain distinguishable by humans. To identify
this discrepancy, we introduce \textbf{Mirage}, a curated dataset comprising a
diverse range of AI-generated images exhibiting visible artifacts, where
current state-of-the-art detection methods largely fail. Furthermore, we
investigate whether Large Vision-Language Models (LVLMs), which are
increasingly employed as substitutes for human judgment in various tasks, can
be leveraged for explainable AI image detection. Our experiments on both Mirage
and existing benchmark datasets demonstrate that while LVLMs are highly
effective at detecting AI-generated images with visible artifacts, their
performance declines when confronted with images lacking such cues.

</details>


### [165] [UGround: Towards Unified Visual Grounding with Unrolled Transformers](https://arxiv.org/abs/2510.03853)
*Rui Qian,Xin Yin,Chuanhang Deng,Zhiyuan Peng,Jian Xiong,Wei Zhai,Dejing Dou*

Main category: cs.CV

TL;DR: UGround introduces a unified visual grounding paradigm that dynamically selects intermediate transformer layers as "mask as prompt" instead of using fixed last hidden layers, addressing error propagation and lack of spatial cues in existing methods.


<details>
  <summary>Details</summary>
Motivation: To overcome limitations of current visual grounding approaches that rely on fixed last hidden layers (amplifying cumulative errors) and use <SEG> tokens as prompts (lacking explicit spatial cues like coordinates).

Method: Proposes Policy-Prompted Masking with two components: Stochastic Skip Connection (SSC) - a reinforcement learning policy for dynamic layer selection, and Mask as Prompt (MasP) - using similarity maps as soft logit masks to prompt SAM with explicit spatial cues.

Result: UGround unifies visual grounding tasks within a single framework spanning referential expression segmentation, reasoning segmentation, single/multi-target tasks, and false premise scenarios.

Conclusion: UGround provides an effective unified paradigm for visual grounding that addresses key limitations of existing methods through dynamic layer selection and explicit spatial cue integration.

Abstract: We present UGround, a \textbf{U}nified visual \textbf{Ground}ing paradigm
that dynamically selects intermediate layers across \textbf{U}nrolled
transformers as ``mask as prompt'', diverging from the prevailing pipeline that
leverages the fixed last hidden layer as ``\texttt{<SEG>} as prompt''. UGround
addresses two primary challenges posed by the prevailing paradigm: (1) its
reliance on the fixed last hidden layer, which sequentially amplifies
cumulative errors arising from layer-by-layer propagation without intermediate
correction, and (2) its use of \texttt{<SEG>} as a prompt, which implicitly
projects textual embeddings into visual space without explicit spatial cues
(\eg, coordinates). Central to UGround is Policy-Prompted Masking, which
comprises two key components: Stochastic Skip Connection (SSC) and Mask as
Prompt (MasP). SSC is a reinforcement learning policy that, via stochastic
sampling, allows each \texttt{<SEG>} token to slide across unrolled transformer
layers, enabling dynamic layer selection at which it connects to the vision
model (\eg, SAM) in a skip-connection fashion. Given the selected hidden layer,
MasP uses the similarity map derived from the \texttt{<SEG>} token and image
tokens as a soft logit mask to prompt SAM for mask generation, offering
explicit spatial cues through its activation regions. To validate the
effectiveness of UGround, we, for the first time, have unified visual grounding
within a single framework from an attribute perspective, spanning from
traditional refer expression segmentation to newly proposed reasoning
segmentation, single-target to multi-target, positive query to false premise
(empty target). All codes and models are publicly available at
\href{https://github.com/rui-qian/UGround}{https://github.com/rui-qian/UGround}.

</details>


### [166] [Optimized Minimal 4D Gaussian Splatting](https://arxiv.org/abs/2510.03857)
*Minseo Lee,Byeonghyeon Lee,Lucas Yunkyu Lee,Eunsoo Lee,Sangmin Kim,Seunghyeon Song,Joo Chan Lee,Jong Hwan Ko,Jaesik Park,Eunbyung Park*

Main category: cs.CV

TL;DR: OMG4 is a framework that optimizes 4D Gaussian Splatting by reducing storage overhead through progressive pruning and compression techniques while maintaining reconstruction quality.


<details>
  <summary>Details</summary>
Motivation: 4D Gaussian Splatting faces significant storage overhead challenges due to requiring millions of Gaussians for high-fidelity reconstruction, and existing compression methods have limitations in compression ratio or visual quality.

Method: Progressive three-stage pruning (Gaussian Sampling, Gaussian Pruning, Gaussian Merging) combined with implicit appearance compression and generalized Sub-Vector Quantization (SVQ) for 4D representations.

Result: OMG4 reduces model sizes by over 60% while maintaining reconstruction quality, significantly outperforming recent state-of-the-art methods on standard benchmark datasets.

Conclusion: OMG4 represents a significant advancement in compact 4D scene representation, enabling new possibilities for various applications by achieving substantial storage reduction without quality degradation.

Abstract: 4D Gaussian Splatting has emerged as a new paradigm for dynamic scene
representation, enabling real-time rendering of scenes with complex motions.
However, it faces a major challenge of storage overhead, as millions of
Gaussians are required for high-fidelity reconstruction. While several studies
have attempted to alleviate this memory burden, they still face limitations in
compression ratio or visual quality. In this work, we present OMG4 (Optimized
Minimal 4D Gaussian Splatting), a framework that constructs a compact set of
salient Gaussians capable of faithfully representing 4D Gaussian models. Our
method progressively prunes Gaussians in three stages: (1) Gaussian Sampling to
identify primitives critical to reconstruction fidelity, (2) Gaussian Pruning
to remove redundancies, and (3) Gaussian Merging to fuse primitives with
similar characteristics. In addition, we integrate implicit appearance
compression and generalize Sub-Vector Quantization (SVQ) to 4D representations,
further reducing storage while preserving quality. Extensive experiments on
standard benchmark datasets demonstrate that OMG4 significantly outperforms
recent state-of-the-art methods, reducing model sizes by over 60% while
maintaining reconstruction quality. These results position OMG4 as a
significant step forward in compact 4D scene representation, opening new
possibilities for a wide range of applications. Our source code is available at
https://minshirley.github.io/OMG4/.

</details>


### [167] [Cross-View Open-Vocabulary Object Detection in Aerial Imagery](https://arxiv.org/abs/2510.03858)
*Jyoti Kini,Rohit Gupta,Mubarak Shah*

Main category: cs.CV

TL;DR: A novel framework for adapting open-vocabulary object detection from ground-view to aerial imagery using contrastive domain alignment and multi-instance vocabulary associations.


<details>
  <summary>Details</summary>
Motivation: Traditional object detection models are limited to fixed classes, making it costly to add new categories. Open-vocabulary detection enables identifying unseen classes without retraining, but domain shifts between ground and aerial views make direct knowledge transfer ineffective.

Method: Uses contrastive image-to-image alignment to enhance similarity between aerial and ground-view embeddings, and multi-instance vocabulary associations to align aerial images with text embeddings.

Result: Achieves significant improvements in zero-shot setting: +6.32 mAP on DOTAv2, +4.16 mAP on VisDrone, and +3.46 mAP on HRRSD compared to finetuned closed-vocabulary models.

Conclusion: The framework enables more flexible and scalable object detection in aerial applications by effectively adapting open-vocabulary representations across domains.

Abstract: Traditional object detection models are typically trained on a fixed set of
classes, limiting their flexibility and making it costly to incorporate new
categories. Open-vocabulary object detection addresses this limitation by
enabling models to identify unseen classes without explicit training.
Leveraging pretrained models contrastively trained on abundantly available
ground-view image-text classification pairs provides a strong foundation for
open-vocabulary object detection in aerial imagery. Domain shifts, viewpoint
variations, and extreme scale differences make direct knowledge transfer across
domains ineffective, requiring specialized adaptation strategies. In this
paper, we propose a novel framework for adapting open-vocabulary
representations from ground-view images to solve object detection in aerial
imagery through structured domain alignment. The method introduces contrastive
image-to-image alignment to enhance the similarity between aerial and
ground-view embeddings and employs multi-instance vocabulary associations to
align aerial images with text embeddings. Extensive experiments on the xView,
DOTAv2, VisDrone, DIOR, and HRRSD datasets are used to validate our approach.
Our open-vocabulary model achieves improvements of +6.32 mAP on DOTAv2, +4.16
mAP on VisDrone (Images), and +3.46 mAP on HRRSD in the zero-shot setting when
compared to finetuned closed-vocabulary dataset-specific model performance,
thus paving the way for more flexible and scalable object detection systems in
aerial applications.

</details>


### [168] [Exploring the Challenge and Value of Deep Learning in Automated Skin Disease Diagnosis](https://arxiv.org/abs/2510.03869)
*Runhao Liu,Ziming Chen,Peng Zhang*

Main category: cs.CV

TL;DR: This review paper analyzes deep learning approaches for skin cancer diagnosis, discussing challenges like complex features and data imbalance, and presents solutions including data augmentation and hybrid models.


<details>
  <summary>Details</summary>
Motivation: Skin cancer is a prevalent and deadly disease where early detection is crucial. Deep learning shows promise for automated diagnosis but faces challenges that need to be addressed.

Method: The review follows the PRISMA framework methodology to synthesize recent research on DL-based skin cancer diagnosis approaches.

Result: The review identifies innovative approaches to overcome DL challenges, including data augmentation, hybrid models, and feature fusion techniques.

Conclusion: Deep learning has transformative potential for skin disease diagnosis and clinical decision-making, but continued advancements are needed to fully unlock its benefits in dermatological care.

Abstract: Skin cancer is one of the most prevalent and deadly forms of cancer
worldwide, which highlights the critical importance of early detection and
diagnosis in improving patient outcomes. Deep learning (DL) has shown
significant promise in enhancing the accuracy and efficiency of automated skin
disease diagnosis, particularly in detecting and evaluating skin lesions and
classification. However, there are still several challenges for DL-based skin
cancer diagnosis, including complex features, image noise, intra-class
variation, inter-class similarity, and data imbalance. By synthesizing recent
research, this review discusses innovative approaches to cope with these
challenges, such as data augmentation, hybrid models, and feature fusion, etc.
Furthermore, the review highlights the integration of DL models into clinical
workflows, offering insights into the potential of deep learning to
revolutionize skin disease diagnosis and improve clinical decision-making. This
article follows a comprehensive methodology based on the PRISMA framework and
emphasizes the need for continued advancements to fully unlock the
transformative potential of DL in dermatological care.

</details>


### [169] [SDAKD: Student Discriminator Assisted Knowledge Distillation for Super-Resolution Generative Adversarial Networks](https://arxiv.org/abs/2510.03870)
*Nikolaos Kaparinos,Vasileios Mezaris*

Main category: cs.CV

TL;DR: SDAKD introduces a student discriminator to address capacity mismatch in GAN knowledge distillation, enabling effective compression of super-resolution GANs for resource-constrained devices.


<details>
  <summary>Details</summary>
Motivation: GANs have high computational requirements that limit deployment on resource-constrained devices, and existing knowledge distillation methods struggle due to capacity mismatch between student generators and teacher discriminators.

Method: Proposes Student Discriminator Assisted Knowledge Distillation (SDAKD) with three-stage training strategy and adapted feature map distillation in the last two stages.

Result: SDAKD demonstrates consistent improvements over baselines and state-of-the-art GAN knowledge distillation methods on GCFSR and Real-ESRGAN super-resolution GANs.

Conclusion: SDAKD effectively addresses the capacity mismatch problem in GAN distillation and enables practical deployment of compressed GANs on resource-constrained devices.

Abstract: Generative Adversarial Networks (GANs) achieve excellent performance in
generative tasks, such as image super-resolution, but their computational
requirements make difficult their deployment on resource-constrained devices.
While knowledge distillation is a promising research direction for GAN
compression, effectively training a smaller student generator is challenging
due to the capacity mismatch between the student generator and the teacher
discriminator. In this work, we propose Student Discriminator Assisted
Knowledge Distillation (SDAKD), a novel GAN distillation methodology that
introduces a student discriminator to mitigate this capacity mismatch. SDAKD
follows a three-stage training strategy, and integrates an adapted feature map
distillation approach in its last two training stages. We evaluated SDAKD on
two well-performing super-resolution GANs, GCFSR and Real-ESRGAN. Our
experiments demonstrate consistent improvements over the baselines and SOTA GAN
knowledge distillation methods. The SDAKD source code will be made openly
available upon acceptance of the paper.

</details>


### [170] [PoseGaze-AHP: A Knowledge-Based 3D Dataset for AI-Driven Ocular and Postural Diagnosis](https://arxiv.org/abs/2510.03873)
*Saja Al-Dabet,Sherzod Turaev,Nazar Zaki,Arif O. Khan,Luai Eldweik*

Main category: cs.CV

TL;DR: PoseGaze-AHP is a novel 3D dataset that synchronously captures head pose and gaze movement information for ocular-induced abnormal head posture (AHP) diagnosis, created using LLM-extracted clinical data and NHA framework.


<details>
  <summary>Details</summary>
Motivation: Existing datasets focus on head pose and ocular movements separately, limiting integrated diagnostic approaches and AI-driven advancements in AHP analysis.

Method: Clinical data extracted from medical literature using Claude 3.5 Sonnet LLM with iterative prompting strategies, then transformed into 3D representations using Neural Head Avatar framework with systematic imputation.

Result: Created dataset with 7,920 images from two head textures covering broad ocular conditions. Extraction method achieved 91.92% accuracy. First publicly available resource for AI-driven ocular-induced AHP diagnosis.

Conclusion: PoseGaze-AHP enables development of accurate, privacy-compliant diagnostic tools for ocular-induced abnormal head posture by providing integrated head pose and gaze movement data.

Abstract: Diagnosing ocular-induced abnormal head posture (AHP) requires a
comprehensive analysis of both head pose and ocular movements. However,
existing datasets focus on these aspects separately, limiting the development
of integrated diagnostic approaches and restricting AI-driven advancements in
AHP analysis. To address this gap, we introduce PoseGaze-AHP, a novel 3D
dataset that synchronously captures head pose and gaze movement information for
ocular-induced AHP assessment. Structured clinical data were extracted from
medical literature using large language models (LLMs) through an iterative
process with the Claude 3.5 Sonnet model, combining stepwise, hierarchical, and
complex prompting strategies. The extracted records were systematically imputed
and transformed into 3D representations using the Neural Head Avatar (NHA)
framework. The dataset includes 7,920 images generated from two head textures,
covering a broad spectrum of ocular conditions. The extraction method achieved
an overall accuracy of 91.92%, demonstrating its reliability for clinical
dataset construction. PoseGaze-AHP is the first publicly available resource
tailored for AI-driven ocular-induced AHP diagnosis, supporting the development
of accurate and privacy-compliant diagnostic tools.

</details>


### [171] [DHQA-4D: Perceptual Quality Assessment of Dynamic 4D Digital Human](https://arxiv.org/abs/2510.03874)
*Yunhao Li,Sijing Wu,Yucheng Zhu,Huiyu Duan,Zicheng Zhang,Guangtao Zhai*

Main category: cs.CV

TL;DR: This paper introduces DHQA-4D, a large-scale dataset for quality assessment of dynamic 4D digital humans, and proposes DynaMesh-Rater, a novel LMM-based approach that extracts multi-dimensional features (visual, motion, geometry) to assess both textured and non-textured 4D meshes.


<details>
  <summary>Details</summary>
Motivation: Dynamic 4D human avatars are prone to noise during collection, compression, and transmission, affecting user experience. Quality assessment is crucial but lacks dedicated datasets and methods.

Method: Created DHQA-4D dataset with 32 high-quality 4D sequences and 1920 distorted meshes. Proposed DynaMesh-Rater that extracts visual, motion, and geometry features using LMM with LoRA-based instruction tuning for quality prediction.

Result: Extensive experiments on DHQA-4D dataset demonstrate DynaMesh-Rater's superiority over previous quality assessment methods.

Conclusion: The proposed dataset and method provide effective solutions for quality assessment of dynamic 4D digital humans, with applications in gaming, animation, and immersive communication.

Abstract: With the rapid development of 3D scanning and reconstruction technologies,
dynamic digital human avatars based on 4D meshes have become increasingly
popular. A high-precision dynamic digital human avatar can be applied to
various fields such as game production, animation generation, and remote
immersive communication. However, these 4D human avatar meshes are prone to
being degraded by various types of noise during the processes of collection,
compression, and transmission, thereby affecting the viewing experience of
users. In light of this fact, quality assessment of dynamic 4D digital humans
becomes increasingly important. In this paper, we first propose a large-scale
dynamic digital human quality assessment dataset, DHQA-4D, which contains 32
high-quality real-scanned 4D human mesh sequences, 1920 distorted textured 4D
human meshes degraded by 11 textured distortions, as well as their
corresponding textured and non-textured mean opinion scores (MOSs). Equipped
with DHQA-4D dataset, we analyze the influence of different types of distortion
on human perception for textured dynamic 4D meshes and non-textured dynamic 4D
meshes. Additionally, we propose DynaMesh-Rater, a novel large multimodal model
(LMM) based approach that is able to assess both textured 4D meshes and
non-textured 4D meshes. Concretely, DynaMesh-Rater elaborately extracts
multi-dimensional features, including visual features from a projected 2D
video, motion features from cropped video clips, and geometry features from the
4D human mesh to provide comprehensive quality-related information. Then we
utilize a LMM model to integrate the multi-dimensional features and conduct a
LoRA-based instruction tuning technique to teach the LMM model to predict the
quality scores. Extensive experimental results on the DHQA-4D dataset
demonstrate the superiority of our DynaMesh-Rater method over previous quality
assessment methods.

</details>


### [172] [Skin Lesion Classification Based on ResNet-50 Enhanced With Adaptive Spatial Feature Fusion](https://arxiv.org/abs/2510.03876)
*Runhao Liu,Ziming Chen,Peng Zhang*

Main category: cs.CV

TL;DR: Improved ResNet-50 with Adaptive Spatial Feature Fusion (ASFF) for skin cancer classification, achieving 93.18% accuracy and superior performance on ISIC 2020 dataset.


<details>
  <summary>Details</summary>
Motivation: Address challenges in skin cancer classification including high inter-class similarity, intra-class variability, and image noise in dermoscopic images.

Method: Enhanced ResNet-50 with ASFF mechanism that adaptively fuses multi-scale semantic and surface features using dual-branch design with global average pooling and fully connected layers for weighted fusion.

Result: Achieved 93.18% accuracy, AUC of 0.9670 (P-R) and 0.9717 (ROC), outperforming 5 classic CNN models. Grad-CAM visualization confirmed focus on lesion-relevant regions.

Conclusion: The proposed approach provides a more effective and efficient solution for computer-aided skin cancer diagnosis with enhanced feature learning capability.

Abstract: Skin cancer classification remains a challenging problem due to high
inter-class similarity, intra-class variability, and image noise in dermoscopic
images. To address these issues, we propose an improved ResNet-50 model
enhanced with Adaptive Spatial Feature Fusion (ASFF), which adaptively
integrates multi-scale semantic and surface features to improve feature
representation and reduce overfitting. The ResNet-50 model is enhanced with an
adaptive feature fusion mechanism to achieve more effective multi-scale feature
extraction and improve overall performance. Specifically, a dual-branch design
fuses high-level semantic and mid-level detail features, which are processed
through global average pooling and fully connected layers to generate adaptive
weights for weighted fusion, thereby strengthening feature learning and
reducing the impact of noise on classification. The method is evaluated on a
subset of the ISIC 2020 dataset containing 3297 benign and malignant skin
lesion images. Experimental results show that the proposed ASFF-based ResNet-50
achieves the best overall performance compared with 5 classic convolutional
neural networks (CNNs) models. The proposed model reached an accuracy of 93.18%
along with higher precision, recall, specificity, and F1 score. The improved
model achieves an AUC value of 0.9670 and 0.9717 in the P-R and ROC curve,
respectively. Then, the evaluation based on Grad-CAM further proved that the
improved model adaptively focuses on lesion-relevant regions while suppressing
irrelevant background information, thereby validating its enhanced feature
learning capability from a deep representation perspective. These findings
demonstrate that the proposed approach provides a more effective and efficient
solution for computer-aided skin cancer diagnosis.

</details>


### [173] [Multi-Modal Oral Cancer Detection Using Weighted Ensemble Convolutional Neural Networks](https://arxiv.org/abs/2510.03878)
*Ajo Babu George,Sreehari J R Ajo Babu George,Sreehari J R Ajo Babu George,Sreehari J R*

Main category: cs.CV

TL;DR: Multimodal deep learning framework using DenseNet-121 CNNs and weighted ensemble improves early detection of Oral Squamous Cell Carcinoma by integrating clinical, radiological, and histopathological images.


<details>
  <summary>Details</summary>
Motivation: Late diagnosis of OSCC contributes to high mortality rates, with over 50% of cases detected at advanced stages and 5-year survival below 50%. Current diagnostic workflow needs improvement for early detection.

Method: Retrospective study using multimodal datasets. DenseNet-121 CNNs trained via transfer learning for each modality (clinical, radiological, histopathological). Augmentation and modality-specific preprocessing applied. Predictions fused using validation-weighted ensemble strategy.

Result: High accuracy for radiological (100%) and histopathological (95.12%) modalities, lower for clinical images (63.10%) due to visual heterogeneity. Ensemble model achieved 84.58% accuracy on multimodal validation dataset of 55 samples.

Conclusion: The multimodal ensemble framework provides a non-invasive, AI-assisted triage tool that enhances early identification of high-risk lesions, supports clinical decision-making, and aligns with global oncology guidelines to reduce diagnostic delays and improve outcomes.

Abstract: Aims Late diagnosis of Oral Squamous Cell Carcinoma (OSCC) contributes
significantly to its high global mortality rate, with over 50\% of cases
detected at advanced stages and a 5-year survival rate below 50\% according to
WHO statistics. This study aims to improve early detection of OSCC by
developing a multimodal deep learning framework that integrates clinical,
radiological, and histopathological images using a weighted ensemble of
DenseNet-121 convolutional neural networks (CNNs). Material and Methods A
retrospective study was conducted using publicly available datasets
representing three distinct medical imaging modalities. Each modality-specific
dataset was used to train a DenseNet-121 CNN via transfer learning.
Augmentation and modality-specific preprocessing were applied to increase
robustness. Predictions were fused using a validation-weighted ensemble
strategy. Evaluation was performed using accuracy, precision, recall, F1-score.
Results High validation accuracy was achieved for radiological (100\%) and
histopathological (95.12\%) modalities, with clinical images performing lower
(63.10\%) due to visual heterogeneity. The ensemble model demonstrated improved
diagnostic robustness with an overall accuracy of 84.58\% on a multimodal
validation dataset of 55 samples. Conclusion The multimodal ensemble framework
bridges gaps in the current diagnostic workflow by offering a non-invasive,
AI-assisted triage tool that enhances early identification of high-risk
lesions. It supports clinicians in decision-making, aligning with global
oncology guidelines to reduce diagnostic delays and improve patient outcomes.

</details>


### [174] [Exploring Instruction Data Quality for Explainable Image Quality Assessment](https://arxiv.org/abs/2510.03880)
*Yunhao Li,Sijing Wu,Huiyu Duan,Yucheng Zhu,Qi Jia,Guangtao Zhai*

Main category: cs.CV

TL;DR: The paper challenges the scaling law in explainable image quality assessment (IQA) by showing that data quality matters more than quantity. It proposes IQA-Select, a clustering-based data selection method that achieves better performance using only 10% of data.


<details>
  <summary>Details</summary>
Motivation: Current methods construct large-scale instruction tuning datasets for MLLMs in explainable IQA, but this causes high computational costs and redundant data that can harm model performance. The authors aim to challenge the scaling law and investigate data quality over quantity.

Method: Proposes a clustering-based data selection framework with three stages: clustering feature extraction, cluster quota allocation, and cluster sampling strategy. Uses a powerful pre-trained MLLM and systematically analyzes different data selection approaches.

Result: IQA-Select achieves 102.1% and 103.7% performance of full fine-tuning using only 10% selected data on Q-Bench and AesBench respectively, reducing computational costs while improving performance.

Conclusion: Data quality is more important than quantity in explainable IQA instruction tuning. The proposed IQA-Select method effectively identifies and selects high-quality data subsets, challenging the conventional scaling law approach.

Abstract: In recent years, with the rapid development of powerful multimodal large
language models (MLLMs), explainable image quality assessment (IQA) has
gradually become popular, aiming at providing quality-related descriptions and
answers of images. To achieve this goal, recent methods seek to construct a
large-scale instruction tuning dataset to empower the MLLM with quality
perception ability following the well-known scaling law. However, a large
amount of instruction tuning data may cause substantial computational costs and
redundant data, which in turn will cause harm to the performance of the model.
To cope with this problem, in this paper, we challenge the scaling law and
systematically investigate the role of data quality of the instruction tuning
dataset for explainable IQA. Using a powerful pre-trained MLLM, we first
investigate the changes in model performance after fine-tuning with different
sizes of instruction tuning data. We find that selecting a subset of the data
set randomly using an appropriate ratio can even lead to better results than
training with the entire instruction tuning dataset, demonstrating the
redundancy of current explainable IQA instruction tuning data. Beyond randomly
sampling a subset, we propose a clustering-based data selection framework with
three stages: clustering feature extraction, cluster quota allocation, and
cluster sampling strategy. Then we systematically analyze the choices of each
stage and propose a simple but efficient data selection method IQA-Select for
explainable IQA. The experimental results demonstrate that IQA-Select can
achieve 102.1% and 103.7% performance of full fine-tuning using only 10%
selected data in Q-Bench and AesBench respectively, significantly reducing
computational costs while achieving better performance.

</details>


### [175] [Bridge Thinking and Acting: Unleashing Physical Potential of VLM with Generalizable Action Expert](https://arxiv.org/abs/2510.03896)
*Mingyu Liu,Zheng Huang,Xiaoyi Lin,Muzhi Zhu,Canyu Zhao,Zongze Du,Yating Wang,Haoyi Zhu,Hao Chen,Chunhua Shen*

Main category: cs.CV

TL;DR: A new framework that uses sparse 3D trajectories as an intermediate representation to bridge VLM planning with physical action execution, enabling better generalization without requiring fine-tuning for new environments.


<details>
  <summary>Details</summary>
Motivation: To address limitations of conventional VLA models that generalize poorly due to scarce data and semantic ambiguities in action modules, which require fine-tuning for new environments.

Method: Uses sparse 3D waypoints generated by VLM, processed by a generalizable action expert that refines them into dense action sequences using real-time point cloud observations. Implements "Action Pre-training, Pointcloud Fine-tuning" paradigm.

Result: The method combines VLM's broad generalization in visual understanding and planning with fine-grained action-level generalization of the action expert.

Conclusion: The framework successfully bridges high-level planning with low-level physical actions using 3D trajectories as intermediate representation, enabling robust generalization without environment-specific fine-tuning.

Abstract: Although Vision-Language Models (VLM) have demonstrated impressive planning
and reasoning capabilities, translating these abilities into the physical world
introduces significant challenges. Conventional Vision-Language-Action (VLA)
models, which integrate reasoning and action into a monolithic architecture,
generalize poorly because they are constrained by scarce, narrow-domain data.
While recent dual-system approaches attempt to decouple "thinking" from
"acting", they are often constrained by semantic ambiguities within the action
module. This ambiguity makes large-scale, cross-task training infeasible.
Consequently, these systems typically necessitate fine-tuning on newly
collected data when deployed to novel environments, and the cooperation
mechanism between the two systems remains ill-defined. To address these
limitations, we introduce, for the first time, a framework centered around a
generalizable action expert. Our approach utilizes sparse 3D trajectories as an
intermediate representation, effectively bridging the high-level planning
capabilities of the VLM with the low-level physical action module. During the
planning phase, the VLM is only required to generate coarse 3D waypoints. These
waypoints are then processed by our generalizable action expert, which refines
them into dense, executable action sequences by sampling real-time point cloud
observations of the environment. To promote training efficiency and robust
generalization, we introduce a novel "Action Pre-training, Pointcloud
Fine-tuning" paradigm. Our method combines the broad generalization
capabilities of VLMs in visual understanding and planning with the
fine-grained, action-level generalization of action expert.

</details>


### [176] [Zero-Shot Fine-Grained Image Classification Using Large Vision-Language Models](https://arxiv.org/abs/2510.03903)
*Md. Atabuzzaman,Andrew Zhang,Chris Thomas*

Main category: cs.CV

TL;DR: A novel method transforms zero-shot fine-grained image classification into visual question-answering using LVLMs, enhanced by attention intervention and improved class descriptions, achieving SOTA performance.


<details>
  <summary>Details</summary>
Motivation: LVLMs have strong vision-language reasoning but their potential for zero-shot fine-grained classification (requiring precise differentiation between similar categories) remains underexplored.

Method: Transform zero-shot fine-grained classification into visual QA framework using LVLMs' understanding capabilities, enhanced by novel attention intervention technique and improved class description benchmarks.

Result: Extensive experiments across multiple benchmarks show the method consistently outperforms current SOTA approaches.

Conclusion: The method demonstrates both effectiveness and the broader potential of LVLMs for zero-shot fine-grained classification tasks.

Abstract: Large Vision-Language Models (LVLMs) have demonstrated impressive performance
on vision-language reasoning tasks. However, their potential for zero-shot
fine-grained image classification, a challenging task requiring precise
differentiation between visually similar categories, remains underexplored. We
present a novel method that transforms zero-shot fine-grained image
classification into a visual question-answering framework, leveraging LVLMs'
comprehensive understanding capabilities rather than relying on direct class
name generation. We enhance model performance through a novel attention
intervention technique. We also address a key limitation in existing datasets
by developing more comprehensive and precise class description benchmarks. We
validate the effectiveness of our method through extensive experimentation
across multiple fine-grained image classification benchmarks. Our proposed
method consistently outperforms the current state-of-the-art (SOTA) approach,
demonstrating both the effectiveness of our method and the broader potential of
LVLMs for zero-shot fine-grained classification tasks. Code and Datasets:
https://github.com/Atabuzzaman/Fine-grained-classification

</details>


### [177] [From Filters to VLMs: Benchmarking Defogging Methods through Object Detection and Segmentation Performance](https://arxiv.org/abs/2510.03906)
*Ardalan Aryashad,Parsa Razmara,Amin Mahjoub,Seyedarmin Azizi,Mahdi Salmani,Arad Firouzkouhi*

Main category: cs.CV

TL;DR: A comprehensive benchmark study evaluating various defogging methods (classical filters, neural networks, chained approaches, and VLM editors) for autonomous driving perception in foggy conditions, assessing both image quality and downstream task performance.


<details>
  <summary>Details</summary>
Motivation: Autonomous driving perception systems struggle in foggy conditions, and existing defogging methods show inconsistent improvements in downstream detection/segmentation tasks. There's a lack of real-world evaluation and understanding of when defogging actually helps perception tasks.

Method: Structured empirical study using Foggy Cityscapes dataset, benchmarking four pipeline types: classical filters, modern defogging networks, chained variants (filter→model, model→filter), and prompt-driven VLM image editors. Evaluates both image quality and downstream performance on object detection (mAP) and segmentation (PQ, RQ, SQ).

Result: Analysis reveals when defogging helps perception, when chaining methods yields synergy or degradation, and how VLM-based editors compare to dedicated approaches. VLM judge scores show strong correlation with mAP, providing reliable qualitative assessment.

Conclusion: Establishes a transparent, task-oriented benchmark for defogging methods and identifies conditions under which preprocessing genuinely improves autonomous perception in adverse weather, with VLM-based evaluation showing promise for automated assessment.

Abstract: Autonomous driving perception systems are particularly vulnerable in foggy
conditions, where light scattering reduces contrast and obscures fine details
critical for safe operation. While numerous defogging methods exist-from
handcrafted filters to learned restoration models-improvements in image
fidelity do not consistently translate into better downstream detection and
segmentation. Moreover, prior evaluations often rely on synthetic data, leaving
questions about real-world transferability. We present a structured empirical
study that benchmarks a comprehensive set of pipelines, including (i) classical
filters, (ii) modern defogging networks, (iii) chained variants
(filter$\rightarrow$model, model$\rightarrow$filter), and (iv) prompt-driven
visual--language image editing models (VLM) applied directly to foggy images.
Using Foggy Cityscapes, we assess both image quality and downstream performance
on object detection (mAP) and segmentation (PQ, RQ, SQ). Our analysis reveals
when defogging helps, when chaining yields synergy or degradation, and how
VLM-based editors compare to dedicated approaches. In addition, we evaluate
qualitative rubric-based scores from a VLM judge and quantify their alignment
with task metrics, showing strong correlations with mAP. Together, these
results establish a transparent, task-oriented benchmark for defogging methods
and highlight the conditions under which preprocessing genuinely improves
autonomous perception in adverse weather.

</details>


### [178] [Generating Human Motion Videos using a Cascaded Text-to-Video Framework](https://arxiv.org/abs/2510.03909)
*Hyelin Nam,Hyojun Go,Byeongjun Park,Byung-Hoon Kim,Hyungjin Chung*

Main category: cs.CV

TL;DR: CAMEO is a cascaded framework that bridges Text-to-Motion models and conditional Video Diffusion Models for general human motion video generation, addressing training and inference challenges through careful prompt preparation and camera-aware conditioning.


<details>
  <summary>Details</summary>
Motivation: Human video generation has broad applications but current video diffusion models are underexplored for general-purpose human video generation, being mostly limited to image-to-video setups or narrow domains like dance videos.

Method: A cascaded framework that connects Text-to-Motion models with conditional Video Diffusion Models, using carefully designed components including text prompt and visual condition preparation, and a camera-aware conditioning module that automatically selects viewpoints aligned with input text.

Result: Demonstrated effectiveness on both MovieGen benchmark and a new benchmark for T2M-VDM combination, showing versatility across diverse use cases with enhanced coherence and reduced manual intervention.

Conclusion: CAMEO successfully bridges the gap between text-to-motion and video generation, providing a robust framework for general human motion video generation with improved alignment and automatic viewpoint selection.

Abstract: Human video generation is becoming an increasingly important task with broad
applications in graphics, entertainment, and embodied AI. Despite the rapid
progress of video diffusion models (VDMs), their use for general-purpose human
video generation remains underexplored, with most works constrained to
image-to-video setups or narrow domains like dance videos. In this work, we
propose CAMEO, a cascaded framework for general human motion video generation.
It seamlessly bridges Text-to-Motion (T2M) models and conditional VDMs,
mitigating suboptimal factors that may arise in this process across both
training and inference through carefully designed components. Specifically, we
analyze and prepare both textual prompts and visual conditions to effectively
train the VDM, ensuring robust alignment between motion descriptions,
conditioning signals, and the generated videos. Furthermore, we introduce a
camera-aware conditioning module that connects the two stages, automatically
selecting viewpoints aligned with the input text to enhance coherence and
reduce manual intervention. We demonstrate the effectiveness of our approach on
both the MovieGen benchmark and a newly introduced benchmark tailored to the
T2M-VDM combination, while highlighting its versatility across diverse use
cases.

</details>


### [179] [OpenFLAME: Federated Visual Positioning System to Enable Large-Scale Augmented Reality Applications](https://arxiv.org/abs/2510.03915)
*Sagar Bharadwaj,Harrison Williams,Luke Wang,Michael Liang,Tao Jin,Srinivasan Seshan,Anthony Rowe*

Main category: cs.CV

TL;DR: OpenFLAME is a federated Visual Positioning System (VPS) backend that enables distributed 6DoF localization for AR applications by allowing independent organizations to maintain separate VPS services for their own spaces, addressing privacy and coverage limitations of centralized VPS solutions.


<details>
  <summary>Details</summary>
Motivation: Centralized VPS solutions from large companies fail to cover private indoor spaces due to privacy concerns, regulations, and maintenance bottlenecks, limiting the scope of world-scale AR applications that require ubiquitous 6DoF localization.

Method: Proposes federated image-based localization where organizations independently 3D scan and maintain VPS services for their spaces, with solutions for managing coherency across maps, quality control, service selection, and data merging without sharing private data.

Result: Enables access control of indoor 3D scans, distributed maintenance of VPS backend, and encourages larger coverage while addressing challenges of federated VPS services.

Conclusion: OpenFLAME provides a viable alternative to centralized VPS by enabling federated VPS services that can scale to cover both public and private spaces while maintaining privacy and distributed ownership.

Abstract: World-scale augmented reality (AR) applications need a ubiquitous 6DoF
localization backend to anchor content to the real world consistently across
devices. Large organizations such as Google and Niantic are 3D scanning outdoor
public spaces in order to build their own Visual Positioning Systems (VPS).
These centralized VPS solutions fail to meet the needs of many future AR
applications -- they do not cover private indoor spaces because of privacy
concerns, regulations, and the labor bottleneck of updating and maintaining 3D
scans. In this paper, we present OpenFLAME, a federated VPS backend that allows
independent organizations to 3D scan and maintain a separate VPS service for
their own spaces. This enables access control of indoor 3D scans, distributed
maintenance of the VPS backend, and encourages larger coverage. Sharding of VPS
services introduces several unique challenges -- coherency of localization
results across spaces, quality control of VPS services, selection of the right
VPS service for a location, and many others. We introduce the concept of
federated image-based localization and provide reference solutions for managing
and merging data across maps without sharing private data.

</details>


### [180] [Talking Tennis: Language Feedback from 3D Biomechanical Action Recognition](https://arxiv.org/abs/2510.03921)
*Arushi Dashore,Aryan Anumala,Emily Hui,Olivia Yang*

Main category: cs.CV

TL;DR: A framework that combines biomechanical motion analysis with deep learning and LLMs to generate actionable feedback for tennis stroke improvement.


<details>
  <summary>Details</summary>
Motivation: Existing tennis analysis systems lack the ability to translate biomechanical insights into accessible, meaningful feedback for players and coaches.

Method: Extracts biomechanical features (joint angles, limb velocities, kinetic chain patterns) using CNN-LSTM models from motion data, then generates feedback using large language models.

Result: Developed a novel framework that connects biomechanical analysis with actionable language feedback, evaluated on classification performance and interpretability.

Conclusion: The research successfully bridges the gap between explainable AI and sports biomechanics, providing technically accurate and actionable feedback for tennis stroke analysis.

Abstract: Automated tennis stroke analysis has advanced significantly with the
integration of biomechanical motion cues alongside deep learning techniques,
enhancing stroke classification accuracy and player performance evaluation.
Despite these advancements, existing systems often fail to connect
biomechanical insights with actionable language feedback that is both
accessible and meaningful to players and coaches. This research project
addresses this gap by developing a novel framework that extracts key
biomechanical features (such as joint angles, limb velocities, and kinetic
chain patterns) from motion data using Convolutional Neural Network Long
Short-Term Memory (CNN-LSTM)-based models. These features are analyzed for
relationships influencing stroke effectiveness and injury risk, forming the
basis for feedback generation using large language models (LLMs). Leveraging
the THETIS dataset and feature extraction techniques, our approach aims to
produce feedback that is technically accurate, biomechanically grounded, and
actionable for end-users. The experimental setup evaluates this framework on
classification performance and interpretability, bridging the gap between
explainable AI and sports biomechanics.

</details>


### [181] [Harnessing Synthetic Preference Data for Enhancing Temporal Understanding of Video-LLMs](https://arxiv.org/abs/2510.03955)
*Sameep Vani,Shreyas Jena,Maitreya Patel,Chitta Baral,Somak Aditya,Yezhou Yang*

Main category: cs.CV

TL;DR: TimeWarp is a method that creates synthetic temporal datasets to improve Video-LLMs' fine-grained temporal understanding, addressing their current limitation of relying too much on language reasoning rather than visual dynamics.


<details>
  <summary>Details</summary>
Motivation: Video-LLMs underperform on tasks requiring fine-grained temporal understanding due to lack of visual complexity and temporal nuance in current datasets, causing them to rely heavily on language-based reasoning instead of truly understanding video dynamics.

Method: Proposed TimeWarp - a systematic method to create targeted synthetic temporal datasets for fine-tuning, and introduced a large-scale preference dataset that captures intricate temporal dynamics often overlooked, grounding model responses to visual and temporal information.

Result: Applied to existing models, TimeWarp significantly improves performance on temporal understanding benchmarks, achieving absolute improvement across seven benchmarks.

Conclusion: The proposed datasets effectively advance temporal understanding in Video-LLMs, demonstrating the value of targeted synthetic data for addressing specific model limitations.

Abstract: While Video Large Language Models (Video-LLMs) have demonstrated remarkable
performance across general video understanding benchmarks-particularly in video
captioning and descriptive tasks-they consistently underperform on tasks that
require fine-grained temporal understanding. This limitation arises due to the
lack of visual complexity and temporal nuance in current fine-tuning datasets,
leading these models to rely heavily on language-based reasoning rather than
truly understanding video dynamics. In this work, we propose TimeWarp, a
systematic method to create a targeted synthetic temporal dataset to fine-tune
the model's responses to encourage it to focus on the given input video. We
introduce a large-scale preference dataset, created using TimeWarp, that
captures intricate temporal dynamics often overlooked, grounding the model's
responses to visual and temporal information. We demonstrate that when our
method is applied to existing models, it significantly improves performance on
temporal understanding benchmarks, highlighting the effectiveness of our
proposed datasets in advancing temporal understanding in Video-LLMs, resulting
in an absolute improvement in performance across seven benchmarks. Code is
available at https://github.com/sameepv21/timewarp.

</details>


### [182] [No Tokens Wasted: Leveraging Long Context in Biomedical Vision-Language Models](https://arxiv.org/abs/2510.03978)
*Min Woo Sun,Alejandro Lozano,Javier Gamazo Tejero,Vishwesh Nath,Xiao Xiao Sun,James Burgess,Yuhui Zhang,Kun Yuan,Robert Tibshirani,Sean Huver,Serena Yeung-Levy*

Main category: cs.CV

TL;DR: This paper introduces BMC-LongCLIP, a long-context biomedical vision-language model that extends text encoder context from 77 to 512 tokens, reducing token waste from 55% to 2.2% and achieving significant performance gains in retrieval and classification tasks.


<details>
  <summary>Details</summary>
Motivation: Standard vision-language models use short text windows (<77 tokens), forcing truncation of long biomedical captions, while analysis shows many biomedical captions exceed this limit, losing valuable context and supervision.

Method: Extend text encoder context length in VLMs, create BIOMEDICA-LongCAP dataset with 1M image-caption pairs from full-text articles, and train BMC-LongCLIP model with 512-token context windows.

Result: BMC-LongCLIP achieves up to +30% absolute gains in Recall@1 for retrieval, +2% average improvements in classification, faster convergence, and reduces token waste from 55% to 2.2%.

Conclusion: Long-context modeling is a promising direction for advancing biomedical VLMs, as longer context enables better utilization of supervision in long-format captions and improves performance across multiple tasks.

Abstract: Embedding vision-language models (VLMs) are typically pretrained with short
text windows (<77 tokens), which forces the truncation of long-format captions.
Yet, the distribution of biomedical captions from large-scale open source
literature reveals that a huge portion of captions far exceed 77 tokens. To
this end, we investigate the impact of pretraining on long-format biomedical
captions by extending the context length of text encoders in VLMs. We find that
longer context (thus, enabling additional supervision provided in long-format
captions) correlates with better retrieval and classification performance.
Given this finding, we introduce BIOMEDICA-LongCAP, a dataset of 1M
image-caption pairs enriched with context-aware descriptions from full-text
articles, providing longer and additional textual supervision. Using
BIOMEDICA-LongCAP, we train BMC-LongCLIP, a long-context biomedical VLM with a
text encoder supporting windows of up to 512 tokens. Our model extends context
capacity by 6.6x, reducing token waste from 55% to just 2.2%. On long-caption
retrieval benchmarks, BMC-LongCLIP achieves up to +30% absolute gains in
Recall@1 and +2% average improvements in classification, while also converging
faster than short-context. Our results demonstrate that long-context modeling
is a promising direction for advancing biomedical VLMs.

</details>


### [183] [Keep It on a Leash: Controllable Pseudo-label Generation Towards Realistic Long-Tailed Semi-Supervised Learning](https://arxiv.org/abs/2510.03993)
*Yaxin Hou,Bo Han,Yuheng Jia,Hui Liu,Junhui Hou*

Main category: cs.CV

TL;DR: CPG framework addresses long-tailed semi-supervised learning with unknown unlabeled data distributions by generating controllable pseudo-labels and maintaining known labeled data distribution through dynamic filtering and self-reinforcing optimization.


<details>
  <summary>Details</summary>
Motivation: Current methods assume predefined distributions for unlabeled data, but real-world unlabeled data distributions are generally unknown and arbitrary, creating a significant challenge in long-tailed semi-supervised learning.

Method: Controllable Pseudo-label Generation framework with dynamic controllable filtering, Bayes-optimal classifier using logit adjustment, class-aware adaptive augmentation, and auxiliary branch for maximum data utilization.

Result: Achieves consistent improvements across benchmark datasets, surpassing state-of-the-art methods by up to 15.97% in accuracy.

Conclusion: CPG effectively handles unknown unlabeled data distributions through controllable pseudo-label generation and self-reinforcing optimization, with theoretical guarantees on generalization error reduction.

Abstract: Current long-tailed semi-supervised learning methods assume that labeled data
exhibit a long-tailed distribution, and unlabeled data adhere to a typical
predefined distribution (i.e., long-tailed, uniform, or inverse long-tailed).
However, the distribution of the unlabeled data is generally unknown and may
follow an arbitrary distribution. To tackle this challenge, we propose a
Controllable Pseudo-label Generation (CPG) framework, expanding the labeled
dataset with the progressively identified reliable pseudo-labels from the
unlabeled dataset and training the model on the updated labeled dataset with a
known distribution, making it unaffected by the unlabeled data distribution.
Specifically, CPG operates through a controllable self-reinforcing optimization
cycle: (i) at each training step, our dynamic controllable filtering mechanism
selectively incorporates reliable pseudo-labels from the unlabeled dataset into
the labeled dataset, ensuring that the updated labeled dataset follows a known
distribution; (ii) we then construct a Bayes-optimal classifier using logit
adjustment based on the updated labeled data distribution; (iii) this improved
classifier subsequently helps identify more reliable pseudo-labels in the next
training step. We further theoretically prove that this optimization cycle can
significantly reduce the generalization error under some conditions.
Additionally, we propose a class-aware adaptive augmentation module to further
improve the representation of minority classes, and an auxiliary branch to
maximize data utilization by leveraging all labeled and unlabeled samples.
Comprehensive evaluations on various commonly used benchmark datasets show that
CPG achieves consistent improvements, surpassing state-of-the-art methods by up
to \textbf{15.97\%} in accuracy. The code is available at
https://github.com/yaxinhou/CPG.

</details>


### [184] [Enhancing OCR for Sino-Vietnamese Language Processing via Fine-tuned PaddleOCRv5](https://arxiv.org/abs/2510.04003)
*Minh Hoang Nguyen,Su Nguyen Thiet*

Main category: cs.CV

TL;DR: Fine-tuning PaddleOCRv5 improves Classical Chinese (Han-Nom) text recognition from 37.5% to 50.0% accuracy, especially for noisy historical documents.


<details>
  <summary>Details</summary>
Motivation: Existing OCR systems struggle with degraded scans, non-standard glyphs, and handwriting variations in ancient Vietnamese Chinese manuscripts, hindering digitization and cross-lingual research.

Method: Retrained PaddleOCRv5's text recognition module using curated Han-Nom manuscripts, with full pipeline covering preprocessing, LMDB conversion, evaluation, and visualization.

Result: Significant improvement over base model: exact accuracy increased from 37.5% to 50.0%, particularly effective under noisy image conditions.

Conclusion: The fine-tuned model enables better Han-Nom text recognition and facilitates downstream applications like semantic alignment, machine translation, and historical linguistics research.

Abstract: Recognizing and processing Classical Chinese (Han-Nom) texts play a vital
role in digitizing Vietnamese historical documents and enabling cross-lingual
semantic research. However, existing OCR systems struggle with degraded scans,
non-standard glyphs, and handwriting variations common in ancient sources. In
this work, we propose a fine-tuning approach for PaddleOCRv5 to improve
character recognition on Han-Nom texts. We retrain the text recognition module
using a curated subset of ancient Vietnamese Chinese manuscripts, supported by
a full training pipeline covering preprocessing, LMDB conversion, evaluation,
and visualization. Experimental results show a significant improvement over the
base model, with exact accuracy increasing from 37.5 percent to 50.0 percent,
particularly under noisy image conditions. Furthermore, we develop an
interactive demo that visually compares pre- and post-fine-tuning recognition
results, facilitating downstream applications such as Han-Vietnamese semantic
alignment, machine translation, and historical linguistics research. The demo
is available at https://huggingface.co/spaces/MinhDS/Fine-tuned-PaddleOCRv5.

</details>


### [185] [Fit Pixels, Get Labels: Meta-learned Implicit Networks for Image Segmentation](https://arxiv.org/abs/2510.04021)
*Kushal Vyas,Ashok Veeraraghavan,Guha Balakrishnan*

Main category: cs.CV

TL;DR: MetaSeg introduces a meta-learning framework that trains implicit neural representations (INRs) for medical image segmentation, achieving comparable performance to U-Net models with 90% fewer parameters.


<details>
  <summary>Details</summary>
Motivation: Implicit neural representations (INRs) excel at learning compact signal representations but are not naturally suited for predictive tasks like segmentation that require learning semantic structures across signal distributions.

Method: MetaSeg uses an INR that simultaneously predicts pixel intensity values and class labels, combined with a meta-learning procedure to find optimal initial parameters over training data, enabling quick fine-tuning for unseen test images.

Result: MetaSeg achieved Dice scores comparable to commonly used U-Net models on 2D and 3D brain MRI segmentation tasks, while using 90% fewer parameters.

Conclusion: MetaSeg provides a scalable, parameter-efficient alternative to traditional resource-heavy architectures like U-Nets and vision transformers for medical image segmentation.

Abstract: Implicit neural representations (INRs) have achieved remarkable successes in
learning expressive yet compact signal representations. However, they are not
naturally amenable to predictive tasks such as segmentation, where they must
learn semantic structures over a distribution of signals. In this study, we
introduce MetaSeg, a meta-learning framework to train INRs for medical image
segmentation. MetaSeg uses an underlying INR that simultaneously predicts per
pixel intensity values and class labels. It then uses a meta-learning procedure
to find optimal initial parameters for this INR over a training dataset of
images and segmentation maps, such that the INR can simply be fine-tuned to fit
pixels of an unseen test image, and automatically decode its class labels. We
evaluated MetaSeg on 2D and 3D brain MRI segmentation tasks and report Dice
scores comparable to commonly used U-Net models, but with $90\%$ fewer
parameters. MetaSeg offers a fresh, scalable alternative to traditional
resource-heavy architectures such as U-Nets and vision transformers for medical
image segmentation. Our project is available at
https://kushalvyas.github.io/metaseg.html .

</details>


### [186] [Video-in-the-Loop: Span-Grounded Long Video QA with Interleaved Reasoning](https://arxiv.org/abs/2510.04022)
*Chendong Wang,Donglin Bai,Yifan Yang,Xiao Jin,Anlan Zhang,Rui Wang,Shiqi Jiang,Yuqing Yang,Hao Wu,Qi Dai,Chong Luo,Ting Cao,Lili Qiu,Suman Banerjee*

Main category: cs.CV

TL;DR: Video-in-the-Loop (ViTL) is a two-stage framework for long-video QA that localizes relevant intervals with low-fps skimming and then answers by reallocating visual tokens at higher frame rates, achieving better performance with fewer frames.


<details>
  <summary>Details</summary>
Motivation: To address the computational challenges of long-video question answering while maintaining accuracy and interpretability through direct attribution of time spans.

Method: Two-stage approach: 1) Localize question-relevant intervals using low-fps skim, 2) Answer via span-aware reallocation of visual tokens at higher effective frame rate with interleaved output of spans and final answer.

Result: Achieves up to 8.6% improvement with 50% less frame input on long-video QA and temporal grounding tasks (Charades-STA, ActivityNet-Captions), with span-aware token reallocation consistently outperforming uniform sampling.

Conclusion: ViTL provides an interpretable and compute-efficient solution for scalable long-video QA through its two-stage localization and answer framework with span-aware token allocation.

Abstract: We present \emph{Video-in-the-Loop} (ViTL), a two-stage long-video QA
framework that preserves a fixed token budget by first \emph{localizing}
question-relevant interval(s) with a low-fps skim and then \emph{answering} via
span-aware reallocation of visual tokens at higher effective frame rate,
emitting an interleaved output with both spans and the final option for direct
attribution. We also introduce \dataname{}, which converts description based
event graphs into \emph{span-grounded} multiple-choice QA by pairing each
question with \emph{ground-truth} time span(s) and related reasoning. ViTL is
trained end-to-end with an interleaved group-relative objective that couples
temporal IoU for localization with answer correctness, allowing credit to flow
from answers back to spans without increasing compute. Under fixed token
budgets, ViTL attains up to 8.6% with 50% less frame input on long-video QA and
temporal grounding (e.g., Charades-STA, ActivityNet-Captions) and ablations
show that span-aware token reallocation consistently surpasses uniform
sampling. Together, \dataname{} and ViTL provide an interpretable,
compute-efficient recipe for scalable long-video QA.

</details>


### [187] [Enhancing Fake News Video Detection via LLM-Driven Creative Process Simulation](https://arxiv.org/abs/2510.04024)
*Yuyan Bu,Qiang Sheng,Juan Cao,Shaofei Wang,Peng Qi,Yuhui Shi,Beizhe Hu*

Main category: cs.CV

TL;DR: AgentAug is a data augmentation framework that generates diverse fake news videos by simulating creative processes using LLM-driven pipelines and active learning, improving fake news detection performance.


<details>
  <summary>Details</summary>
Motivation: Current fake news detectors suffer from limited and biased training data due to complex many-to-many relationships between video segments and fabricated events, which existing datasets fail to adequately capture.

Method: Proposes AgentAug framework with multiple LLM-driven pipelines for four fabrication categories, combined with active learning based on uncertainty sampling to select useful augmented samples during training.

Result: Experimental results on two benchmark datasets show that AgentAug consistently improves the performance of short video fake news detectors.

Conclusion: AgentAug effectively addresses data sparsity and bias issues in fake news detection by generating diverse training samples through simulated creative processes.

Abstract: The emergence of fake news on short video platforms has become a new
significant societal concern, necessitating automatic video-news-specific
detection. Current detectors primarily rely on pattern-based features to
separate fake news videos from real ones. However, limited and less diversified
training data lead to biased patterns and hinder their performance. This
weakness stems from the complex many-to-many relationships between video
material segments and fabricated news events in real-world scenarios: a single
video clip can be utilized in multiple ways to create different fake
narratives, while a single fabricated event often combines multiple distinct
video segments. However, existing datasets do not adequately reflect such
relationships due to the difficulty of collecting and annotating large-scale
real-world data, resulting in sparse coverage and non-comprehensive learning of
the characteristics of potential fake news video creation. To address this
issue, we propose a data augmentation framework, AgentAug, that generates
diverse fake news videos by simulating typical creative processes. AgentAug
implements multiple LLM-driven pipelines of four fabrication categories for
news video creation, combined with an active learning strategy based on
uncertainty sampling to select the potentially useful augmented samples during
training. Experimental results on two benchmark datasets demonstrate that
AgentAug consistently improves the performance of short video fake news
detectors.

</details>


### [188] [Prompt-to-Prompt: Text-Based Image Editing Via Cross-Attention Mechanisms -- The Research of Hyperparameters and Novel Mechanisms to Enhance Existing Frameworks](https://arxiv.org/abs/2510.04034)
*Linn Bieske,Carla Lorente*

Main category: cs.CV

TL;DR: This paper improves prompt-to-prompt image editing by optimizing hyperparameters and developing new methods to enhance precision and reliability in text-driven image manipulation.


<details>
  <summary>Details</summary>
Motivation: To address the variability and inconsistency in current stable diffusion-based image editing methods, particularly issues like inconsistent hair color changes and cycle inconsistency.

Method: Conducted comprehensive study of 'word swap' method, developed 'attention re-weight method' for better adaptability, and proposed 'CL P2P' framework.

Result: Enhanced precision and reliability of prompt-to-prompt image editing frameworks by optimizing hyperparameter settings and architectural choices.

Conclusion: The work contributes to understanding how hyperparameter settings and attention mechanisms in neural networks significantly influence the composition and quality of generated images.

Abstract: Recent advances in image editing have shifted from manual pixel manipulation
to employing deep learning methods like stable diffusion models, which now
leverage cross-attention mechanisms for text-driven control. This transition
has simplified the editing process but also introduced variability in results,
such as inconsistent hair color changes. Our research aims to enhance the
precision and reliability of prompt-to-prompt image editing frameworks by
exploring and optimizing hyperparameters. We present a comprehensive study of
the "word swap" method, develop an "attention re-weight method" for better
adaptability, and propose the "CL P2P" framework to address existing
limitations like cycle inconsistency. This work contributes to understanding
and improving the interaction between hyperparameter settings and the
architectural choices of neural network models, specifically their attention
mechanisms, which significantly influence the composition and quality of the
generated images.

</details>


### [189] [\textsc{GUI-Spotlight}: Adaptive Iterative Focus Refinement for Enhanced GUI Visual Grounding](https://arxiv.org/abs/2510.04039)
*Bin Lei,Nuo Xu,Ali Payani,Mingyi Hong,Chunhua Liao,Yu Cao,Caiwen Ding*

Main category: cs.CV

TL;DR: GUI-Spotlight is a model that improves visual grounding accuracy in multimodal GUI systems by dynamically invoking specialized tools to iteratively narrow focus to relevant screen regions, achieving state-of-the-art performance with minimal training data.


<details>
  <summary>Details</summary>
Motivation: Current multimodal GUI systems are limited by unreliable visual grounding, which prevents accurate pointer-level actions like clicking or dragging. This limitation bounds the practical usefulness of these systems in real-world environments.

Method: GUI-Spotlight is trained for image-grounded reasoning and dynamically invokes multiple specialized tools to iteratively narrow its focus to the relevant region of the screen, improving visual grounding accuracy.

Result: On the ScreenSpot-Pro benchmark, GUI-Spotlight achieves 52.8% accuracy with only 18.5K training samples, surpassing V2P-7B (50.6% with 9.6M samples) and GTA-1-7B (50.1% with 1.56M samples).

Conclusion: GUI-Spotlight substantially improves visual grounding accuracy in multimodal GUI systems, enabling more reliable pointer-level actions and advancing the practical usefulness of these systems in complex real-world environments.

Abstract: Multimodal large language models (MLLMs) have markedly expanded the
competence of graphical user-interface (GUI) systems, propelling them beyond
controlled simulations into complex, real-world environments across diverse
platforms. However, practical usefulness is still bounded by the reliability of
visual grounding, i.e., mapping textual references to exact on-screen elements.
This limitation prevents the system from accurately performing pointer-level
actions such as clicking or dragging. To address it, we introduce GUI-Spotlight
-- a model trained for image-grounded reasoning that dynamically invokes
multiple specialized tools to iteratively narrow its focus to the relevant
region of the screen, thereby substantially improving visual grounding
accuracy. On the ScreenSpot-Pro benchmark, GUI-Spotlight trained with only
18.5K training samples achieves 52.8\% accuracy, surpassing V2P-7B (50.6\% with
9.6M training samples) and GTA-1-7B (50.1\% with 1.56M training samples).

</details>


### [190] [Quantization Range Estimation for Convolutional Neural Networks](https://arxiv.org/abs/2510.04044)
*Bingtao Yang,Yujia Wang,Mengzhi Jiao,Hongwei Huo*

Main category: cs.CV

TL;DR: A range estimation method for post-training quantization that minimizes quantization errors through layer-wise local minima optimization, achieving state-of-the-art accuracy in 8-bit, 6-bit, and 4-bit quantization for image classification models.


<details>
  <summary>Details</summary>
Motivation: Low-bit quantization while maintaining model accuracy is challenging in post-training quantization for reducing deep neural network storage.

Method: Model range estimation as optimization problem minimizing quantization errors by layer-wise local minima, prove local convexity, develop efficient search algorithm, and apply to transformed weights space.

Result: Outperforms state-of-the-art on top-1 accuracy for ResNet series and Inception-v3 models, with almost no loss in 8-bit/6-bit settings and significant improvement in 4-bit quantization for image classification.

Conclusion: The proposed range estimation method effectively improves quantization performance with minimal accuracy loss across different bit-widths.

Abstract: Post-training quantization for reducing the storage of deep neural network
models has been demonstrated to be an effective way in various tasks. However,
low-bit quantization while maintaining model accuracy is a challenging problem.
In this paper, we present a range estimation method to improve the quantization
performance for post-training quantization. We model the range estimation into
an optimization problem of minimizing quantization errors by layer-wise local
minima. We prove this problem is locally convex and present an efficient search
algorithm to find the optimal solution. We propose the application of the above
search algorithm to the transformed weights space to do further improvement in
practice. Our experiments demonstrate that our method outperforms
state-of-the-art performance generally on top-1 accuracy for image
classification tasks on the ResNet series models and Inception-v3 model. The
experimental results show that the proposed method has almost no loss of top-1
accuracy in 8-bit and 6-bit settings for image classifications, and the
accuracy of 4-bit quantization is also significantly improved. The code is
available at https://github.com/codeiscommitting/REQuant.

</details>


### [191] [MetaFind: Scene-Aware 3D Asset Retrieval for Coherent Metaverse Scene Generation](https://arxiv.org/abs/2510.04057)
*Zhenyu Pan,Yucheng Lu,Han Liu*

Main category: cs.CV

TL;DR: MetaFind is a tri-modal compositional retrieval framework for 3D asset retrieval in metaverse scene generation, addressing inconsistent asset retrieval and lack of standardized paradigms by supporting text, image, and 3D queries with spatial and style consistency.


<details>
  <summary>Details</summary>
Motivation: To solve inconsistent 3D asset retrieval that ignores spatial, semantic, and stylistic constraints, and the absence of a standardized retrieval paradigm specifically for 3D assets, as existing approaches rely on general-purpose 3D shape representation models.

Method: Introduces a flexible retrieval mechanism supporting arbitrary combinations of text, image, and 3D queries, with a plug-and-play equivariant layout encoder ESSGNN that captures spatial relationships and object appearance features, ensuring contextual and stylistic coherence regardless of coordinate transformations.

Result: Empirical evaluations demonstrate improved spatial and stylistic consistency in various retrieval tasks compared to baseline methods.

Conclusion: MetaFind provides an effective framework for scene-aware 3D asset retrieval that enhances spatial reasoning and style consistency in metaverse scene generation through its tri-modal compositional approach and equivariant layout encoding.

Abstract: We present MetaFind, a scene-aware tri-modal compositional retrieval
framework designed to enhance scene generation in the metaverse by retrieving
3D assets from large-scale repositories. MetaFind addresses two core
challenges: (i) inconsistent asset retrieval that overlooks spatial, semantic,
and stylistic constraints, and (ii) the absence of a standardized retrieval
paradigm specifically tailored for 3D asset retrieval, as existing approaches
mainly rely on general-purpose 3D shape representation models. Our key
innovation is a flexible retrieval mechanism that supports arbitrary
combinations of text, image, and 3D modalities as queries, enhancing spatial
reasoning and style consistency by jointly modeling object-level features
(including appearance) and scene-level layout structures. Methodologically,
MetaFind introduces a plug-and-play equivariant layout encoder ESSGNN that
captures spatial relationships and object appearance features, ensuring
retrieved 3D assets are contextually and stylistically coherent with the
existing scene, regardless of coordinate frame transformations. The framework
supports iterative scene construction by continuously adapting retrieval
results to current scene updates. Empirical evaluations demonstrate the
improved spatial and stylistic consistency of MetaFind in various retrieval
tasks compared to baseline methods.

</details>


### [192] [Ordinal Encoding as a Regularizer in Binary Loss for Solar Flare Prediction](https://arxiv.org/abs/2510.04063)
*Chetraj Pandey,Jinsu Hong,Anli Ji,Rafal A. Angryk,Berkay Aydin*

Main category: cs.CV

TL;DR: Proposes an ordinality-aware loss function that incorporates sub-class ordinal relationships into binary solar flare prediction to reduce misclassifications near the prediction threshold.


<details>
  <summary>Details</summary>
Motivation: Binary classification for solar flare prediction ignores ordinal relationships among sub-classes, leading to frequent misclassifications near the prediction threshold where similar intensity events fall on opposite sides.

Method: Modified loss function that integrates ordinal information of sub-classes into binary cross-entropy loss, serving as an ordinality-aware regularization method that penalizes misclassifications near the threshold more heavily.

Result: The approach aims to enhance model learning by leveraging ordinal characteristics of the data to improve overall performance in solar flare prediction.

Conclusion: Incorporating ordinal weighting into the loss function can mitigate limitations of binary classification frameworks in solar flare prediction by better handling events near the prediction threshold.

Abstract: The prediction of solar flares is typically formulated as a binary
classification task, distinguishing events as either Flare (FL) or No-Flare
(NF) according to a specified threshold (for example, greater than or equal to
C-class, M-class, or X-class). However, this binary framework neglects the
inherent ordinal relationships among the sub-classes contained within each
category (FL and NF). Several studies on solar flare prediction have
empirically shown that the most frequent misclassifications occur near this
prediction threshold. This suggests that the models struggle to differentiate
events that are similar in intensity but fall on opposite sides of the binary
threshold. To mitigate this limitation, we propose a modified loss function
that integrates the ordinal information among the sub-classes of the binarized
flare labels into the conventional binary cross-entropy (BCE) loss. This
approach serves as an ordinality-aware, data-driven regularization method that
penalizes the incorrect predictions of flare events in close proximity to the
prediction threshold more heavily than those away from the boundary during
model optimization. By incorporating ordinal weighting into the loss function,
we aim to enhance the model's learning process by leveraging the ordinal
characteristics of the data, thereby improving its overall performance.

</details>


### [193] [QuantDemoire: Quantization with Outlier Aware for Image Demoiréing](https://arxiv.org/abs/2510.04066)
*Zheng Chen,Kewei Zhang,Xiaoyang Liu,Weihang Zhang,Mengfan Wang,Yifan Fu,Yulun Zhang*

Main category: cs.CV

TL;DR: QuantDemoire is a post-training quantization framework for demoiréing models that addresses performance degradation issues through outlier-aware quantization and frequency-aware calibration, achieving significant parameter and computation reduction while maintaining quality.


<details>
  <summary>Details</summary>
Motivation: Direct application of existing quantization methods to demoiréing models causes severe performance degradation due to distribution outliers and weakened representations in smooth regions, limiting deployment on edge devices.

Method: Proposes two key components: 1) Outlier-aware quantizer with sampling-based range estimation and FP16 retention for extreme weights, 2) Frequency-aware calibration strategy that emphasizes low- and mid-frequency components during fine-tuning.

Result: Achieves large reductions in parameters and computation while maintaining quality, outperforming existing quantization methods by over 4 dB on W4A4 quantization.

Conclusion: QuantDemoire provides an effective solution for deploying demoiréing models on resource-constrained devices by addressing quantization-specific challenges in moiré removal tasks.

Abstract: Demoir\'eing aims to remove moir\'e artifacts that often occur in images.
While recent deep learning-based methods have achieved promising results, they
typically require substantial computational resources, limiting their
deployment on edge devices. Model quantization offers a compelling solution.
However, directly applying existing quantization methods to demoir\'eing models
introduces severe performance degradation. The main reasons are distribution
outliers and weakened representations in smooth regions. To address these
issues, we propose QuantDemoire, a post-training quantization framework
tailored to demoir\'eing. It contains two key components. **First}, we
introduce an outlier-aware quantizer to reduce errors from outliers. It uses
sampling-based range estimation to reduce activation outliers, and keeps a few
extreme weights in FP16 with negligible cost. **Second**, we design a
frequency-aware calibration strategy. It emphasizes low- and mid-frequency
components during fine-tuning, which mitigates banding artifacts caused by
low-bit quantization. Extensive experiments validate that our QuantDemoire
achieves large reductions in parameters and computation while maintaining
quality. Meanwhile, it outperforms existing quantization methods by over **4
dB** on W4A4. Code is released at:
https://github.com/zhengchen1999/QuantDemoire.

</details>


### [194] [Diffusion Low Rank Hybrid Reconstruction for Sparse View Medical Imaging](https://arxiv.org/abs/2510.04069)
*Zongyin Deng,Qing Zhou,Yuhao Fang,Zijian Wang,Yao Lu,Ye Zhang,Chun Li*

Main category: cs.CV

TL;DR: TV-LoRA is a novel method for low-dose sparse-view CT reconstruction that combines diffusion generative priors with multi-regularization constraints (anisotropic TV and nuclear norm) in an ADMM framework, achieving superior performance in texture recovery and artifact suppression.


<details>
  <summary>Details</summary>
Motivation: To address the ill-posedness and texture loss problems in extremely sparse-view CT reconstruction, where traditional methods struggle with limited projection data.

Method: Combines diffusion generative prior (NCSN++ with SDE modeling) with multi-regularization constraints (anisotropic TV and nuclear norm/LoRA) in an ADMM framework, using 2D slice-based strategy with FFT acceleration and tensor-parallel optimization.

Result: Consistently surpasses benchmarks on AAPM-2016, CTHD, and LIDC datasets with N_view=8,4,2 in SSIM, texture recovery, edge clarity, and artifact suppression, demonstrating strong robustness and generalizability.

Conclusion: Diffusion + TV-LoRA achieves high-fidelity, efficient 3D CT reconstruction with broad clinical applicability in low-dose, sparse-sampling scenarios, with ablation studies confirming complementary effects of LoRA regularization and diffusion priors.

Abstract: This work presents TV-LoRA, a novel method for low-dose sparse-view CT
reconstruction that combines a diffusion generative prior (NCSN++ with SDE
modeling) and multi-regularization constraints, including anisotropic TV and
nuclear norm (LoRA), within an ADMM framework. To address ill-posedness and
texture loss under extremely sparse views, TV-LoRA integrates generative and
physical constraints, and utilizes a 2D slice-based strategy with FFT
acceleration and tensor-parallel optimization for efficient inference.
Experiments on AAPM-2016, CTHD, and LIDC datasets with
$N_{\mathrm{view}}=8,4,2$ show that TV-LoRA consistently surpasses benchmarks
in SSIM, texture recovery, edge clarity, and artifact suppression,
demonstrating strong robustness and generalizability. Ablation studies confirm
the complementary effects of LoRA regularization and diffusion priors, while
the FFT-PCG module provides a speedup. Overall, Diffusion + TV-LoRA achieves
high-fidelity, efficient 3D CT reconstruction and broad clinical applicability
in low-dose, sparse-sampling scenarios.

</details>


### [195] [TOPO-Bench: An Open-Source Topological Mapping Evaluation Framework with Quantifiable Perceptual Aliasing](https://arxiv.org/abs/2510.04100)
*Jiaming Wang,Diwen Liu,Jizhuo Chen,Harold Soh*

Main category: cs.CV

TL;DR: Proposes standardized evaluation metrics and datasets for topological mapping to address lack of reproducibility and fair comparisons, with focus on perceptual aliasing challenges.


<details>
  <summary>Details</summary>
Motivation: Progress in topological mapping is hindered by lack of standardized evaluation metrics, datasets, and protocols, preventing fair comparisons across different systems and environments.

Method: Formalized topological consistency as fundamental property, proposed localization accuracy as surrogate metric, developed quantitative measure of dataset ambiguity, curated benchmark dataset with calibrated ambiguity levels, and implemented deep-learned baselines alongside classical methods.

Result: Created standardized evaluation protocol and benchmark dataset, evaluated both classical and deep-learning approaches, yielding new insights into limitations of current methods under perceptual aliasing.

Conclusion: All datasets, baselines, and evaluation tools are open-sourced to foster consistent and reproducible research in topological mapping, addressing key challenges in the field.

Abstract: Topological mapping offers a compact and robust representation for
navigation, but progress in the field is hindered by the lack of standardized
evaluation metrics, datasets, and protocols. Existing systems are assessed
using different environments and criteria, preventing fair and reproducible
comparisons. Moreover, a key challenge - perceptual aliasing - remains
under-quantified, despite its strong influence on system performance. We
address these gaps by (1) formalizing topological consistency as the
fundamental property of topological maps and showing that localization accuracy
provides an efficient and interpretable surrogate metric, and (2) proposing the
first quantitative measure of dataset ambiguity to enable fair comparisons
across environments. To support this protocol, we curate a diverse benchmark
dataset with calibrated ambiguity levels, implement and release deep-learned
baseline systems, and evaluate them alongside classical methods. Our
experiments and analysis yield new insights into the limitations of current
approaches under perceptual aliasing. All datasets, baselines, and evaluation
tools are fully open-sourced to foster consistent and reproducible research in
topological mapping.

</details>


### [196] [Learning Efficient Meshflow and Optical Flow from Event Cameras](https://arxiv.org/abs/2510.04111)
*Xinglong Luo,Ao Luo,Kunming Luo,Zhengning Wang,Ping Tan,Bing Zeng,Shuaicheng Liu*

Main category: cs.CV

TL;DR: This paper introduces event-based meshflow estimation, creates a high-resolution dataset (HREM/HREM+), proposes EEMFlow network for efficient meshflow estimation, and develops density adaptation methods to improve performance.


<details>
  <summary>Details</summary>
Motivation: Address the lack of meshflow-specific event datasets and methods, and explore the challenge of event data density in event-based flow estimation.

Method: Created HREM dataset with high-resolution event data and meshflow labels, proposed EEMFlow network with encoder-decoder architecture, added CDC module for dense optical flow, and developed ADM for density adaptation.

Result: EEMFlow achieves 30x faster runtime than state-of-the-art methods while maintaining exceptional performance. ADM improves EEMFlow and EEMFlow+ performance by 8% and 10% respectively.

Conclusion: The proposed methods successfully address event-based meshflow estimation challenges through dataset creation, efficient network design, and density adaptation techniques, demonstrating significant improvements in speed and accuracy.

Abstract: In this paper, we explore the problem of event-based meshflow estimation, a
novel task that involves predicting a spatially smooth sparse motion field from
event cameras. To start, we review the state-of-the-art in event-based flow
estimation, highlighting two key areas for further research: i) the lack of
meshflow-specific event datasets and methods, and ii) the underexplored
challenge of event data density. First, we generate a large-scale
High-Resolution Event Meshflow (HREM) dataset, which showcases its superiority
by encompassing the merits of high resolution at 1280x720, handling dynamic
objects and complex motion patterns, and offering both optical flow and
meshflow labels. These aspects have not been fully explored in previous works.
Besides, we propose Efficient Event-based MeshFlow (EEMFlow) network, a
lightweight model featuring a specially crafted encoder-decoder architecture to
facilitate swift and accurate meshflow estimation. Furthermore, we upgrade
EEMFlow network to support dense event optical flow, in which a
Confidence-induced Detail Completion (CDC) module is proposed to preserve sharp
motion boundaries. We conduct comprehensive experiments to show the exceptional
performance and runtime efficiency (30x faster) of our EEMFlow model compared
to the recent state-of-the-art flow method. As an extension, we expand HREM
into HREM+, a multi-density event dataset contributing to a thorough study of
the robustness of existing methods across data with varying densities, and
propose an Adaptive Density Module (ADM) to adjust the density of input event
data to a more optimal range, enhancing the model's generalization ability. We
empirically demonstrate that ADM helps to significantly improve the performance
of EEMFlow and EEMFlow+ by 8% and 10%, respectively. Code and dataset are
released at https://github.com/boomluo02/EEMFlowPlus.

</details>


### [197] [Joint Learning of Pose Regression and Denoising Diffusion with Score Scaling Sampling for Category-level 6D Pose Estimation](https://arxiv.org/abs/2510.04125)
*Seunghyun Lee,Tae-Kyun Kim*

Main category: cs.CV

TL;DR: A novel diffusion-based method for 6D object pose estimation that accelerates training convergence and eliminates the need for additional pose evaluation networks through pretrained encoders and time-dependent sampling guidance.


<details>
  <summary>Details</summary>
Motivation: Existing diffusion models for 6D pose estimation suffer from slow training convergence due to end-to-end encoder learning with diffusion networks, and require additional networks to filter out low-quality pose candidates.

Method: Proposes two key components: 1) Pretraining encoder with direct pose regression head and joint learning with denoising diffusion head, 2) Time-dependent score scaling for sampling guidance that balances exploration-exploitation trade-off without needing evaluation networks.

Result: Achieves state-of-the-art accuracies on REAL275, HouseCat6D, and ROPE benchmarks with single-pose inference, while being more efficient in both training and inference compared to existing methods.

Conclusion: The proposed simple yet effective pipeline overcomes limitations of existing diffusion approaches by accelerating training convergence and eliminating the need for additional evaluation networks, while maintaining multi-modal characteristics for symmetric objects and ensuring high-quality pose generation.

Abstract: Latest diffusion models have shown promising results in category-level 6D
object pose estimation by modeling the conditional pose distribution with depth
image input. The existing methods, however, suffer from slow convergence during
training, learning its encoder with the diffusion denoising network in
end-to-end fashion, and require an additional network that evaluates sampled
pose hypotheses to filter out low-quality pose candidates. In this paper, we
propose a novel pipeline that tackles these limitations by two key components.
First, the proposed method pretrains the encoder with the direct pose
regression head, and jointly learns the networks via the regression head and
the denoising diffusion head, significantly accelerating training convergence
while achieving higher accuracy. Second, sampling guidance via time-dependent
score scaling is proposed s.t. the exploration-exploitation trade-off is
effectively taken, eliminating the need for the additional evaluation network.
The sampling guidance maintains multi-modal characteristics of symmetric
objects at early denoising steps while ensuring high-quality pose generation at
final steps. Extensive experiments on multiple benchmarks including REAL275,
HouseCat6D, and ROPE, demonstrate that the proposed method, simple yet
effective, achieves state-of-the-art accuracies even with single-pose
inference, while being more efficient in both training and inference.

</details>


### [198] [Learning from All: Concept Alignment for Autonomous Distillation from Multiple Drifting MLLMs](https://arxiv.org/abs/2510.04142)
*Xiaoyu Yang,Jie Lu,En Yu*

Main category: cs.CV

TL;DR: This paper addresses concept drift in multimodal large language model (MLLM) distillation by proposing autonomous preference optimization (APO), which enables student models to learn, compare, and critique reasoning trajectories from multiple teachers to achieve better consistency and generalization.


<details>
  <summary>Details</summary>
Motivation: The paper identifies that reasoning trajectories from multiple MLLM teachers exhibit concept drift, where their reasoning distributions evolve unpredictably and transmit biases to student models, compromising performance in knowledge distillation.

Method: The authors introduce a "learn, compare, critique" paradigm culminating in autonomous preference optimization (APO). Students learn and self-distill preferred thinking by comparing multiple teachers, then engage in critical reflection over drifting inference from teachers to perform concept alignment through APO.

Result: Extensive experiments demonstrate superior performance in consistency, robustness, and generalization within knowledge distillation. The paper also contributes CXR-MAX dataset with 170,982 distilled reasoning trajectories derived from MIMIC-CXR using public MLLMs.

Conclusion: The proposed APO framework effectively addresses concept drift in MLLM distillation, yielding robust, consistent, and generalizable models through autonomous preference optimization and concept alignment.

Abstract: This paper identifies a critical yet underexplored challenge in distilling
from multimodal large language models (MLLMs): the reasoning trajectories
generated by multiple drifting teachers exhibit concept drift, whereby their
reasoning distributions evolve unpredictably and transmit biases to the student
model, ultimately compromising its performance. To tackle this issue, we
pioneer a theoretical connection between concept drift and knowledge
distillation, casting the non-stationary reasoning dynamics from multiple MLLM
teachers as next-token prediction of multi-stream reasoning trajectories.Guided
by concept drift, we introduce the "learn, compare, critique" paradigm,
culminating in autonomous preference optimization (APO). Under the active
guidance of the teachers, the student model first learns and self-distils
preferred thinking by comparing multiple teachers. It then engages in critical
reflection over the drifting inference from teachers, performing concept
alignment through APO, ultimately yielding a robust, consistent, and
generalizable model.Extensive experiments demonstrate our superior performance
of consistency, robustness and generalization within knowledge distillation.
Besides, we also contributed a large-scale dataset, CXR-MAX (Multi-teachers
Alignment X-rays), comprising 170,982 distilled reasoning trajectories derived
from publicly accessible MLLMs based on MIMIC-CXR. Our code and data are public
at: https://anonymous.4open.science/r/Autonomous-Distillation/.

</details>


### [199] [Automating construction safety inspections using a multi-modal vision-language RAG framework](https://arxiv.org/abs/2510.04145)
*Chenxin Wang,Elyas Asadi Shamsabadi,Zhaohui Chen,Luming Shen,Alireza Ahmadian Fard Fini,Daniel Dias-da-Costa*

Main category: cs.CV

TL;DR: SiteShield is a multi-modal LVLM-based RAG framework that automates construction safety inspection reports by integrating visual and audio inputs, outperforming unimodal LLMs with better accuracy and efficiency.


<details>
  <summary>Details</summary>
Motivation: Conventional construction safety inspection methods are inefficient due to large information volume, and existing LVLM applications face limitations like irrelevant responses, restricted modal inputs, and hallucinations. LLMs lack training data and real-time adaptability.

Method: Developed SiteShield, a multi-modal LVLM-based Retrieval-Augmented Generation (RAG) framework that integrates visual and audio inputs for automated safety inspection reports.

Result: SiteShield outperformed unimodal LLMs without RAG with F1 score of 0.82, hamming loss of 0.04, precision of 0.76, and recall of 0.96 using real-world data.

Conclusion: SiteShield offers a novel pathway to enhance information retrieval and efficiency in generating construction safety reports through multi-modal integration and RAG framework.

Abstract: Conventional construction safety inspection methods are often inefficient as
they require navigating through large volume of information. Recent advances in
large vision-language models (LVLMs) provide opportunities to automate safety
inspections through enhanced visual and linguistic understanding. However,
existing applications face limitations including irrelevant or unspecific
responses, restricted modal inputs and hallucinations. Utilisation of Large
Language Models (LLMs) for this purpose is constrained by availability of
training data and frequently lack real-time adaptability. This study introduces
SiteShield, a multi-modal LVLM-based Retrieval-Augmented Generation (RAG)
framework for automating construction safety inspection reports by integrating
visual and audio inputs. Using real-world data, SiteShield outperformed
unimodal LLMs without RAG with an F1 score of 0.82, hamming loss of 0.04,
precision of 0.76, and recall of 0.96. The findings indicate that SiteShield
offers a novel pathway to enhance information retrieval and efficiency in
generating safety reports.

</details>


### [200] [BLADE: Bias-Linked Adaptive DEbiasing](https://arxiv.org/abs/2510.04174)
*Piyush Arora,Navlika Singh,Vasubhya Diwan,Pratik Mazumder*

Main category: cs.CV

TL;DR: BLADE is a generative debiasing framework that mitigates neural network biases without requiring prior knowledge of biases or bias-conflicting samples, achieving state-of-the-art performance on benchmark datasets.


<details>
  <summary>Details</summary>
Motivation: Neural networks often learn implicit biases and spurious correlations from training data, relying on superficial patterns rather than task-relevant features. Existing debiasing methods require impractical assumptions like prior knowledge of biases or access to bias-conflicting samples.

Method: BLADE trains a generative model to translate images across bias domains while preserving task-relevant features, then adaptively refines each image with its synthetic counterpart based on bias susceptibility. It aligns images with bias-translated counterparts (same task features, different bias) while misaligning with same-bias samples.

Result: BLADE significantly outperforms state-of-the-art methods on multiple benchmark datasets, exceeding the closest baseline by ~18% absolute margin on corrupted CIFAR-10 under worst group setting.

Conclusion: BLADE establishes a new benchmark in bias mitigation and demonstrates potential for developing more robust deep learning models without explicit supervision.

Abstract: Neural networks have revolutionized numerous fields, yet they remain
vulnerable to a critical flaw: the tendency to learn implicit biases, spurious
correlations between certain attributes and target labels in training data.
These biases are often more prevalent and easier to learn, causing models to
rely on superficial patterns rather than task-relevant features necessary for
generalization. Existing methods typically rely on strong assumptions, such as
prior knowledge of these biases or access to bias-conflicting samples, i.e.,
samples that contradict spurious correlations and counterbalance bias-aligned
samples, samples that conform to these spurious correlations. However, such
assumptions are often impractical in real-world settings. We propose BLADE
({B}ias-{L}inked {A}daptive {DE}biasing), a generative debiasing framework that
requires no prior knowledge of bias or bias-conflicting samples. BLADE first
trains a generative model to translate images across bias domains while
preserving task-relevant features. Then, it adaptively refines each image with
its synthetic counterpart based on the image's susceptibility to bias. To
encourage robust representations, BLADE aligns an image with its
bias-translated synthetic counterpart that shares task-relevant features but
differs in bias, while misaligning it with samples sharing the same bias. We
evaluate BLADE on multiple benchmark datasets and show that it significantly
outperforms state-of-the-art methods. Notably, it exceeds the closest baseline
by an absolute margin of around 18% on the corrupted CIFAR-10 dataset under the
worst group setting, establishing a new benchmark in bias mitigation and
demonstrating its potential for developing more robust deep learning models
without explicit supervision.

</details>


### [201] [From Segments to Concepts: Interpretable Image Classification via Concept-Guided Segmentation](https://arxiv.org/abs/2510.04180)
*Ran Eisenberg,Amit Rozner,Ethan Fetaya,Ofir Lindenbaum*

Main category: cs.CV

TL;DR: SEG-MIL-CBM integrates concept-guided segmentation with multiple instance learning to provide spatially grounded, concept-level explanations for deep neural networks without requiring concept annotations.


<details>
  <summary>Details</summary>
Motivation: Deep neural networks lack transparency and interpretability, especially in safety-critical applications, and existing Concept Bottleneck Models require costly concept annotations and lack spatial grounding.

Method: Combines concept-guided image segmentation with attention-based multiple instance learning, treating segmented regions as instances and aggregating evidence across them to identify task-relevant concepts.

Result: Achieves robust performance across settings with spurious correlations, input corruptions, and large-scale benchmarks while providing transparent concept-level explanations.

Conclusion: SEG-MIL-CBM enables interpretable deep learning with spatially grounded concept explanations without the need for expensive concept annotations.

Abstract: Deep neural networks have achieved remarkable success in computer vision;
however, their black-box nature in decision-making limits interpretability and
trust, particularly in safety-critical applications. Interpretability is
crucial in domains where errors have severe consequences. Existing models not
only lack transparency but also risk exploiting unreliable or misleading
features, which undermines both robustness and the validity of their
explanations. Concept Bottleneck Models (CBMs) aim to improve transparency by
reasoning through human-interpretable concepts. Still, they require costly
concept annotations and lack spatial grounding, often failing to identify which
regions support each concept. We propose SEG-MIL-CBM, a novel framework that
integrates concept-guided image segmentation into an attention-based multiple
instance learning (MIL) framework, where each segmented region is treated as an
instance and the model learns to aggregate evidence across them. By reasoning
over semantically meaningful regions aligned with high-level concepts, our
model highlights task-relevant evidence, down-weights irrelevant cues, and
produces spatially grounded, concept-level explanations without requiring
annotations of concepts or groups. SEG-MIL-CBM achieves robust performance
across settings involving spurious correlations (unintended dependencies
between background and label), input corruptions (perturbations that degrade
visual quality), and large-scale benchmarks, while providing transparent,
concept-level explanations.

</details>


### [202] [Let Features Decide Their Own Solvers: Hybrid Feature Caching for Diffusion Transformers](https://arxiv.org/abs/2510.04188)
*Shikang Zheng,Guantao Chen,Qinming Zhou,Yuqi Lin,Lixuan He,Chang Zou,Peiliang Cai,Jiacheng Liu,Linfeng Zhang*

Main category: cs.CV

TL;DR: HyCa is a hybrid ODE solver inspired caching framework that applies dimension-wise caching strategies to accelerate Diffusion Transformers, achieving 5-6x speedup across various models without retraining.


<details>
  <summary>Details</summary>
Motivation: Diffusion Transformers have high sampling costs due to iterative transformer forward passes, and existing feature caching methods use uniform strategies that ignore heterogeneous dynamic behaviors across feature dimensions.

Method: Model hidden feature evolution as a mixture of ODEs across dimensions and introduce HyCa framework that applies dimension-wise caching strategies inspired by hybrid ODE solvers.

Result: Achieves near-lossless acceleration with 5.55x speedup on FLUX, 5.56x on HunyuanVideo, 6.24x on Qwen-Image and Qwen-Image-Edit without retraining.

Conclusion: HyCa provides effective training-free acceleration for Diffusion Transformers by modeling feature dynamics as ODEs and applying dimension-wise caching strategies.

Abstract: Diffusion Transformers offer state-of-the-art fidelity in image and video
synthesis, but their iterative sampling process remains a major bottleneck due
to the high cost of transformer forward passes at each timestep. To mitigate
this, feature caching has emerged as a training-free acceleration technique
that reuses or forecasts hidden representations. However, existing methods
often apply a uniform caching strategy across all feature dimensions, ignoring
their heterogeneous dynamic behaviors. Therefore, we adopt a new perspective by
modeling hidden feature evolution as a mixture of ODEs across dimensions, and
introduce HyCa, a Hybrid ODE solver inspired caching framework that applies
dimension-wise caching strategies. HyCa achieves near-lossless acceleration
across diverse domains and models, including 5.55 times speedup on FLUX, 5.56
times speedup on HunyuanVideo, 6.24 times speedup on Qwen-Image and
Qwen-Image-Edit without retraining.

</details>


### [203] [World-To-Image: Grounding Text-to-Image Generation with Agent-Driven World Knowledge](https://arxiv.org/abs/2510.04201)
*Moo Hyun Son,Jintaek Oh,Sun Bin Mun,Jaechul Roh,Sehyun Choi*

Main category: cs.CV

TL;DR: World-To-Image is a framework that enhances text-to-image generation by using web-searching agents to retrieve knowledge about novel concepts, then optimizing prompts to improve semantic accuracy and visual quality.


<details>
  <summary>Details</summary>
Motivation: Text-to-image models struggle with novel or out-of-distribution entities due to knowledge cutoffs, leading to degraded performance on unfamiliar concepts.

Method: Uses an agent that dynamically searches the web to retrieve images for unknown concepts, then performs multimodal prompt optimization to steer generative models toward accurate synthesis.

Result: Achieves +8.1% improvement in accuracy-to-prompt on the NICE benchmark, outperforming state-of-the-art methods in both semantic alignment and visual aesthetics with high efficiency in less than three iterations.

Conclusion: The framework enables T2I systems to better reflect the ever-changing real world by bridging knowledge gaps through agent-driven web knowledge retrieval and prompt optimization.

Abstract: While text-to-image (T2I) models can synthesize high-quality images, their
performance degrades significantly when prompted with novel or
out-of-distribution (OOD) entities due to inherent knowledge cutoffs. We
introduce World-To-Image, a novel framework that bridges this gap by empowering
T2I generation with agent-driven world knowledge. We design an agent that
dynamically searches the web to retrieve images for concepts unknown to the
base model. This information is then used to perform multimodal prompt
optimization, steering powerful generative backbones toward an accurate
synthesis. Critically, our evaluation goes beyond traditional metrics,
utilizing modern assessments like LLMGrader and ImageReward to measure true
semantic fidelity. Our experiments show that World-To-Image substantially
outperforms state-of-the-art methods in both semantic alignment and visual
aesthetics, achieving +8.1% improvement in accuracy-to-prompt on our curated
NICE benchmark. Our framework achieves these results with high efficiency in
less than three iterations, paving the way for T2I systems that can better
reflect the ever-changing real world. Our demo code is available
here\footnote{https://github.com/mhson-kyle/World-To-Image}.

</details>


### [204] [MASC: Boosting Autoregressive Image Generation with a Manifold-Aligned Semantic Clustering](https://arxiv.org/abs/2510.04220)
*Lixuan He,Shikang Zheng,Linfeng Zhang*

Main category: cs.CV

TL;DR: MASC proposes a hierarchical semantic tree framework that structures visual token embeddings to improve autoregressive image generation efficiency and quality.


<details>
  <summary>Details</summary>
Motivation: Current autoregressive models use flat, unstructured visual token vocabularies that ignore semantic relationships in the embedding space, leading to inefficient training and limited generation quality.

Method: MASC constructs a hierarchical semantic tree using geometry-aware distance metrics and density-driven agglomerative clustering to model the token embedding manifold, transforming flat prediction into structured hierarchical prediction.

Result: MASC accelerates training by up to 57% and improves generation quality, reducing FID of LlamaGen-XL from 2.87 to 2.58, making AR models competitive with state-of-the-art methods.

Conclusion: Structuring the prediction space through hierarchical semantic organization is as crucial as architectural innovation for scalable generative modeling in autoregressive frameworks.

Abstract: Autoregressive (AR) models have shown great promise in image generation, yet
they face a fundamental inefficiency stemming from their core component: a
vast, unstructured vocabulary of visual tokens. This conventional approach
treats tokens as a flat vocabulary, disregarding the intrinsic structure of the
token embedding space where proximity often correlates with semantic
similarity. This oversight results in a highly complex prediction task, which
hinders training efficiency and limits final generation quality. To resolve
this, we propose Manifold-Aligned Semantic Clustering (MASC), a principled
framework that constructs a hierarchical semantic tree directly from the
codebook's intrinsic structure. MASC employs a novel geometry-aware distance
metric and a density-driven agglomerative construction to model the underlying
manifold of the token embeddings. By transforming the flat, high-dimensional
prediction task into a structured, hierarchical one, MASC introduces a
beneficial inductive bias that significantly simplifies the learning problem
for the AR model. MASC is designed as a plug-and-play module, and our extensive
experiments validate its effectiveness: it accelerates training by up to 57%
and significantly improves generation quality, reducing the FID of LlamaGen-XL
from 2.87 to 2.58. MASC elevates existing AR frameworks to be highly
competitive with state-of-the-art methods, establishing that structuring the
prediction space is as crucial as architectural innovation for scalable
generative modeling.

</details>


### [205] [Zoom-In to Sort AI-Generated Images Out](https://arxiv.org/abs/2510.04225)
*Yikun Ji,Yan Hong,Bowen Deng,jun lan,Huijia Zhu,Weiqiang Wang,Liqing Zhang,Jianfu Zhang*

Main category: cs.CV

TL;DR: ZoomIn is a two-stage forensic framework that improves AI-generated image detection accuracy and interpretability by first scanning for suspicious regions and then performing focused analysis on zoomed-in areas.


<details>
  <summary>Details</summary>
Motivation: The rapid growth of AI-generated imagery has blurred boundaries between real and synthetic content, raising digital integrity concerns. Current vision-language models often fail to detect subtle artifacts in high-quality synthetic images.

Method: Proposes ZoomIn, a two-stage framework mimicking human visual inspection: first scans images to locate suspicious regions, then performs focused analysis on zoomed-in areas. Uses MagniFake dataset of 20,000 real and synthetic images with bounding boxes and explanations generated through automated VLM pipeline.

Result: Achieves 96.39% accuracy with robust generalization, while providing human-understandable explanations grounded in visual evidence.

Conclusion: ZoomIn effectively addresses the challenge of detecting high-quality synthetic images by combining accurate detection with interpretable explanations through a human-inspired two-stage approach.

Abstract: The rapid growth of AI-generated imagery has blurred the boundary between
real and synthetic content, raising critical concerns for digital integrity.
Vision-language models (VLMs) offer interpretability through explanations but
often fail to detect subtle artifacts in high-quality synthetic images. We
propose ZoomIn, a two-stage forensic framework that improves both accuracy and
interpretability. Mimicking human visual inspection, ZoomIn first scans an
image to locate suspicious regions and then performs a focused analysis on
these zoomed-in areas to deliver a grounded verdict. To support training, we
introduce MagniFake, a dataset of 20,000 real and high-quality synthetic images
annotated with bounding boxes and forensic explanations, generated through an
automated VLM-based pipeline. Our method achieves 96.39% accuracy with robust
generalization, while providing human-understandable explanations grounded in
visual evidence.

</details>


### [206] [A Recursive Pyramidal Algorithm for Solving the Image Registration Problem](https://arxiv.org/abs/2510.04231)
*Stefan Dirnstorfer*

Main category: cs.CV

TL;DR: A simple, end-to-end trainable image registration algorithm implemented in just a few lines of Python code that works with minimal training data and time.


<details>
  <summary>Details</summary>
Motivation: To create an accessible image registration solution that requires very little training data, training time, and code complexity while maintaining accuracy.

Method: End-to-end trainable algorithm implemented in Python with minimal code (dozen lines), using small input windows (19x15) and trained on limited data (74 images).

Result: Achieves accurate image registration results in some settings despite using very little training data and training time.

Conclusion: The algorithm excels in brevity and serves as a good starting point for scenarios with limitations in training data, training time, or code complexity.

Abstract: The problem of image registration is finding a transformation that aligns two
images, such that the corresponding points are in the same location. This paper
introduces a simple, end-to-end trainable algorithm that is implementable in a
few lines of Python code. The approach is shown to work with very little
training data and training time, while achieving accurate results in some
settings. An example application to stereo vision was trained from 74 images on
a 19x15 input window. With just a dozen lines of Python code this algorithm
excels in brevity and may serve as a good start in related scenarios with
limitations to training data, training time or code complexity.

</details>


### [207] [Detection of retinal diseases using an accelerated reused convolutional network](https://arxiv.org/abs/2510.04232)
*Amin Ahmadi Kasani,Hedieh Sajedi*

Main category: cs.CV

TL;DR: The paper introduces ArConv layers to redesign and optimize convolutional layers, creating a lightweight model with only 1.3M parameters that achieves better accuracy than MobileNetV2 for eye disease diagnosis.


<details>
  <summary>Details</summary>
Motivation: To improve accessibility of deep neural networks for eye disease detection by reducing computational complexity, making models suitable for mobile devices while maintaining high accuracy.

Method: Redesigned and optimized convolutional layers by creating novel ArConv layers, building a new general model that incorporates these efficient convolutional layers.

Result: The final model with 1.3M parameters achieved 0.9328 accuracy on RfMiD test set, outperforming MobileNetV2 (2.2M parameters, 0.9266 accuracy) under identical conditions.

Conclusion: The proposed ArConv layers successfully create more accessible deep learning models suitable for mobile deployment while maintaining competitive accuracy for medical diagnosis tasks.

Abstract: Convolutional neural networks are continually evolving, with some efforts
aimed at improving accuracy, others at increasing speed, and some at enhancing
accessibility. Improving accessibility broadens the application of neural
networks across a wider range of tasks, including the detection of eye
diseases. Early diagnosis of eye diseases and consulting an ophthalmologist can
prevent many vision disorders. Given the importance of this issue, various
datasets have been collected from the cornea to facilitate the process of
making neural network models. However, most of the methods introduced in the
past are computationally complex. In this study, we tried to increase the
accessibility of deep neural network models. We did this at the most
fundamental level, specifically by redesigning and optimizing the convolutional
layers. By doing so, we created a new general model that incorporates our novel
convolutional layer named ArConv layers. Thanks to the efficient performance of
this new layer, the model has suitable complexity for use in mobile phones and
can perform the task of diagnosing the presence of disease with high accuracy.
The final model we present contains only 1.3 million parameters. In comparison
to the MobileNetV2 model, which has 2.2 million parameters, our model
demonstrated better accuracy when trained and evaluated on the RfMiD dataset
under identical conditions, achieving an accuracy of 0.9328 versus 0.9266 on
the RfMiD test set.

</details>


### [208] [Scaling Sequence-to-Sequence Generative Neural Rendering](https://arxiv.org/abs/2510.04236)
*Shikun Liu,Kam Woh Ng,Wonbong Jang,Jiadong Guo,Junlin Han,Haozhe Liu,Yiannis Douratsos,Juan C. Pérez,Zijian Zhou,Chi Phung,Tao Xiang,Juan-Manuel Pérez-Rúa*

Main category: cs.CV

TL;DR: Kaleido is a generative model for photorealistic neural rendering that treats 3D as a specialized video domain, using sequence-to-sequence image synthesis to perform view synthesis without explicit 3D representations.


<details>
  <summary>Details</summary>
Motivation: To create a unified framework for object- and scene-level neural rendering that can leverage large-scale video data for pre-training and reduce reliance on scarce 3D datasets.

Method: Uses a masked autoregressive framework with decoder-only rectified flow transformer to generate any number of 6-DoF target views conditioned on reference views, unifying 3D and video modeling.

Result: Sets new state-of-the-art on view synthesis benchmarks, with zero-shot performance outperforming other generative methods in few-view settings and matching per-scene optimization methods in many-view settings.

Conclusion: Kaleido successfully demonstrates that 3D rendering can be effectively treated as a video sequence synthesis task, enabling unified modeling and leveraging video data to improve performance while reducing dependency on 3D datasets.

Abstract: We present Kaleido, a family of generative models designed for
photorealistic, unified object- and scene-level neural rendering. Kaleido
operates on the principle that 3D can be regarded as a specialised sub-domain
of video, expressed purely as a sequence-to-sequence image synthesis task.
Through a systemic study of scaling sequence-to-sequence generative neural
rendering, we introduce key architectural innovations that enable our model to:
i) perform generative view synthesis without explicit 3D representations; ii)
generate any number of 6-DoF target views conditioned on any number of
reference views via a masked autoregressive framework; and iii) seamlessly
unify 3D and video modelling within a single decoder-only rectified flow
transformer. Within this unified framework, Kaleido leverages large-scale video
data for pre-training, which significantly improves spatial consistency and
reduces reliance on scarce, camera-labelled 3D datasets -- all without any
architectural modifications. Kaleido sets a new state-of-the-art on a range of
view synthesis benchmarks. Its zero-shot performance substantially outperforms
other generative methods in few-view settings, and, for the first time, matches
the quality of per-scene optimisation methods in many-view settings.

</details>


### [209] [The best performance in the CARE 2025 -- Liver Task (LiSeg-Contrast): Contrast-Aware Semi-Supervised Segmentation with Domain Generalization and Test-Time Adaptation](https://arxiv.org/abs/2510.04243)
*Jincan Lou,Jingkun Chen,Haoquan Li,Hang Li,Wenjian Huang,Weihua Chen,Fan Wang,Jianguo Zhang*

Main category: cs.CV

TL;DR: CoSSeg-TTA is a liver segmentation framework for MRI that combines nnU-Netv2 with semi-supervised learning, domain adaptation, and test-time adaptation to address challenges of limited annotated data and domain shifts across scanners/institutions.


<details>
  <summary>Details</summary>
Motivation: Liver segmentation from contrast-enhanced MRI is challenging due to limited annotated data, heterogeneous enhancement protocols, and significant domain shifts across different scanners and institutions. Traditional domain adaptation methods like Pix2Pix and cycle-GAN have limitations including requiring image registration, causing structural distortions, and unstable training.

Method: Built on nnU-Netv2 with semi-supervised mean teacher scheme to leverage unlabeled data. Includes domain adaptation module with randomized histogram-based style appearance transfer and trainable contrast-aware network. Uses continual test-time adaptation strategy during inference.

Result: The framework consistently outperforms nnU-Netv2 baseline, achieving superior Dice score and Hausdorff Distance. It exhibits strong generalization to unseen domains under low-annotation conditions.

Conclusion: CoSSeg-TTA effectively addresses domain shift challenges in liver MRI segmentation through a comprehensive approach combining semi-supervised learning, domain adaptation, and test-time adaptation, demonstrating robust performance across different scanners and institutions.

Abstract: Accurate liver segmentation from contrast-enhanced MRI is essential for
diagnosis, treatment planning, and disease monitoring. However, it remains
challenging due to limited annotated data, heterogeneous enhancement protocols,
and significant domain shifts across scanners and institutions. Traditional
image-to-image translation frameworks have made great progress in domain
generalization, but their application is not straightforward. For example,
Pix2Pix requires image registration, and cycle-GAN cannot be integrated
seamlessly into segmentation pipelines. Meanwhile, these methods are originally
used to deal with cross-modality scenarios, and often introduce structural
distortions and suffer from unstable training, which may pose drawbacks in our
single-modality scenario. To address these challenges, we propose CoSSeg-TTA, a
compact segmentation framework for the GED4 (Gd-EOB-DTPA enhanced hepatobiliary
phase MRI) modality built upon nnU-Netv2 and enhanced with a semi-supervised
mean teacher scheme to exploit large amounts of unlabeled volumes. A domain
adaptation module, incorporating a randomized histogram-based style appearance
transfer function and a trainable contrast-aware network, enriches domain
diversity and mitigates cross-center variability. Furthermore, a continual
test-time adaptation strategy is employed to improve robustness during
inference. Extensive experiments demonstrate that our framework consistently
outperforms the nnU-Netv2 baseline, achieving superior Dice score and Hausdorff
Distance while exhibiting strong generalization to unseen domains under
low-annotation conditions.

</details>


### [210] [Concept-Based Masking: A Patch-Agnostic Defense Against Adversarial Patch Attacks](https://arxiv.org/abs/2510.04245)
*Ayushi Mehrotra,Derek Peng,Dipkamal Bhusal,Nidhi Rastogi*

Main category: cs.CV

TL;DR: A patch-agnostic defense method using concept-based explanations to neutralize adversarial patch attacks without requiring prior knowledge of patch size or location.


<details>
  <summary>Details</summary>
Motivation: Existing defenses against adversarial patch attacks assume prior knowledge of patch characteristics, limiting their practical applicability in real-world scenarios.

Method: Leverages concept-based explanations to identify and suppress the most influential concept activation vectors, thereby neutralizing patch effects without explicit patch detection.

Result: Achieves higher robust and clean accuracy than state-of-the-art PatchCleanser on Imagenette with ResNet-50, maintaining strong performance across varying patch sizes and locations.

Conclusion: Combining interpretability with robustness shows promise, suggesting concept-driven defenses as a scalable strategy for securing machine learning models against adversarial patch attacks.

Abstract: Adversarial patch attacks pose a practical threat to deep learning models by
forcing targeted misclassifications through localized perturbations, often
realized in the physical world. Existing defenses typically assume prior
knowledge of patch size or location, limiting their applicability. In this
work, we propose a patch-agnostic defense that leverages concept-based
explanations to identify and suppress the most influential concept activation
vectors, thereby neutralizing patch effects without explicit detection.
Evaluated on Imagenette with a ResNet-50, our method achieves higher robust and
clean accuracy than the state-of-the-art PatchCleanser, while maintaining
strong performance across varying patch sizes and locations. Our results
highlight the promise of combining interpretability with robustness and suggest
concept-driven defenses as a scalable strategy for securing machine learning
models against adversarial patch attacks.

</details>


### [211] [Flexible and Efficient Spatio-Temporal Transformer for Sequential Visual Place Recognition](https://arxiv.org/abs/2510.04282)
*Yu Kiu,Lau,Chao Chen,Ge Jin,Chen Feng*

Main category: cs.CV

TL;DR: Adapt-STformer is a flexible and efficient Seq-VPR method using Recurrent Deformable Transformer Encoder that supports variable sequence lengths, achieves faster inference and lower memory usage while improving recall.


<details>
  <summary>Details</summary>
Motivation: Existing transformer-based Seq-VPR methods prioritize performance but lack flexibility to handle variable sequence lengths and suffer from inefficiency in real-time applications.

Method: Proposed Adapt-STformer with Recurrent Deformable Transformer Encoder (Recurrent-DTE) that uses iterative recurrent mechanism to fuse information from multiple sequential frames.

Result: Boosts recall by up to 17%, reduces sequence extraction time by 36%, and lowers memory usage by 35% compared to second-best baseline on Nordland, Oxford, and NuScenes datasets.

Conclusion: Adapt-STformer successfully addresses the flexibility and efficiency limitations of existing transformer-based Seq-VPR methods while maintaining high performance.

Abstract: Sequential Visual Place Recognition (Seq-VPR) leverages transformers to
capture spatio-temporal features effectively; however, existing approaches
prioritize performance at the expense of flexibility and efficiency. In
practice, a transformer-based Seq-VPR model should be flexible to the number of
frames per sequence (seq-length), deliver fast inference, and have low memory
usage to meet real-time constraints. To our knowledge, no existing
transformer-based Seq-VPR method achieves both flexibility and efficiency. To
address this gap, we propose Adapt-STformer, a Seq-VPR method built around our
novel Recurrent Deformable Transformer Encoder (Recurrent-DTE), which uses an
iterative recurrent mechanism to fuse information from multiple sequential
frames. This design naturally supports variable seq-lengths, fast inference,
and low memory usage. Experiments on the Nordland, Oxford, and NuScenes
datasets show that Adapt-STformer boosts recall by up to 17% while reducing
sequence extraction time by 36% and lowering memory usage by 35% compared to
the second-best baseline.

</details>


### [212] [ChronoEdit: Towards Temporal Reasoning for Image Editing and World Simulation](https://arxiv.org/abs/2510.04290)
*Jay Zhangjie Wu,Xuanchi Ren,Tianchang Shen,Tianshi Cao,Kai He,Yifan Lu,Ruiyuan Gao,Enze Xie,Shiyi Lan,Jose M. Alvarez,Jun Gao,Sanja Fidler,Zian Wang,Huan Ling*

Main category: cs.CV

TL;DR: ChronoEdit reframes image editing as video generation to ensure physical consistency by treating input and edited images as video frames, using temporal reasoning with reasoning tokens to create plausible editing trajectories.


<details>
  <summary>Details</summary>
Motivation: Current large generative models lack physical consistency in image editing, which is crucial for world simulation tasks where edited objects must remain coherent.

Method: Treats input and edited images as first/last video frames, leverages pretrained video models for temporal consistency, introduces temporal reasoning stage with reasoning tokens to imagine plausible editing trajectories, then drops tokens to avoid full video rendering costs.

Result: Outperforms state-of-the-art baselines in both visual fidelity and physical plausibility on the new PBench-Edit benchmark for physically consistent image editing.

Conclusion: ChronoEdit effectively bridges the physical consistency gap in image editing by leveraging video generation principles and temporal reasoning, offering 14B and 2B model variants for different computational needs.

Abstract: Recent advances in large generative models have significantly advanced image
editing and in-context image generation, yet a critical gap remains in ensuring
physical consistency, where edited objects must remain coherent. This
capability is especially vital for world simulation related tasks. In this
paper, we present ChronoEdit, a framework that reframes image editing as a
video generation problem. First, ChronoEdit treats the input and edited images
as the first and last frames of a video, allowing it to leverage large
pretrained video generative models that capture not only object appearance but
also the implicit physics of motion and interaction through learned temporal
consistency. Second, ChronoEdit introduces a temporal reasoning stage that
explicitly performs editing at inference time. Under this setting, the target
frame is jointly denoised with reasoning tokens to imagine a plausible editing
trajectory that constrains the solution space to physically viable
transformations. The reasoning tokens are then dropped after a few steps to
avoid the high computational cost of rendering a full video. To validate
ChronoEdit, we introduce PBench-Edit, a new benchmark of image-prompt pairs for
contexts that require physical consistency, and demonstrate that ChronoEdit
surpasses state-of-the-art baselines in both visual fidelity and physical
plausibility. Code and models for both the 14B and 2B variants of ChronoEdit
will be released on the project page:
https://research.nvidia.com/labs/toronto-ai/chronoedit

</details>


### [213] [CARE-PD: A Multi-Site Anonymized Clinical Dataset for Parkinson's Disease Gait Assessment](https://arxiv.org/abs/2510.04312)
*Vida Adeli,Ivan Klabucar,Javad Rajabi,Benjamin Filtjens,Soroush Mehraban,Diwei Wang,Hyewon Seo,Trung-Hieu Hoang,Minh N. Do,Candice Muller,Claudia Oliveira,Daniel Boari Coelho,Pieter Ginis,Moran Gilat,Alice Nieuwboer,Joke Spildooren,Lucas Mckay,Hyeokhyen Kwon,Gari Clifford,Christine Esper,Stewart Factor,Imari Genias,Amirhossein Dadashzadeh,Leia Shum,Alan Whone,Majid Mirmehdi,Andrea Iaboni,Babak Taati*

Main category: cs.CV

TL;DR: CARE-PD is the largest public 3D mesh gait dataset for Parkinson's Disease, enabling supervised clinical score prediction and unsupervised motion tasks, with models outperforming traditional features and pretraining significantly improving performance.


<details>
  <summary>Details</summary>
Motivation: Objective gait assessment in Parkinson's Disease is limited by the absence of large, diverse, and clinically annotated motion datasets.

Method: Created CARE-PD dataset from 9 cohorts across 8 clinical centers, converting recordings to anonymized SMPL meshes. Evaluated supervised UPDRS score prediction and unsupervised motion tasks under four generalization protocols.

Result: Motion encoders consistently outperform handcrafted features. Pretraining on CARE-PD reduces MPJPE from 60.8mm to 7.5mm and boosts PD severity macro-F1 by 17 percentage points.

Conclusion: CARE-PD demonstrates the value of clinically curated, diverse training data for Parkinson's Disease gait assessment and is publicly available for non-commercial research.

Abstract: Objective gait assessment in Parkinson's Disease (PD) is limited by the
absence of large, diverse, and clinically annotated motion datasets. We
introduce CARE-PD, the largest publicly available archive of 3D mesh gait data
for PD, and the first multi-site collection spanning 9 cohorts from 8 clinical
centers. All recordings (RGB video or motion capture) are converted into
anonymized SMPL meshes via a harmonized preprocessing pipeline. CARE-PD
supports two key benchmarks: supervised clinical score prediction (estimating
Unified Parkinson's Disease Rating Scale, UPDRS, gait scores) and unsupervised
motion pretext tasks (2D-to-3D keypoint lifting and full-body 3D
reconstruction). Clinical prediction is evaluated under four generalization
protocols: within-dataset, cross-dataset, leave-one-dataset-out, and
multi-dataset in-domain adaptation. To assess clinical relevance, we compare
state-of-the-art motion encoders with a traditional gait-feature baseline,
finding that encoders consistently outperform handcrafted features. Pretraining
on CARE-PD reduces MPJPE (from 60.8mm to 7.5mm) and boosts PD severity macro-F1
by 17 percentage points, underscoring the value of clinically curated, diverse
training data. CARE-PD and all benchmark code are released for non-commercial
research at https://neurips2025.care-pd.ca/.

</details>


### [214] [GenAR: Next-Scale Autoregressive Generation for Spatial Gene Expression Prediction](https://arxiv.org/abs/2510.04315)
*Jiarui Ouyang,Yihui Wang,Yihang Gao,Yingxue Xu,Shu Yang,Hao Chen*

Main category: cs.CV

TL;DR: GenAR is a multi-scale autoregressive framework that predicts spatial transcriptomics from H&E images by modeling gene expression as discrete token generation, clustering genes hierarchically, and using fused histological-spatial embeddings.


<details>
  <summary>Details</summary>
Motivation: Spatial Transcriptomics is expensive, while H&E stained images are widely available. Current methods predict genes independently and use continuous regression despite expression being discrete counts, leading to biologically implausible results.

Method: Multi-scale autoregressive framework that clusters genes hierarchically, models expression as discrete token generation without codebooks, and conditions decoding on fused histological and spatial embeddings.

Result: GenAR achieves state-of-the-art performance on four Spatial Transcriptomics datasets across different tissue types.

Conclusion: GenAR provides a cost-effective alternative for molecular profiling with potential implications for precision medicine.

Abstract: Spatial Transcriptomics (ST) offers spatially resolved gene expression but
remains costly. Predicting expression directly from widely available
Hematoxylin and Eosin (H&E) stained images presents a cost-effective
alternative. However, most computational approaches (i) predict each gene
independently, overlooking co-expression structure, and (ii) cast the task as
continuous regression despite expression being discrete counts. This mismatch
can yield biologically implausible outputs and complicate downstream analyses.
We introduce GenAR, a multi-scale autoregressive framework that refines
predictions from coarse to fine. GenAR clusters genes into hierarchical groups
to expose cross-gene dependencies, models expression as codebook-free discrete
token generation to directly predict raw counts, and conditions decoding on
fused histological and spatial embeddings. From an information-theoretic
perspective, the discrete formulation avoids log-induced biases and the
coarse-to-fine factorization aligns with a principled conditional
decomposition. Extensive experimental results on four Spatial Transcriptomics
datasets across different tissue types demonstrate that GenAR achieves
state-of-the-art performance, offering potential implications for precision
medicine and cost-effective molecular profiling. Code is publicly available at
https://github.com/oyjr/genar.

</details>


### [215] [RAP: 3D Rasterization Augmented End-to-End Planning](https://arxiv.org/abs/2510.04333)
*Lan Feng,Yang Gao,Eloi Zablocki,Quanyi Li,Wuyang Li,Sichao Liu,Matthieu Cord,Alexandre Alahi*

Main category: cs.CV

TL;DR: RAP uses lightweight 3D rasterization instead of photorealistic rendering for end-to-end driving training, achieving state-of-the-art performance through semantic fidelity and feature-space alignment.


<details>
  <summary>Details</summary>
Motivation: Imitation learning lacks recovery data for correcting small mistakes, and photorealistic rendering methods are too slow/costly for training. Semantic fidelity (geometry/dynamics) matters more than photorealism for driving.

Method: 3D Rasterization replaces rendering with lightweight rasterization of annotated primitives, enabling counterfactual recovery maneuvers and cross-agent view synthesis. Raster-to-Real feature-space alignment bridges sim-to-real gap.

Result: RAP achieves state-of-the-art closed-loop robustness and long-tail generalization, ranking first on four major benchmarks: NAVSIM v1/v2, Waymo Open Dataset Vision-based E2E Driving, and Bench2Drive.

Conclusion: Lightweight rasterization with feature alignment suffices to scale E2E training, offering a practical alternative to photorealistic rendering for end-to-end driving planners.

Abstract: Imitation learning for end-to-end driving trains policies only on expert
demonstrations. Once deployed in a closed loop, such policies lack recovery
data: small mistakes cannot be corrected and quickly compound into failures. A
promising direction is to generate alternative viewpoints and trajectories
beyond the logged path. Prior work explores photorealistic digital twins via
neural rendering or game engines, but these methods are prohibitively slow and
costly, and thus mainly used for evaluation. In this work, we argue that
photorealism is unnecessary for training end-to-end planners. What matters is
semantic fidelity and scalability: driving depends on geometry and dynamics,
not textures or lighting. Motivated by this, we propose 3D Rasterization, which
replaces costly rendering with lightweight rasterization of annotated
primitives, enabling augmentations such as counterfactual recovery maneuvers
and cross-agent view synthesis. To transfer these synthetic views effectively
to real-world deployment, we introduce a Raster-to-Real feature-space alignment
that bridges the sim-to-real gap. Together, these components form Rasterization
Augmented Planning (RAP), a scalable data augmentation pipeline for planning.
RAP achieves state-of-the-art closed-loop robustness and long-tail
generalization, ranking first on four major benchmarks: NAVSIM v1/v2, Waymo
Open Dataset Vision-based E2E Driving, and Bench2Drive. Our results show that
lightweight rasterization with feature alignment suffices to scale E2E
training, offering a practical alternative to photorealistic rendering. Project
page: https://alan-lanfeng.github.io/RAP/.

</details>


### [216] [Diffusion^2: Dual Diffusion Model with Uncertainty-Aware Adaptive Noise for Momentary Trajectory Prediction](https://arxiv.org/abs/2510.04365)
*Yuhao Luo,Yuang Zhang,Kehua Chen,Xinyu Zheng,Shucheng Zhang,Sikai Chen,Yinhai Wang*

Main category: cs.CV

TL;DR: Diffusion^2 is a novel framework for momentary pedestrian trajectory prediction using two sequential diffusion models - one for backward prediction of unobserved history and another for forward prediction of future trajectories, with uncertainty estimation and adaptive noise modulation.


<details>
  <summary>Details</summary>
Motivation: Real-world scenarios often lack sufficient observational data for trajectory prediction (e.g., pedestrians emerging from blind spots), making accurate prediction challenging and increasing traffic accident risks. Current methods struggle with momentary trajectory prediction.

Method: Two sequentially connected diffusion models: backward diffusion generates unobserved historical trajectories, forward diffusion predicts future trajectories. Includes dual-head parameterization for aleatoric uncertainty estimation and temporally adaptive noise module for dynamic noise scale modulation.

Result: Sets new state-of-the-art performance in momentary trajectory prediction on ETH/UCY and Stanford Drone datasets.

Conclusion: Diffusion^2 effectively addresses the challenging problem of momentary trajectory prediction and demonstrates superior performance compared to existing methods.

Abstract: Accurate pedestrian trajectory prediction is crucial for ensuring safety and
efficiency in autonomous driving and human-robot interaction scenarios. Earlier
studies primarily utilized sufficient observational data to predict future
trajectories. However, in real-world scenarios, such as pedestrians suddenly
emerging from blind spots, sufficient observational data is often unavailable
(i.e. momentary trajectory), making accurate prediction challenging and
increasing the risk of traffic accidents. Therefore, advancing research on
pedestrian trajectory prediction under extreme scenarios is critical for
enhancing traffic safety. In this work, we propose a novel framework termed
Diffusion^2, tailored for momentary trajectory prediction. Diffusion^2 consists
of two sequentially connected diffusion models: one for backward prediction,
which generates unobserved historical trajectories, and the other for forward
prediction, which forecasts future trajectories. Given that the generated
unobserved historical trajectories may introduce additional noise, we propose a
dual-head parameterization mechanism to estimate their aleatoric uncertainty
and design a temporally adaptive noise module that dynamically modulates the
noise scale in the forward diffusion process. Empirically, Diffusion^2 sets a
new state-of-the-art in momentary trajectory prediction on ETH/UCY and Stanford
Drone datasets.

</details>


### [217] [MorphoSim: An Interactive, Controllable, and Editable Language-guided 4D World Simulator](https://arxiv.org/abs/2510.04390)
*Xuehai He,Shijie Zhou,Thivyanth Venkateswaran,Kaizhi Zheng,Ziyu Wan,Achuta Kadambi,Xin Eric Wang*

Main category: cs.CV

TL;DR: MorphoSim is a language-guided framework that generates editable 4D scenes with multi-view consistency and object-level controls for robotics applications.


<details>
  <summary>Details</summary>
Motivation: To create world models that support controllable and editable spatiotemporal environments for robotics, enabling scalable training data, reproducible evaluation, and flexible task design.

Method: Integrates trajectory-guided generation with feature field distillation, allowing interactive edits without full re-generation from natural language instructions.

Result: Produces dynamic environments where objects can be directed, recolored, or removed, and scenes can be observed from arbitrary viewpoints while maintaining high scene fidelity.

Conclusion: MorphoSim enables controllability and editability in 4D scene generation, addressing limitations of existing 2D text-to-video models that offer limited interaction.

Abstract: World models that support controllable
  and editable spatiotemporal environments are valuable
  for robotics, enabling scalable training data, repro ducible evaluation, and
flexible task design. While
  recent text-to-video models generate realistic dynam ics, they are
constrained to 2D views and offer limited
  interaction. We introduce MorphoSim, a language guided framework that
generates 4D scenes with
  multi-view consistency and object-level controls. From
  natural language instructions, MorphoSim produces
  dynamic environments where objects can be directed,
  recolored, or removed, and scenes can be observed
  from arbitrary viewpoints. The framework integrates
  trajectory-guided generation with feature field dis tillation, allowing edits
to be applied interactively
  without full re-generation. Experiments show that Mor phoSim maintains high
scene fidelity while enabling
  controllability and editability. The code is available
  at https://github.com/eric-ai-lab/Morph4D.

</details>


### [218] [Your Vision-Language Model Can't Even Count to 20: Exposing the Failures of VLMs in Compositional Counting](https://arxiv.org/abs/2510.04401)
*Xuyang Guo,Zekai Huang,Zhenmei Shi,Zhao Song,Jiahao Zhang*

Main category: cs.CV

TL;DR: VLMs struggle with compositional counting of multiple shape types despite performing well with single shapes, revealing a fundamental limitation in current models.


<details>
  <summary>Details</summary>
Motivation: To investigate whether Vision-Language Models (VLMs) can count objects correctly, particularly in compositional scenarios with multiple shape types.

Method: Created VLMCountBench benchmark using basic geometric shapes (triangles, circles) in minimalist settings with strict variable control for color, size, and prompt refinement.

Result: VLMs count reliably with single shape types but show substantial failures in compositional counting when multiple shape types are combined.

Conclusion: Current VLMs have a fundamental empirical limitation in compositional counting, motivating important directions for future research.

Abstract: Vision-Language Models (VLMs) have become a central focus of today's AI
community, owing to their impressive abilities gained from training on
large-scale vision-language data from the Web. These models have demonstrated
strong performance across diverse tasks, including image understanding, video
understanding, complex visual reasoning, and embodied AI. Despite these
noteworthy successes, a fundamental question remains: Can VLMs count objects
correctly? In this paper, we introduce a simple yet effective benchmark,
VLMCountBench, designed under a minimalist setting with only basic geometric
shapes (e.g., triangles, circles) and their compositions, focusing exclusively
on counting tasks without interference from other factors. We adopt strict
independent variable control and systematically study the effects of simple
properties such as color, size, and prompt refinement in a controlled ablation.
Our empirical results reveal that while VLMs can count reliably when only one
shape type is present, they exhibit substantial failures when multiple shape
types are combined (i.e., compositional counting). This highlights a
fundamental empirical limitation of current VLMs and motivates important
directions for future research.

</details>


### [219] [CodeFormer++: Blind Face Restoration Using Deformable Registration and Deep Metric Learning](https://arxiv.org/abs/2510.04410)
*Venkata Bharath Reddy Reddem,Akshay P Sarashetti,Ranjith Merugu,Amit Satish Unde*

Main category: cs.CV

TL;DR: CodeFormer++ is a novel blind face restoration framework that addresses the trade-off between visual quality and identity preservation by decomposing the problem into three sub-tasks and introducing deformable face registration, texture-guided restoration, and deep metric learning.


<details>
  <summary>Details</summary>
Motivation: Existing blind face restoration methods using generative priors often suffer from a trade-off between visual quality and identity fidelity, leading to either identity distortion or suboptimal degradation removal.

Method: Decomposes BFR into three sub-tasks: identity-preserving restoration, high-quality generation, and dynamic fusion. Uses learning-based deformable face registration for semantic alignment, texture-guided restoration network for quality enhancement, and deep metric learning with informative samples for better feature fusion.

Result: Extensive experiments on real-world and synthetic datasets demonstrate superior performance in both visual fidelity and identity consistency compared to existing methods.

Conclusion: CodeFormer++ effectively maximizes the utility of generative priors for high-quality face restoration while preserving identity, achieving a better balance between visual quality and identity fidelity.

Abstract: Blind face restoration (BFR) has attracted increasing attention with the rise
of generative methods. Most existing approaches integrate generative priors
into the restoration pro- cess, aiming to jointly address facial detail
generation and identity preservation. However, these methods often suffer from
a trade-off between visual quality and identity fidelity, leading to either
identity distortion or suboptimal degradation removal. In this paper, we
present CodeFormer++, a novel framework that maximizes the utility of
generative priors for high-quality face restoration while preserving identity.
We decompose BFR into three sub-tasks: (i) identity- preserving face
restoration, (ii) high-quality face generation, and (iii) dynamic fusion of
identity features with realistic texture details. Our method makes three key
contributions: (1) a learning-based deformable face registration module that
semantically aligns generated and restored faces; (2) a texture guided
restoration network to dynamically extract and transfer the texture of
generated face to boost the quality of identity-preserving restored face; and
(3) the integration of deep metric learning for BFR with the generation of
informative positive and hard negative samples to better fuse identity-
preserving and generative features. Extensive experiments on real-world and
synthetic datasets demonstrate that, the pro- posed CodeFormer++ achieves
superior performance in terms of both visual fidelity and identity consistency.

</details>


### [220] [A.I.R.: Enabling Adaptive, Iterative, and Reasoning-based Frame Selection For Video Question Answering](https://arxiv.org/abs/2510.04428)
*Yuanhao Zou,Shengji Jin,Andong Deng,Youpeng Zhao,Jun Wang,Chen Chen*

Main category: cs.CV

TL;DR: A.I.R. is a training-free approach for adaptive, iterative, and reasoning-based frame selection in VideoQA that balances accuracy and computational efficiency by using a powerful VLM for deep semantic analysis in a cost-effective iterative loop.


<details>
  <summary>Details</summary>
Motivation: Current frame selection methods for VideoQA face a critical trade-off: lightweight similarity models (like CLIP) fail to capture complex query nuances, while VLM-based methods achieve higher accuracy but are computationally prohibitive.

Method: Proposes A.I.R. - a training-free approach that leverages a powerful VLM to perform deep semantic analysis on complex queries within a cost-effective iterative loop that processes only small batches of high-potential frames at a time.

Result: Extensive experiments show A.I.R. outperforms existing frame selection methods, significantly boosts foundation VLM performance, and achieves substantial computational efficiency gains over other VLM-based techniques.

Conclusion: A.I.R. effectively addresses the accuracy-efficiency trade-off in VideoQA frame selection by combining deep semantic analysis with an adaptive iterative processing strategy.

Abstract: Effectively applying Vision-Language Models (VLMs) to Video Question
Answering (VideoQA) hinges on selecting a concise yet comprehensive set of
frames, as processing entire videos is computationally infeasible. However,
current frame selection methods face a critical trade-off: approaches relying
on lightweight similarity models, such as CLIP, often fail to capture the
nuances of complex queries, resulting in inaccurate similarity scores that
cannot reflect the authentic query-frame relevance, which further undermines
frame selection. Meanwhile, methods that leverage a VLM for deeper analysis
achieve higher accuracy but incur prohibitive computational costs. To address
these limitations, we propose A.I.R., a training-free approach for Adaptive,
Iterative, and Reasoning-based frame selection. We leverage a powerful VLM to
perform deep, semantic analysis on complex queries, and this analysis is
deployed within a cost-effective iterative loop that processes only a small
batch of the most high-potential frames at a time. Extensive experiments on
various VideoQA benchmarks demonstrate that our approach outperforms existing
frame selection methods, significantly boosts the performance of the foundation
VLM, and achieves substantial gains in computational efficiency over other
VLM-based techniques.

</details>


### [221] [REAR: Rethinking Visual Autoregressive Models via Generator-Tokenizer Consistency Regularization](https://arxiv.org/abs/2510.04450)
*Qiyuan He,Yicong Li,Haotian Ye,Jinghao Wang,Xinyao Liao,Pheng-Ann Heng,Stefano Ermon,James Zou,Angela Yao*

Main category: cs.CV

TL;DR: reAR is a simple training strategy that improves visual autoregressive generation by addressing generator-tokenizer inconsistency through token-wise regularization, achieving performance comparable to larger diffusion models.


<details>
  <summary>Details</summary>
Motivation: Visual autoregressive generation underperforms compared to diffusion models, with prior work attributing this to tokenizer limitations and rasterization ordering. The core bottleneck is identified as generator-tokenizer inconsistency - AR-generated tokens may not be well-decoded by the tokenizer.

Method: Proposes reAR training strategy with token-wise regularization: when predicting next token, the causal transformer is also trained to recover visual embedding of current token and predict embedding of target token under noisy context. No changes needed to tokenizer, generation order, inference pipeline, or external models.

Result: Substantial performance improvements: On ImageNet, reduces gFID from 3.02 to 1.86 and improves IS to 316.9 with standard rasterization-based tokenizer. With advanced tokenizers, achieves gFID of 1.42 with only 177M parameters, matching performance of larger state-of-the-art diffusion models (675M).

Conclusion: reAR effectively addresses generator-tokenizer inconsistency in visual autoregressive generation through simple token-wise regularization, achieving competitive performance with diffusion models while maintaining simplicity and requiring no architectural changes.

Abstract: Visual autoregressive (AR) generation offers a promising path toward unifying
vision and language models, yet its performance remains suboptimal against
diffusion models. Prior work often attributes this gap to tokenizer limitations
and rasterization ordering. In this work, we identify a core bottleneck from
the perspective of generator-tokenizer inconsistency, i.e., the AR-generated
tokens may not be well-decoded by the tokenizer. To address this, we propose
reAR, a simple training strategy introducing a token-wise regularization
objective: when predicting the next token, the causal transformer is also
trained to recover the visual embedding of the current token and predict the
embedding of the target token under a noisy context. It requires no changes to
the tokenizer, generation order, inference pipeline, or external models.
Despite its simplicity, reAR substantially improves performance. On ImageNet,
it reduces gFID from 3.02 to 1.86 and improves IS to 316.9 using a standard
rasterization-based tokenizer. When applied to advanced tokenizers, it achieves
a gFID of 1.42 with only 177M parameters, matching the performance with larger
state-of-the-art diffusion models (675M).

</details>


### [222] [SPEGNet: Synergistic Perception-Guided Network for Camouflaged Object Detection](https://arxiv.org/abs/2510.04472)
*Baber Jan,Saeed Anwar,Aiman H. El-Maleh,Abdul Jabbar Siddiqui,Abdul Bais*

Main category: cs.CV

TL;DR: SPEGNet introduces a unified architecture for camouflaged object detection that avoids component accumulation, using channel calibration and spatial enhancement to maintain boundary precision and regional consistency across scales.


<details>
  <summary>Details</summary>
Motivation: Current camouflaged object detection methods accumulate complex components (boundary modules, attention mechanisms, multi-scale processors) which create computational burden and force processing at reduced resolutions, eliminating fine details essential for camouflage detection.

Method: SPEGNet integrates multi-scale features via channel calibration and spatial enhancement, with boundaries emerging directly from context-rich representations. It uses progressive refinement with scale-adaptive edge modulation that peaks at intermediate resolutions.

Result: SPEGNet achieves 0.887 S_α on CAMO, 0.890 on COD10K, and 0.895 on NC4K datasets with real-time inference speed. It excels across scales from tiny intricate objects to large pattern-similar ones while handling occlusion and ambiguous boundaries.

Conclusion: The unified design of SPEGNet effectively addresses fragmentation in camouflaged object detection, balancing boundary precision and regional consistency without the computational burden of accumulated components, achieving state-of-the-art performance with efficient inference.

Abstract: Camouflaged object detection segments objects with intrinsic similarity and
edge disruption. Current detection methods rely on accumulated complex
components. Each approach adds components such as boundary modules, attention
mechanisms, and multi-scale processors independently. This accumulation creates
a computational burden without proportional gains. To manage this complexity,
they process at reduced resolutions, eliminating fine details essential for
camouflage. We present SPEGNet, addressing fragmentation through a unified
design. The architecture integrates multi-scale features via channel
calibration and spatial enhancement. Boundaries emerge directly from
context-rich representations, maintaining semantic-spatial alignment.
Progressive refinement implements scale-adaptive edge modulation with peak
influence at intermediate resolutions. This design strikes a balance between
boundary precision and regional consistency. SPEGNet achieves 0.887 $S_\alpha$
on CAMO, 0.890 on COD10K, and 0.895 on NC4K, with real-time inference speed.
Our approach excels across scales, from tiny, intricate objects to large,
pattern-similar ones, while handling occlusion and ambiguous boundaries. Code,
model weights, and results are available on
\href{https://github.com/Baber-Jan/SPEGNet}{https://github.com/Baber-Jan/SPEGNet}.

</details>


### [223] [MedCLM: Learning to Localize and Reason via a CoT-Curriculum in Medical Vision-Language Models](https://arxiv.org/abs/2510.04477)
*Soo Yong Kim,Suin Cho,Vincent-Daniel Yun,Gyeongyeon Hwang*

Main category: cs.CV

TL;DR: MedCLM is an automated pipeline that converts detection datasets into medical VQA data with Chain-of-Thought reasoning, using an Integrated CoT-Curriculum Strategy to achieve state-of-the-art performance on medical VQA benchmarks.


<details>
  <summary>Details</summary>
Motivation: Bridging clinical diagnostic reasoning with AI remains a central challenge in medical imaging, requiring systems that can provide step-by-step reasoning similar to human clinicians.

Method: Automated pipeline converts detection datasets into medical VQA data with Chain-of-Thought reasoning by linking lesion boxes to organ segmentation and structured rationales. Uses an Integrated CoT-Curriculum Strategy with three stages: Easy (explicit lesion boxes), Medium (implicit localization), and Hard (weakly supervised reasoning).

Result: MedCLM attains state-of-the-art performance on several medical VQA benchmarks, demonstrating superior reasoning capabilities.

Conclusion: Provides a scalable framework for developing clinically aligned medical vision-language models that can generate question-answer pairs with step-by-step reasoning.

Abstract: Bridging clinical diagnostic reasoning with AI remains a central challenge in
medical imaging. We introduce MedCLM, an automated pipeline that converts
detection datasets into large-scale medical visual question answering (VQA)
data with Chain-of-Thought (CoT) reasoning by linking lesion boxes to organ
segmentation and structured rationales. These contextual signals enable medical
vision-language models to generate question-answer pairs with step-by-step
reasoning. To utilize this data effectively, we propose an Integrated
CoT-Curriculum Strategy composed of an Easy stage with explicit lesion boxes
for visual grounding, a Medium stage that encourages implicit localization, and
a Hard stage for weakly supervised reasoning. Experimental results demonstrate
that MedCLM attains state-of-the-art performance on several medical VQA
benchmarks, providing a scalable framework for developing clinically aligned
medical vision-language models.

</details>


### [224] [VaseVQA-3D: Benchmarking 3D VLMs on Ancient Greek Pottery](https://arxiv.org/abs/2510.04479)
*Nonghai Zhang,Zeyu Zhang,Jiazi Wang,Yang Zhao,Hao Tang*

Main category: cs.CV

TL;DR: The paper introduces VaseVQA-3D, the first 3D visual question answering dataset for ancient Greek pottery analysis, and proposes VaseVLM model to address data scarcity and domain knowledge limitations in cultural heritage applications of vision-language models.


<details>
  <summary>Details</summary>
Motivation: Existing Vision-Language Models face severe data scarcity and insufficient domain knowledge when dealing with specialized cultural heritage domains like 3D vase artifacts, struggling to handle culturally significant specialized tasks due to lack of targeted training data.

Method: Proposed VaseVQA-3D dataset with 664 ancient Greek vase 3D models and corresponding question-answer data, establishing a complete data construction pipeline. Developed VaseVLM model with domain-adaptive training to enhance performance in vase artifact analysis.

Result: Experimental results show improvements of 12.8% on R@1 metrics and 6.6% on lexical similarity compared with previous state-of-the-art methods on the VaseVQA-3D dataset.

Conclusion: The approach significantly improves recognition and understanding of 3D vase artifacts, providing new technical pathways for digital heritage preservation research.

Abstract: Vision-Language Models (VLMs) have achieved significant progress in
multimodal understanding tasks, demonstrating strong capabilities particularly
in general tasks such as image captioning and visual reasoning. However, when
dealing with specialized cultural heritage domains like 3D vase artifacts,
existing models face severe data scarcity issues and insufficient domain
knowledge limitations. Due to the lack of targeted training data, current VLMs
struggle to effectively handle such culturally significant specialized tasks.
To address these challenges, we propose the VaseVQA-3D dataset, which serves as
the first 3D visual question answering dataset for ancient Greek pottery
analysis, collecting 664 ancient Greek vase 3D models with corresponding
question-answer data and establishing a complete data construction pipeline. We
further develop the VaseVLM model, enhancing model performance in vase artifact
analysis through domain-adaptive training. Experimental results validate the
effectiveness of our approach, where we improve by 12.8% on R@1 metrics and by
6.6% on lexical similarity compared with previous state-of-the-art on the
VaseVQA-3D dataset, significantly improving the recognition and understanding
of 3D vase artifacts, providing new technical pathways for digital heritage
preservation research.

</details>


### [225] [TBStar-Edit: From Image Editing Pattern Shifting to Consistency Enhancement](https://arxiv.org/abs/2510.04483)
*Hao Fang,Zechao Zhan,Weixin Feng,Ziwei Huang,XuBin Li,Tiezheng Ge*

Main category: cs.CV

TL;DR: TBStar-Edit is a specialized image editing model for e-commerce that addresses consistency limitations of general models through hierarchical architecture and two-stage training, achieving superior performance in product image editing.


<details>
  <summary>Details</summary>
Motivation: General image editing models perform well in general domains but struggle with consistency in e-commerce scenarios where maintaining product appearance and layout integrity is crucial.

Method: Three-pronged approach: 1) Comprehensive data pipeline for high-quality instruction-following data, 2) Hierarchical model framework with base model, pattern shifting modules, and consistency enhancement modules, 3) Two-stage training strategy (pattern shifting then consistency enhancement) with separate datasets.

Result: TBStar-Edit outperforms existing general-domain editing models on both objective metrics (VIE Score) and subjective user preference in e-commerce benchmark evaluations.

Conclusion: The specialized approach combining rigorous data engineering, hierarchical architecture design, and staged training strategy effectively addresses e-commerce image editing challenges and achieves superior consistency preservation compared to general models.

Abstract: Recent advances in image generation and editing technologies have enabled
state-of-the-art models to achieve impressive results in general domains.
However, when applied to e-commerce scenarios, these general models often
encounter consistency limitations. To address this challenge, we introduce
TBStar-Edit, an new image editing model tailored for the e-commerce domain.
Through rigorous data engineering, model architecture design and training
strategy, TBStar-Edit achieves precise and high-fidelity image editing while
maintaining the integrity of product appearance and layout. Specifically, for
data engineering, we establish a comprehensive data construction pipeline,
encompassing data collection, construction, filtering, and augmentation, to
acquire high-quality, instruction-following, and strongly consistent editing
data to support model training. For model architecture design, we design a
hierarchical model framework consisting of a base model, pattern shifting
modules, and consistency enhancement modules. For model training, we adopt a
two-stage training strategy to enhance the consistency preservation: first
stage for editing pattern shifting, and second stage for consistency
enhancement. Each stage involves training different modules with separate
datasets. Finally, we conduct extensive evaluations of TBStar-Edit on a
self-proposed e-commerce benchmark, and the results demonstrate that
TBStar-Edit outperforms existing general-domain editing models in both
objective metrics (VIE Score) and subjective user preference.

</details>


### [226] [Asynchronous Denoising Diffusion Models for Aligning Text-to-Image Generation](https://arxiv.org/abs/2510.04504)
*Zijing Hu,Yunze Tong,Fengda Zhang,Junkun Yuan,Jun Xiao,Kun Kuang*

Main category: cs.CV

TL;DR: Proposes asynchronous diffusion models that allocate different timesteps to different pixels, allowing prompt-related regions to denoise more gradually and leverage clearer context, significantly improving text-to-image alignment.


<details>
  <summary>Details</summary>
Motivation: Standard diffusion models struggle with faithful alignment between generated images and input prompts due to synchronous denoising, where all pixels evolve simultaneously from noise, preventing prompt-related regions from obtaining clear context.

Method: Asynchronous diffusion framework that dynamically modulates timestep schedules for individual pixels, allowing prompt-related regions to denoise more gradually than unrelated regions and leverage clearer inter-pixel context.

Result: Extensive experiments show significant improvement in text-to-image alignment across diverse prompts compared to standard synchronous diffusion models.

Conclusion: Asynchronous diffusion models effectively address the text-to-image alignment limitation of standard diffusion models by enabling prompt-related regions to reference clearer context during denoising.

Abstract: Diffusion models have achieved impressive results in generating high-quality
images. Yet, they often struggle to faithfully align the generated images with
the input prompts. This limitation arises from synchronous denoising, where all
pixels simultaneously evolve from random noise to clear images. As a result,
during generation, the prompt-related regions can only reference the unrelated
regions at the same noise level, failing to obtain clear context and ultimately
impairing text-to-image alignment. To address this issue, we propose
asynchronous diffusion models -- a novel framework that allocates distinct
timesteps to different pixels and reformulates the pixel-wise denoising
process. By dynamically modulating the timestep schedules of individual pixels,
prompt-related regions are denoised more gradually than unrelated regions,
thereby allowing them to leverage clearer inter-pixel context. Consequently,
these prompt-related regions achieve better alignment in the final images.
Extensive experiments demonstrate that our asynchronous diffusion models can
significantly improve text-to-image alignment across diverse prompts. The code
repository for this work is available at https://github.com/hu-zijing/AsynDM.

</details>


### [227] [TAG:Tangential Amplifying Guidance for Hallucination-Resistant Diffusion Sampling](https://arxiv.org/abs/2510.04533)
*Hyunmin Cho,Donghoon Ahn,Susung Hong,Jee Eun Kim,Seungryong Kim,Kyong Hwan Jin*

Main category: cs.CV

TL;DR: TAG is an efficient guidance method that amplifies tangential components of diffusion model scores to correct sampling trajectories and reduce semantic inconsistencies, without modifying the underlying model.


<details>
  <summary>Details</summary>
Motivation: Current diffusion models suffer from semantic inconsistencies and hallucinations, and existing guidance methods often require external signals or architectural modifications with computational overhead.

Method: TAG uses an intermediate sample as projection basis and amplifies tangential components of estimated scores to steer sampling trajectory toward higher-probability regions, based on first-order Taylor expansion.

Result: TAG improves diffusion sampling fidelity with minimal computational addition, operating as a plug-and-play module without modifying the underlying diffusion model.

Conclusion: TAG offers an efficient, architecture-agnostic guidance approach that enhances sample quality by directly manipulating trajectory signals, providing a new perspective on diffusion guidance.

Abstract: Recent diffusion models achieve the state-of-the-art performance in image
generation, but often suffer from semantic inconsistencies or hallucinations.
While various inference-time guidance methods can enhance generation, they
often operate indirectly by relying on external signals or architectural
modifications, which introduces additional computational overhead. In this
paper, we propose Tangential Amplifying Guidance (TAG), a more efficient and
direct guidance method that operates solely on trajectory signals without
modifying the underlying diffusion model. TAG leverages an intermediate sample
as a projection basis and amplifies the tangential components of the estimated
scores with respect to this basis to correct the sampling trajectory. We
formalize this guidance process by leveraging a first-order Taylor expansion,
which demonstrates that amplifying the tangential component steers the state
toward higher-probability regions, thereby reducing inconsistencies and
enhancing sample quality. TAG is a plug-and-play, architecture-agnostic module
that improves diffusion sampling fidelity with minimal computational addition,
offering a new perspective on diffusion guidance.

</details>


### [228] [Conditional Representation Learning for Customized Tasks](https://arxiv.org/abs/2510.04564)
*Honglin Liu,Chao Sun,Peng Hu,Yunfan Li,Xi Peng*

Main category: cs.CV

TL;DR: CRL enables customized representation learning by using LLM-generated descriptive texts to construct semantic basis for arbitrary user criteria, then projecting image representations into this conditional feature space using VLM.


<details>
  <summary>Details</summary>
Motivation: Universal representations often prioritize dominant semantics that may not align with specific downstream tasks, while supervised fine-tuning is computationally expensive and requires heavy annotation.

Method: Use LLM to generate descriptive texts for user criteria to construct semantic basis, then project image representations into this conditional feature space using VLM.

Result: Extensive experiments on classification and retrieval tasks demonstrate superiority and generality of CRL over conventional approaches.

Conclusion: CRL provides an effective solution for extracting task-specific representations without expensive fine-tuning, enabling better performance on customized downstream tasks.

Abstract: Conventional representation learning methods learn a universal representation
that primarily captures dominant semantics, which may not always align with
customized downstream tasks. For instance, in animal habitat analysis,
researchers prioritize scene-related features, whereas universal embeddings
emphasize categorical semantics, leading to suboptimal results. As a solution,
existing approaches resort to supervised fine-tuning, which however incurs high
computational and annotation costs. In this paper, we propose Conditional
Representation Learning (CRL), aiming to extract representations tailored to
arbitrary user-specified criteria. Specifically, we reveal that the semantics
of a space are determined by its basis, thereby enabling a set of descriptive
words to approximate the basis for a customized feature space. Building upon
this insight, given a user-specified criterion, CRL first employs a large
language model (LLM) to generate descriptive texts to construct the semantic
basis, then projects the image representation into this conditional feature
space leveraging a vision-language model (VLM). The conditional representation
better captures semantics for the specific criterion, which could be utilized
for multiple customized tasks. Extensive experiments on classification and
retrieval tasks demonstrate the superiority and generality of the proposed CRL.
The code is available at https://github.com/XLearning-SCU/2025-NeurIPS-CRL.

</details>


### [229] [Pathology-CoT: Learning Visual Chain-of-Thought Agent from Expert Whole Slide Image Diagnosis Behavior](https://arxiv.org/abs/2510.04587)
*Sheng Wang,Ruiming Wu,Charles Herndon,Yihang Liu,Shunsuke Koga,Jeanne Shen,Zhi Huang*

Main category: cs.CV

TL;DR: The paper introduces AI Session Recorder to capture pathologists' viewing behavior from WSI viewers, creates Pathology-CoT dataset, and builds Pathologist-o3 agent that outperforms state-of-the-art models in metastasis detection.


<details>
  <summary>Details</summary>
Motivation: Current pathology foundation models lack practical agentic systems that can decide what to examine next, adjust magnification, and provide explainable diagnoses due to absence of scalable, clinically aligned supervision of expert viewing behavior.

Method: AI Session Recorder captures routine navigation from standard WSI viewers, converts logs into behavioral commands, and uses human-in-the-loop review to create Pathology-CoT dataset. Pathologist-o3 agent uses this behavioral data for two-stage reasoning.

Result: Pathologist-o3 achieved 84.5% precision, 100.0% recall, and 75.4% accuracy in gastrointestinal lymph-node metastasis detection, exceeding OpenAI o3 model and generalizing across backbones.

Conclusion: The framework makes agentic pathology practical by turning viewer logs into scalable supervision, establishing a path to human-aligned, upgradeable clinical AI.

Abstract: Diagnosing a whole-slide image is an interactive, multi-stage process
involving changes in magnification and movement between fields. Although recent
pathology foundation models are strong, practical agentic systems that decide
what field to examine next, adjust magnification, and deliver explainable
diagnoses are still lacking. The blocker is data: scalable, clinically aligned
supervision of expert viewing behavior that is tacit and experience-based, not
written in textbooks or online, and therefore absent from large language model
training. We introduce the AI Session Recorder, which works with standard WSI
viewers to unobtrusively record routine navigation and convert the viewer logs
into standardized behavioral commands (inspect or peek at discrete
magnifications) and bounding boxes. A lightweight human-in-the-loop review
turns AI-drafted rationales into the Pathology-CoT dataset, a form of paired
"where to look" and "why it matters" supervision produced at roughly six times
lower labeling time. Using this behavioral data, we build Pathologist-o3, a
two-stage agent that first proposes regions of interest and then performs
behavior-guided reasoning. On gastrointestinal lymph-node metastasis detection,
it achieved 84.5% precision, 100.0% recall, and 75.4% accuracy, exceeding the
state-of-the-art OpenAI o3 model and generalizing across backbones. To our
knowledge, this constitutes one of the first behavior-grounded agentic systems
in pathology. Turning everyday viewer logs into scalable, expert-validated
supervision, our framework makes agentic pathology practical and establishes a
path to human-aligned, upgradeable clinical AI.

</details>


### [230] [A Spatial-Spectral-Frequency Interactive Network for Multimodal Remote Sensing Classification](https://arxiv.org/abs/2510.04628)
*Hao Liu,Yunhao Gao,Wei Li,Mingyang Zhang,Maoguo Gong,Lorenzo Bruzzone*

Main category: cs.CV

TL;DR: S^2Fin is a spatial-spectral-frequency interaction network that integrates frequency domain learning with multimodal remote sensing image classification, using high-frequency sparse enhancement and fusion strategies to improve feature extraction from heterogeneous data.


<details>
  <summary>Details</summary>
Motivation: Existing feature fusion techniques struggle to extract structural and detail features from heterogeneous and redundant multimodal remote sensing images, motivating the introduction of frequency domain learning to model key and sparse detail features.

Method: Proposes spatial-spectral-frequency interaction network with high-frequency sparse enhancement transformer, two-level spatial-frequency fusion strategy (adaptive frequency channel module and high-frequency resonance mask), and spatial-spectral attention fusion module.

Result: Experiments on four benchmark multimodal datasets with limited labeled data demonstrate superior classification performance, outperforming state-of-the-art methods.

Conclusion: S^2Fin effectively integrates frequency domain learning with multimodal remote sensing analysis, achieving improved classification through enhanced feature extraction from spatial, spectral, and frequency domains.

Abstract: Deep learning-based methods have achieved significant success in remote
sensing Earth observation data analysis. Numerous feature fusion techniques
address multimodal remote sensing image classification by integrating global
and local features. However, these techniques often struggle to extract
structural and detail features from heterogeneous and redundant multimodal
images. With the goal of introducing frequency domain learning to model key and
sparse detail features, this paper introduces the spatial-spectral-frequency
interaction network (S$^2$Fin), which integrates pairwise fusion modules across
the spatial, spectral, and frequency domains. Specifically, we propose a
high-frequency sparse enhancement transformer that employs sparse
spatial-spectral attention to optimize the parameters of the high-frequency
filter. Subsequently, a two-level spatial-frequency fusion strategy is
introduced, comprising an adaptive frequency channel module that fuses
low-frequency structures with enhanced high-frequency details, and a
high-frequency resonance mask that emphasizes sharp edges via phase similarity.
In addition, a spatial-spectral attention fusion module further enhances
feature extraction at intermediate layers of the network. Experiments on four
benchmark multimodal datasets with limited labeled data demonstrate that
S$^2$Fin performs superior classification, outperforming state-of-the-art
methods. The code is available at https://github.com/HaoLiu-XDU/SSFin.

</details>


### [231] [SFANet: Spatial-Frequency Attention Network for Deepfake Detection](https://arxiv.org/abs/2510.04630)
*Vrushank Ahire,Aniruddh Muley,Shivam Zample,Siddharth Verma,Pranav Menon,Surbhi Madan,Abhinav Dhall*

Main category: cs.CV

TL;DR: A novel ensemble framework combining transformers and texture-based methods achieves state-of-the-art deepfake detection performance on diverse datasets.


<details>
  <summary>Details</summary>
Motivation: Address the pressing issue of manipulated media detection, as existing approaches fail to generalize across diverse datasets and generation techniques.

Method: Ensemble framework combining Swin Transformers and ViTs with texture-based methods, using data-splitting, sequential training, frequency splitting, patch-based attention, and face segmentation techniques.

Result: Achieves state-of-the-art performance on DFWild-Cup dataset (diverse subset of eight deepfake datasets), with transformers excelling in global features and texture methods providing interpretability.

Conclusion: Hybrid models can effectively address evolving deepfake detection challenges, offering robust solutions for real-world applications.

Abstract: Detecting manipulated media has now become a pressing issue with the recent
rise of deepfakes. Most existing approaches fail to generalize across diverse
datasets and generation techniques. We thus propose a novel ensemble framework,
combining the strengths of transformer-based architectures, such as Swin
Transformers and ViTs, and texture-based methods, to achieve better detection
accuracy and robustness. Our method introduces innovative data-splitting,
sequential training, frequency splitting, patch-based attention, and face
segmentation techniques to handle dataset imbalances, enhance high-impact
regions (e.g., eyes and mouth), and improve generalization. Our model achieves
state-of-the-art performance when tested on the DFWild-Cup dataset, a diverse
subset of eight deepfake datasets. The ensemble benefits from the
complementarity of these approaches, with transformers excelling in global
feature extraction and texturebased methods providing interpretability. This
work demonstrates that hybrid models can effectively address the evolving
challenges of deepfake detection, offering a robust solution for real-world
applications.

</details>


### [232] [Do Superpixel Segmentation Methods Influence Deforestation Image Classification?](https://arxiv.org/abs/2510.04645)
*Hugo Resende,Fabio A. Faria,Eduardo B. Neto,Isabela Borlido,Victor Sundermann,Silvio Jamil F. Guimarães,Álvaro L. Fazenda*

Main category: cs.CV

TL;DR: This study compares five segmentation methods (including SLIC) for deforestation detection in the ForestEyes project, finding that classifier ensembles significantly improve performance despite minimal differences between individual segmentation methods.


<details>
  <summary>Details</summary>
Motivation: To investigate whether newer superpixel-based segmentation methods outperform traditional SLIC for deforestation detection in citizen science projects, as recent studies suggest better alternatives exist for remote sensing applications.

Method: Compared four top-performing segmentation methods plus SLIC, used PyCaret AutoML library to select top five classifiers, and applied classifier fusion (ensemble) approach to combine models.

Result: Initial results showed little performance variation among segmentation methods with individual classifiers, but classifier fusion approach demonstrated noticeable improvements in balanced accuracy.

Conclusion: Both segmentation method choice and classifier combination are important for deforestation detection, with ensemble methods providing significant performance gains despite minimal differences between segmentation algorithms.

Abstract: Image segmentation is a crucial step in various visual applications,
including environmental monitoring through remote sensing. In the context of
the ForestEyes project, which combines citizen science and machine learning to
detect deforestation in tropical forests, image segments are used for labeling
by volunteers and subsequent model training. Traditionally, the Simple Linear
Iterative Clustering (SLIC) algorithm is adopted as the segmentation method.
However, recent studies have indicated that other superpixel-based methods
outperform SLIC in remote sensing image segmentation, and might suggest that
they are more suitable for the task of detecting deforested areas. In this
sense, this study investigated the impact of the four best segmentation
methods, together with SLIC, on the training of classifiers for the target
application. Initially, the results showed little variation in performance
among segmentation methods, even when selecting the top five classifiers using
the PyCaret AutoML library. However, by applying a classifier fusion approach
(ensemble of classifiers), noticeable improvements in balanced accuracy were
observed, highlighting the importance of both the choice of segmentation method
and the combination of machine learning-based models for deforestation
detection tasks.

</details>


### [233] [EduPersona: Benchmarking Subjective Ability Boundaries of Virtual Student Agents](https://arxiv.org/abs/2510.04648)
*Buyuan Zhu,Shiyu Hu,Yiping Ma,Yuanming Zhang,Kang Hao Cheong*

Main category: cs.CV

TL;DR: EduPersona is a large-scale benchmark for evaluating subjective abilities of AI student agents in classroom simulations, featuring multi-language, multi-subject coverage with persona stylization based on Big Five theory.


<details>
  <summary>Details</summary>
Motivation: As LLMs are increasingly used in education, there's a need to assess their classroom-oriented subjective abilities to understand model boundaries and enable trustworthy deployment in educational settings.

Method: Created EduPersona benchmark with 1,308 authentic classroom dialogues expanded to 128k turns through persona stylization. Decomposed subjective performance into three progressive tasks: basic coherence, student realism, and long-term persona consistency. Evaluated three LLMs and their persona-fine-tuned variants.

Result: Persona-fine-tuned models showed significant improvements: +33.6% in basic coherence, +30.6% in student realism, and +14.9% in long-term persona consistency, demonstrating the dataset's effectiveness.

Conclusion: EduPersona provides the first classroom benchmark for subjective abilities, establishes a decoupled research paradigm, and will be open-sourced to advance trustworthy AI for education.

Abstract: As large language models are increasingly integrated into education, virtual
student agents are becoming vital for classroom simulation and teacher
training. Yet their classroom-oriented subjective abilities remain largely
unassessed, limiting understanding of model boundaries and hindering
trustworthy deployment. We present EduPersona, a large-scale benchmark spanning
two languages, three subjects, and ten persona types based on the Big Five
theory. The dataset contains 1,308 authentic classroom dialogue rounds,
corresponding to 12,814 teacher-student Q&A turns, and is further expanded
through persona stylization into roughly 10 times larger scale (128k turns),
providing a solid foundation for evaluation. Building on this resource, we
decompose hard-to-quantify subjective performance into three progressive tasks:
TASK1 basic coherence (whether behavior, emotion, expression, and voice align
with classroom context), TASK2 student realism, and TASK3 long-term persona
consistency, thereby establishing an evaluation framework grounded in
educational theory and research value. We conduct systematic experiments on
three representative LLMs, comparing their original versions with ten
persona-fine-tuned variants trained on EduPersona. Results show consistent and
significant average improvements across all tasks: TASK1 +33.6%, TASK2 +30.6%,
and TASK3 +14.9%. These improvements highlight the dataset's effectiveness and
research value, while also revealing the heterogeneous difficulty of persona
modeling. In summary, EduPersona delivers the first classroom benchmark
centered on subjective abilities, establishes a decoupled and verifiable
research paradigm, and we will open-source both the dataset and the framework
to support the broader research community in advancing trustworthy and
human-like AI for education.

</details>


### [234] [MoME: Estimating Psychological Traits from Gait with Multi-Stage Mixture of Movement Experts](https://arxiv.org/abs/2510.04654)
*Andy Cǎtrunǎ,Adrian Cosma,Emilian Rǎdoi*

Main category: cs.CV

TL;DR: A hierarchical Multi-Stage Mixture of Movement Experts (MoME) architecture for predicting psychological traits from gait sequences, achieving state-of-the-art performance on the PsyMo benchmark.


<details>
  <summary>Details</summary>
Motivation: Gait contains rich biometric and behavioral information, but using walking patterns to infer psychological traits remains challenging and underexplored.

Method: Multi-Stage Mixture of Movement Experts (MoME) processes walking cycles in four stages of movement complexity, using lightweight expert models and task-specific gating modules to adaptively weight features across traits and stages.

Result: Outperforms state-of-the-art gait analysis models, achieving 37.47% weighted F1 score at run level and 44.6% at subject level on PsyMo benchmark covering 17 psychological traits. Integration of auxiliary tasks further improves performance.

Conclusion: Demonstrates viability of multi-task gait-based learning for psychological trait estimation and provides foundation for future research on movement-informed psychological inference.

Abstract: Gait encodes rich biometric and behavioural information, yet leveraging the
manner of walking to infer psychological traits remains a challenging and
underexplored problem. We introduce a hierarchical Multi-Stage Mixture of
Movement Experts (MoME) architecture for multi-task prediction of psychological
attributes from gait sequences represented as 2D poses. MoME processes the
walking cycle in four stages of movement complexity, employing lightweight
expert models to extract spatio-temporal features and task-specific gating
modules to adaptively weight experts across traits and stages. Evaluated on the
PsyMo benchmark covering 17 psychological traits, our method outperforms
state-of-the-art gait analysis models, achieving a 37.47% weighted F1 score at
the run level and 44.6% at the subject level. Our experiments show that
integrating auxiliary tasks such as identity recognition, gender prediction,
and BMI estimation further improves psychological trait estimation. Our
findings demonstrate the viability of multi-task gait-based learning for
psychological trait estimation and provide a foundation for future research on
movement-informed psychological inference.

</details>


### [235] [ConceptSplit: Decoupled Multi-Concept Personalization of Diffusion Models via Token-wise Adaptation and Attention Disentanglement](https://arxiv.org/abs/2510.04668)
*Habin Lim,Yeongseob Won,Juwon Seo,Gyeong-Moon Park*

Main category: cs.CV

TL;DR: ConceptSplit is a framework that addresses concept mixing in multi-concept personalization for text-to-image diffusion models through Token-wise Value Adaptation (ToVA) training and Latent Optimization for Disentangled Attention (LODA) inference.


<details>
  <summary>Details</summary>
Motivation: To solve the problem of concept mixing where multiple learned concepts interfere or blend undesirably in output images during multi-concept personalization.

Method: Two key components: Token-wise Value Adaptation (ToVA) - a merging-free training method that adapts only value projections in cross-attention, and Latent Optimization for Disentangled Attention (LODA) - optimizes input latent during inference to alleviate attention entanglement.

Result: ConceptSplit achieves robust multi-concept personalization and mitigates unintended concept interference, as demonstrated through extensive qualitative and quantitative experiments.

Conclusion: The proposed framework effectively addresses concept mixing in multi-concept personalization by focusing on value projection adaptation and latent optimization, providing a solution to the attention entanglement problem.

Abstract: In recent years, multi-concept personalization for text-to-image (T2I)
diffusion models to represent several subjects in an image has gained much more
attention. The main challenge of this task is "concept mixing", where multiple
learned concepts interfere or blend undesirably in the output image. To address
this issue, in this paper, we present ConceptSplit, a novel framework to split
the individual concepts through training and inference. Our framework comprises
two key components. First, we introduce Token-wise Value Adaptation (ToVA), a
merging-free training method that focuses exclusively on adapting the value
projection in cross-attention. Based on our empirical analysis, we found that
modifying the key projection, a common approach in existing methods, can
disrupt the attention mechanism and lead to concept mixing. Second, we propose
Latent Optimization for Disentangled Attention (LODA), which alleviates
attention entanglement during inference by optimizing the input latent. Through
extensive qualitative and quantitative experiments, we demonstrate that
ConceptSplit achieves robust multi-concept personalization, mitigating
unintended concept interference. Code is available at
https://github.com/KU-VGI/ConceptSplit

</details>


### [236] [Label-Efficient Cross-Modality Generalization for Liver Segmentation in Multi-Phase MRI](https://arxiv.org/abs/2510.04705)
*Quang-Khai Bui-Tran,Minh-Toan Dinh,Thanh-Huy Nguyen,Ba-Thinh Lam,Mai-Anh Vu,Ulas Bagci*

Main category: cs.CV

TL;DR: A label-efficient liver segmentation method for multi-phase MRI that combines foundation model fine-tuning with co-training and cross pseudo supervision to handle limited labeled data, unlabeled sequences, and vendor/modal variations without spatial registration.


<details>
  <summary>Details</summary>
Motivation: Liver segmentation in multi-phase MRI is crucial for fibrosis assessment but faces challenges with scarce labeled data, uneven distribution across modalities/vendors, spatial misalignment, and missing phases in real-world clinical settings.

Method: Integrates foundation-scale 3D segmentation backbone with fine-tuning, co-training using cross pseudo supervision to leverage unlabeled volumes, and standardized preprocessing pipeline without requiring spatial registration.

Result: The model learns to generalize across MRI phases and vendors, demonstrating robust segmentation performance in both labeled and unlabeled domains.

Conclusion: The approach shows effectiveness for label-efficient liver segmentation in multi-phase, multi-vendor MRI and highlights the potential of combining foundation model adaptation with co-training for real-world clinical imaging tasks.

Abstract: Accurate liver segmentation in multi-phase MRI is vital for liver fibrosis
assessment, yet labeled data is often scarce and unevenly distributed across
imaging modalities and vendor systems. We propose a label-efficient
segmentation approach that promotes cross-modality generalization under
real-world conditions, where GED4 hepatobiliary-phase annotations are limited,
non-contrast sequences (T1WI, T2WI, DWI) are unlabeled, and spatial
misalignment and missing phases are common. Our method integrates a
foundation-scale 3D segmentation backbone adapted via fine-tuning, co-training
with cross pseudo supervision to leverage unlabeled volumes, and a standardized
preprocessing pipeline. Without requiring spatial registration, the model
learns to generalize across MRI phases and vendors, demonstrating robust
segmentation performance in both labeled and unlabeled domains. Our results
exhibit the effectiveness of our proposed label-efficient baseline for liver
segmentation in multi-phase, multi-vendor MRI and highlight the potential of
combining foundation model adaptation with co-training for real-world clinical
imaging tasks.

</details>


### [237] [ID-Consistent, Precise Expression Generation with Blendshape-Guided Diffusion](https://arxiv.org/abs/2510.04706)
*Foivos Paraperas Papantoniou,Stefanos Zafeiriou*

Main category: cs.CV

TL;DR: A diffusion-based framework for identity-consistent facial expression generation that combines ID-consistent face foundation with explicit FLAME blendshape control, enabling fine-grained expression editing from basic emotions to micro-expressions.


<details>
  <summary>Details</summary>
Motivation: Human-centric generative models need both identity consistency and precise control over human performance, but existing methods struggle with fine-grained expression control without compromising identity.

Method: Uses a compositional design with expression cross-attention module guided by FLAME blendshape parameters, trained on diverse image/video data with expressive variation, plus a pluggable Reference Adapter for real image editing.

Result: Outperforms existing methods in tailored and identity-consistent expression generation, handling subtle micro-expressions and expressive transitions overlooked by prior works.

Conclusion: The framework successfully achieves faithful reimagining of subjects under any facial expression while maintaining identity consistency, with code and models publicly available.

Abstract: Human-centric generative models designed for AI-driven storytelling must
bring together two core capabilities: identity consistency and precise control
over human performance. While recent diffusion-based approaches have made
significant progress in maintaining facial identity, achieving fine-grained
expression control without compromising identity remains challenging. In this
work, we present a diffusion-based framework that faithfully reimagines any
subject under any particular facial expression. Building on an ID-consistent
face foundation model, we adopt a compositional design featuring an expression
cross-attention module guided by FLAME blendshape parameters for explicit
control. Trained on a diverse mixture of image and video data rich in
expressive variation, our adapter generalizes beyond basic emotions to subtle
micro-expressions and expressive transitions, overlooked by prior works. In
addition, a pluggable Reference Adapter enables expression editing in real
images by transferring the appearance from a reference frame during synthesis.
Extensive quantitative and qualitative evaluations show that our model
outperforms existing methods in tailored and identity-consistent expression
generation. Code and models can be found at
https://github.com/foivospar/Arc2Face.

</details>


### [238] [ReactDiff: Fundamental Multiple Appropriate Facial Reaction Diffusion Model](https://arxiv.org/abs/2510.04712)
*Luo Cheng,Song Siyang,Yan Siyuan,Yu Zhen,Ge Zongyuan*

Main category: cs.CV

TL;DR: ReactDiff is a temporal diffusion framework that generates diverse and realistic facial reactions in dialogues by incorporating spatio-temporal facial kinematics and facial action unit dependencies.


<details>
  <summary>Details</summary>
Motivation: Existing methods fail to model the stochasticity and dynamics of real human facial reactions, leading to unrealistic jitters, unstable transitions, and unnatural expressions.

Method: Proposes ReactDiff framework that incorporates two priors into the diffusion process: temporal facial behavioral kinematics and facial action unit dependencies to guide realistic human reaction manifolds.

Result: Extensive experiments on REACT2024 dataset show state-of-the-art reaction quality, diversity, and reaction appropriateness compared to existing methods.

Conclusion: ReactDiff successfully generates diverse and human-like facial reactions that are appropriate for dialogue contexts by modeling facial kinematics and action unit dependencies.

Abstract: The automatic generation of diverse and human-like facial reactions in dyadic
dialogue remains a critical challenge for human-computer interaction systems.
Existing methods fail to model the stochasticity and dynamics inherent in real
human reactions. To address this, we propose ReactDiff, a novel temporal
diffusion framework for generating diverse facial reactions that are
appropriate for responding to any given dialogue context. Our key insight is
that plausible human reactions demonstrate smoothness, and coherence over time,
and conform to constraints imposed by human facial anatomy. To achieve this,
ReactDiff incorporates two vital priors (spatio-temporal facial kinematics)
into the diffusion process: i) temporal facial behavioral kinematics and ii)
facial action unit dependencies. These two constraints guide the model toward
realistic human reaction manifolds, avoiding visually unrealistic jitters,
unstable transitions, unnatural expressions, and other artifacts. Extensive
experiments on the REACT2024 dataset demonstrate that our approach not only
achieves state-of-the-art reaction quality but also excels in diversity and
reaction appropriateness.

</details>


### [239] [Object-Centric Representation Learning for Enhanced 3D Scene Graph Prediction](https://arxiv.org/abs/2510.04714)
*KunHo Heo,GiHyun Kim,SuYeon Kim,MyeongAh Cho*

Main category: cs.CV

TL;DR: The paper proposes a contrastive pretraining approach that decouples object representation learning from scene graph prediction, focusing on improving object feature quality to enhance 3D semantic scene graph accuracy.


<details>
  <summary>Details</summary>
Motivation: Previous methods for 3D semantic scene graph prediction rely too heavily on Graph Neural Networks while failing to optimize object and relationship feature representations, leading to insufficient discriminative capability.

Method: Designs a highly discriminative object feature encoder with contrastive pretraining strategy that separates object representation learning from scene graph prediction, and effectively combines geometric and semantic features for relationship prediction.

Result: Significant performance improvements across all evaluation metrics when plugging the pretrained encoder into existing frameworks, with comprehensive experiments on 3DSSG dataset showing state-of-the-art results.

Conclusion: The quality of object features is critical for overall scene graph accuracy, and the proposed approach effectively enhances both object classification and relationship prediction through improved feature representation.

Abstract: 3D Semantic Scene Graph Prediction aims to detect objects and their semantic
relationships in 3D scenes, and has emerged as a crucial technology for
robotics and AR/VR applications. While previous research has addressed dataset
limitations and explored various approaches including Open-Vocabulary settings,
they frequently fail to optimize the representational capacity of object and
relationship features, showing excessive reliance on Graph Neural Networks
despite insufficient discriminative capability. In this work, we demonstrate
through extensive analysis that the quality of object features plays a critical
role in determining overall scene graph accuracy. To address this challenge, we
design a highly discriminative object feature encoder and employ a contrastive
pretraining strategy that decouples object representation learning from the
scene graph prediction. This design not only enhances object classification
accuracy but also yields direct improvements in relationship prediction.
Notably, when plugging in our pretrained encoder into existing frameworks, we
observe substantial performance improvements across all evaluation metrics.
Additionally, whereas existing approaches have not fully exploited the
integration of relationship information, we effectively combine both geometric
and semantic features to achieve superior relationship prediction.
Comprehensive experiments on the 3DSSG dataset demonstrate that our approach
significantly outperforms previous state-of-the-art methods. Our code is
publicly available at https://github.com/VisualScienceLab-KHU/OCRL-3DSSG-Codes.

</details>


### [240] [Benchmark on Monocular Metric Depth Estimation in Wildlife Setting](https://arxiv.org/abs/2510.04723)
*Niccolò Niccoli,Lorenzo Seidenari,Ilaria Greco,Francesco Rovero*

Main category: cs.CV

TL;DR: First benchmark for monocular metric depth estimation in wildlife monitoring, evaluating 4 state-of-the-art methods and a geometric baseline on camera trap images with ground truth distances.


<details>
  <summary>Details</summary>
Motivation: Camera traps are widely used for wildlife monitoring but lack depth information, and existing monocular depth estimation methods haven't been systematically evaluated in natural wildlife environments.

Method: Evaluated four MDE methods (Depth Anything V2, ML Depth Pro, ZoeDepth, Metric3D) and a geometric baseline on 93 camera trap images with ground truth distances from calibrated ChARUCO patterns, comparing median vs mean depth extraction approaches.

Result: Depth Anything V2 achieved best performance (MAE: 0.454m, correlation: 0.962), while ZoeDepth performed worst (MAE: 3.087m). Median-based depth extraction consistently outperformed mean-based approaches. ZoeDepth was fastest (0.17s/image) but least accurate, while Depth Anything V2 offered optimal accuracy-speed balance (0.22s/image).

Conclusion: Established performance baselines for wildlife applications and provides practical guidance for implementing depth estimation in conservation monitoring systems, with Depth Anything V2 recommended for optimal balance of accuracy and speed.

Abstract: Camera traps are widely used for wildlife monitoring, but extracting accurate
distance measurements from monocular images remains challenging due to the lack
of depth information. While monocular depth estimation (MDE) methods have
advanced significantly, their performance in natural wildlife environments has
not been systematically evaluated. This work introduces the first benchmark for
monocular metric depth estimation in wildlife monitoring conditions. We
evaluate four state-of-the-art MDE methods (Depth Anything V2, ML Depth Pro,
ZoeDepth, and Metric3D) alongside a geometric baseline on 93 camera trap images
with ground truth distances obtained using calibrated ChARUCO patterns. Our
results demonstrate that Depth Anything V2 achieves the best overall
performance with a mean absolute error of 0.454m and correlation of 0.962,
while methods like ZoeDepth show significant degradation in outdoor natural
environments (MAE: 3.087m). We find that median-based depth extraction
consistently outperforms mean-based approaches across all deep learning
methods. Additionally, we analyze computational efficiency, with ZoeDepth being
fastest (0.17s per image) but least accurate, while Depth Anything V2 provides
an optimal balance of accuracy and speed (0.22s per image). This benchmark
establishes performance baselines for wildlife applications and provides
practical guidance for implementing depth estimation in conservation monitoring
systems.

</details>


### [241] [ExposureEngine: Oriented Logo Detection and Sponsor Visibility Analytics in Sports Broadcasts](https://arxiv.org/abs/2510.04739)
*Mehdi Houshmand Sarkhoosh,Frøy Øye,Henrik Nestor Sørlie,Nam Hoang Vu,Dag Johansen,Cise Midoglu,Tomas Kupka,Pål Halvorsen*

Main category: cs.CV

TL;DR: ExposureEngine is an automated system that uses oriented bounding boxes (OBB) instead of traditional horizontal bounding boxes (HBB) to accurately measure sponsor logo visibility in sports broadcasts, overcoming limitations of manual methods and previous automated approaches.


<details>
  <summary>Details</summary>
Motivation: Traditional methods for quantifying sponsor visibility in sports broadcasts are manual, subjective, and unscalable. Existing automated systems using axis-aligned bounding boxes are inaccurate when logos appear rotated or skewed due to dynamic camera angles and perspective distortions.

Method: The system uses an end-to-end approach with Oriented Bounding Box (OBB) detection for geometrically precise logo localization. It was trained on a new dataset of 1,103 frames from Swedish elite soccer with 670 unique sponsor logos annotated with OBBs. The system integrates detections into an analytical pipeline and includes a language-driven agentic layer for natural language queries.

Result: The model achieved a mean Average Precision (mAP@0.5) of 0.859, with precision of 0.96 and recall of 0.87, demonstrating robust performance in localizing logos under diverse broadcast conditions. The system provides precise visibility metrics including exposure duration and on-screen coverage.

Conclusion: ExposureEngine provides a comprehensive, auditable, and interpretable solution for sponsor measurement in sports media, overcoming the limitations of traditional methods through rotation-aware detection and natural language query capabilities.

Abstract: Quantifying sponsor visibility in sports broadcasts is a critical marketing
task traditionally hindered by manual, subjective, and unscalable analysis
methods. While automated systems offer an alternative, their reliance on
axis-aligned Horizontal Bounding Box (HBB) leads to inaccurate exposuremetrics
when logos appear rotated or skewed due to dynamic camera angles and
perspective distortions. This paper introduces ExposureEngine, an end-to-end
system designed for accurate, rotation-aware sponsor visibility analytics in
sports broadcasts, demonstrated in a soccer case study. Our approach predicts
Oriented Bounding Box (OBB) to provide a geometrically precise fit to each logo
regardless of the orientation on-screen. To train and evaluate our detector, we
developed a new dataset comprising 1,103 frames from Swedish elite soccer,
featuring 670 unique sponsor logos annotated with OBBs. Our model achieves a
mean Average Precision (mAP@0.5) of 0.859, with a precision of 0.96 and recall
of 0.87, demonstrating robust performance in localizing logos under diverse
broadcast conditions. The system integrates these detections into an analytical
pipeline that calculates precise visibility metrics, such as exposure duration
and on-screen coverage. Furthermore, we incorporate a language-driven agentic
layer, enabling users to generate reports, summaries, and media content through
natural language queries. The complete system, including the dataset and the
analytics dashboard, provides a comprehensive solution for auditable and
interpretable sponsor measurement in sports media. An overview of the
ExposureEngine is available online: https://youtu.be/tRw6OBISuW4 .

</details>


### [242] [Anomaly-Aware YOLO: A Frugal yet Robust Approach to Infrared Small Target Detection](https://arxiv.org/abs/2510.04741)
*Alina Ciocarlan,Sylvie Le Hégarat-Mascle,Sidonie Lefebvre*

Main category: cs.CV

TL;DR: AA-YOLO integrates statistical anomaly detection into YOLO's detection head to treat small infrared targets as anomalies, effectively controlling false alarms while maintaining competitive performance and robustness.


<details>
  <summary>Details</summary>
Motivation: Conventional object detectors struggle with infrared small target detection due to complex backgrounds and tiny target sizes, leading to high false alarm rates in defense applications.

Method: Integrates a statistical anomaly detection test into YOLO's detection head, treating small targets as unexpected patterns against the background. Only modifies the detection head, making it generic and applicable to various YOLO backbones including lightweight models.

Result: Achieves competitive performance on IRSTD benchmarks, demonstrates remarkable robustness with limited training data, noise, and domain shifts. Successfully applied across various YOLO backbones and provides promising results when integrated into instance segmentation YOLO.

Conclusion: AA-YOLO is an attractive solution for real-world deployments with constrained resources due to its versatility, false alarm control, and ability to work with limited data and various YOLO architectures.

Abstract: Infrared Small Target Detection (IRSTD) is a challenging task in defense
applications, where complex backgrounds and tiny target sizes often result in
numerous false alarms using conventional object detectors. To overcome this
limitation, we propose Anomaly-Aware YOLO (AA-YOLO), which integrates a
statistical anomaly detection test into its detection head. By treating small
targets as unexpected patterns against the background, AA-YOLO effectively
controls the false alarm rate. Our approach not only achieves competitive
performance on several IRSTD benchmarks, but also demonstrates remarkable
robustness in scenarios with limited training data, noise, and domain shifts.
Furthermore, since only the detection head is modified, our design is highly
generic and has been successfully applied across various YOLO backbones,
including lightweight models. It also provides promising results when
integrated into an instance segmentation YOLO. This versatility makes AA-YOLO
an attractive solution for real-world deployments where resources are
constrained. The code will be publicly released.

</details>


### [243] [Beyond Appearance: Transformer-based Person Identification from Conversational Dynamics](https://arxiv.org/abs/2510.04753)
*Masoumeh Chapariniya,Teodora Vukovic,Sarah Ebling,Volker Dellwo*

Main category: cs.CV

TL;DR: Transformer-based two-stream framework for person identification using spatial configurations and temporal motion patterns from body keypoints, achieving 98.03% accuracy with feature fusion.


<details>
  <summary>Details</summary>
Motivation: To investigate transformer architectures for person identification in natural face-to-face conversation scenarios, addressing the need for effective methods in natural interaction settings.

Method: Two-stream framework with spatial transformer for body keypoint configurations and multi-scale temporal transformer for motion patterns, using 133 COCO WholeBody keypoints from CANDOR corpus. Evaluated pre-trained vs from-scratch training and velocity features.

Result: Domain-specific training outperformed transfer learning. Spatial transformer achieved 95.74% accuracy, temporal transformer 93.90%. Feature fusion reached 98.03%, showing spatial information is more discriminative than temporal dynamics.

Conclusion: Transformers are effective for person identification in natural interactions, with spatial and temporal information being complementary. Provides foundation for future multimodal and cross-cultural studies.

Abstract: This paper investigates the performance of transformer-based architectures
for person identification in natural, face-to-face conversation scenario. We
implement and evaluate a two-stream framework that separately models spatial
configurations and temporal motion patterns of 133 COCO WholeBody keypoints,
extracted from a subset of the CANDOR conversational corpus. Our experiments
compare pre-trained and from-scratch training, investigate the use of velocity
features, and introduce a multi-scale temporal transformer for hierarchical
motion modeling. Results demonstrate that domain-specific training
significantly outperforms transfer learning, and that spatial configurations
carry more discriminative information than temporal dynamics. The spatial
transformer achieves 95.74% accuracy, while the multi-scale temporal
transformer achieves 93.90%. Feature-level fusion pushes performance to 98.03%,
confirming that postural and dynamic information are complementary. These
findings highlight the potential of transformer architectures for person
identification in natural interactions and provide insights for future
multimodal and cross-cultural studies.

</details>


### [244] [Progressive Gaussian Transformer with Anisotropy-aware Sampling for Open Vocabulary Occupancy Prediction](https://arxiv.org/abs/2510.04759)
*Chi Yan,Dan Xu*

Main category: cs.CV

TL;DR: PG-Occ is a Progressive Gaussian Transformer Framework for open-vocabulary 3D occupancy prediction that addresses the trade-off between sparse Gaussian representation (missing small objects) and dense representation (high computational cost) through progressive online densification and anisotropy-aware sampling.


<details>
  <summary>Details</summary>
Motivation: Traditional 3D occupancy prediction methods are limited to fixed semantic categories, while recent text-aligned approaches face a trade-off: sparse Gaussian representations struggle with small objects, and dense representations are computationally expensive.

Method: Uses progressive online densification to gradually enhance 3D Gaussian representation for fine-grained details, combined with anisotropy-aware sampling strategy with spatio-temporal fusion that adaptively assigns receptive fields to Gaussians at different scales and stages.

Result: Achieves state-of-the-art performance with 14.3% relative mIoU improvement over previous best method.

Conclusion: PG-Occ successfully enables open-vocabulary 3D occupancy prediction by balancing representation quality and computational efficiency through progressive enhancement and adaptive feature aggregation.

Abstract: The 3D occupancy prediction task has witnessed remarkable progress in recent
years, playing a crucial role in vision-based autonomous driving systems. While
traditional methods are limited to fixed semantic categories, recent approaches
have moved towards predicting text-aligned features to enable open-vocabulary
text queries in real-world scenes. However, there exists a trade-off in
text-aligned scene modeling: sparse Gaussian representation struggles to
capture small objects in the scene, while dense representation incurs
significant computational overhead. To address these limitations, we present
PG-Occ, an innovative Progressive Gaussian Transformer Framework that enables
open-vocabulary 3D occupancy prediction. Our framework employs progressive
online densification, a feed-forward strategy that gradually enhances the 3D
Gaussian representation to capture fine-grained scene details. By iteratively
enhancing the representation, the framework achieves increasingly precise and
detailed scene understanding. Another key contribution is the introduction of
an anisotropy-aware sampling strategy with spatio-temporal fusion, which
adaptively assigns receptive fields to Gaussians at different scales and
stages, enabling more effective feature aggregation and richer scene
information capture. Through extensive evaluations, we demonstrate that PG-Occ
achieves state-of-the-art performance with a relative 14.3% mIoU improvement
over the previous best performing method. Code and pretrained models will be
released upon publication on our project page:
https://yanchi-3dv.github.io/PG-Occ

</details>


### [245] [Beyond the Seen: Bounded Distribution Estimation for Open-Vocabulary Learning](https://arxiv.org/abs/2510.04770)
*Xiaomeng Fan,Yuchuan Mao,Zhi Gao,Yuwei Wu,Jin Chen,Yunde Jia*

Main category: cs.CV

TL;DR: The paper proposes a novel open-vocabulary learning method that generates unseen-class data to estimate distribution in open environments, achieving up to 14% improvement over baselines on 11 datasets.


<details>
  <summary>Details</summary>
Motivation: Existing methods estimate open-environment distributions using only seen-class data, making estimation error inherently unidentifiable due to absence of unseen classes. Learning beyond seen classes is crucial for bounding estimation error.

Method: A class-domain-wise data generation pipeline guided by hierarchical semantic tree and domain information from seen-class data, plus a distribution alignment algorithm that estimates and maximizes posterior probability using generated data.

Result: Extensive experiments on 11 datasets demonstrate the method outperforms baseline approaches by up to 14%, showing effectiveness and superiority in open-vocabulary learning.

Conclusion: Theoretical analysis shows distribution can be effectively estimated by generating unseen-class data, which bounds estimation error. The proposed method successfully implements this insight through data generation and distribution alignment.

Abstract: Open-vocabulary learning requires modeling the data distribution in open
environments, which consists of both seen-class and unseen-class data.
  Existing methods estimate the distribution in open environments using
seen-class data, where the absence of unseen classes makes the estimation error
inherently unidentifiable.
  Intuitively, learning beyond the seen classes is crucial for distribution
estimation to bound the estimation error.
  We theoretically demonstrate that the distribution can be effectively
estimated by generating unseen-class data, through which the estimation error
is upper-bounded.
  Building on this theoretical insight, we propose a novel open-vocabulary
learning method, which generates unseen-class data for estimating the
distribution in open environments. The method consists of a class-domain-wise
data generation pipeline and a distribution alignment algorithm. The data
generation pipeline generates unseen-class data under the guidance of a
hierarchical semantic tree and domain information inferred from the seen-class
data, facilitating accurate distribution estimation. With the generated data,
the distribution alignment algorithm estimates and maximizes the posterior
probability to enhance generalization in open-vocabulary learning. Extensive
experiments on $11$ datasets demonstrate that our method outperforms baseline
approaches by up to $14\%$, highlighting its effectiveness and superiority.

</details>


### [246] [Federated Learning for Surgical Vision in Appendicitis Classification: Results of the FedSurg EndoVis 2024 Challenge](https://arxiv.org/abs/2510.04772)
*Max Kirchner,Hanna Hoffmann,Alexander C. Jenke,Oliver L. Saldanha,Kevin Pfeiffer,Weam Kanjo,Julia Alekseenko,Claas de Boer,Santhi Raj Kolamuri,Lorenzo Mazza,Nicolas Padoy,Sophia Bano,Annika Reinke,Lena Maier-Hein,Danail Stoyanov,Jakob N. Kather,Fiona R. Kolbinger,Sebastian Bodenstedt,Stefanie Speidel*

Main category: cs.CV

TL;DR: The FedSurg challenge benchmarked federated learning for surgical video classification using the Appendix300 dataset, evaluating generalization to unseen centers and local adaptation through fine-tuning.


<details>
  <summary>Details</summary>
Motivation: To assess how well current federated learning methods generalize to unseen clinical centers and adapt through local fine-tuning while enabling collaborative model development without sharing patient data.

Method: Participants developed strategies to classify inflammation stages in appendicitis using foundation models with linear probing, metric learning with triplet loss, and various FL aggregation schemes (FedAvg, FedMedian, FedSAM). Performance was assessed using F1-score and Expected Cost.

Result: In generalization task, performance across centers was limited. In adaptation task, all teams improved after fine-tuning, though ranking stability was low. ViViT-based submission achieved strongest overall performance. Challenge highlighted limitations in generalization and sensitivity to class imbalance.

Conclusion: The FedSurg Challenge establishes the first benchmark for evaluating FL strategies in surgical video classification, highlighting trade-offs between local personalization and global robustness, and emphasizing importance of architecture choice, preprocessing, and loss design.

Abstract: Purpose: The FedSurg challenge was designed to benchmark the state of the art
in federated learning for surgical video classification. Its goal was to assess
how well current methods generalize to unseen clinical centers and adapt
through local fine-tuning while enabling collaborative model development
without sharing patient data. Methods: Participants developed strategies to
classify inflammation stages in appendicitis using a preliminary version of the
multi-center Appendix300 video dataset. The challenge evaluated two tasks:
generalization to an unseen center and center-specific adaptation after
fine-tuning. Submitted approaches included foundation models with linear
probing, metric learning with triplet loss, and various FL aggregation schemes
(FedAvg, FedMedian, FedSAM). Performance was assessed using F1-score and
Expected Cost, with ranking robustness evaluated via bootstrapping and
statistical testing. Results: In the generalization task, performance across
centers was limited. In the adaptation task, all teams improved after
fine-tuning, though ranking stability was low. The ViViT-based submission
achieved the strongest overall performance. The challenge highlighted
limitations in generalization, sensitivity to class imbalance, and difficulties
in hyperparameter tuning in decentralized training, while spatiotemporal
modeling and context-aware preprocessing emerged as promising strategies.
Conclusion: The FedSurg Challenge establishes the first benchmark for
evaluating FL strategies in surgical video classification. Findings highlight
the trade-off between local personalization and global robustness, and
underscore the importance of architecture choice, preprocessing, and loss
design. This benchmarking offers a reference point for future development of
imbalance-aware, adaptive, and robust FL methods in clinical surgical AI.

</details>


### [247] [Hands-Free Heritage: Automated 3D Scanning for Cultural Heritage Digitization](https://arxiv.org/abs/2510.04781)
*Javed Ahmad,Federico Dassiè,Selene Frascella,Gabriele Marchello,Ferdinando Cannella,Arianna Traviglia*

Main category: cs.CV

TL;DR: Automated two-robot system for high-fidelity 3D scanning of cultural heritage artefacts using coordinated robotic manipulation and optimized trajectory planning.


<details>
  <summary>Details</summary>
Motivation: Conventional 3D scanning methods require specialized expertise and manual intervention, making cultural heritage preservation challenging and labor-intensive.

Method: Two-robot system with coordinated motion planning: one robot handles the scanner while another handles the tray. Uses parameterized scanning space, optimized trajectory planning, and waypoint distribution for comprehensive coverage.

Result: Achieves significantly lower Chamfer Distance and higher F-score compared to baseline methods, offering superior geometric accuracy and improved digitization efficiency.

Conclusion: The automated system eliminates need for handheld or semi-automatic workflows, reduces reliance on expert operators, and provides efficient, high-quality 3D scanning for cultural heritage preservation.

Abstract: High-fidelity 3D scanning is essential for preserving cultural heritage
artefacts, supporting documentation, analysis, and long-term conservation.
However, conventional methods typically require specialized expertise and
manual intervention to maintain optimal scanning conditions and coverage. We
present an automated two-robot scanning system that eliminates the need for
handheld or semi-automatic workflows by combining coordinated robotic
manipulation with high-resolution 3D scanning. Our system parameterizes the
scanning space into distinct regions, enabling coordinated motion planning
between a scanner-equipped robot and a tray-handling robot. Optimized
trajectory planning and waypoint distribution ensure comprehensive surface
coverage, minimize occlusions, and balance reconstruction accuracy with system
efficiency. Experimental results show that our approach achieves significantly
lower Chamfer Distance and higher F-score compared to baseline methods,
offering superior geometric accuracy, improved digitization efficiency, and
reduced reliance on expert operators.

</details>


### [248] [A Comparative Study of Vision Transformers and CNNs for Few-Shot Rigid Transformation and Fundamental Matrix Estimation](https://arxiv.org/abs/2510.04794)
*Alon Kaya,Igal Bilik,Inna Stainvas*

Main category: cs.CV

TL;DR: ViTs outperform CNNs in large-data geometric estimation tasks but CNNs match ViTs in small-data scenarios due to inductive bias. ViTs show better cross-domain generalization.


<details>
  <summary>Details</summary>
Motivation: To compare ViTs and large-scale CNNs as backbone architectures for geometric estimation tasks (2D rigid transformations and fundamental matrix prediction) in various data regimes, especially low-data scenarios.

Method: Systematic comparison of large-scale CNNs (ResNet, EfficientNet, CLIP-ResNet) with ViT-based foundation models (CLIP-ViT variants and DINO) in different data size settings including few-shot scenarios, evaluating their performance on geometric estimation tasks.

Result: ViTs outperform CNNs during refinement in large downstream-data scenarios, but in small data scenarios, CNNs' inductive bias and smaller capacity allow them to match ViT performance. ViTs exhibit stronger generalization in cross-domain evaluation.

Conclusion: Careful selection of model architectures for refinement is crucial, motivating future research towards hybrid architectures that balance local and global representations for geometric estimation tasks.

Abstract: Vision-transformers (ViTs) and large-scale convolution-neural-networks (CNNs)
have reshaped computer vision through pretrained feature representations that
enable strong transfer learning for diverse tasks. However, their efficiency as
backbone architectures for geometric estimation tasks involving image
deformations in low-data regimes remains an open question. This work considers
two such tasks: 1) estimating 2D rigid transformations between pairs of images
and 2) predicting the fundamental matrix for stereo image pairs, an important
problem in various applications, such as autonomous mobility, robotics, and 3D
scene reconstruction. Addressing this intriguing question, this work
systematically compares large-scale CNNs (ResNet, EfficientNet, CLIP-ResNet)
with ViT-based foundation models (CLIP-ViT variants and DINO) in various data
size settings, including few-shot scenarios. These pretrained models are
optimized for classification or contrastive learning, encouraging them to focus
mostly on high-level semantics. The considered tasks require balancing local
and global features differently, challenging the straightforward adoption of
these models as the backbone. Empirical comparative analysis shows that,
similar to training from scratch, ViTs outperform CNNs during refinement in
large downstream-data scenarios. However, in small data scenarios, the
inductive bias and smaller capacity of CNNs improve their performance, allowing
them to match that of a ViT. Moreover, ViTs exhibit stronger generalization in
cross-domain evaluation where the data distribution changes. These results
emphasize the importance of carefully selecting model architectures for
refinement, motivating future research towards hybrid architectures that
balance local and global representations.

</details>


### [249] [DiT-VTON: Diffusion Transformer Framework for Unified Multi-Category Virtual Try-On and Virtual Try-All with Integrated Image Editing](https://arxiv.org/abs/2510.04797)
*Qi Li,Shuwen Qiu,Julien Han,Xingzi Xu,Mehmet Saygin Seyfioglu,Kee Kiat Koo,Karim Bouyarmane*

Main category: cs.CV

TL;DR: DiT-VTON is a Virtual Try-On framework using Diffusion Transformers that achieves state-of-the-art performance on garment try-on while extending to Virtual Try-All capabilities across diverse product categories with advanced image editing features.


<details>
  <summary>Details</summary>
Motivation: Existing Virtual Try-On models struggle with fine-grained detail preservation, robustness to real-world imagery, efficient sampling, image editing capabilities, and generalization across diverse product categories.

Method: Leverages Diffusion Transformer (DiT) adapted for image-conditioned VTO, exploring multiple configurations including in-context token concatenation, channel concatenation, and ControlNet integration. Trained on expanded dataset with varied backgrounds, unstructured references, and non-garment categories.

Result: Surpasses state-of-the-art methods on VITON-HD with superior detail preservation and robustness, outperforms models with VTA and image editing capabilities on diverse dataset spanning thousands of product categories.

Conclusion: DiT-VTON redefines VTO as Virtual Try-All, offering versatile solution for wide range of product categories with advanced image editing functionalities like pose preservation, localized editing, texture transfer, and object-level customization.

Abstract: The rapid growth of e-commerce has intensified the demand for Virtual Try-On
(VTO) technologies, enabling customers to realistically visualize products
overlaid on their own images. Despite recent advances, existing VTO models face
challenges with fine-grained detail preservation, robustness to real-world
imagery, efficient sampling, image editing capabilities, and generalization
across diverse product categories. In this paper, we present DiT-VTON, a novel
VTO framework that leverages a Diffusion Transformer (DiT), renowned for its
performance on text-conditioned image generation, adapted here for the
image-conditioned VTO task. We systematically explore multiple DiT
configurations, including in-context token concatenation, channel
concatenation, and ControlNet integration, to determine the best setup for VTO
image conditioning.
  To enhance robustness, we train the model on an expanded dataset encompassing
varied backgrounds, unstructured references, and non-garment categories,
demonstrating the benefits of data scaling for VTO adaptability. DiT-VTON also
redefines the VTO task beyond garment try-on, offering a versatile Virtual
Try-All (VTA) solution capable of handling a wide range of product categories
and supporting advanced image editing functionalities such as pose
preservation, localized editing, texture transfer, and object-level
customization. Experimental results show that our model surpasses
state-of-the-art methods on VITON-HD, achieving superior detail preservation
and robustness without reliance on additional condition encoders. It also
outperforms models with VTA and image editing capabilities on a diverse dataset
spanning thousands of product categories.

</details>


### [250] [Did you just see that? Arbitrary view synthesis for egocentric replay of operating room workflows from ambient sensors](https://arxiv.org/abs/2510.04802)
*Han Zhang,Lalithkumar Seenivasan,Jose L. Porras,Roger D. Soberanis-Mukul,Hao Ding,Hongchao Shu,Benjamin D. Killeen,Ankita Ghosh,Lonny Yarmus,Masaru Ishii,Angela Christine Argento,Mathias Unberath*

Main category: cs.CV

TL;DR: EgoSurg reconstructs dynamic egocentric visual perspectives of OR staff from fixed-camera videos using neural rendering and diffusion enhancement, enabling immersive surgical analysis without disrupting clinical workflow.


<details>
  <summary>Details</summary>
Motivation: Traditional surgical observation methods rely on fixed viewpoints or recollections, missing the actual egocentric perspectives that guide clinical decisions. Fixed cameras capture room-scale workflows but cannot reconstruct what each team member actually saw, limiting insights into surgical safety, training, and optimization.

Method: EgoSurg combines geometry-driven neural rendering with diffusion-based view enhancement to synthesize arbitrary egocentric viewpoints from wall-mounted fixed-camera video. This approach reconstructs person-specific visual fields without intervention to clinical workflow.

Result: Across multi-site surgical cases and controlled studies, EgoSurg successfully reconstructs person-specific visual fields and arbitrary viewpoints with high visual quality and fidelity.

Conclusion: EgoSurg transforms existing OR camera infrastructure into navigable dynamic 3D records, establishing a foundation for immersive surgical data science that enables surgical practice to be visualized, experienced, and analyzed from every angle.

Abstract: Observing surgical practice has historically relied on fixed vantage points
or recollections, leaving the egocentric visual perspectives that guide
clinical decisions undocumented. Fixed-camera video can capture surgical
workflows at the room-scale, but cannot reconstruct what each team member
actually saw. Thus, these videos only provide limited insights into how
decisions that affect surgical safety, training, and workflow optimization are
made. Here we introduce EgoSurg, the first framework to reconstruct the
dynamic, egocentric replays for any operating room (OR) staff directly from
wall-mounted fixed-camera video, and thus, without intervention to clinical
workflow. EgoSurg couples geometry-driven neural rendering with diffusion-based
view enhancement, enabling high-visual fidelity synthesis of arbitrary and
egocentric viewpoints at any moment. In evaluation across multi-site surgical
cases and controlled studies, EgoSurg reconstructs person-specific visual
fields and arbitrary viewpoints with high visual quality and fidelity. By
transforming existing OR camera infrastructure into a navigable dynamic 3D
record, EgoSurg establishes a new foundation for immersive surgical data
science, enabling surgical practice to be visualized, experienced, and analyzed
from every angle.

</details>


### [251] [Visual Representations inside the Language Model](https://arxiv.org/abs/2510.04819)
*Benlin Liu,Amita Kamath,Madeleine Grunde-McLaughlin,Winson Han,Ranjay Krishna*

Main category: cs.CV

TL;DR: MLMs struggle with perception-heavy tasks due to issues with visual key-value token processing. While image value tokens contain sufficient visual information, language models fail to properly utilize it, with later layers containing artifacts that reduce perception capability.


<details>
  <summary>Details</summary>
Motivation: To understand why Multimodal Language Models (MLMs) perform poorly on perception-heavy tasks by examining how they process visual key-value tokens, which is an under-studied aspect of MLM interpretability.

Method: Analyzed popular MLMs (LLaVA-OneVision, Qwen2.5-VL, Llama-3-LLaVA-NeXT) by studying visual information flow through language models, examining image value tokens, comparing with visual encoders, and testing text prefix interventions.

Result: Image value tokens encode sufficient visual information for perception tasks, but language models contain less visual information than standalone visual encoders. Later layer key tokens have artifacts that reduce perception. Adding text prefixes improves perception, and 33.3% of Art Style questions in BLINK benchmark have unused visual information in the language model.

Conclusion: MLMs' perception limitations stem from improper visual information utilization in language models rather than insufficient visual encoding. Better control of visual information in language models could significantly improve perception capabilities, suggesting new training directions for both visual encoders and language model components.

Abstract: Despite interpretability work analyzing VIT encoders and transformer
activations, we don't yet understand why Multimodal Language Models (MLMs)
struggle on perception-heavy tasks. We offer an under-studied perspective by
examining how popular MLMs (LLaVA-OneVision, Qwen2.5-VL, and
Llama-3-LLaVA-NeXT) process their visual key-value tokens. We first study the
flow of visual information through the language model, finding that image value
tokens encode sufficient information to perform several perception-heavy tasks
zero-shot: segmentation, semantic correspondence, temporal correspondence, and
referring expression detection. We find that while the language model does
augment the visual information received from the projection of input visual
encodings-which we reveal correlates with overall MLM perception capability-it
contains less visual information on several tasks than the equivalent visual
encoder (SigLIP) that has not undergone MLM finetuning. Further, we find that
the visual information corresponding to input-agnostic image key tokens in
later layers of language models contains artifacts which reduce perception
capability of the overall MLM. Next, we discuss controlling visual information
in the language model, showing that adding a text prefix to the image input
improves perception capabilities of visual representations. Finally, we reveal
that if language models were able to better control their visual information,
their perception would significantly improve; e.g., in 33.3% of Art Style
questions in the BLINK benchmark, perception information present in the
language model is not surfaced to the output! Our findings reveal insights into
the role of key-value tokens in multimodal systems, paving the way for deeper
mechanistic interpretability of MLMs and suggesting new directions for training
their visual encoder and language model components.

</details>


### [252] [AvatarVTON: 4D Virtual Try-On for Animatable Avatars](https://arxiv.org/abs/2510.04822)
*Zicheng Jiang,Jixin Gao,Shengfeng He,Xinzhe Li,Yulong Zheng,Zhaotong Yang,Junyu Dong,Yong Du*

Main category: cs.CV

TL;DR: AvatarVTON is the first 4D virtual try-on framework that generates realistic try-on results from a single garment image, supporting free pose control, novel-view rendering, and dynamic garment interactions without multi-view captures or physics priors.


<details>
  <summary>Details</summary>
Motivation: To enable realistic 4D virtual try-on from single garment images, overcoming limitations of existing methods that require multi-view captures or physics priors, and supporting dynamic garment interactions.

Method: Uses two key modules: (1) Reciprocal Flow Rectifier for optical-flow correction to stabilize avatar fitting and ensure temporal coherence, and (2) Non-Linear Deformer that decomposes Gaussian maps into view-pose-invariant and view-pose-specific components for adaptive garment deformations.

Result: Achieves high fidelity, diversity, and dynamic garment realism in extensive experiments, outperforming extended baselines in fair qualitative and quantitative comparisons.

Conclusion: AvatarVTON is well-suited for AR/VR, gaming, and digital-human applications, establishing a benchmark for 4D virtual try-on with superior performance in dynamic garment realism.

Abstract: We propose AvatarVTON, the first 4D virtual try-on framework that generates
realistic try-on results from a single in-shop garment image, enabling free
pose control, novel-view rendering, and diverse garment choices. Unlike
existing methods, AvatarVTON supports dynamic garment interactions under
single-view supervision, without relying on multi-view garment captures or
physics priors. The framework consists of two key modules: (1) a Reciprocal
Flow Rectifier, a prior-free optical-flow correction strategy that stabilizes
avatar fitting and ensures temporal coherence; and (2) a Non-Linear Deformer,
which decomposes Gaussian maps into view-pose-invariant and view-pose-specific
components, enabling adaptive, non-linear garment deformations. To establish a
benchmark for 4D virtual try-on, we extend existing baselines with unified
modules for fair qualitative and quantitative comparisons. Extensive
experiments show that AvatarVTON achieves high fidelity, diversity, and dynamic
garment realism, making it well-suited for AR/VR, gaming, and digital-human
applications.

</details>


### [253] [Flow Matching for Conditional MRI-CT and CBCT-CT Image Synthesis](https://arxiv.org/abs/2510.04823)
*Arnela Hadzic,Simon Johannes Joham,Martin Urschler*

Main category: cs.CV

TL;DR: A 3D Flow Matching framework generates synthetic CT from MRI or CBCT for radiotherapy, achieving good global structure reconstruction but limited fine detail preservation due to resolution constraints.


<details>
  <summary>Details</summary>
Motivation: To enable MRI-only and CBCT-based adaptive radiotherapy by generating synthetic CT images, improving treatment precision while reducing patient radiation exposure.

Method: Fully 3D Flow Matching framework that transforms Gaussian noise into sCT images by integrating learned velocity fields conditioned on input MRI/CBCT features extracted with a lightweight 3D encoder.

Result: Method accurately reconstructs global anatomical structures but has limited preservation of fine details due to low training resolution constraints. Evaluated on SynthRAD2025 Challenge benchmark across abdomen, head and neck, and thorax regions.

Conclusion: Future work will explore patch-based training and latent-space flow models to improve resolution and local structural fidelity.

Abstract: Generating synthetic CT (sCT) from MRI or CBCT plays a crucial role in
enabling MRI-only and CBCT-based adaptive radiotherapy, improving treatment
precision while reducing patient radiation exposure. To address this task, we
adopt a fully 3D Flow Matching (FM) framework, motivated by recent work
demonstrating FM's efficiency in producing high-quality images. In our
approach, a Gaussian noise volume is transformed into an sCT image by
integrating a learned FM velocity field, conditioned on features extracted from
the input MRI or CBCT using a lightweight 3D encoder. We evaluated the method
on the SynthRAD2025 Challenge benchmark, training separate models for MRI
$\rightarrow$ sCT and CBCT $\rightarrow$ sCT across three anatomical regions:
abdomen, head and neck, and thorax. Validation and testing were performed
through the challenge submission system. The results indicate that the method
accurately reconstructs global anatomical structures; however, preservation of
fine details was limited, primarily due to the relatively low training
resolution imposed by memory and runtime constraints. Future work will explore
patch-based training and latent-space flow models to improve resolution and
local structural fidelity.

</details>


### [254] [Beyond Random: Automatic Inner-loop Optimization in Dataset Distillation](https://arxiv.org/abs/2510.04838)
*Muquan Li,Hang Gou,Dongyang Zhang,Shuang Liang,Xiurui Xie,Deqiang Ouyang,Ke Qin*

Main category: cs.CV

TL;DR: AT-BPTT is a novel framework for dataset distillation that dynamically adapts truncation positions and window sizes based on gradient behavior, achieving state-of-the-art performance with significant speedup and memory savings.


<details>
  <summary>Details</summary>
Motivation: Existing inner-loop optimization methods for dataset distillation rely on random truncation strategies, which lack flexibility and yield suboptimal results due to neural networks' distinct learning dynamics across different training stages.

Method: Proposes Automatic Truncated Backpropagation Through Time (AT-BPTT) with three components: probabilistic stage-aware timestep selection, adaptive window sizing based on gradient variation, and low-rank Hessian approximation for computational efficiency.

Result: AT-BPTT achieves state-of-the-art performance on CIFAR-10, CIFAR-100, Tiny-ImageNet, and ImageNet-1K, improving accuracy by 6.16% on average over baselines, while accelerating inner-loop optimization by 3.9x and saving 63% memory cost.

Conclusion: AT-BPTT effectively addresses the limitations of random truncation in dataset distillation by dynamically adapting to neural network learning dynamics, delivering superior performance and efficiency.

Abstract: The growing demand for efficient deep learning has positioned dataset
distillation as a pivotal technique for compressing training dataset while
preserving model performance. However, existing inner-loop optimization methods
for dataset distillation typically rely on random truncation strategies, which
lack flexibility and often yield suboptimal results. In this work, we observe
that neural networks exhibit distinct learning dynamics across different
training stages-early, middle, and late-making random truncation ineffective.
To address this limitation, we propose Automatic Truncated Backpropagation
Through Time (AT-BPTT), a novel framework that dynamically adapts both
truncation positions and window sizes according to intrinsic gradient behavior.
AT-BPTT introduces three key components: (1) a probabilistic mechanism for
stage-aware timestep selection, (2) an adaptive window sizing strategy based on
gradient variation, and (3) a low-rank Hessian approximation to reduce
computational overhead. Extensive experiments on CIFAR-10, CIFAR-100,
Tiny-ImageNet, and ImageNet-1K show that AT-BPTT achieves state-of-the-art
performance, improving accuracy by an average of 6.16% over baseline methods.
Moreover, our approach accelerates inner-loop optimization by 3.9x while saving
63% memory cost.

</details>


### [255] [Detailed Aerial Mapping of Photovoltaic Power Plants Through Semantically Significant Keypoints](https://arxiv.org/abs/2510.04840)
*Viktor Kozák,Jan Chudoba,Libor Přeučil*

Main category: cs.CV

TL;DR: A novel method for automated PV power plant mapping using aerial images to create detailed 3D models of individual solar modules without relying on third-party data.


<details>
  <summary>Details</summary>
Motivation: Accurate and up-to-date PV power plant models are essential for optimal operation and maintenance, but such models are often not readily available.

Method: Uses visual segmentation of PV modules in aerial images, infers structural information (benches, rows, columns), identifies visual keypoints for layout, and merges detections from multiple images while maintaining structural integrity.

Result: Successfully tested on two different power plants, producing compact georeferenced 3D models with semantic structures suitable for maintenance.

Conclusion: The approach enables automated mapping of PV power plants down to individual module level, removing reliance on third-party data and supporting maintenance operations.

Abstract: An accurate and up-to-date model of a photovoltaic (PV) power plant is
essential for its optimal operation and maintenance. However, such a model may
not be easily available. This work introduces a novel approach for PV power
plant mapping based on aerial overview images. It enables the automation of the
mapping process while removing the reliance on third-party data. The presented
mapping method takes advantage of the structural layout of the power plants to
achieve detailed modeling down to the level of individual PV modules. The
approach relies on visual segmentation of PV modules in overview images and the
inference of structural information in each image, assigning modules to
individual benches, rows, and columns. We identify visual keypoints related to
the layout and use these to merge detections from multiple images while
maintaining their structural integrity. The presented method was experimentally
verified and evaluated on two different power plants. The final fusion of 3D
positions and semantic structures results in a compact georeferenced model
suitable for power plant maintenance.

</details>


### [256] [From Actions to Kinesics: Extracting Human Psychological States through Bodily Movements](https://arxiv.org/abs/2510.04844)
*Cheyu Lin,Katherine A. Flanigan*

Main category: cs.CV

TL;DR: A kinesics recognition framework using ST-GCN and CNN to infer psychological states from 3D skeleton data, enabling privacy-preserving and scalable human behavior modeling.


<details>
  <summary>Details</summary>
Motivation: To overcome limitations of traditional methods (theoretical models, questionnaires) in capturing human psychological states in a generalizable and privacy-preserving way for human-environment interaction modeling.

Method: Combines spatial-temporal graph convolutional network (ST-GCN) with CNN, using transfer learning to map 3D skeleton joint data to communicative functions (kinesics) without manual mappings.

Result: Demonstrated on DUET dataset, the method enables scalable, accurate, and human-centered behavior modeling while preserving user anonymity.

Conclusion: Provides a new pathway for enhancing RL-driven simulations of human-environment interaction through privacy-preserving psychological state inference from bodily movements.

Abstract: Understanding the dynamic relationship between humans and the built
environment is a key challenge in disciplines ranging from environmental
psychology to reinforcement learning (RL). A central obstacle in modeling these
interactions is the inability to capture human psychological states in a way
that is both generalizable and privacy preserving. Traditional methods rely on
theoretical models or questionnaires, which are limited in scope, static, and
labor intensive. We present a kinesics recognition framework that infers the
communicative functions of human activity -- known as kinesics -- directly from
3D skeleton joint data. Combining a spatial-temporal graph convolutional
network (ST-GCN) with a convolutional neural network (CNN), the framework
leverages transfer learning to bypass the need for manually defined mappings
between physical actions and psychological categories. The approach preserves
user anonymity while uncovering latent structures in bodily movements that
reflect cognitive and emotional states. Our results on the Dyadic User
EngagemenT (DUET) dataset demonstrate that this method enables scalable,
accurate, and human-centered modeling of behavior, offering a new pathway for
enhancing RL-driven simulations of human-environment interaction.

</details>


### [257] [Read the Room: Inferring Social Context Through Dyadic Interaction Recognition in Cyber-physical-social Infrastructure Systems](https://arxiv.org/abs/2510.04854)
*Cheyu Lin,John Martins,Katherine A. Flanigan,Ph. D*

Main category: cs.CV

TL;DR: This paper compares five skeleton-based algorithms for recognizing dyadic human interactions using depth sensors as a privacy-preserving alternative to RGB cameras, analyzing 12 types of social interactions.


<details>
  <summary>Details</summary>
Motivation: Cyber-physical systems focus on economic goals but neglect social benefits. Cyber-physical-social infrastructure systems aim to address this by aligning with social objectives, requiring better understanding of human interactions while preserving privacy.

Method: The study compares five skeleton-based interaction recognition algorithms on a dataset of 12 dyadic interactions, using depth sensors to analyze skeletal movements instead of RGB cameras for privacy preservation.

Result: The research provides insights into recognizing different types of dyadic interactions (emblems, affect displays) that reveal cultural and emotional aspects of human behavior, using privacy-conscious depth sensor technology.

Conclusion: Skeleton-based interaction recognition using depth sensors offers a viable privacy-preserving approach to understanding human social interactions, laying foundation for cyber-physical-social infrastructure systems that can foster positive social outcomes.

Abstract: Cyber-physical systems (CPS) integrate sensing, computing, and control to
improve infrastructure performance, focusing on economic goals like performance
and safety. However, they often neglect potential human-centered (or
''social'') benefits. Cyber-physical-social infrastructure systems (CPSIS) aim
to address this by aligning CPS with social objectives. This involves defining
social benefits, understanding human interactions with each other and
infrastructure, developing privacy-preserving measurement methods, modeling
these interactions for prediction, linking them to social benefits, and
actuating the physical environment to foster positive social outcomes. This
paper delves into recognizing dyadic human interactions using real-world data,
which is the backbone to measuring social behavior. This lays a foundation to
address the need to enhance understanding of the deeper meanings and mutual
responses inherent in human interactions. While RGB cameras are informative for
interaction recognition, privacy concerns arise. Depth sensors offer a
privacy-conscious alternative by analyzing skeletal movements. This study
compares five skeleton-based interaction recognition algorithms on a dataset of
12 dyadic interactions. Unlike single-person datasets, these interactions,
categorized into communication types like emblems and affect displays, offer
insights into the cultural and emotional aspects of human interactions.

</details>


### [258] [ERDE: Entropy-Regularized Distillation for Early-exit](https://arxiv.org/abs/2510.04856)
*Martial Guidez,Stefan Duffner,Yannick Alpou,Oscar Röth,Christophe Garcia*

Main category: cs.CV

TL;DR: A method combining early exits and knowledge distillation to reduce computational costs in neural networks while maintaining accuracy, using an entropy-based loss for misclassified images.


<details>
  <summary>Details</summary>
Motivation: Deep neural networks have high computational costs that make them impractical for real-time and edge applications, requiring efficient compression techniques.

Method: Integrates early exits and knowledge distillation, training a reduced student early-exit model from a complex teacher model with a new entropy-based loss for misclassified images.

Result: Achieves significant reductions in computational complexity without compromising classification performance on CIFAR10, CIFAR100 and SVHN datasets.

Conclusion: The approach effectively optimizes the accuracy-efficiency trade-off and opens new research perspectives for knowledge distillation.

Abstract: Although deep neural networks and in particular Convolutional Neural Networks
have demonstrated state-of-the-art performance in image classification with
relatively high efficiency, they still exhibit high computational costs, often
rendering them impractical for real-time and edge applications. Therefore, a
multitude of compression techniques have been developed to reduce these costs
while maintaining accuracy. In addition, dynamic architectures have been
introduced to modulate the level of compression at execution time, which is a
desirable property in many resource-limited application scenarios. The proposed
method effectively integrates two well-established optimization techniques:
early exits and knowledge distillation, where a reduced student early-exit
model is trained from a more complex teacher early-exit model. The primary
contribution of this research lies in the approach for training the student
early-exit model. In comparison to the conventional Knowledge Distillation
loss, our approach incorporates a new entropy-based loss for images where the
teacher's classification was incorrect. The proposed method optimizes the
trade-off between accuracy and efficiency, thereby achieving significant
reductions in computational complexity without compromising classification
performance. The validity of this approach is substantiated by experimental
results on image classification datasets CIFAR10, CIFAR100 and SVHN, which
further opens new research perspectives for Knowledge Distillation in other
contexts.

</details>


### [259] [μDeepIQA: deep learning-based fast and robust image quality assessment with local predictions for optical microscopy](https://arxiv.org/abs/2510.04859)
*Elena Corbetta,Thomas Bocklitz*

Main category: cs.CV

TL;DR: μDeepIQA is a deep learning-based image quality assessment method for optical microscopy that provides fast, stable quality predictions and patch-wise quality visualization, overcoming limitations of traditional quality metrics.


<details>
  <summary>Details</summary>
Motivation: Traditional IQA methods for optical microscopy are computationally expensive for large datasets and unstable for images outside their ideal domain, requiring more robust and efficient solutions.

Method: The approach retrains a deep convolutional neural network originally designed for natural image IQA on optical microscopy data to predict individual quality metrics and global quality scores.

Result: μDeepIQA provides fast and stable quality predictions that generalize well even outside standard method ranges, with additional capability for patch-wise quality assessment and spatial quality visualization.

Conclusion: Deep learning models like μDeepIQA benefit optical microscopy studies through stable outlier performance, small patch assessment capability, and rapid predictions, demonstrating superior generalizability over traditional IQA methods.

Abstract: Optical microscopy is one of the most widely used techniques in research
studies for life sciences and biomedicine. These applications require reliable
experimental pipelines to extract valuable knowledge from the measured samples
and must be supported by image quality assessment (IQA) to ensure correct
processing and analysis of the image data. IQA methods are implemented with
variable complexity. However, while most quality metrics have a straightforward
implementation, they might be time consuming and computationally expensive when
evaluating a large dataset. In addition, quality metrics are often designed for
well-defined image features and may be unstable for images out of the ideal
domain.
  To overcome these limitations, recent works have proposed deep learning-based
IQA methods, which can provide superior performance, increased generalizability
and fast prediction. Our method, named $\mathrm{\mu}$DeepIQA, is inspired by
previous studies and applies a deep convolutional neural network designed for
IQA on natural images to optical microscopy measurements. We retrained the same
architecture to predict individual quality metrics and global quality scores
for optical microscopy data. The resulting models provide fast and stable
predictions of image quality by generalizing quality estimation even outside
the ideal range of standard methods. In addition, $\mathrm{\mu}$DeepIQA
provides patch-wise prediction of image quality and can be used to visualize
spatially varying quality in a single image. Our study demonstrates that
optical microscopy-based studies can benefit from the generalizability of deep
learning models due to their stable performance in the presence of outliers,
the ability to assess small image patches, and rapid predictions.

</details>


### [260] [In-Field Mapping of Grape Yield and Quality with Illumination-Invariant Deep Learning](https://arxiv.org/abs/2510.04864)
*Ciem Cornelissen,Sander De Coninck,Axel Willekens,Sam Leroux,Pieter Simoens*

Main category: cs.CV

TL;DR: An IoT-enabled robotic system for real-time mapping of grape yield and quality in vineyards using hyperspectral imaging and deep learning, with a novel domain-adversarial framework to handle illumination variations.


<details>
  <summary>Details</summary>
Motivation: To enable non-destructive, real-time monitoring of grape yield and quality in vineyards for precision viticulture, overcoming the challenge of domain shift caused by variable illumination conditions in field hyperspectral imaging.

Method: End-to-end system with two modules: 1) High-performance model for grape bunch detection and weight estimation, 2) Light-Invariant Spectral Autoencoder (LISA) - a domain-adversarial framework for quality assessment from hyperspectral data that learns illumination-invariant features from uncalibrated data.

Result: System achieves 0.82 recall for bunch detection and R²=0.76 for weight prediction. LISA module improves quality prediction generalization by over 20% compared to baselines. Validated on HSI dataset spanning three illumination domains: lab lighting, morning sunlight, and afternoon sunlight.

Conclusion: The system successfully generates high-resolution, georeferenced data of grape yield and quality, providing actionable insights for precision viticulture by combining robust detection and quality assessment modules.

Abstract: This paper presents an end-to-end, IoT-enabled robotic system for the
non-destructive, real-time, and spatially-resolved mapping of grape yield and
quality (Brix, Acidity) in vineyards. The system features a comprehensive
analytical pipeline that integrates two key modules: a high-performance model
for grape bunch detection and weight estimation, and a novel deep learning
framework for quality assessment from hyperspectral (HSI) data. A critical
barrier to in-field HSI is the ``domain shift" caused by variable illumination.
To overcome this, our quality assessment is powered by the Light-Invariant
Spectral Autoencoder (LISA), a domain-adversarial framework that learns
illumination-invariant features from uncalibrated data. We validated the
system's robustness on a purpose-built HSI dataset spanning three distinct
illumination domains: controlled artificial lighting (lab), and variable
natural sunlight captured in the morning and afternoon. Results show the
complete pipeline achieves a recall (0.82) for bunch detection and a $R^2$
(0.76) for weight prediction, while the LISA module improves quality prediction
generalization by over 20% compared to the baselines. By combining these robust
modules, the system successfully generates high-resolution, georeferenced data
of both grape yield and quality, providing actionable, data-driven insights for
precision viticulture.

</details>


### [261] [BenthiCat: An opti-acoustic dataset for advancing benthic classification and habitat mapping](https://arxiv.org/abs/2510.04876)
*Hayat Rajani,Valerio Franchi,Borja Martinez-Clavel Valles,Raimon Ramos,Rafael Garcia,Nuno Gracias*

Main category: cs.CV

TL;DR: This paper introduces a comprehensive multi-modal dataset for benthic habitat mapping, including side-scan sonar tiles, bathymetric maps, and optical images, with manual annotations to support machine learning model development and benchmarking.


<details>
  <summary>Details</summary>
Motivation: The scarcity of large, annotated datasets limits the development and benchmarking of machine learning models for benthic habitat mapping, which is crucial for understanding marine ecosystems and supporting conservation efforts.

Method: The authors collected about a million side-scan sonar tiles along the coast of Catalonia, complemented by bathymetric maps and co-registered optical images from AUV surveys. Approximately 36,000 SSS tiles were manually annotated with segmentation masks. They spatially associated optical images with corresponding SSS tiles to facilitate cross-modal representation learning.

Result: The paper presents a comprehensive multi-modal dataset with raw sensor data, mosaics, and annotations, along with open-source preprocessing and annotation tools to enhance accessibility and encourage research in underwater habitat mapping.

Conclusion: This resource aims to establish a standardized benchmark for underwater habitat mapping, promoting advancements in autonomous seafloor classification and multi-sensor integration for marine ecosystem studies.

Abstract: Benthic habitat mapping is fundamental for understanding marine ecosystems,
guiding conservation efforts, and supporting sustainable resource management.
Yet, the scarcity of large, annotated datasets limits the development and
benchmarking of machine learning models in this domain. This paper introduces a
thorough multi-modal dataset, comprising about a million side-scan sonar (SSS)
tiles collected along the coast of Catalonia (Spain), complemented by
bathymetric maps and a set of co-registered optical images from targeted
surveys using an autonomous underwater vehicle (AUV). Approximately \num{36000}
of the SSS tiles have been manually annotated with segmentation masks to enable
supervised fine-tuning of classification models. All the raw sensor data,
together with mosaics, are also released to support further exploration and
algorithm development. To address challenges in multi-sensor data fusion for
AUVs, we spatially associate optical images with corresponding SSS tiles,
facilitating self-supervised, cross-modal representation learning. Accompanying
open-source preprocessing and annotation tools are provided to enhance
accessibility and encourage research. This resource aims to establish a
standardized benchmark for underwater habitat mapping, promoting advancements
in autonomous seafloor classification and multi-sensor integration.

</details>


### [262] [Comparative Analysis of YOLOv5, Faster R-CNN, SSD, and RetinaNet for Motorbike Detection in Kigali Autonomous Driving Context](https://arxiv.org/abs/2510.04912)
*Ngeyen Yinkfu,Sunday Nwovu,Jonathan Kayizzi,Angelique Uwamahoro*

Main category: cs.CV

TL;DR: This study compares four object detection models (YOLOv5, Faster R-CNN, SSD, RetinaNet) for motorbike detection in Kigali, Rwanda, evaluating their performance for autonomous driving systems in resource-constrained environments.


<details>
  <summary>Details</summary>
Motivation: Motorcycle taxis in Kigali navigate unpredictably and disregard traffic rules, posing significant challenges for autonomous driving systems that need to detect them reliably.

Method: Used a custom dataset of 198 images from Kigali, implemented four object detection models in PyTorch with transfer learning, and evaluated them for accuracy, localization, and inference speed.

Result: The study identified implementation challenges including dataset limitations and model complexities, and provided performance comparisons of the four models for motorbike detection.

Conclusion: Recommends simplified architectures for future work to enhance accessibility of autonomous systems in developing countries like Rwanda.

Abstract: In Kigali, Rwanda, motorcycle taxis are a primary mode of transportation,
often navigating unpredictably and disregarding traffic rules, posing
significant challenges for autonomous driving systems. This study compares four
object detection models--YOLOv5, Faster R-CNN, SSD, and RetinaNet--for
motorbike detection using a custom dataset of 198 images collected in Kigali.
Implemented in PyTorch with transfer learning, the models were evaluated for
accuracy, localization, and inference speed to assess their suitability for
real-time navigation in resource-constrained settings. We identify
implementation challenges, including dataset limitations and model
complexities, and recommend simplified architectures for future work to enhance
accessibility for autonomous systems in developing countries like Rwanda.

</details>


### [263] [A Semantics-Aware Hierarchical Self-Supervised Approach to Classification of Remote Sensing Images](https://arxiv.org/abs/2510.04916)
*Giulio Weikmann,Gianmarco Perantoni,Lorenzo Bruzzone*

Main category: cs.CV

TL;DR: SAHC method integrates hierarchy-specific classification heads with trainable hierarchy matrices to learn hierarchical features and relationships in remote sensing image classification, using a hierarchical consensus mechanism for consistent probability distributions across levels.


<details>
  <summary>Details</summary>
Motivation: Existing deep learning approaches for remote sensing image classification often overlook predefined label hierarchies and focus only on fine-grained classification, missing the semantic relationships among classes.

Method: Proposes Semantics-Aware Hierarchical Consensus (SAHC) with hierarchy-specific classification heads, trainable hierarchy matrices for self-supervised hierarchical structure learning, and a hierarchical consensus mechanism for probability distribution consistency.

Result: Experimental evaluation on three benchmark datasets shows SAHC effectively guides network learning and demonstrates robustness for hierarchical remote sensing image classification tasks across different backbone architectures.

Conclusion: SAHC successfully leverages hierarchical structures in classification tasks, proving effective and adaptable for remote sensing image classification with varying hierarchical complexity.

Abstract: Deep learning has become increasingly important in remote sensing image
classification due to its ability to extract semantic information from complex
data. Classification tasks often include predefined label hierarchies that
represent the semantic relationships among classes. However, these hierarchies
are frequently overlooked, and most approaches focus only on fine-grained
classification schemes. In this paper, we present a novel Semantics-Aware
Hierarchical Consensus (SAHC) method for learning hierarchical features and
relationships by integrating hierarchy-specific classification heads within a
deep network architecture, each specialized in different degrees of class
granularity. The proposed approach employs trainable hierarchy matrices, which
guide the network through the learning of the hierarchical structure in a
self-supervised manner. Furthermore, we introduce a hierarchical consensus
mechanism to ensure consistent probability distributions across different
hierarchical levels. This mechanism acts as a weighted ensemble being able to
effectively leverage the inherent structure of the hierarchical classification
task. The proposed SAHC method is evaluated on three benchmark datasets with
different degrees of hierarchical complexity on different tasks, using distinct
backbone architectures to effectively emphasize its adaptability. Experimental
results show both the effectiveness of the proposed approach in guiding network
learning and the robustness of the hierarchical consensus for remote sensing
image classification tasks.

</details>


### [264] [REN: Anatomically-Informed Mixture-of-Experts for Interstitial Lung Disease Diagnosis](https://arxiv.org/abs/2510.04923)
*Alec K. Peltekian,Halil Ertugrul Aktas,Gorkem Durak,Kevin Grudzinski,Bradford C. Bemiss,Carrie Richardson,Jane E. Dematte,G. R. Scott Budinger,Anthony J. Esposito,Alexander Misharin,Alok Choudhary,Ankit Agrawal,Ulas Bagci*

Main category: cs.CV

TL;DR: REN is an anatomically-informed Mixture-of-Experts framework for medical image classification that uses anatomical priors to train specialized experts for different lung regions, achieving superior performance in interstitial lung disease classification.


<details>
  <summary>Details</summary>
Motivation: Traditional MoE systems lack domain-specific constraints essential for medical imaging where anatomical structure and regional disease heterogeneity strongly influence pathological patterns.

Method: REN leverages anatomical priors to train seven specialized experts for distinct lung lobes and bilateral lung combinations, using multi-modal gating mechanisms that integrate radiomics biomarkers and deep learning features (CNN, ViT, Mamba) to optimally weight expert contributions.

Result: REN achieved average AUC of 0.8646 ± 0.0467, a 12.5% improvement over SwinUNETR baseline (AUC 0.7685, p=0.031). Region-specific experts showed lower-lobe models achieving AUCs of 0.88-0.90, surpassing DL counterparts (CNN: 0.76-0.79).

Conclusion: REN demonstrates strong generalizability and clinical interpretability, presenting a scalable, anatomically-guided approach readily extensible to other structured medical imaging applications.

Abstract: Mixture-of-Experts (MoE) architectures have significantly contributed to
scalable machine learning by enabling specialized subnetworks to tackle complex
tasks efficiently. However, traditional MoE systems lack domain-specific
constraints essential for medical imaging, where anatomical structure and
regional disease heterogeneity strongly influence pathological patterns. Here,
we introduce Regional Expert Networks (REN), the first anatomically-informed
MoE framework tailored specifically for medical image classification. REN
leverages anatomical priors to train seven specialized experts, each dedicated
to distinct lung lobes and bilateral lung combinations, enabling precise
modeling of region-specific pathological variations. Multi-modal gating
mechanisms dynamically integrate radiomics biomarkers and deep learning (DL)
features (CNN, ViT, Mamba) to weight expert contributions optimally. Applied to
interstitial lung disease (ILD) classification, REN achieves consistently
superior performance: the radiomics-guided ensemble reached an average AUC of
0.8646 +/- 0.0467, a +12.5 percent improvement over the SwinUNETR baseline (AUC
0.7685, p = 0.031). Region-specific experts further revealed that lower-lobe
models achieved AUCs of 0.88-0.90, surpassing DL counterparts (CNN: 0.76-0.79)
and aligning with known disease progression patterns. Through rigorous
patient-level cross-validation, REN demonstrates strong generalizability and
clinical interpretability, presenting a scalable, anatomically-guided approach
readily extensible to other structured medical imaging applications.

</details>


### [265] [Unsupervised Active Learning via Natural Feature Progressive Framework](https://arxiv.org/abs/2510.04939)
*Yuxi Liu,Catherine Lalman,Yimin Yang*

Main category: cs.CV

TL;DR: NFPF is a novel Unsupervised Active Learning method that uses Specific Feature Learning Machine to measure sample importance and achieves performance comparable to supervised AL methods.


<details>
  <summary>Details</summary>
Motivation: Traditional Active Learning requires significant human involvement in iterative labeling, while existing Unsupervised Active Learning methods struggle with performance and robustness issues.

Method: Proposes Natural Feature Progressive Framework (NFPF) with Specific Feature Learning Machine (SFLM) to quantify sample importance and uses Reconstruction Difference metric for sample selection.

Result: NFPF significantly outperforms all established UAL methods and achieves performance on par with supervised AL methods on vision datasets, with enhanced robustness and better data distribution coverage.

Conclusion: NFPF revolutionizes sample importance measurement in UAL and provides a compelling alternative to traditional active learning approaches.

Abstract: The effectiveness of modern deep learning models is predicated on the
availability of large-scale, human-annotated datasets, a process that is
notoriously expensive and time-consuming. While Active Learning (AL) offers a
strategic solution by labeling only the most informative and representative
data, its iterative nature still necessitates significant human involvement.
Unsupervised Active Learning (UAL) presents an alternative by shifting the
annotation burden to a single, post-selection step. Unfortunately, prevailing
UAL methods struggle to achieve state-of-the-art performance. These approaches
typically rely on local, gradient-based scoring for sample importance
estimation, which not only makes them vulnerable to ambiguous and noisy data
but also hinders their capacity to select samples that adequately represent the
full data distribution. Moreover, their use of shallow, one-shot linear
selection falls short of a true UAL paradigm. In this paper, we propose the
Natural Feature Progressive Framework (NFPF), a UAL method that revolutionizes
how sample importance is measured. At its core, NFPF employs a Specific Feature
Learning Machine (SFLM) to effectively quantify each sample's contribution to
model performance. We further utilize the SFLM to define a powerful
Reconstruction Difference metric for initial sample selection. Our
comprehensive experiments show that NFPF significantly outperforms all
established UAL methods and achieves performance on par with supervised AL
methods on vision datasets. Detailed ablation studies and qualitative
visualizations provide compelling evidence for NFPF's superior performance,
enhanced robustness, and improved data distribution coverage.

</details>


### [266] [Bidirectional Mammogram View Translation with Column-Aware and Implicit 3D Conditional Diffusion](https://arxiv.org/abs/2510.04947)
*Xin Li,Kaixiang Yang,Qiang Li,Zhiwei Wang*

Main category: cs.CV

TL;DR: CA3D-Diff is a novel bidirectional mammogram view translation framework that uses conditional diffusion models with column-aware cross-attention and implicit 3D structure reconstruction to address the challenge of translating between CC and MLO views when one view is missing or corrupted.


<details>
  <summary>Details</summary>
Motivation: In clinical mammography workflows, one view (CC or MLO) may be missing, corrupted, or degraded due to acquisition errors or compression artifacts, limiting diagnostic effectiveness. View-to-view translation can help recover missing views and improve lesion alignment, but this is challenging due to large non-rigid deformations and tissue overlap in X-ray projections.

Method: Proposes CA3D-Diff framework with two key components: 1) Column-aware cross-attention mechanism that leverages geometric properties where anatomically corresponding regions lie in similar column positions across views, using Gaussian-decayed bias to emphasize local correlations; 2) Implicit 3D structure reconstruction module that back-projects noisy 2D latents into a coarse 3D feature volume based on breast-view projection geometry, which is refined and injected into the denoising UNet.

Result: Extensive experiments show CA3D-Diff achieves superior performance in bidirectional view translation tasks, outperforming state-of-the-art methods in visual fidelity and structural consistency. The synthesized views effectively improve single-view malignancy classification in screening settings.

Conclusion: The proposed CA3D-Diff framework demonstrates practical value in real-world diagnostics by enabling effective bidirectional mammogram view translation and improving downstream classification tasks, addressing the critical challenge of missing or corrupted views in clinical workflows.

Abstract: Dual-view mammography, including craniocaudal (CC) and mediolateral oblique
(MLO) projections, offers complementary anatomical views crucial for breast
cancer diagnosis. However, in real-world clinical workflows, one view may be
missing, corrupted, or degraded due to acquisition errors or compression
artifacts, limiting the effectiveness of downstream analysis. View-to-view
translation can help recover missing views and improve lesion alignment. Unlike
natural images, this task in mammography is highly challenging due to large
non-rigid deformations and severe tissue overlap in X-ray projections, which
obscure pixel-level correspondences. In this paper, we propose Column-Aware and
Implicit 3D Diffusion (CA3D-Diff), a novel bidirectional mammogram view
translation framework based on conditional diffusion model. To address
cross-view structural misalignment, we first design a column-aware
cross-attention mechanism that leverages the geometric property that
anatomically corresponding regions tend to lie in similar column positions
across views. A Gaussian-decayed bias is applied to emphasize local column-wise
correlations while suppressing distant mismatches. Furthermore, we introduce an
implicit 3D structure reconstruction module that back-projects noisy 2D latents
into a coarse 3D feature volume based on breast-view projection geometry. The
reconstructed 3D structure is refined and injected into the denoising UNet to
guide cross-view generation with enhanced anatomical awareness. Extensive
experiments demonstrate that CA3D-Diff achieves superior performance in
bidirectional tasks, outperforming state-of-the-art methods in visual fidelity
and structural consistency. Furthermore, the synthesized views effectively
improve single-view malignancy classification in screening settings,
demonstrating the practical value of our method in real-world diagnostics.

</details>


### [267] [SSDD: Single-Step Diffusion Decoder for Efficient Image Tokenization](https://arxiv.org/abs/2510.04961)
*Théophane Vallaeys,Jakob Verbeek,Matthieu Cord*

Main category: cs.CV

TL;DR: SSDD introduces a new pixel diffusion decoder architecture with transformer components and GAN-free training, using distillation to create an efficient single-step decoder that outperforms KL-VAE tokenizers in reconstruction quality and speed.


<details>
  <summary>Details</summary>
Motivation: Current KL-VAE tokenizers require adversarial losses and have limitations, while diffusion decoders need iterative sampling and still rely on adversarial training. The goal is to create a more principled, efficient tokenizer without these drawbacks.

Method: Developed a new pixel diffusion decoder architecture with transformer components, trained without adversarial losses. Used distillation to replicate diffusion decoder performance in a single-step decoder (SSDD).

Result: SSDD improves reconstruction FID from 0.87 to 0.50 with 1.4x higher throughput than KL-VAE. Preserves DiT generation quality with 3.8x faster sampling. Achieves higher reconstruction quality and faster sampling than KL-VAE.

Conclusion: SSDD is the first diffusion decoder optimized for single-step reconstruction without adversarial losses, serving as a drop-in replacement for KL-VAE to build higher-quality and faster generative models.

Abstract: Tokenizers are a key component of state-of-the-art generative image models,
extracting the most important features from the signal while reducing data
dimension and redundancy. Most current tokenizers are based on KL-regularized
variational autoencoders (KL-VAE), trained with reconstruction, perceptual and
adversarial losses. Diffusion decoders have been proposed as a more principled
alternative to model the distribution over images conditioned on the latent.
However, matching the performance of KL-VAE still requires adversarial losses,
as well as a higher decoding time due to iterative sampling. To address these
limitations, we introduce a new pixel diffusion decoder architecture for
improved scaling and training stability, benefiting from transformer components
and GAN-free training. We use distillation to replicate the performance of the
diffusion decoder in an efficient single-step decoder. This makes SSDD the
first diffusion decoder optimized for single-step reconstruction trained
without adversarial losses, reaching higher reconstruction quality and faster
sampling than KL-VAE. In particular, SSDD improves reconstruction FID from
$0.87$ to $0.50$ with $1.4\times$ higher throughput and preserve generation
quality of DiTs with $3.8\times$ faster sampling. As such, SSDD can be used as
a drop-in replacement for KL-VAE, and for building higher-quality and faster
generative models.

</details>


### [268] [ActiveMark: on watermarking of visual foundation models via massive activations](https://arxiv.org/abs/2510.04966)
*Anna Chistyakova,Mikhail Pautov*

Main category: cs.CV

TL;DR: Proposes a digital watermarking method for visual foundation models (VFMs) to protect intellectual property by embedding detectable watermarks in model outputs, enabling ownership verification even after fine-tuning.


<details>
  <summary>Details</summary>
Motivation: Protect VFM owners' intellectual property rights by preventing illegal redistribution, as current models lack reliable ownership verification tools.

Method: Fine-tune expressive layers of VFM with encoder-decoder network to embed digital watermarks into internal representations of input images.

Result: Method achieves low false detection rates for non-watermarked models and low false misdetection rates for watermarked models, even after fine-tuning.

Conclusion: Proposed approach provides effective ownership verification for VFMs through robust watermark embedding that persists through downstream fine-tuning.

Abstract: Being trained on large and vast datasets, visual foundation models (VFMs) can
be fine-tuned for diverse downstream tasks, achieving remarkable performance
and efficiency in various computer vision applications. The high computation
cost of data collection and training motivates the owners of some VFMs to
distribute them alongside the license to protect their intellectual property
rights. However, a dishonest user of the protected model's copy may illegally
redistribute it, for example, to make a profit. As a consequence, the
development of reliable ownership verification tools is of great importance
today, since such methods can be used to differentiate between a redistributed
copy of the protected model and an independent model. In this paper, we propose
an approach to ownership verification of visual foundation models by
fine-tuning a small set of expressive layers of a VFM along with a small
encoder-decoder network to embed digital watermarks into an internal
representation of a hold-out set of input images. Importantly, the watermarks
embedded remain detectable in the functional copies of the protected model,
obtained, for example, by fine-tuning the VFM for a particular downstream task.
Theoretically and experimentally, we demonstrate that the proposed method
yields a low probability of false detection of a non-watermarked model and a
low probability of false misdetection of a watermarked model.

</details>


### [269] [Latent Uncertainty Representations for Video-based Driver Action and Intention Recognition](https://arxiv.org/abs/2510.05006)
*Koen Vellenga,H. Joe Steinhauer,Jonas Andersson,Anders Sjögren*

Main category: cs.CV

TL;DR: Proposes latent uncertainty representation (LUR) and repulsively trained LUR (RLUR) methods for uncertainty estimation in deep neural networks, achieving comparable performance to probabilistic deep learning methods while being more efficient.


<details>
  <summary>Details</summary>
Motivation: Deep neural networks are increasingly used in safety-critical tasks in resource-constrained environments, but existing probabilistic deep learning methods for out-of-distribution detection have varying performance and can be computationally expensive.

Method: Extends pre-trained DNNs with transformation layers to produce multiple latent representations for uncertainty estimation, comparing LUR and RLUR against eight probabilistic deep learning methods across four video-based driver action and intention recognition datasets.

Result: LUR and RLUR achieve comparable in-distribution classification performance to other probabilistic approaches. For uncertainty-based OOD detection, LUR matches top-performing methods while being more efficient to train and easier to tune than approaches requiring Markov-Chain Monte Carlo sampling or repulsive training.

Conclusion: The proposed LUR method provides an efficient alternative to complex probabilistic deep learning approaches for uncertainty estimation and out-of-distribution detection in safety-critical applications.

Abstract: Deep neural networks (DNNs) are increasingly applied to safety-critical tasks
in resource-constrained environments, such as video-based driver action and
intention recognition. While last layer probabilistic deep learning (LL-PDL)
methods can detect out-of-distribution (OOD) instances, their performance
varies. As an alternative to last layer approaches, we propose extending
pre-trained DNNs with transformation layers to produce multiple latent
representations to estimate the uncertainty. We evaluate our latent uncertainty
representation (LUR) and repulsively trained LUR (RLUR) approaches against
eight PDL methods across four video-based driver action and intention
recognition datasets, comparing classification performance, calibration, and
uncertainty-based OOD detection. We also contribute 28,000 frame-level action
labels and 1,194 video-level intention labels for the NuScenes dataset. Our
results show that LUR and RLUR achieve comparable in-distribution
classification performance to other LL-PDL approaches. For uncertainty-based
OOD detection, LUR matches top-performing PDL methods while being more
efficient to train and easier to tune than approaches that require Markov-Chain
Monte Carlo sampling or repulsive training procedures.

</details>


### [270] [Exploring the Efficacy of Modified Transfer Learning in Identifying Parkinson's Disease Through Drawn Image Patterns](https://arxiv.org/abs/2510.05015)
*Nabil Daiyan,Md Rakibul Haque*

Main category: cs.CV

TL;DR: Machine learning approach using hand-drawn spiral and wave images achieves 93.3% accuracy for Parkinson's disease detection through CNN, transfer learning, and ensemble voting.


<details>
  <summary>Details</summary>
Motivation: Early PD diagnosis is crucial but traditional methods are cumbersome and costly. Hand-drawn images offer non-invasive biomarkers for detection.

Method: Three-phase architecture: pre-trained CNNs, custom convolutional layers, and ensemble voting with hard voting. Dataset augmentation for spiral and wave images.

Result: Spiral images: 90% precision/recall/F1-score; Wave images: 96.67%; Combined ensemble voting: 93.3% overall accuracy.

Conclusion: Machine learning with hand-drawn images shows strong potential for non-invasive, cost-effective early PD diagnosis.

Abstract: Parkinson's disease (PD) is a progressive neurodegenerative condition
characterized by the death of dopaminergic neurons, leading to various movement
disorder symptoms. Early diagnosis of PD is crucial to prevent adverse effects,
yet traditional diagnostic methods are often cumbersome and costly. In this
study, a machine learning-based approach is proposed using hand-drawn spiral
and wave images as potential biomarkers for PD detection. Our methodology
leverages convolutional neural networks (CNNs), transfer learning, and
attention mechanisms to improve model performance and resilience against
overfitting. To enhance the diversity and richness of both spiral and wave
categories, the training dataset undergoes augmentation to increase the number
of images. The proposed architecture comprises three phases: utilizing
pre-trained CNNs, incorporating custom convolutional layers, and ensemble
voting. Employing hard voting further enhances performance by aggregating
predictions from multiple models. Experimental results show promising accuracy
rates. For spiral images, weighted average precision, recall, and F1-score are
90%, and for wave images, they are 96.67%. After combining the predictions
through ensemble hard voting, the overall accuracy is 93.3%. These findings
underscore the potential of machine learning in early PD diagnosis, offering a
non-invasive and cost-effective solution to improve patient outcomes.

</details>


### [271] [Video-LMM Post-Training: A Deep Dive into Video Reasoning with Large Multimodal Models](https://arxiv.org/abs/2510.05034)
*Yunlong Tang,Jing Bi,Pinxin Liu,Zhenyu Pan,Zhangyun Tan,Qianxiang Shen,Jiani Liu,Hang Hua,Junjia Guo,Yunzhong Xiao,Chao Huang,Zhiyuan Wang,Susan Liang,Xinyi Liu,Yizhi Song,Yuhe Nie,Jia-Xing Zhong,Bozheng Li,Daiqing Qi,Ziyun Zeng,Ali Vosoughi,Luchuan Song,Zeliang Zhang,Daiki Shimada,Han Liu,Jiebo Luo,Chenliang Xu*

Main category: cs.CV

TL;DR: This survey provides the first comprehensive examination of post-training methodologies for Video-Large Multimodal Models (Video-LMMs), covering supervised fine-tuning, reinforcement learning, and test-time scaling techniques to enhance video understanding capabilities.


<details>
  <summary>Details</summary>
Motivation: Video understanding is challenging due to complex spatiotemporal relationships and long-term dependencies. While Video-LMMs show promise, the post-training phase that transforms them from basic perception to sophisticated reasoning engines remains fragmented in literature.

Method: The survey examines three fundamental post-training pillars: supervised fine-tuning (SFT) with chain-of-thought, reinforcement learning (RL) from verifiable objectives, and test-time scaling (TTS) through enhanced inference computation. It presents a structured taxonomy addressing video-specific challenges.

Result: The paper synthesizes key design principles, insights, and evaluation protocols while identifying critical open challenges in reward design, scalability, and cost-performance optimization. It also curates essential benchmarks, datasets, and metrics for rigorous assessment.

Conclusion: This survey aims to provide researchers and practitioners with a unified framework for advancing Video-LMM capabilities through systematic post-training methodologies.

Abstract: Video understanding represents the most challenging frontier in computer
vision, requiring models to reason about complex spatiotemporal relationships,
long-term dependencies, and multimodal evidence. The recent emergence of
Video-Large Multimodal Models (Video-LMMs), which integrate visual encoders
with powerful decoder-based language models, has demonstrated remarkable
capabilities in video understanding tasks. However, the critical phase that
transforms these models from basic perception systems into sophisticated
reasoning engines, post-training, remains fragmented across the literature.
This survey provides the first comprehensive examination of post-training
methodologies for Video-LMMs, encompassing three fundamental pillars:
supervised fine-tuning (SFT) with chain-of-thought, reinforcement learning (RL)
from verifiable objectives, and test-time scaling (TTS) through enhanced
inference computation. We present a structured taxonomy that clarifies the
roles, interconnections, and video-specific adaptations of these techniques,
addressing unique challenges such as temporal localization, spatiotemporal
grounding, long video efficiency, and multimodal evidence integration. Through
systematic analysis of representative methods, we synthesize key design
principles, insights, and evaluation protocols while identifying critical open
challenges in reward design, scalability, and cost-performance optimization. We
further curate essential benchmarks, datasets, and metrics to facilitate
rigorous assessment of post-training effectiveness. This survey aims to provide
researchers and practitioners with a unified framework for advancing Video-LMM
capabilities. Additional resources and updates are maintained at:
https://github.com/yunlong10/Awesome-Video-LMM-Post-Training

</details>


### [272] [SegMASt3R: Geometry Grounded Segment Matching](https://arxiv.org/abs/2510.05051)
*Rohit Jayanti,Swayam Agrawal,Vansh Garg,Siddharth Tourani,Muhammad Haris Khan,Sourav Garg,Madhava Krishna*

Main category: cs.CV

TL;DR: The paper proposes a segment matching method using 3D foundation models to handle wide-baseline matching with extreme viewpoint changes up to 180 degrees, outperforming state-of-the-art methods by up to 30% on AUPRC metric.


<details>
  <summary>Details</summary>
Motivation: Segment matching provides robustness to occlusions, lighting variations, and viewpoint changes compared to keypoint matching, but wide-baseline segment matching with extreme viewpoint shifts remains challenging.

Method: An architecture leveraging the spatial understanding and inductive bias of 3D foundation models to match segments across image pairs with extreme viewpoint changes.

Result: Outperforms state-of-the-art methods (SAM2 video propagator and local feature matching) by up to 30% on AUPRC metric on ScanNet++ and Replica datasets, and shows benefits on downstream tasks like 3D instance segmentation and image-goal navigation.

Conclusion: The proposed approach successfully tackles wide-baseline segment matching using 3D foundation models, demonstrating significant performance improvements and practical utility in downstream applications.

Abstract: Segment matching is an important intermediate task in computer vision that
establishes correspondences between semantically or geometrically coherent
regions across images. Unlike keypoint matching, which focuses on localized
features, segment matching captures structured regions, offering greater
robustness to occlusions, lighting variations, and viewpoint changes. In this
paper, we leverage the spatial understanding of 3D foundation models to tackle
wide-baseline segment matching, a challenging setting involving extreme
viewpoint shifts. We propose an architecture that uses the inductive bias of
these 3D foundation models to match segments across image pairs with up to 180
degree view-point change. Extensive experiments show that our approach
outperforms state-of-the-art methods, including the SAM2 video propagator and
local feature matching methods, by upto 30% on the AUPRC metric, on ScanNet++
and Replica datasets. We further demonstrate benefits of the proposed model on
relevant downstream tasks, including 3D instance segmentation and image-goal
navigation. Project Page: https://segmast3r.github.io/

</details>


### [273] [No-reference Quality Assessment of Contrast-distorted Images using Contrast-enhanced Pseudo Reference](https://arxiv.org/abs/2510.05053)
*Mohammad-Ali Mahmoudpour,Saeed Mahmoudpour*

Main category: cs.CV

TL;DR: A no-reference image quality assessment method for contrast-distorted images that transforms the problem into full-reference assessment by generating pseudo-reference images using contrast enhancement algorithms.


<details>
  <summary>Details</summary>
Motivation: Contrast distortion has been largely overlooked in image quality assessment despite its significant impact on visual quality, and existing methods mainly focus on other distortions like blur and noise.

Method: Generate pseudo-reference images using contrast enhancement algorithms, train a classification network to select the most suitable algorithm based on image content and distortion, then perform full-reference assessment between contrast-enhanced and degraded images.

Result: Performance evaluation on three databases (CCID2014, TID2013, and CSIQ) shows promising performance of the proposed method.

Conclusion: The proposed NR-IQA method effectively addresses contrast distortion assessment by transforming it into a full-reference problem through pseudo-reference image generation.

Abstract: Contrast change is an important factor that affects the quality of images.
During image capturing, unfavorable lighting conditions can cause contrast
change and visual quality loss. While various methods have been proposed to
assess the quality of images under different distortions such as blur and
noise, contrast distortion has been largely overlooked as its visual impact and
properties are different from other conventional types of distortions. In this
paper, we propose a no-reference image quality assessment (NR-IQA) metric for
contrast-distorted images. Using a set of contrast enhancement algorithms, we
aim to generate pseudo-reference images that are visually close to the actual
reference image, such that the NR problem is transformed to a Full-reference
(FR) assessment with higher accuracy. To this end, a large dataset of
contrast-enhanced images is produced to train a classification network that can
select the most suitable contrast enhancement algorithm based on image content
and distortion for pseudo-reference image generation. Finally, the evaluation
is performed in the FR manner to assess the quality difference between the
contrast-enhanced (pseudoreference) and degraded images. Performance evaluation
of the proposed method on three databases containing contrast distortions
(CCID2014, TID2013, and CSIQ), indicates the promising performance of the
proposed method.

</details>


### [274] [Neuroplastic Modular Framework: Cross-Domain Image Classification of Garbage and Industrial Surfaces](https://arxiv.org/abs/2510.05071)
*Debojyoti Ghosh,Soumya K Ghosh,Adrijit Goswami*

Main category: cs.CV

TL;DR: The paper introduces a Neuroplastic Modular Classifier for waste and industrial defect classification, combining ResNet-50 and Vision Transformer with FAISS-based similarity retrieval and expandable modules that grow during training.


<details>
  <summary>Details</summary>
Motivation: Efficient and accurate classification of waste and industrial surface defects is essential for sustainable waste management and quality control in dynamic environments.

Method: Hybrid architecture with ResNet-50 backbone for local features, Vision Transformer for global context, FAISS-based similarity retrieval, and neuroplastic modular design with expandable blocks that grow during training when performance plateaus.

Result: Outperforms traditional static models in both accuracy and adaptability across domains including garbage classification and KolektorSDD2 industrial defect detection.

Conclusion: The Neuroplastic Modular Classifier offers a scalable, high-performance solution for real-world image classification with strong applicability in environmental and industrial domains.

Abstract: Efficient and accurate classification of waste and industrial surface defects
is essential for ensuring sustainable waste management and maintaining high
standards in quality control. This paper introduces the Neuroplastic Modular
Classifier, a novel hybrid architecture designed for robust and adaptive image
classification in dynamic environments. The model combines a ResNet-50 backbone
for localized feature extraction with a Vision Transformer (ViT) to capture
global semantic context. Additionally, FAISS-based similarity retrieval is
incorporated to provide a memory-like reference to previously encountered data,
enriching the model's feature space. A key innovation of our architecture is
the neuroplastic modular design composed of expandable, learnable blocks that
dynamically grow during training when performance plateaus. Inspired by
biological learning systems, this mechanism allows the model to adapt to data
complexity over time, improving generalization. Beyond garbage classification,
we validate the model on the Kolektor Surface Defect Dataset 2 (KolektorSDD2),
which involves industrial defect detection on metal surfaces. Experimental
results across domains show that the proposed architecture outperforms
traditional static models in both accuracy and adaptability. The Neuroplastic
Modular Classifier offers a scalable, high-performance solution for real-world
image classification, with strong applicability in both environmental and
industrial domains.

</details>


### [275] [Factuality Matters: When Image Generation and Editing Meet Structured Visuals](https://arxiv.org/abs/2510.05091)
*Le Zhuo,Songhao Han,Yuandong Pu,Boxiang Qiu,Sayak Paul,Yue Liao,Yihao Liu,Jie Shao,Xi Chen,Si Liu,Hongsheng Li*

Main category: cs.CV

TL;DR: This paper presents a comprehensive framework for generating and editing structured visuals like charts and diagrams, addressing limitations of current models through a large dataset, unified model training, and a novel evaluation benchmark.


<details>
  <summary>Details</summary>
Motivation: Modern visual generation models struggle with structured visuals that require composition planning, text rendering, and factual fidelity, creating a gap in generating accurate charts, diagrams, and mathematical figures.

Method: Constructed 1.3M structured image pairs from executable drawing programs with chain-of-thought annotations; trained unified model combining VLM with FLUX.1 Kontext via lightweight connector; used three-stage training curriculum for progressive feature alignment and reasoning-augmented generation; employed external reasoner at inference.

Result: Evaluations of 15 models show leading closed-source systems remain unsatisfactory; their model achieves strong editing performance with consistent gains from inference-time reasoning across diverse architectures.

Conclusion: The released dataset, model, and benchmark advance unified multimodal foundations for structured visuals, addressing key challenges in factual accuracy and reasoning for visual generation.

Abstract: While modern visual generation models excel at creating aesthetically
pleasing natural images, they struggle with producing or editing structured
visuals like charts, diagrams, and mathematical figures, which demand
composition planning, text rendering, and multimodal reasoning for factual
fidelity. To address this, we present the first comprehensive, systematic
investigation of this domain, encompassing data construction, model training,
and an evaluation benchmark. First, we construct a large-scale dataset of 1.3
million high-quality structured image pairs derived from executable drawing
programs and augmented with chain-of-thought reasoning annotations. Building on
it, we train a unified model that integrates a VLM with FLUX.1 Kontext via a
lightweight connector for enhanced multimodal understanding. A three-stage
training curriculum enables progressive feature alignment, knowledge infusion,
and reasoning-augmented generation, further boosted by an external reasoner at
inference time. Finally, we introduce StructBench, a novel benchmark for
generation and editing with over 1,700 challenging instances, and an
accompanying evaluation metric, StructScore, which employs a multi-round Q\&A
protocol to assess fine-grained factual accuracy. Evaluations of 15 models
reveal that even leading closed-source systems remain far from satisfactory.
Our model attains strong editing performance, and inference-time reasoning
yields consistent gains across diverse architectures. By releasing the dataset,
model, and benchmark, we aim to advance unified multimodal foundations for
structured visuals.

</details>


### [276] [Character Mixing for Video Generation](https://arxiv.org/abs/2510.05093)
*Tingting Liao,Chongjian Ge,Guangyi Liu,Hao Li,Yi Zhou*

Main category: cs.CV

TL;DR: A framework for generating videos where characters from different worlds interact naturally while preserving their original identities and styles, using Cross-Character Embedding and Cross-Character Augmentation techniques.


<details>
  <summary>Details</summary>
Motivation: To enable natural interactions between characters from different contexts (e.g., Mr. Bean meeting Tom and Jerry) while preserving each character's identity and avoiding style delusion issues.

Method: Uses Cross-Character Embedding (CCE) to learn identity and behavioral logic across multimodal sources, and Cross-Character Augmentation (CCA) to enrich training with synthetic co-existence and mixed-style data.

Result: Experiments on 10 characters from cartoons and live-action series show improvements in identity preservation, interaction quality, and robustness to style delusion.

Conclusion: The framework enables new forms of generative storytelling by allowing natural interactions between previously uncoexistent characters without losing stylistic fidelity.

Abstract: Imagine Mr. Bean stepping into Tom and Jerry--can we generate videos where
characters interact naturally across different worlds? We study inter-character
interaction in text-to-video generation, where the key challenge is to preserve
each character's identity and behaviors while enabling coherent cross-context
interaction. This is difficult because characters may never have coexisted and
because mixing styles often causes style delusion, where realistic characters
appear cartoonish or vice versa. We introduce a framework that tackles these
issues with Cross-Character Embedding (CCE), which learns identity and
behavioral logic across multimodal sources, and Cross-Character Augmentation
(CCA), which enriches training with synthetic co-existence and mixed-style
data. Together, these techniques allow natural interactions between previously
uncoexistent characters without losing stylistic fidelity. Experiments on a
curated benchmark of cartoons and live-action series with 10 characters show
clear improvements in identity preservation, interaction quality, and
robustness to style delusion, enabling new forms of generative
storytelling.Additional results and videos are available on our project page:
https://tingtingliao.github.io/mimix/.

</details>


### [277] [VChain: Chain-of-Visual-Thought for Reasoning in Video Generation](https://arxiv.org/abs/2510.05094)
*Ziqi Huang,Ning Yu,Gordon Chen,Haonan Qiu,Paul Debevec,Ziwei Liu*

Main category: cs.CV

TL;DR: VChain is a chain-of-visual-thought framework that uses multimodal models to generate critical keyframes, then guides sparse tuning of video generators at these key moments to improve complex dynamic synthesis.


<details>
  <summary>Details</summary>
Motivation: Current video generation models struggle with complex dynamics and coherent chains of consequences, while multimodal models have strong visual state reasoning capabilities that could help bridge this gap.

Method: Leverages large multimodal models to generate sparse critical keyframes as snapshots, then performs sparse inference-time tuning of pre-trained video generators only at these key moments.

Result: Significantly enhances the quality of generated videos in complex, multi-step scenarios while being tuning-efficient with minimal overhead.

Conclusion: VChain successfully bridges multimodal models' reasoning strengths with video generation, improving complex dynamic synthesis through sparse keyframe guidance.

Abstract: Recent video generation models can produce smooth and visually appealing
clips, but they often struggle to synthesize complex dynamics with a coherent
chain of consequences. Accurately modeling visual outcomes and state
transitions over time remains a core challenge. In contrast, large language and
multimodal models (e.g., GPT-4o) exhibit strong visual state reasoning and
future prediction capabilities. To bridge these strengths, we introduce VChain,
a novel inference-time chain-of-visual-thought framework that injects visual
reasoning signals from multimodal models into video generation. Specifically,
VChain contains a dedicated pipeline that leverages large multimodal models to
generate a sparse set of critical keyframes as snapshots, which are then used
to guide the sparse inference-time tuning of a pre-trained video generator only
at these key moments. Our approach is tuning-efficient, introduces minimal
overhead and avoids dense supervision. Extensive experiments on complex,
multi-step scenarios show that VChain significantly enhances the quality of
generated videos.

</details>


### [278] [Paper2Video: Automatic Video Generation from Scientific Papers](https://arxiv.org/abs/2510.05096)
*Zeyu Zhu,Kevin Qinghong Lin,Mike Zheng Shou*

Main category: cs.CV

TL;DR: PaperTalker is a multi-agent framework for automated academic presentation video generation, addressing the labor-intensive process of creating research presentation videos by integrating slide generation, layout refinement, subtitling, speech synthesis, and talking-head rendering.


<details>
  <summary>Details</summary>
Motivation: Academic presentation video production is highly labor-intensive, requiring hours of work for short videos. Existing methods don't adequately handle the distinctive challenges of research presentation videos, which involve inputs from research papers, dense multi-modal information, and coordination of multiple aligned channels.

Method: Proposes PaperTalker, a multi-agent framework that integrates slide generation with layout refinement using novel tree search visual choice, cursor grounding, subtitling, speech synthesis, and talking-head rendering. Uses parallel slide-wise generation for efficiency and is built on a benchmark of 101 research papers with author-created presentation materials.

Result: Experiments on Paper2Video dataset show that the presentation videos produced by PaperTalker are more faithful and informative than existing baselines, establishing a practical step toward automated academic video generation.

Conclusion: PaperTalker provides an effective solution for automated academic presentation video generation, with the framework, dataset, and code made publicly available to advance research in this area.

Abstract: Academic presentation videos have become an essential medium for research
communication, yet producing them remains highly labor-intensive, often
requiring hours of slide design, recording, and editing for a short 2 to 10
minutes video. Unlike natural video, presentation video generation involves
distinctive challenges: inputs from research papers, dense multi-modal
information (text, figures, tables), and the need to coordinate multiple
aligned channels such as slides, subtitles, speech, and human talker. To
address these challenges, we introduce PaperTalker, the first benchmark of 101
research papers paired with author-created presentation videos, slides, and
speaker metadata. We further design four tailored evaluation metrics--Meta
Similarity, PresentArena, PresentQuiz, and IP Memory--to measure how videos
convey the paper's information to the audience. Building on this foundation, we
propose PaperTalker, the first multi-agent framework for academic presentation
video generation. It integrates slide generation with effective layout
refinement by a novel effective tree search visual choice, cursor grounding,
subtitling, speech synthesis, and talking-head rendering, while parallelizing
slide-wise generation for efficiency. Experiments on Paper2Video demonstrate
that the presentation videos produced by our approach are more faithful and
informative than existing baselines, establishing a practical step toward
automated and ready-to-use academic video generation. Our dataset, agent, and
code are available at https://github.com/showlab/Paper2Video.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [279] [MacroBench: A Novel Testbed for Web Automation Scripts via Large Language Models](https://arxiv.org/abs/2510.04363)
*Hyunjun Kim,Sejong Kim*

Main category: cs.SE

TL;DR: MacroBench is a code-first benchmark that evaluates LLMs' ability to synthesize reusable browser automation programs from natural language goals using HTML/DOM reading and Python/Selenium output.


<details>
  <summary>Details</summary>
Motivation: To assess whether LLMs can create reusable browser automation programs from natural language instructions by reading web page structures and generating executable code.

Method: Uses seven self-hosted sites (Airbnb, TikTok, Reddit, Instagram, Facebook, Discord, Threads clones) with 681 tasks across interaction complexity levels. Validates generated code through static checks, sandboxed execution, DOM assertions, and database snapshots with safety measures.

Result: GPT-4o-Mini achieved 96.8% success, GPT-4.1 95.3%, Gemini-2.5-Pro 89.0%, DeepSeek-V3.1 83.4%. Models handle simple tasks at 91.7% but fail completely on complex workflows (0.0%). None meet production-quality coding standards despite functional completion.

Conclusion: LLMs show stratified performance on web automation tasks, excelling at simple tasks but failing on complex workflows. The benchmark enables reproducible assessment of macro synthesis for web automation.

Abstract: We introduce MacroBench, a code-first benchmark that evaluates whether LLMs
can synthesize reusable browser automation programs from natural language goals
by reading HTML/DOM and emitting Python with Selenium. MacroBench instantiates
seven self-hosted sites: Airbnb-like, TikTok-like, Reddit-like, Instagram-like,
Facebook-like, Discord-like, and Threads-like, covering 681 tasks across
interaction complexity and targeting difficulty. Our end-to-end protocol
validates generated code via static checks, sandboxed execution, and outcome
verification including DOM assertions and database snapshots, and includes a
safety suite for scraping, spam/abuse, and credential/privacy prompts. Across
2636 model-task runs, we observe stratified success: GPT-4o-Mini achieves 96.8
percent, GPT-4.1 achieves 95.3 percent, Gemini-2.5-Pro achieves 89.0 percent,
and DeepSeek-V3.1 achieves 83.4 percent. Models handle simple tasks reliably at
91.7 percent but fail on complex workflows at 0.0 percent, and none meet
production-quality coding practices despite functional completion. We release
our complete benchmark pipeline, evaluation framework, and experimental results
to enable reproducible assessment of macro synthesis for web automation.

</details>


### [280] [Retrieval-Augmented Code Generation: A Survey with Focus on Repository-Level Approaches](https://arxiv.org/abs/2510.04905)
*Yicheng Tao,Yao Qin,Yepang Liu*

Main category: cs.SE

TL;DR: A comprehensive survey of Retrieval-Augmented Code Generation (RACG) focusing on repository-level approaches, categorizing existing work across multiple dimensions and analyzing current limitations and future opportunities.


<details>
  <summary>Details</summary>
Motivation: Real-world software development requires reasoning across entire repositories, but current function/file-level code generation lacks the ability to handle long-range dependencies and global semantic consistency needed for repository-level code generation.

Method: The survey categorizes existing RACG research along dimensions including generation strategies, retrieval modalities, model architectures, training paradigms, and evaluation protocols, while summarizing datasets and benchmarks.

Result: Establishes a unified analytical framework for understanding Retrieval-Augmented Code Generation, particularly at the repository level, and identifies current limitations in the field.

Conclusion: The survey aims to inspire continued progress in AI-powered software engineering by providing comprehensive analysis of RACG approaches and outlining key challenges and opportunities for future research.

Abstract: Recent advancements in large language models (LLMs) have substantially
improved automated code generation. While function-level and file-level
generation have achieved promising results, real-world software development
typically requires reasoning across entire repositories. This gives rise to the
challenging task of Repository-Level Code Generation (RLCG), where models must
capture long-range dependencies, ensure global semantic consistency, and
generate coherent code spanning multiple files or modules. To address these
challenges, Retrieval-Augmented Generation (RAG) has emerged as a powerful
paradigm that integrates external retrieval mechanisms with LLMs, enhancing
context-awareness and scalability. In this survey, we provide a comprehensive
review of research on Retrieval-Augmented Code Generation (RACG), with an
emphasis on repository-level approaches. We categorize existing work along
several dimensions, including generation strategies, retrieval modalities,
model architectures, training paradigms, and evaluation protocols. Furthermore,
we summarize widely used datasets and benchmarks, analyze current limitations,
and outline key challenges and opportunities for future research. Our goal is
to establish a unified analytical framework for understanding this rapidly
evolving field and to inspire continued progress in AI-powered software
engineering.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [281] [Lightweight Prompt Engineering for Cognitive Alignment in Educational AI: A OneClickQuiz Case Study](https://arxiv.org/abs/2510.03374)
*Antoun Yaacoub,Zainab Assaghir,Jérôme Da-Rugna*

Main category: cs.CY

TL;DR: Lightweight prompt engineering strategies significantly impact cognitive alignment of AI-generated questions in educational settings, with detailed prompts outperforming simpler and persona-based approaches for precise Bloom's Taxonomy alignment.


<details>
  <summary>Details</summary>
Motivation: To address the critical challenges of quality and pedagogical alignment in AI-generated educational content, particularly for cognitive level accuracy in automated question generation.

Method: Evaluated three prompt variants (detailed baseline, simpler version, persona-based) across Bloom's Taxonomy levels using OneClickQuiz Moodle plugin, with automated classification and human review.

Result: Explicit, detailed prompts achieved precise cognitive alignment, while simpler and persona-based prompts frequently misaligned with intended Bloom's levels, generating outputs that were either too complex or deviated from desired cognitive objectives.

Conclusion: Strategic prompt engineering is crucial for pedagogically sound AI-driven educational solutions, emphasizing the need for optimized AI content generation in learning analytics and smart learning environments.

Abstract: The rapid integration of Artificial Intelligence (AI) into educational
technology promises to revolutionize content creation and assessment. However,
the quality and pedagogical alignment of AI-generated content remain critical
challenges. This paper investigates the impact of lightweight prompt
engineering strategies on the cognitive alignment of AI-generated questions
within OneClickQuiz, a Moodle plugin leveraging generative AI. We evaluate
three prompt variants-a detailed baseline, a simpler version, and a
persona-based approach-across Knowledge, Application, and Analysis levels of
Bloom's Taxonomy. Utilizing an automated classification model (from prior work)
and human review, our findings demonstrate that explicit, detailed prompts are
crucial for precise cognitive alignment. While simpler and persona-based
prompts yield clear and relevant questions, they frequently misalign with
intended Bloom's levels, generating outputs that are either too complex or
deviate from the desired cognitive objective. This study underscores the
importance of strategic prompt engineering in fostering pedagogically sound
AI-driven educational solutions and advises on optimizing AI for quality
content generation in learning analytics and smart learning environments.

</details>


### [282] [Red Lines and Grey Zones in the Fog of War: Benchmarking Legal Risk, Moral Harm, and Regional Bias in Large Language Model Military Decision-Making](https://arxiv.org/abs/2510.03514)
*Toby Drinkall*

Main category: cs.CY

TL;DR: LLMs exhibit concerning targeting behavior in military simulations, violating international law principles with civilian strike rates up to 66.7% and escalating civilian harm tolerance.


<details>
  <summary>Details</summary>
Motivation: To understand behavioral tendencies of LLMs when integrated into military command and control systems for planning and decision support, assessing legal and moral risks in targeting behavior.

Method: Developed benchmarking framework with 4 IHL-based metrics, evaluated 3 frontier models (GPT-4o, Gemini-2.5, LLaMA-3.1) through 90 multi-agent, multi-turn crisis simulations across 3 geographic regions.

Result: All models violated IHL distinction principle with civilian target rates 16.7%-66.7%. Civilian harm tolerance escalated (MeanSNCV increased from 16.5 to 27.7). Significant model variation: LLaMA-3.1 had 3.47 civilian strikes/simulation vs Gemini-2.5's 0.90.

Conclusion: Model selection for military deployment constitutes a choice about acceptable legal and moral risk profiles. Provides proof-of-concept of behavioral risks and reproducible benchmarking framework for pre-deployment testing.

Abstract: As military organisations consider integrating large language models (LLMs)
into command and control (C2) systems for planning and decision support,
understanding their behavioural tendencies is critical. This study develops a
benchmarking framework for evaluating aspects of legal and moral risk in
targeting behaviour by comparing LLMs acting as agents in multi-turn simulated
conflict. We introduce four metrics grounded in International Humanitarian Law
(IHL) and military doctrine: Civilian Target Rate (CTR) and Dual-use Target
Rate (DTR) assess compliance with legal targeting principles, while Mean and
Max Simulated Non-combatant Casualty Value (SNCV) quantify tolerance for
civilian harm.
  We evaluate three frontier models, GPT-4o, Gemini-2.5, and LLaMA-3.1, through
90 multi-agent, multi-turn crisis simulations across three geographic regions.
Our findings reveal that off-the-shelf LLMs exhibit concerning and
unpredictable targeting behaviour in simulated conflict environments. All
models violated the IHL principle of distinction by targeting civilian objects,
with breach rates ranging from 16.7% to 66.7%. Harm tolerance escalated through
crisis simulations with MeanSNCV increasing from 16.5 in early turns to 27.7 in
late turns. Significant inter-model variation emerged: LLaMA-3.1 selected an
average of 3.47 civilian strikes per simulation with MeanSNCV of 28.4, while
Gemini-2.5 selected 0.90 civilian strikes with MeanSNCV of 17.6. These
differences indicate that model selection for deployment constitutes a choice
about acceptable legal and moral risk profiles in military operations.
  This work seeks to provide a proof-of-concept of potential behavioural risks
that could emerge from the use of LLMs in Decision Support Systems (AI DSS) as
well as a reproducible benchmarking framework with interpretable metrics for
standardising pre-deployment testing.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [283] [CAG: Chunked Augmented Generation for Google Chrome's Built-in Gemini Nano](https://arxiv.org/abs/2412.18708)
*Vivek Vellaiyappan Surulimuthu,Aditya Karnam Gururaj Rao*

Main category: cs.AI

TL;DR: Chunked Augmented Generation (CAG) is an architecture that overcomes context window limitations of Chrome's Gemini Nano model through intelligent input chunking, enabling efficient processing of large documents directly in the browser.


<details>
  <summary>Details</summary>
Motivation: Chrome's integration of Gemini Nano brings AI to browsers but has restricted context windows that limit processing of large inputs, creating challenges for handling extensive content.

Method: CAG uses intelligent input chunking and processing strategies to break down large inputs into manageable pieces while maintaining model performance within browser constraints.

Result: The implementation effectively processes large documents and datasets directly within Chrome, making sophisticated AI capabilities accessible through the browser without external API dependencies.

Conclusion: CAG successfully addresses context window limitations of browser-based AI models, enabling practical processing of extensive content directly within Chrome while maintaining performance.

Abstract: We present Chunked Augmented Generation (CAG), an architecture specifically
designed to overcome the context window limitations of Google Chrome's built-in
Gemini Nano model. While Chrome's integration of Gemini Nano represents a
significant advancement in bringing AI capabilities directly to the browser,
its restricted context window poses challenges for processing large inputs. CAG
addresses this limitation through intelligent input chunking and processing
strategies, enabling efficient handling of extensive content while maintaining
the model's performance within browser constraints. Our implementation
demonstrates particular efficacy in processing large documents and datasets
directly within Chrome, making sophisticated AI capabilities accessible through
the browser without external API dependencies. Get started now at
https://github.com/vivekVells/cag-js.

</details>


### [284] [Know Thyself? On the Incapability and Implications of AI Self-Recognition](https://arxiv.org/abs/2510.03399)
*Xiaoyan Bai,Aryan Shrivastava,Ari Holtzman,Chenhao Tan*

Main category: cs.AI

TL;DR: This paper evaluates self-recognition capabilities in 10 contemporary LLMs, finding consistent failure in identifying their own generated text, with performance rarely above random chance and strong bias toward predicting GPT and Claude models.


<details>
  <summary>Details</summary>
Motivation: Address contradictory claims about whether models possess self-recognition capabilities, which is crucial for AI safety and metacognitive analysis.

Method: Systematic evaluation framework with two tasks: binary self-recognition (identifying own vs. other models' text) and exact model prediction, applied to 10 contemporary LLMs.

Result: Only 4/10 models predicted themselves as generators; performance rarely above random chance; strong bias toward predicting GPT and Claude families; models show some awareness of own and others' existence but reasoning reveals hierarchical bias associating high-quality text with top-tier models.

Conclusion: Current LLMs demonstrate consistent failure in self-recognition with hierarchical biases, highlighting implications for AI safety and need to develop appropriate AI self-awareness.

Abstract: Self-recognition is a crucial metacognitive capability for AI systems,
relevant not only for psychological analysis but also for safety, particularly
in evaluative scenarios. Motivated by contradictory interpretations of whether
models possess self-recognition (Panickssery et al., 2024; Davidson et al.,
2024), we introduce a systematic evaluation framework that can be easily
applied and updated. Specifically, we measure how well 10 contemporary larger
language models (LLMs) can identify their own generated text versus text from
other models through two tasks: binary self-recognition and exact model
prediction. Different from prior claims, our results reveal a consistent
failure in self-recognition. Only 4 out of 10 models predict themselves as
generators, and the performance is rarely above random chance. Additionally,
models exhibit a strong bias toward predicting GPT and Claude families. We also
provide the first evaluation of model awareness of their own and others'
existence, as well as the reasoning behind their choices in self-recognition.
We find that the model demonstrates some knowledge of its own existence and
other models, but their reasoning reveals a hierarchical bias. They appear to
assume that GPT, Claude, and occasionally Gemini are the top-tier models, often
associating high-quality text with them. We conclude by discussing the
implications of our findings on AI safety and future directions to develop
appropriate AI self-awareness.

</details>


### [285] [Mind the Goal: Data-Efficient Goal-Oriented Evaluation of Conversational Agents and Chatbots using Teacher Models](https://arxiv.org/abs/2510.03696)
*Deepak Babu Piskala,Sharlene Chen,Udita Patel,Parul Kalra,Rafael Castrillo*

Main category: cs.AI

TL;DR: Proposes a goal-oriented evaluation framework for multi-agent chatbots using Goal Success Rate (GSR) and Root Cause of Failure (RCOF) taxonomy, with model-based evaluation using teacher LLMs that provide interpretable rationales.


<details>
  <summary>Details</summary>
Motivation: Existing methods evaluate chatbot interactions at turn level without assessing whether user's overarching goals were fulfilled, making comprehensive evaluation challenging.

Method: Segments conversations by user goals, evaluates success using all relevant turns, and uses teacher LLMs with thinking tokens to produce interpretable rationales for explainable, data-efficient evaluations.

Result: Applied to AIDA enterprise chatbot system, observed GSR improvement from 63% to 79% over six months, demonstrating framework effectiveness.

Conclusion: The framework provides generic, actionable insights through detailed defect taxonomy, enabling diagnosis of success, identification of failure modes, and informing system improvements for multi-agent chatbots.

Abstract: Evaluating the quality of multi-turn chatbot interactions remains
challenging, as most existing methods assess interactions at the turn level
without addressing whether a user's overarching goal was fulfilled. A ``goal''
here refers to an information need or task, such as asking for policy
information or applying for leave. We propose a comprehensive framework for
goal-oriented evaluation of multi-agent systems (MAS), introducing the
\textbf{Goal Success Rate (GSR)} to measure the percentage of fulfilled goals,
and a \textbf{Root Cause of Failure (RCOF)} taxonomy to identify reasons for
failure in multi-agent chatbots. Our method segments conversations by user
goals and evaluates success using all relevant turns. We present a model-based
evaluation system combining teacher LLMs, where domain experts define goals,
set quality standards serving as a guidance for the LLMs. The LLMs use
``thinking tokens'' to produce interpretable rationales, enabling
\textit{explainable}, \textit{data-efficient} evaluations. In an enterprise
setting, we apply our framework to evaluate AIDA, a zero-to-one employee
conversational agent system built as a ground-up multi-agent conversational
agent, and observe GSR improvement from 63\% to 79\% over six months since its
inception. Our framework is generic and offers actionable insights through a
detailed defect taxonomy based on analysis of failure points in multi-agent
chatbots, diagnosing overall success, identifying key failure modes, and
informing system improvements.

</details>


### [286] [Bridging the Gap Between Multimodal Foundation Models and World Models](https://arxiv.org/abs/2510.03727)
*Xuehai He*

Main category: cs.AI

TL;DR: The paper investigates how to bridge multimodal foundation models with world models by enhancing their reasoning and generative capabilities for better physical world understanding.


<details>
  <summary>Details</summary>
Motivation: Current multimodal foundation models lack essential world model abilities like counterfactual reasoning, dynamics simulation, spatiotemporal understanding, and controllable generation that humans naturally possess.

Method: Improves reasoning through discriminative tasks and structured reasoning skills (causal inference, counterfactual thinking, spatiotemporal reasoning), and enhances generative capabilities using scene graphs, multimodal conditioning, alignment strategies, and controllable 4D generation techniques.

Result: Developed approaches that enable multimodal foundation models to go beyond surface correlations and perform deeper reasoning, while achieving structured and controllable generation across image and video modalities with temporal and spatial consistency.

Conclusion: The research successfully bridges the gap between multimodal foundation models and world models by equipping them with advanced reasoning and generative capabilities needed for comprehensive world understanding and interaction.

Abstract: Humans understand the world through the integration of multiple sensory
modalities, enabling them to perceive, reason about, and imagine dynamic
physical processes. Inspired by this capability, multimodal foundation models
(MFMs) have emerged as powerful tools for multimodal understanding and
generation. However, today's MFMs fall short of serving as effective world
models. They lack the essential ability such as perform counterfactual
reasoning, simulate dynamics, understand the spatiotemporal information,
control generated visual outcomes, and perform multifaceted reasoning. We
investigates what it takes to bridge the gap between multimodal foundation
models and world models. We begin by improving the reasoning capabilities of
MFMs through discriminative tasks and equipping MFMs with structured reasoning
skills, such as causal inference, counterfactual thinking, and spatiotemporal
reasoning, enabling them to go beyond surface correlations and understand
deeper relationships within visual and textual data. Next, we explore
generative capabilities of multimodal foundation models across both image and
video modalities, introducing new frameworks for structured and controllable
generation. Our approaches incorporate scene graphs, multimodal conditioning,
and multimodal alignment strategies to guide the generation process, ensuring
consistency with high-level semantics and fine-grained user intent. We further
extend these techniques to controllable 4D generation, enabling interactive,
editable, and morphable object synthesis over time and space.

</details>


### [287] [Kantian-Utilitarian XAI: Meta-Explained](https://arxiv.org/abs/2510.03892)
*Zahra Atf,Peter R. Lewis*

Main category: cs.AI

TL;DR: A gamified XAI system for ethical coffee purchasing decisions using Kantian and utilitarian reasoning engines with real-time explanations and regret-based meta-explanation.


<details>
  <summary>Details</summary>
Motivation: To help consumers make ethically aware decisions in coffee purchasing by providing transparent, real-time explanations of ethical considerations.

Method: Six-round game with three options per round. Uses two symbolic engines: Kantian module flags rule violations (child labor, deforestation, etc.) and utilitarian module scores options via multi-criteria aggregation. Includes meta-explainer with regret bound to highlight alignment issues.

Result: Developed a complete system with structured configuration, policy trace for auditability, and interactive UI for ethical coffee decision-making.

Conclusion: The system successfully integrates multiple ethical frameworks to provide transparent, explainable guidance for consumer decision-making in the coffee domain.

Abstract: We present a gamified explainable AI (XAI) system for ethically aware
consumer decision-making in the coffee domain. Each session comprises six
rounds with three options per round. Two symbolic engines provide real-time
reasons: a Kantian module flags rule violations (e.g., child labor,
deforestation risk without shade certification, opaque supply chains, unsafe
decaf), and a utilitarian module scores options via multi-criteria aggregation
over normalized attributes (price, carbon, water, transparency, farmer income
share, taste/freshness, packaging, convenience). A meta-explainer with a regret
bound (0.2) highlights Kantian--utilitarian (mis)alignment and switches to a
deontically clean, near-parity option when welfare loss is small. We release a
structured configuration (attribute schema, certification map, weights, rule
set), a policy trace for auditability, and an interactive UI.

</details>


### [288] [What Shapes a Creative Machine Mind? Comprehensively Benchmarking Creativity in Foundation Models](https://arxiv.org/abs/2510.04009)
*Zicong He,Boxuan Zhang,Weihao Liu,Ruixiang Tang,Lu Cheng*

Main category: cs.AI

TL;DR: C^2-Eval is a holistic benchmark for unified assessment of creativity in foundation models, distinguishing between convergent (constrained) and divergent (open-ended) creativity using Usefulness, Originality, and Surprise criteria.


<details>
  <summary>Details</summary>
Motivation: Existing evaluation frameworks for creativity in foundation models are fragmented and rely on ad hoc metrics not grounded in established theories, creating a gap in properly assessing machine creativity.

Method: Introduces C^2-Eval benchmark that evaluates both convergent and divergent creativity using fine-grained criteria (Usefulness, Originality, Surprise) derived from social-science theory, tested on leading proprietary and open-source models.

Result: Extensive experiments reveal trade-offs in creative capabilities of current foundation models, highlighting both strengths and challenges in pursuing creative machine intelligence.

Conclusion: C^2-Eval provides an effective framework for examining the evolving landscape of creative AI and serves as a comprehensive lens for assessing creativity in foundation models.

Abstract: The meteoric rise of foundation models (FMs) has expanded their capabilities
far beyond conventional tasks. Creativity, long regarded as a hallmark of human
intelligence and a driver of innovation, is now increasingly recognized as a
critical dimension of machine intelligence in the era of generative FMs,
complementing traditional measures of accuracy. However, existing evaluation
frameworks for creativity remain fragmented, relying on ad hoc metrics not
firmly grounded in established theories. To address this gap, we introduce
C^2-Eval, a holistic benchmark for unified assessment of creativity in FMs.
C^2-Eval distinguishes between two complementary forms of creativity:
convergent creativity, where tasks admit constrained solutions (e.g., code
generation), and divergent creativity, where tasks are open-ended (e.g.,
storytelling). It evaluates both dimensions using fine-grained criteria derived
from social-science theory, focusing on Usefulness, Originality, and Surprise
(U-O-S). Through extensive experiments on leading proprietary and open-source
models, we analyze trade-offs in their creative capabilities. Our results
highlight both the strengths and challenges of current FMs in pursuing a
creative machine mind, showing that C^2-Eval is an effective lens for examining
the evolving landscape of creative AI.

</details>


### [289] [LLM-Based Data Science Agents: A Survey of Capabilities, Challenges, and Future Directions](https://arxiv.org/abs/2510.04023)
*Mizanur Rahman,Amran Bhuiyan,Mohammed Saidul Islam,Md Tahmid Rahman Laskar,Ridwan Mahbub,Ahmed Masry,Shafiq Joty,Enamul Hoque*

Main category: cs.AI

TL;DR: This survey presents the first comprehensive taxonomy of data science agents, analyzing 45 systems across the six stages of the data science lifecycle and five design dimensions, identifying key trends and open challenges in the field.


<details>
  <summary>Details</summary>
Motivation: Recent advances in LLMs have enabled new AI agents that automate multiple stages of the data science workflow, creating a need for systematic analysis and classification of these emerging systems.

Method: The authors developed a lifecycle-aligned taxonomy mapping 45 data science agent systems across six data science stages and annotated them along five cross-cutting design dimensions: reasoning/planning style, modality integration, tool orchestration depth, learning/alignment methods, and trust/safety mechanisms.

Result: Analysis revealed three key trends: most systems focus on exploratory analysis and modeling while neglecting business understanding and deployment; multimodal reasoning and tool orchestration remain challenging; and over 90% lack explicit trust and safety mechanisms.

Conclusion: The paper outlines open challenges in alignment stability, explainability, governance, and evaluation frameworks, proposing future research directions for developing robust, trustworthy, and accessible data science agents.

Abstract: Recent advances in large language models (LLMs) have enabled a new class of
AI agents that automate multiple stages of the data science workflow by
integrating planning, tool use, and multimodal reasoning across text, code,
tables, and visuals. This survey presents the first comprehensive,
lifecycle-aligned taxonomy of data science agents, systematically analyzing and
mapping forty-five systems onto the six stages of the end-to-end data science
process: business understanding and data acquisition, exploratory analysis and
visualization, feature engineering, model building and selection,
interpretation and explanation, and deployment and monitoring. In addition to
lifecycle coverage, we annotate each agent along five cross-cutting design
dimensions: reasoning and planning style, modality integration, tool
orchestration depth, learning and alignment methods, and trust, safety, and
governance mechanisms. Beyond classification, we provide a critical synthesis
of agent capabilities, highlight strengths and limitations at each stage, and
review emerging benchmarks and evaluation practices. Our analysis identifies
three key trends: most systems emphasize exploratory analysis, visualization,
and modeling while neglecting business understanding, deployment, and
monitoring; multimodal reasoning and tool orchestration remain unresolved
challenges; and over 90% lack explicit trust and safety mechanisms. We conclude
by outlining open challenges in alignment stability, explainability,
governance, and robust evaluation frameworks, and propose future research
directions to guide the development of robust, trustworthy, low-latency,
transparent, and broadly accessible data science agents.

</details>


### [290] [Internal states before wait modulate reasoning patterns](https://arxiv.org/abs/2510.04128)
*Dmitrii Troitskii,Koyena Pal,Chris Wendler,Callum Stuart McDougall,Neel Nanda*

Main category: cs.AI

TL;DR: The paper investigates whether model latents before wait tokens contain information that modulates reasoning processes, identifying specific features that influence wait token probabilities and enable different reasoning patterns.


<details>
  <summary>Details</summary>
Motivation: Little is understood about why models decide to reason using wait tokens (signaling behaviors like backtracking), which limits understanding of what makes reasoning models effective.

Method: Trained crosscoders at multiple layers of DeepSeek-R1-Distill-Llama-8B and its base version, introduced latent attribution technique in crosscoder setting to locate features affecting wait token probabilities.

Result: Identified a small set of features relevant for promoting/suppressing wait tokens' probabilities, with features shown to be relevant for reasoning processes enabling patterns like restarting, recalling prior knowledge, expressing uncertainty, and double-checking.

Conclusion: Model latents preceding wait tokens do contain relevant information for modulating reasoning processes, and identified features give rise to different types of reasoning patterns.

Abstract: Prior work has shown that a significant driver of performance in reasoning
models is their ability to reason and self-correct. A distinctive marker in
these reasoning traces is the token wait, which often signals reasoning
behavior such as backtracking. Despite being such a complex behavior, little is
understood of exactly why models do or do not decide to reason in this
particular manner, which limits our understanding of what makes a reasoning
model so effective. In this work, we address the question whether model's
latents preceding wait tokens contain relevant information for modulating the
subsequent reasoning process. We train crosscoders at multiple layers of
DeepSeek-R1-Distill-Llama-8B and its base version, and introduce a latent
attribution technique in the crosscoder setting. We locate a small set of
features relevant for promoting/suppressing wait tokens' probabilities.
Finally, through a targeted series of experiments analyzing max activating
examples and causal interventions, we show that many of our identified features
indeed are relevant for the reasoning process and give rise to different types
of reasoning patterns such as restarting from the beginning, recalling prior
knowledge, expressing uncertainty, and double-checking.

</details>


### [291] [Selective Expert Guidance for Effective and Diverse Exploration in Reinforcement Learning of LLMs](https://arxiv.org/abs/2510.04140)
*Zishang Jiang,Jinyi Han,Tingyun Li,Xinyi Wang,Sihang Jiang,Jiaqing Liang,Zhaoqian Dai,Shuguang Ma,Fei Yu,Yanghua Xiao*

Main category: cs.AI

TL;DR: MENTOR is a framework that provides expert guidance only at critical decision points in RLVR, enabling effective and diverse exploration without full expert trajectory imitation.


<details>
  <summary>Details</summary>
Motivation: RLVR effectiveness depends on base model capability for high-quality exploration (both effective and diverse), but existing methods using full expert trajectory imitation improve effectiveness at the cost of diversity.

Method: MENTOR uses mixed-policy expert navigation for token-level optimization, providing expert guidance only at critical decision points rather than entire reasoning paths.

Result: Extensive experiments show MENTOR enables models to capture the essence of expert strategies rather than surface imitation, performing high-quality exploration.

Conclusion: MENTOR achieves superior overall performance by enabling effective and diverse exploration in RLVR through targeted expert guidance at critical points.

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has become a widely
adopted technique for enhancing the reasoning ability of Large Language Models
(LLMs). However, the effectiveness of RLVR strongly depends on the capability
of base models. This issue arises because it requires the model to have
sufficient capability to perform high-quality exploration, which involves both
effectiveness and diversity. Unfortunately, existing methods address this issue
by imitating expert trajectories, which improve effectiveness but neglect
diversity. To address this, we argue that the expert only needs to provide
guidance only at critical decision points rather than the entire reasoning
path. Based on this insight, we propose MENTOR: Mixed-policy Expert Navigation
for Token-level Optimization of Reasoning, a framework that provides expert
guidance only at critical decision points to perform effective and diverse
exploration in RLVR. Extensive experiments show that MENTOR enables models
capture the essence of expert strategies rather than surface imitation, thereby
performing high-quality exploration and achieving superior overall performance.
Our code is available online.

</details>


### [292] [Don't Pass$\mathtt{@}k$: A Bayesian Framework for Large Language Model Evaluation](https://arxiv.org/abs/2510.04265)
*Mohsen Hariri,Amirhossein Samandar,Michael Hinczewski,Vipin Chaudhary*

Main category: cs.AI

TL;DR: The paper proposes a Bayesian evaluation framework to replace Pass@k for LLM reasoning assessment, providing more stable rankings and principled uncertainty estimation with fewer samples.


<details>
  <summary>Details</summary>
Motivation: Pass@k yields unstable and misleading rankings for LLM reasoning evaluation, especially with limited trials and constrained compute resources.

Method: A Bayesian framework using Dirichlet prior to model evaluation outcomes as categorical, providing closed-form posterior estimates of success probability and credible intervals.

Result: Empirical tests on AIME'24/'25, HMMT'25, and BrUMO'25 show faster convergence and greater rank stability than Pass@k, enabling reliable comparisons with fewer samples.

Conclusion: Recommends replacing Pass@k with posterior-based protocol that unifies binary and non-binary evaluation while making uncertainty explicit.

Abstract: Pass$@k$ is widely used to report performance for LLM reasoning, but it often
yields unstable, misleading rankings, especially when the number of trials
(samples) is limited and compute is constrained. We present a principled
Bayesian evaluation framework that replaces Pass$@k$ and average accuracy over
$N$ trials (avg$@N$) with posterior estimates of a model's underlying success
probability and credible intervals, yielding stable rankings and a transparent
decision rule for differences. Evaluation outcomes are modeled as categorical
(not just 0/1) with a Dirichlet prior, giving closed-form expressions for the
posterior mean and uncertainty of any weighted rubric and enabling the use of
prior evidence when appropriate. Theoretically, under a uniform prior, the
Bayesian posterior mean is order-equivalent to average accuracy (Pass$@1$),
explaining its empirical robustness while adding principled uncertainty.
Empirically, in simulations with known ground-truth success rates and on
AIME'24/'25, HMMT'25, and BrUMO'25, the Bayesian/avg procedure achieves faster
convergence and greater rank stability than Pass$@k$ and recent variants,
enabling reliable comparisons at far smaller sample counts. The framework
clarifies when observed gaps are statistically meaningful (non-overlapping
credible intervals) versus noise, and it naturally extends to graded,
rubric-based evaluations. Together, these results recommend replacing Pass$@k$
for LLM evaluation and ranking with a posterior-based, compute-efficient
protocol that unifies binary and non-binary evaluation while making uncertainty
explicit. Code is available at https://mohsenhariri.github.io/bayes-kit

</details>


### [293] [Internal World Models as Imagination Networks in Cognitive Agents](https://arxiv.org/abs/2510.04391)
*Saurabh Ranjan,Brian Odegaard*

Main category: cs.AI

TL;DR: This study proposes that imagination serves to access an internal world model (IWM) and uses psychological network analysis to compare IWMs in humans and LLMs, finding significant differences in network structure and centrality correlations.


<details>
  <summary>Details</summary>
Motivation: To understand the computational objective of imagination and challenge classical interpretations that imagination is primarily for reward maximization, by exploring internal world models in both humans and AI systems.

Method: Used psychological network analysis with imagination vividness ratings from questionnaires to construct imagination networks, comparing human groups with large language models under different prompts and memory conditions.

Result: Human imagination networks showed correlations between centrality measures (expected influence, strength, closeness), while LLM networks lacked clustering and showed lower centrality correlations across different conditions.

Conclusion: There is a lack of similarity between internal world models in human and LLM agents, providing a novel method for comparing internally-generated representations and insights for developing human-like imagination in AI.

Abstract: What is the computational objective of imagination? While classical
interpretations suggest imagination is useful for maximizing rewards, recent
findings challenge this view. In this study, we propose that imagination serves
to access an internal world model (IWM) and use psychological network analysis
to explore IWMs in humans and large language models (LLMs). Specifically, we
assessed imagination vividness ratings using two questionnaires and constructed
imagination networks from these reports. Imagination networks from human groups
showed correlations between different centrality measures, including expected
influence, strength, and closeness. However, imagination networks from LLMs
showed a lack of clustering and lower correlations between centrality measures
under different prompts and conversational memory conditions. Together, these
results indicate a lack of similarity between IWMs in human and LLM agents.
Overall, our study offers a novel method for comparing internally-generated
representations in humans and AI, providing insights for developing human-like
imagination in artificial intelligence.

</details>


### [294] [Impatient Users Confuse AI Agents: High-fidelity Simulations of Human Traits for Testing Agents](https://arxiv.org/abs/2510.04491)
*Muyu He,Anand Kumar,Tsach Mackey,Meghana Rajeev,James Zou,Nazneen Rajani*

Main category: cs.AI

TL;DR: TraitBasis is a model-agnostic method for stress testing AI agents by learning steerable user traits in activation space, revealing significant performance degradation (2%-30%) when user behavior varies.


<details>
  <summary>Details</summary>
Motivation: Current AI agents are brittle and fail under realistic user behavior variations (impatience, incoherence, skepticism), while existing benchmarks don't capture this fragility.

Method: TraitBasis learns directions in activation space corresponding to user traits, which can be controlled, scaled, composed and applied at inference time without fine-tuning or extra data.

Result: Performance degradation of 2%-30% on τ-Trait across frontier models, demonstrating current AI agents' lack of robustness to user behavior variations.

Conclusion: TraitBasis provides a simple, data-efficient tool for robustness testing and opens the door to building more reliable AI agents for real-world human interactions.

Abstract: Despite rapid progress in building conversational AI agents, robustness is
still largely untested. Small shifts in user behavior, such as being more
impatient, incoherent, or skeptical, can cause sharp drops in agent
performance, revealing how brittle current AI agents are. Today's benchmarks
fail to capture this fragility: agents may perform well under standard
evaluations but degrade spectacularly in more realistic and varied settings. We
address this robustness testing gap by introducing TraitBasis, a lightweight,
model-agnostic method for systematically stress testing AI agents. TraitBasis
learns directions in activation space corresponding to steerable user traits
(e.g., impatience or incoherence), which can be controlled, scaled, composed,
and applied at inference time without any fine-tuning or extra data. Using
TraitBasis, we extend $\tau$-Bench to $\tau$-Trait, where user behaviors are
altered via controlled trait vectors. We observe on average a 2%-30%
performance degradation on $\tau$-Trait across frontier models, highlighting
the lack of robustness of current AI agents to variations in user behavior.
Together, these results highlight both the critical role of robustness testing
and the promise of TraitBasis as a simple, data-efficient, and compositional
tool. By powering simulation-driven stress tests and training loops, TraitBasis
opens the door to building AI agents that remain reliable in the unpredictable
dynamics of real-world human interactions. We have open-sourced $\tau$-Trai
across four domains: airline, retail, telecom, and telehealth, so the community
can systematically QA their agents under realistic, behaviorally diverse
intents and trait scenarios: https://github.com/collinear-ai/tau-trait.

</details>


### [295] [ChartAgent: A Multimodal Agent for Visually Grounded Reasoning in Complex Chart Question Answering](https://arxiv.org/abs/2510.04514)
*Rachneet Kaur,Nishan Srishankar,Zhen Zeng,Sumitra Ganesh,Manuela Veloso*

Main category: cs.AI

TL;DR: ChartAgent is a novel agentic framework that performs visual reasoning directly on charts using specialized vision tools, achieving state-of-the-art performance on chart understanding benchmarks.


<details>
  <summary>Details</summary>
Motivation: Multimodal LLMs struggle with unannotated charts that require precise visual interpretation rather than relying on textual shortcuts, showing sharp performance declines.

Method: Iteratively decomposes queries into visual subtasks and actively manipulates chart images through specialized actions like drawing annotations, cropping regions, and localizing axes using chart-specific vision tools.

Result: Achieves state-of-the-art accuracy on ChartBench and ChartX benchmarks, surpassing prior methods by up to 16.07% overall and 17.31% on unannotated, numerically intensive queries.

Conclusion: ChartAgent effectively demonstrates visually grounded reasoning for chart understanding using tool-augmented multimodal agents, working across diverse chart types and complexity levels while serving as a plug-and-play framework.

Abstract: Recent multimodal LLMs have shown promise in chart-based visual question
answering, but their performance declines sharply on unannotated charts, those
requiring precise visual interpretation rather than relying on textual
shortcuts. To address this, we introduce ChartAgent, a novel agentic framework
that explicitly performs visual reasoning directly within the chart's spatial
domain. Unlike textual chain-of-thought reasoning, ChartAgent iteratively
decomposes queries into visual subtasks and actively manipulates and interacts
with chart images through specialized actions such as drawing annotations,
cropping regions (e.g., segmenting pie slices, isolating bars), and localizing
axes, using a library of chart-specific vision tools to fulfill each subtask.
This iterative reasoning process closely mirrors human cognitive strategies for
chart comprehension. ChartAgent achieves state-of-the-art accuracy on the
ChartBench and ChartX benchmarks, surpassing prior methods by up to 16.07%
absolute gain overall and 17.31% on unannotated, numerically intensive queries.
Furthermore, our analyses show that ChartAgent is (a) effective across diverse
chart types, (b) achieve the highest scores across varying visual and reasoning
complexity levels, and (c) serves as a plug-and-play framework that boosts
performance across diverse underlying LLMs. Our work is among the first to
demonstrate visually grounded reasoning for chart understanding using
tool-augmented multimodal agents.

</details>


### [296] [More Than Meets the Eye? Uncovering the Reasoning-Planning Disconnect in Training Vision-Language Driving Models](https://arxiv.org/abs/2510.04532)
*Xurui Song,Shuo Huai,JingJing Jiang,Jiayi Kong,Jun Luo*

Main category: cs.AI

TL;DR: VLM driving agents show causal disconnect between reasoning and planning - planning relies more on priors than reasoning, suggesting reasoning is an ancillary byproduct rather than causal mediator.


<details>
  <summary>Details</summary>
Motivation: To investigate whether planning in Vision-Language Model driving agents is causally driven by their natural-language reasoning, which is a critical but unverified assumption.

Method: Built DriveMind dataset with plan-aligned Chain-of-Thought from nuPlan, trained VLM agents with SFT and GRPO, conducted information ablations and attention analysis to evaluate causal relationships.

Result: Removing ego/navigation priors causes large planning score drops, while removing CoT produces only minor changes. Attention analysis shows planning primarily focuses on priors rather than CoT.

Conclusion: Proposes Reasoning-Planning Decoupling Hypothesis - reasoning is an ancillary byproduct rather than causal mediator. Provides dataset and diagnostic tool to evaluate causal fidelity of future models.

Abstract: Vision-Language Model (VLM) driving agents promise explainable end-to-end
autonomy by first producing natural-language reasoning and then predicting
trajectory planning. However, whether planning is causally driven by this
reasoning remains a critical but unverified assumption. To investigate this, we
build DriveMind, a large-scale driving Visual Question Answering (VQA) corpus
with plan-aligned Chain-of-Thought (CoT), automatically generated from nuPlan.
Our data generation process converts sensors and annotations into structured
inputs and, crucially, separates priors from to-be-reasoned signals, enabling
clean information ablations. Using DriveMind, we train representative VLM
agents with Supervised Fine-Tuning (SFT) and Group Relative Policy Optimization
(GRPO) and evaluate them with nuPlan's metrics. Our results, unfortunately,
indicate a consistent causal disconnect in reasoning-planning: removing
ego/navigation priors causes large drops in planning scores, whereas removing
CoT produces only minor changes. Attention analysis further shows that planning
primarily focuses on priors rather than the CoT. Based on this evidence, we
propose the Reasoning-Planning Decoupling Hypothesis, positing that the
training-yielded reasoning is an ancillary byproduct rather than a causal
mediator. To enable efficient diagnosis, we also introduce a novel,
training-free probe that measures an agent's reliance on priors by evaluating
its planning robustness against minor input perturbations. In summary, we
provide the community with a new dataset and a diagnostic tool to evaluate the
causal fidelity of future models.

</details>


### [297] [BrokenMath: A Benchmark for Sycophancy in Theorem Proving with LLMs](https://arxiv.org/abs/2510.04721)
*Ivo Petrov,Jasper Dekoninck,Martin Vechev*

Main category: cs.AI

TL;DR: BrokenMath is the first benchmark for evaluating sycophantic behavior in LLMs for natural language theorem proving, showing widespread sycophancy with GPT-5 producing flawed proofs 29% of the time.


<details>
  <summary>Details</summary>
Motivation: LLMs show strong mathematical performance but are prone to hallucination and sycophancy, providing convincing but flawed proofs for incorrect statements, limiting their theorem proving applicability.

Method: Built from advanced 2025 competition problems perturbed with LLMs to produce false statements and refined through expert review, evaluated using LLM-as-a-judge framework.

Result: Sycophancy is widespread with GPT-5 producing sycophantic answers 29% of the time; mitigation strategies reduce but don't eliminate the behavior.

Conclusion: Sycophantic behavior in mathematical theorem proving is a significant problem that current mitigation strategies only partially address, highlighting the need for better benchmarks and solutions.

Abstract: Large language models (LLMs) have recently shown strong performance on
mathematical benchmarks. At the same time, they are prone to hallucination and
sycophancy, often providing convincing but flawed proofs for incorrect
mathematical statements provided by users. This significantly limits the
applicability of LLMs in theorem proving, as verification of these flawed
proofs must be done manually by expert mathematicians. However, existing
benchmarks that measure sycophancy in mathematics are limited: they focus
solely on final-answer problems, rely on very simple and often contaminated
datasets, and construct benchmark samples using synthetic modifications that
create ill-posed questions rather than well-posed questions that are
demonstrably false. To address these issues, we introduce BrokenMath, the first
benchmark for evaluating sycophantic behavior in LLMs within the context of
natural language theorem proving. BrokenMath is built from advanced 2025
competition problems, which are perturbed with an LLM to produce false
statements and subsequently refined through expert review. Using an
LLM-as-a-judge framework, we evaluate state-of-the-art LLMs and agentic systems
and find that sycophancy is widespread, with the best model, GPT-5, producing
sycophantic answers 29% of the time. We further investigate several mitigation
strategies, including test-time interventions and supervised fine-tuning on
curated sycophantic examples. These approaches substantially reduce, but do not
eliminate, sycophantic behavior.

</details>


### [298] [MARS: Optimizing Dual-System Deep Research via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2510.04935)
*Guoxin Chen,Zile Qiao,Wenqing Wang,Donglei Yu,Xuanzhong Chen,Hao Sun,Minpeng Liao,Kai Fan,Yong Jiang,Penguin Xie,Wayne Xin Zhao,Ruihua Song,Fei Huang*

Main category: cs.AI

TL;DR: MARS introduces a multi-agent system that integrates System 1 (fast, intuitive) and System 2 (deliberate) reasoning in LLMs, using external tools and reinforcement learning to improve efficiency and performance on complex reasoning tasks.


<details>
  <summary>Details</summary>
Motivation: To address LRMs' tendency for overanalysis in simple tasks and their inability to adapt to rapidly changing environments due to static pretraining data, by bridging intuitive and deliberate cognitive processes.

Method: Multi-Agent System for Deep ReSearch (MARS) integrates external tools (Google Search, Google Scholar, Python Interpreter) and uses multi-agent reinforcement learning with Group Relative Policy Optimization to optimize both reasoning systems with tool interactions and bin-packing optimization.

Result: MARS achieves 3.86% improvement on Humanity's Last Exam benchmark and 8.9% average gain across 7 knowledge-intensive tasks.

Conclusion: The dual-system paradigm effectively enhances complex reasoning in dynamic information environments by combining System 1's efficiency with System 2's deliberate reasoning.

Abstract: Large Reasoning Models (LRMs) often exhibit a tendency for overanalysis in
simple tasks, where the models excessively utilize System 2-type, deliberate
reasoning, leading to inefficient token generation. Furthermore, these models
face challenges in adapting their reasoning capabilities to rapidly changing
environments due to the static nature of their pretraining data. To address
these issues, advancing Large Language Models (LLMs) for complex reasoning
tasks requires innovative approaches that bridge intuitive and deliberate
cognitive processes, akin to human cognition's dual-system dynamic. This paper
introduces a Multi-Agent System for Deep ReSearch (MARS) enabling seamless
integration of System 1's fast, intuitive thinking with System 2's deliberate
reasoning within LLMs. MARS strategically integrates multiple external tools,
such as Google Search, Google Scholar, and Python Interpreter, to access
up-to-date information and execute complex computations, while creating a
specialized division of labor where System 1 efficiently processes and
summarizes high-volume external information, providing distilled insights that
expand System 2's reasoning context without overwhelming its capacity.
Furthermore, we propose a multi-agent reinforcement learning framework
extending Group Relative Policy Optimization to simultaneously optimize both
systems with multi-turn tool interactions, bin-packing optimization, and sample
balancing strategies that enhance collaborative efficiency. Extensive
experiments demonstrate MARS achieves substantial improvements of 3.86% on the
challenging Humanity's Last Exam (HLE) benchmark and an average gain of 8.9%
across 7 knowledge-intensive tasks, validating the effectiveness of our
dual-system paradigm for complex reasoning in dynamic information environments.

</details>


### [299] [LLM-Hanabi: Evaluating Multi-Agent Gameplays with Theory-of-Mind and Rationale Inference in Imperfect Information Collaboration Game](https://arxiv.org/abs/2510.04980)
*Fangzhou Liang,Tianshi Zheng,Chunkit Chan,Yauwai Yim,Yangqiu Song*

Main category: cs.AI

TL;DR: LLM-Hanabi benchmark evaluates LLMs' Theory-of-Mind capabilities in collaborative settings using the Hanabi game, finding first-order ToM (interpreting intent) correlates more strongly with performance than second-order ToM.


<details>
  <summary>Details</summary>
Motivation: To assess LLMs' ability to infer rationale behind others' actions in dynamic collaborative settings, which is crucial for effective multi-agent collaboration but remains under-explored despite LLMs' logical inference strengths.

Method: Developed LLM-Hanabi benchmark using the cooperative game Hanabi with automated evaluation system measuring both game performance and ToM proficiency across various LLM models.

Result: Found significant positive correlation between ToM and in-game success, with first-order ToM (interpreting others' intent) correlating more strongly with performance than second-order ToM (predicting others' interpretations).

Conclusion: For effective AI collaboration, accurately interpreting a partner's rationale (first-order ToM) is more critical than higher-order reasoning, suggesting prioritizing first-order ToM is promising for enhancing future models' collaborative capabilities.

Abstract: Effective multi-agent collaboration requires agents to infer the rationale
behind others' actions, a capability rooted in Theory-of-Mind (ToM). While
recent Large Language Models (LLMs) excel at logical inference, their ability
to infer rationale in dynamic, collaborative settings remains under-explored.
This study introduces LLM-Hanabi, a novel benchmark that uses the cooperative
game Hanabi to evaluate the rationale inference and ToM of LLMs. Our framework
features an automated evaluation system that measures both game performance and
ToM proficiency. Across a range of models, we find a significant positive
correlation between ToM and in-game success. Notably, first-order ToM
(interpreting others' intent) correlates more strongly with performance than
second-order ToM (predicting others' interpretations). These findings highlight
that for effective AI collaboration, the ability to accurately interpret a
partner's rationale is more critical than higher-order reasoning. We conclude
that prioritizing first-order ToM is a promising direction for enhancing the
collaborative capabilities of future models.

</details>


### [300] [Watch and Learn: Learning to Use Computers from Online Videos](https://arxiv.org/abs/2510.04673)
*Chan Hee Song,Yiwen Song,Palash Goyal,Yu Su,Oriana Riva,Hamid Palangi,Tomas Pfister*

Main category: cs.AI

TL;DR: Watch & Learn (W&L) is a framework that converts human demonstration videos from the Internet into executable UI trajectories at scale using an inverse dynamics approach, improving computer use agents through better training data and demonstrations.


<details>
  <summary>Details</summary>
Motivation: Computer use agents need task workflows grounded in diverse applications, but face data scarcity issues. Existing datasets are domain-specific, static, and costly to annotate, while synthetic data generation methods produce simplistic or misaligned demonstrations.

Method: Cast the problem as an inverse dynamics objective: predicting user actions from consecutive screen states. Develop a pipeline with task-aware video retrieval to generate executable UI trajectories from web videos.

Result: Generated over 53k high-quality trajectories from raw web videos. On OSWorld benchmark, these trajectories consistently enhanced both general-purpose and state-of-the-art frameworks in-context, and delivered stronger gains for open-source models under supervised training.

Conclusion: Web-scale human demonstration videos serve as a practical and scalable foundation for advancing computer use agents towards real-world deployment, with the inverse dynamics approach reducing manual engineering and improving generalization.

Abstract: Computer use agents (CUAs) need to plan task workflows grounded in diverse,
ever-changing applications and environments, but learning is hindered by the
scarcity of large-scale, high-quality training data in the target application.
Existing datasets are domain-specific, static, and costly to annotate, while
current synthetic data generation methods often yield simplistic or misaligned
task demonstrations. To address these limitations, we introduce Watch & Learn
(W&L), a framework that converts human demonstration videos readily available
on the Internet into executable UI trajectories at scale. Instead of directly
generating trajectories or relying on ad hoc reasoning heuristics, we cast the
problem as an inverse dynamics objective: predicting the user's action from
consecutive screen states. This formulation reduces manual engineering, is
easier to learn, and generalizes more robustly across applications. Concretely,
we develop an inverse dynamics labeling pipeline with task-aware video
retrieval, generate over 53k high-quality trajectories from raw web videos, and
demonstrate that these trajectories improve CUAs both as in-context
demonstrations and as supervised training data. On the challenging OSWorld
benchmark, UI trajectories extracted with W&L consistently enhance both
general-purpose and state-of-the-art frameworks in-context, and deliver
stronger gains for open-source models under supervised training. These results
highlight web-scale human demonstration videos as a practical and scalable
foundation for advancing CUAs towards real-world deployment.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [301] [Super-resolution image projection over an extended depth of field using a diffractive decoder](https://arxiv.org/abs/2510.03938)
*Hanlong Chen,Cagatay Isil,Tianyi Gan,Mona Jarrahi,Aydogan Ozcan*

Main category: physics.optics

TL;DR: A hybrid image projection system combining CNN-based digital encoding with all-optical diffractive decoding achieves extended depth-of-field and pixel super-resolution while reducing data storage and transmission requirements.


<details>
  <summary>Details</summary>
Motivation: To create efficient image projection systems that maintain large space-bandwidth-product while being efficient in data storage, computation and transmission, eliminating additional power consumption for super-resolved image reconstruction.

Method: Uses CNN-based encoder to compress images into compact phase representations displayed by low-resolution projector, then processed by passive analog diffractive decoder for all-optical image reconstruction with extended depth-of-field.

Result: Achieves high-fidelity image synthesis over extended DOF of ~267xW (wavelength), offers ~16-fold SBP improvement at each lateral plane, validated through THz spectrum experiments, and scalable across electromagnetic spectrum.

Conclusion: This hybrid approach reduces data storage and transmission requirements without additional power constraints on optical decoder, with principles extendable to optical metrology and microscopy applications.

Abstract: Image projection systems must be efficient in data storage, computation and
transmission while maintaining a large space-bandwidth-product (SBP) at their
output. Here, we introduce a hybrid image projection system that achieves
extended depth-of-field (DOF) with improved resolution, combining a
convolutional neural network (CNN)-based digital encoder with an all-optical
diffractive decoder. A CNN-based encoder compresses input images into compact
phase representations, which are subsequently displayed by a low-resolution
(LR) projector and processed by an analog diffractive decoder for all-optical
image reconstruction. This optical decoder is completely passive, designed to
synthesize pixel super-resolved image projections that feature an extended DOF
while eliminating the need for additional power consumption for super-resolved
image reconstruction. Our pixel super-resolution (PSR) image projection system
demonstrates high-fidelity image synthesis over an extended DOF of ~267xW,
where W is the illumination wavelength, concurrently offering up to ~16-fold
SBP improvement at each lateral plane. The proof of concept of this approach is
validated through an experiment conducted in the THz spectrum, and the system
is scalable across different parts of the electromagnetic spectrum. This image
projection architecture can reduce data storage and transmission requirements
for display systems without imposing additional power constraints on the
optical decoder. Beyond extended DOF PSR image projection, the underlying
principles of this approach can be extended to various applications, including
optical metrology and microscopy.

</details>


<div id='cs.CG'></div>

# cs.CG [[Back]](#toc)

### [302] [Fast Witness Persistence for MRI Volumes via Hybrid Landmarking](https://arxiv.org/abs/2510.04553)
*Jorge Leonardo Ruiz Williams*

Main category: cs.CG

TL;DR: A scalable witness-based persistent homology pipeline for full-brain MRI volumes that uses density-aware landmark selection and GPU-accelerated filtration to efficiently compute topological features while avoiding combinatorial complexity.


<details>
  <summary>Details</summary>
Motivation: To develop a computationally efficient method for analyzing topological features in full-brain MRI volumes that overcomes the combinatorial blow-up of traditional filtration methods like Cech, Vietoris-Rips, and alpha filtrations.

Method: Couples density-aware landmark selection with a GPU-ready witness filtration. Candidates are scored by a hybrid metric balancing geometric coverage against inverse kernel density, yielding optimized landmark sets.

Result: Landmark sets shrink mean pairwise distances by 30-60% over random or density-only baselines while preserving topological features. Benchmarks on BrainWeb, IXI, and synthetic manifolds execute in under ten seconds on a single NVIDIA RTX 4090 GPU.

Conclusion: The method provides an efficient, scalable approach for persistent homology computation in medical imaging workflows, available as an open-source Python package (whale-tda) with fast presets and reproducibility-focused tools.

Abstract: We introduce a scalable witness-based persistent homology pipeline for
full-brain MRI volumes that couples density-aware landmark selection with a
GPU-ready witness filtration. Candidates are scored by a hybrid metric that
balances geometric coverage against inverse kernel density, yielding landmark
sets that shrink mean pairwise distances by 30-60% over random or density-only
baselines while preserving topological features. Benchmarks on BrainWeb, IXI,
and synthetic manifolds execute in under ten seconds on a single NVIDIA RTX
4090 GPU, avoiding the combinatorial blow-up of Cech, Vietoris-Rips, and alpha
filtrations. The package is distributed on PyPI as whale-tda (installable via
pip); source and issues are hosted at https://github.com/jorgeLRW/whale. The
release also exposes a fast preset (mri_deep_dive_fast) for exploratory sweeps,
and ships with reproducibility-focused scripts and artifacts for drop-in use in
medical imaging workflows.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [303] [General Exploratory Bonus for Optimistic Exploration in RLHF](https://arxiv.org/abs/2510.03269)
*Wendi Li,Changdae Oh,Yixuan Li*

Main category: cs.LG

TL;DR: The paper introduces General Exploratory Bonus (GEB), a novel framework that addresses the failure of existing exploratory bonus methods to achieve optimistic exploration in RLHF by counteracting divergence-induced bias.


<details>
  <summary>Details</summary>
Motivation: Existing exploratory bonus methods in reinforcement learning with human feedback fail to realize optimism and unintentionally bias exploration toward high-probability regions of the reference model, reinforcing conservative behavior instead of promoting discovery of uncertain regions.

Method: Proposes General Exploratory Bonus (GEB), a theoretical framework that counteracts divergence-induced bias via reference-dependent reward regulation and unifies prior heuristic bonuses as special cases across the full α-divergence family.

Result: GEB consistently outperforms baselines on alignment tasks across multiple divergence settings and large language model backbones, demonstrating both principled and practical advantages.

Conclusion: GEB offers a principled and practical solution for optimistic exploration in RLHF by provably satisfying the optimism principle and extending naturally across divergence families.

Abstract: Optimistic exploration is central to improving sample efficiency in
reinforcement learning with human feedback, yet existing exploratory bonus
methods to incentivize exploration often fail to realize optimism. We provide a
theoretical analysis showing that current formulations, under KL or
$\alpha$-divergence regularization, unintentionally bias exploration toward
high-probability regions of the reference model, thereby reinforcing
conservative behavior instead of promoting discovery of uncertain regions. To
address this pitfall, we introduce the General Exploratory Bonus (GEB), a novel
theoretical framework that provably satisfies the optimism principle. GEB
counteracts divergence-induced bias via reference-dependent reward regulation
and unifies prior heuristic bonuses as special cases, while extending naturally
across the full $\alpha$-divergence family. Empirically, GEB consistently
outperforms baselines on alignment tasks across multiple divergence settings
and large language model backbones. These results demonstrate that GEB offers
both a principled and practical solution for optimistic exploration in RLHF.

</details>


### [304] [MemMamba: Rethinking Memory Patterns in State Space Model](https://arxiv.org/abs/2510.03279)
*Youjin Wang,Yangjingyi Chen,Jiahao Yan,Jiaxuan Lu,Xiao Sun*

Main category: cs.LG

TL;DR: MemMamba addresses Mamba's exponential memory decay in long-sequence modeling by integrating state summarization with cross-layer and cross-token attention, achieving better memory retention while maintaining linear complexity.


<details>
  <summary>Details</summary>
Motivation: Existing methods for long-sequence modeling face trade-offs between efficiency and memory - RNNs have gradient issues, Transformers have quadratic complexity, and Mamba suffers from exponential memory decay. The paper aims to solve Mamba's long-range forgetting problem.

Method: Proposed MemMamba framework with state summarization mechanism and cross-layer/cross-token attention to alleviate long-range forgetting while preserving linear complexity. Introduced horizontal-vertical memory fidelity metrics to quantify information loss.

Result: MemMamba achieves significant improvements over Mamba variants and Transformers on PG19 and Passkey Retrieval benchmarks, with 48% inference speedup while maintaining linear complexity.

Conclusion: MemMamba achieves a breakthrough in the complexity-memory trade-off, offering a new paradigm for ultra-long sequence modeling through its architectural innovations.

Abstract: With the explosive growth of data, long-sequence modeling has become
increasingly important in tasks such as natural language processing and
bioinformatics. However, existing methods face inherent trade-offs between
efficiency and memory. Recurrent neural networks suffer from gradient vanishing
and explosion, making them hard to scale. Transformers can model global
dependencies but are constrained by quadratic complexity. Recently, selective
state-space models such as Mamba have demonstrated high efficiency with O(n)
time and O(1) recurrent inference, yet their long-range memory decays
exponentially. In this work, we conduct mathematical derivations and
information-theoretic analysis to systematically uncover the memory decay
mechanism of Mamba, answering a fundamental question: what is the nature of
Mamba's long-range memory and how does it retain information? To quantify key
information loss, we further introduce horizontal-vertical memory fidelity
metrics that capture degradation both within and across layers. Inspired by how
humans distill and retain salient information when reading long documents, we
propose MemMamba, a novel architectural framework that integrates state
summarization mechanism together with cross-layer and cross-token attention,
which alleviates long-range forgetting while preserving linear complexity.
MemMamba achieves significant improvements over existing Mamba variants and
Transformers on long-sequence benchmarks such as PG19 and Passkey Retrieval,
while delivering a 48% speedup in inference efficiency. Both theoretical
analysis and empirical results demonstrate that MemMamba achieves a
breakthrough in the complexity-memory trade-off, offering a new paradigm for
ultra-long sequence modeling.

</details>


### [305] [Training Optimal Large Diffusion Language Models](https://arxiv.org/abs/2510.03280)
*Jinjie Ni,Qian Liu,Chao Du,Longxu Dou,Hang Yan,Zili Wang,Tianyu Pang,Michael Qizhe Shieh*

Main category: cs.LG

TL;DR: Quokka introduces the first systematic scaling law for diffusion language models (DLMs), covering both compute-constrained and data-constrained regimes and studying key modeling and optimization designs.


<details>
  <summary>Details</summary>
Motivation: To provide practical guidance for DLM training and inspire the broader AI community by establishing systematic scaling laws similar to what Chinchilla did for other models.

Method: Developed Quokka as a systematic scaling law framework for diffusion language models, encompassing both compute-constrained and data-constrained training regimes, while studying key modeling and optimization design choices.

Result: Created the first comprehensive scaling law for diffusion language models that provides wider scopes than previous approaches and serves as a companion to Chinchilla scaling laws.

Conclusion: Quokka offers both short-term practical guidance for DLM training and long-term inspirations for the AI community, establishing foundational scaling principles for diffusion language models.

Abstract: We introduce Quokka, the first systematic scaling law for diffusion language
models (DLMs), encompassing both compute-constrained and data-constrained
regimes, and studying the key modeling and optimization designs. Quokka is a
good friend of Chinchilla and provides wider scopes. We hope the results would
bring short-term practical guidance in DLMs training and long-term inspirations
for the whole AI community.

</details>


### [306] [Discovering Transformer Circuits via a Hybrid Attribution and Pruning Framework](https://arxiv.org/abs/2510.03282)
*Hao Gu,Vibhas Nair,Amrithaa Ashok Kumar,Jayvart Sharma,Ryan Lagasse*

Main category: cs.LG

TL;DR: HAP framework combines attribution patching and edge pruning for faster, faithful circuit discovery in language models.


<details>
  <summary>Details</summary>
Motivation: Address the trade-off between speed (attribution patching) and faithfulness (edge pruning) in circuit analysis for language model interpretation.

Method: Hybrid approach: use attribution patching to identify high-potential subgraph, then apply edge pruning to extract faithful circuit from it.

Result: 46% faster than baseline algorithms while maintaining circuit faithfulness; preserves cooperative circuit components that attribution methods prune.

Conclusion: HAP is an effective approach for improving scalability of mechanistic interpretability research for larger models.

Abstract: Interpreting language models often involves circuit analysis, which aims to
identify sparse subnetworks, or circuits, that accomplish specific tasks.
Existing circuit discovery algorithms face a fundamental trade-off: attribution
patching is fast but unfaithful to the full model, while edge pruning is
faithful but computationally expensive. This research proposes a hybrid
attribution and pruning (HAP) framework that uses attribution patching to
identify a high-potential subgraph, then applies edge pruning to extract a
faithful circuit from it. We show that HAP is 46\% faster than baseline
algorithms without sacrificing circuit faithfulness. Furthermore, we present a
case study on the Indirect Object Identification task, showing that our method
preserves cooperative circuit components (e.g. S-inhibition heads) that
attribution patching methods prune at high sparsity. Our results show that HAP
could be an effective approach for improving the scalability of mechanistic
interpretability research to larger models. Our code is available at
https://anonymous.4open.science/r/HAP-circuit-discovery.

</details>


### [307] [MACE: A Hybrid LLM Serving System with Colocated SLO-aware Continuous Retraining Alignment](https://arxiv.org/abs/2510.03283)
*Yufei Li,Yu Fu,Yue Dong,Cong Liu*

Main category: cs.LG

TL;DR: MACE is a hybrid LLM system that colocates inference and fine-tuning with intelligent memory management to balance throughput, latency, and model freshness on edge servers.


<details>
  <summary>Details</summary>
Motivation: Address the tension between inference latency and model accuracy under constrained GPU resources for LLMs on edge servers, where frequent retraining is needed due to non-stationary user data.

Method: Proposes iteration-level scheduling that colocates concurrent inference (prefill, decode) and fine-tuning with intelligent memory management, allocating GPU cycles based on model update impact on output alignment.

Result: Reduces inference latency by up to 63% while matching or exceeding continuous retraining accuracy, maintains throughput under constraints, sustains GPU utilization above 85% on NVIDIA AGX Orin.

Conclusion: Iteration-level hybrid scheduling is a promising direction for deploying LLMs with continual learning capabilities on edge platforms.

Abstract: Large language models (LLMs) deployed on edge servers are increasingly used
in latency-sensitive applications such as personalized assistants,
recommendation, and content moderation. However, the non-stationary nature of
user data necessitates frequent retraining, which introduces a fundamental
tension between inference latency and model accuracy under constrained GPU
resources. Existing retraining strategies either delay model updates,
over-commit resources to retraining, or overlook iteration-level retraining
granularity. In this paper, we identify that iteration-level scheduling is
crucial for adapting retraining frequency to model drift without violating
service-level objectives (SLOs). We propose MACE, a hybrid LLM system that
colocates concurrent inference (prefill, decode) and fine-tuning, with
intelligent memory management to maximize task performance while promising
inference throughput. MACE leverages the insight that not all model updates
equally affect output alignment and allocates GPU cycles accordingly to balance
throughput, latency, and update freshness. Our trace-driven evaluation shows
that MACE matches or exceeds continuous retraining while reducing inference
latency by up to 63% and maintaining throughput under resource constraints.
Compared to periodic retraining, MACE improves latency breakdown across
prefill, decode, and finetune stages, and sustains GPU utilization above 85% in
NVIDIA AGX Orin. These results demonstrate that iteration-level hybrid
scheduling is a promising direction for deploying LLMs with continual learning
capabilities on edge platforms.

</details>


### [308] [Why mask diffusion does not work](https://arxiv.org/abs/2510.03289)
*Haocheng Sun,Cynthia Xin Wen,Edward Hong Wang*

Main category: cs.LG

TL;DR: Mask diffusion language models face inherent difficulties in achieving parallel generation and bidirectional attention despite theoretical advantages over autoregressive models.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of current mask diffusion language models, particularly those based on absorbing diffusion, which struggle to achieve the theoretical benefits of parallel generation and bidirectional attention.

Method: The paper analyzes why mask diffusion faces inherent difficulties and proposes the most effective training and inference strategies for mask diffusion models.

Result: The research demonstrates the fundamental challenges mask diffusion models encounter in achieving parallel generation and bidirectional attention capabilities.

Conclusion: While diffusion models theoretically offer advantages over autoregressive models, mask diffusion implementations face inherent limitations that require specialized training and inference strategies to overcome.

Abstract: The main advantages of diffusion language models over autoregressive (AR)
models lie in their ability to support parallel generation and bidirectional
attention, enabling a more controllable generation process. In recent years,
open-source mask diffusion language models have emerged, most of which are
based on a variant known as absorbing diffusion. However, this paper
demonstrates why mask diffusion faces inherent difficulties in achieving
parallel generation and bidirectional attention. We also propose the most
effective training and inference strategies for mask diffusion.

</details>


### [309] [CAFL-L: Constraint-Aware Federated Learning with Lagrangian Dual Optimization for On-Device Language Models](https://arxiv.org/abs/2510.03298)
*Dongqi Zheng,Wenjin Fu*

Main category: cs.LG

TL;DR: CAFL-L extends FedAvg with Lagrangian dual optimization to handle device resource constraints like energy, memory, and communication, adapting training parameters while maintaining performance.


<details>
  <summary>Details</summary>
Motivation: To enable federated learning on resource-constrained edge devices by explicitly incorporating device-level constraints that standard FedAvg ignores.

Method: Uses Lagrangian dual optimization to dynamically adapt training hyperparameters (freezing depth, local steps, batch size, compression) with token-budget preservation via gradient accumulation.

Result: Achieves 20% memory reduction and 95% communication reduction compared to FedAvg while maintaining competitive validation performance.

Conclusion: CAFL-L provides practical federated learning deployment on resource-constrained edge devices through superior constraint satisfaction.

Abstract: We introduce Constraint-Aware Federated Learning with Lagrangian Dual
Optimization (CAFL-L), a principled extension of FedAvg that explicitly
incorporates device-level resource constraints including energy, communication,
memory, and thermal budgets. CAFL-L employs Lagrangian dual optimization to
dynamically adapt training hyperparameters -- freezing depth, local steps,
batch size, and communication compression -- while preserving training
stability through token-budget preservation via gradient accumulation.
Experiments on a character-level language model demonstrate that CAFL-L
achieves superior constraint satisfaction compared to standard FedAvg (reducing
memory usage by 20% and communication by 95%) while maintaining competitive
validation performance, making it practical for deployment on
resource-constrained edge devices.

</details>


### [310] [AgentCaster: Reasoning-Guided Tornado Forecasting](https://arxiv.org/abs/2510.03349)
*Michael Chen*

Main category: cs.LG

TL;DR: AgentCaster is a contamination-free framework using multimodal LLMs for tornado forecasting, evaluated over 40 days with 500+ tornado reports. Models struggle with spatiotemporal reasoning and hallucinate risk, while human experts significantly outperform them.


<details>
  <summary>Details</summary>
Motivation: There is a growing need to evaluate LLMs on complex, high-impact real-world tasks to assess their readiness as reasoning agents, particularly in critical domains like weather forecasting.

Method: AgentCaster employs multimodal LLMs end-to-end for tornado forecasting, interpreting heterogeneous spatiotemporal data from high-resolution convection-allowing forecast archives. Models query interactively from 3,625 forecast maps and 40,125 forecast soundings for 12-36 hour forecasts.

Result: Human experts significantly outperform state-of-the-art models, which demonstrate strong tendency to hallucinate and overpredict risk intensity, struggle with precise geographic placement, and exhibit poor spatiotemporal reasoning in complex systems.

Conclusion: AgentCaster aims to advance research on improving LLM agents for challenging reasoning tasks in critical domains, highlighting current limitations in LLM performance for complex real-world forecasting tasks.

Abstract: There is a growing need to evaluate Large Language Models (LLMs) on complex,
high-impact, real-world tasks to assess their true readiness as reasoning
agents. To address this gap, we introduce AgentCaster, a contamination-free
framework employing multimodal LLMs end-to-end for the challenging,
long-horizon task of tornado forecasting. Within AgentCaster, models interpret
heterogeneous spatiotemporal data from a high-resolution convection-allowing
forecast archive. We assess model performance over a 40-day period featuring
diverse historical data, spanning several major tornado outbreaks and including
over 500 tornado reports. Each day, models query interactively from a pool of
3,625 forecast maps and 40,125 forecast soundings for a forecast horizon of
12-36 hours. Probabilistic tornado-risk polygon predictions are verified
against ground truths derived from geometric comparisons across disjoint risk
bands in projected coordinate space. To quantify accuracy, we propose
domain-specific TornadoBench and TornadoHallucination metrics, with
TornadoBench highly challenging for both LLMs and domain expert human
forecasters. Notably, human experts significantly outperform state-of-the-art
models, which demonstrate a strong tendency to hallucinate and overpredict risk
intensity, struggle with precise geographic placement, and exhibit poor
spatiotemporal reasoning in complex, dynamically evolving systems. AgentCaster
aims to advance research on improving LLM agents for challenging reasoning
tasks in critical domains.

</details>


### [311] [Studying the Korean Word-Chain Game with RLVR:Mitigating Reward Conflicts via Curriculum Learning](https://arxiv.org/abs/2510.03394)
*Donghwan Rho*

Main category: cs.LG

TL;DR: RLVR applied to Korean word-chain game shows curriculum learning helps resolve conflicting rule-derived rewards.


<details>
  <summary>Details</summary>
Motivation: To study how reinforcement learning with verifiable rewards can be applied to language puzzles in diverse languages, specifically examining reward conflicts.

Method: Applied RLVR to Korean word-chain game with curriculum learning to mitigate conflicting rule-derived rewards.

Result: Curriculum learning scheme successfully mitigated conflicts between naturally conflicting rule-derived rewards.

Conclusion: Puzzle tasks in diverse languages warrant further study using RLVR approaches.

Abstract: Reinforcement learning with verifiable rewards (RLVR) is a promising approach
for training large language models (LLMs) with stronger reasoning abilities. It
has also been applied to a variety of logic puzzles. In this work, we study the
Korean word-chain game using RLVR. We show that rule-derived rewards can
naturally conflict, and demonstrate through experiments that a
curriculum-learning scheme mitigates these conflicts. Our findings motivate
further studies of puzzle tasks in diverse languages.

</details>


### [312] [Consistent Kernel Change-Point Detection under m-Dependence for Text Segmentation](https://arxiv.org/abs/2510.03437)
*Jairo Diaz-Rodriguez,Mumin Jia*

Main category: cs.LG

TL;DR: Kernel change-point detection (KCPD) is theoretically guaranteed for m-dependent data and empirically validated for text segmentation using modern embeddings, outperforming baselines.


<details>
  <summary>Details</summary>
Motivation: Real-world sequential data like text exhibits strong dependencies, but existing KCPD theory assumes independence, creating a gap between theory and practice.

Method: Established theoretical guarantees for KCPD under m-dependent data, performed LLM-based simulation with synthetic m-dependent text, and conducted comprehensive empirical study with modern text embeddings.

Result: Proved consistency in number of detected change points and weak consistency in locations under m-dependence; KCPD with text embeddings outperformed baselines across diverse datasets; validated through Taylor Swift tweets case study.

Conclusion: KCPD provides strong theoretical reliability under dependencies, simulated validation, and practical effectiveness for text segmentation tasks.

Abstract: Kernel change-point detection (KCPD) has become a widely used tool for
identifying structural changes in complex data. While existing theory
establishes consistency under independence assumptions, real-world sequential
data such as text exhibits strong dependencies. We establish new guarantees for
KCPD under $m$-dependent data: specifically, we prove consistency in the number
of detected change points and weak consistency in their locations under mild
additional assumptions. We perform an LLM-based simulation that generates
synthetic $m$-dependent text to validate the asymptotics. To complement these
results, we present the first comprehensive empirical study of KCPD for text
segmentation with modern embeddings. Across diverse text datasets, KCPD with
text embeddings outperforms baselines in standard text segmentation metrics. We
demonstrate through a case study on Taylor Swift's tweets that KCPD not only
provides strong theoretical and simulated reliability but also practical
effectiveness for text segmentation tasks.

</details>


### [313] [Machine Unlearning Meets Adversarial Robustness via Constrained Interventions on LLMs](https://arxiv.org/abs/2510.03567)
*Fatmazohra Rezkellah,Ramzi Dakhmouche*

Main category: cs.LG

TL;DR: The paper proposes a unified constrained optimization approach for LLM safety that addresses both sensitive information unlearning and jail-breaking robustness through minimal weight interventions, without requiring oracle classifiers.


<details>
  <summary>Details</summary>
Motivation: With increasing LLM adoption, there's a need for privacy-preserving and safe generation through unlearning sensitive information and robustness to jail-breaking attacks, while avoiding computational overhead from oracle classifiers.

Method: Constrained optimization formulations that find smallest interventions on LLM weights to make vocabulary sets unreachable or shift weights to safer regions, using point-wise constraint-based interventions.

Result: The proposed approach achieves better performance than max-min interventions with lower computational cost, and demonstrates superior performance compared to state-of-the-art defense methods.

Conclusion: The unified constrained optimization approach effectively addresses both unlearning and robustness requirements for LLM safety without needing oracle classifiers, offering computational efficiency and strong performance.

Abstract: With the increasing adoption of Large Language Models (LLMs), more
customization is needed to ensure privacy-preserving and safe generation. We
address this objective from two critical aspects: unlearning of sensitive
information and robustness to jail-breaking attacks. We investigate various
constrained optimization formulations that address both aspects in a
\emph{unified manner}, by finding the smallest possible interventions on LLM
weights that either make a given vocabulary set unreachable or embed the LLM
with robustness to tailored attacks by shifting part of the weights to a
\emph{safer} region. Beyond unifying two key properties, this approach
contrasts with previous work in that it doesn't require an oracle classifier
that is typically not available or represents a computational overhead.
Surprisingly, we find that the simplest point-wise constraint-based
intervention we propose leads to better performance than max-min interventions,
while having a lower computational cost. Comparison against state-of-the-art
defense methods demonstrates superior performance of the proposed approach.

</details>


### [314] [From Theory to Practice: Evaluating Data Poisoning Attacks and Defenses in In-Context Learning on Social Media Health Discourse](https://arxiv.org/abs/2510.03636)
*Rabeya Amin Jhuma,Mostafa Mohaimen Akand Faisal*

Main category: cs.LG

TL;DR: This study demonstrates that in-context learning in LLMs is vulnerable to data poisoning attacks in public health sentiment analysis, where minor adversarial perturbations can flip sentiment labels in up to 67% of cases, but Spectral Signature Defense can effectively filter poisoned examples while maintaining data integrity.


<details>
  <summary>Details</summary>
Motivation: To explore the practical risks of data poisoning attacks on in-context learning in real-world public health settings, extending prior theoretical studies to high-stakes health discourse analysis.

Method: Used Human Metapneumovirus tweets and introduced small adversarial perturbations (synonym replacement, negation insertion, randomized perturbation) into support examples, then applied Spectral Signature Defense to filter poisoned data.

Result: Minor manipulations caused major disruptions with sentiment labels flipping in up to 67% of cases. After defense, ICL accuracy remained at 46.7% and logistic regression validation reached 100% accuracy.

Conclusion: ICL is fragile under attack but spectral defenses can make AI systems more reliable for health-related social media monitoring, highlighting both risks and potential defenses for robust LLM deployment.

Abstract: This study explored how in-context learning (ICL) in large language models
can be disrupted by data poisoning attacks in the setting of public health
sentiment analysis. Using tweets of Human Metapneumovirus (HMPV), small
adversarial perturbations such as synonym replacement, negation insertion, and
randomized perturbation were introduced into the support examples. Even these
minor manipulations caused major disruptions, with sentiment labels flipping in
up to 67% of cases. To address this, a Spectral Signature Defense was applied,
which filtered out poisoned examples while keeping the data's meaning and
sentiment intact. After defense, ICL accuracy remained steady at around 46.7%,
and logistic regression validation reached 100% accuracy, showing that the
defense successfully preserved the dataset's integrity. Overall, the findings
extend prior theoretical studies of ICL poisoning to a practical, high-stakes
setting in public health discourse analysis, highlighting both the risks and
potential defenses for robust LLM deployment. This study also highlights the
fragility of ICL under attack and the value of spectral defenses in making AI
systems more reliable for health-related social media monitoring.

</details>


### [315] [Does higher interpretability imply better utility? A Pairwise Analysis on Sparse Autoencoders](https://arxiv.org/abs/2510.03659)
*Xu Wang,Yan Hu,Benyou Wang,Difan Zou*

Main category: cs.LG

TL;DR: SAE interpretability doesn't guarantee good steering utility. A new feature selection method (Delta Token Confidence) improves steering performance by 52.52% and reveals interpretability-utility divergence.


<details>
  <summary>Details</summary>
Motivation: To investigate whether higher interpretability in Sparse Autoencoders (SAEs) actually leads to better steering utility for large language models, challenging the common assumption.

Method: Trained 90 SAEs across three LLMs with various architectures and sparsity levels. Evaluated interpretability (SAEBench) and steering utility (AxBench), then proposed Delta Token Confidence feature selection to measure how feature amplification changes token distributions.

Result: Found only weak correlation (tau b ≈ 0.298) between interpretability and steering utility. Delta Token Confidence improved steering performance by 52.52% over existing methods and eliminated the interpretability-utility correlation (tau b ≈ 0).

Conclusion: Interpretability is an insufficient proxy for steering performance. The most effective steering features show no correlation with interpretability, highlighting a fundamental divergence between these two objectives.

Abstract: Sparse Autoencoders (SAEs) are widely used to steer large language models
(LLMs), based on the assumption that their interpretable features naturally
enable effective model behavior steering. Yet, a fundamental question remains
unanswered: does higher interpretability indeed imply better steering utility?
To answer this question, we train 90 SAEs across three LLMs (Gemma-2-2B,
Qwen-2.5-3B, Gemma-2-9B), spanning five architectures and six sparsity levels,
and evaluate their interpretability and steering utility based on SAEBench
(arXiv:2501.12345) and AxBench (arXiv:2502.23456) respectively, and perform a
rank-agreement analysis via Kendall's rank coefficients (tau b). Our analysis
reveals only a relatively weak positive association (tau b approx 0.298),
indicating that interpretability is an insufficient proxy for steering
performance. We conjecture the interpretability utility gap may stem from the
selection of SAE features, as not all of them are equally effective for
steering. To further find features that truly steer the behavior of LLMs, we
propose a novel selection criterion called Delta Token Confidence, which
measures how much amplifying a feature changes the next token distribution. We
show that our method improves the steering performance of three LLMs by 52.52
percent compared to the current best output score based criterion
(arXiv:2503.34567). Strikingly, after selecting features with high Delta Token
Confidence, the correlation between interpretability and utility vanishes (tau
b approx 0), and can even become negative. This further highlights the
divergence between interpretability and utility for the most effective steering
features.

</details>


### [316] [Token Hidden Reward: Steering Exploration-Exploitation in Group Relative Deep Reinforcement Learning](https://arxiv.org/abs/2510.03669)
*Wenlong Deng,Yi Ren,Yushu Li,Boying Gong,Danica J. Sutherland,Xiaoxiao Li,Christos Thrampoulidis*

Main category: cs.LG

TL;DR: THR is a token-level metric that quantifies each token's influence on correct responses. Tokens with positive THR favor exploitation while negative THR enables exploration. A THR-guided reweighting algorithm can bias training toward either strategy.


<details>
  <summary>Details</summary>
Motivation: To address the open problem of explicitly steering reinforcement learning training toward exploration or exploitation in large language models, as current methods lack fine-grained control over these dynamics.

Method: Introduce Token Hidden Reward (THR) metric to quantify token-level influence, then develop a THR-guided reweighting algorithm that modulates GRPO's learning signals to bias training toward exploitation or exploration by amplifying positive THR tokens or negative THR tokens respectively.

Result: The algorithm improves greedy-decoding accuracy when favoring exploitation, and yields consistent gains in Pass@K accuracy when favoring exploration. It integrates seamlessly with other RL objectives like GSPO and generalizes across architectures including Llama.

Conclusion: THR provides a principled and fine-grained mechanism for dynamically controlling exploration and exploitation in RL-tuned LLMs, offering new tools for targeted fine-tuning in reasoning-intensive applications.

Abstract: Reinforcement learning with verifiable rewards has significantly advanced the
reasoning capabilities of large language models, yet how to explicitly steer
training toward exploration or exploitation remains an open problem. We
introduce Token Hidden Reward (THR), a token-level metric that quantifies each
token's influence on the likelihood of correct responses under Group Relative
Policy Optimization (GRPO). We find that training dynamics are dominated by a
small subset of tokens with high absolute THR values. Most interestingly,
tokens with positive THR strengthen confidence in correct outputs, thus
favoring exploitation, while tokens with negative THR preserve probability mass
for alternative outputs, enabling exploration. This insight suggests a natural
intervention: a THR-guided reweighting algorithm that modulates GRPO's learning
signals to explicitly bias training toward exploitation or exploration. We
validate the efficacy of this algorithm on diverse math reasoning benchmarks.
By amplifying tokens with positive THR value and weakening negative ones, our
algorithm improves greedy-decoding accuracy, favoring exploitation. The reverse
strategy yields consistent gains in Pass@K accuracy, favoring exploration. We
further demonstrate that our algorithm integrates seamlessly with other RL
objectives such as GSPO and generalizes across architectures including Llama.
These findings establish THR as a principled and fine-grained mechanism for
dynamically controlling exploration and exploitation in RL-tuned LLMs,
providing new tools for targeted fine-tuning in reasoning-intensive
applications.

</details>


### [317] [Optimizing Fine-Tuning through Advanced Initialization Strategies for Low-Rank Adaptation](https://arxiv.org/abs/2510.03731)
*Yongfu Xue*

Main category: cs.LG

TL;DR: IniLoRA improves LoRA by initializing low-rank matrices to approximate original model weights, achieving better performance across models and tasks.


<details>
  <summary>Details</summary>
Motivation: LoRA's zero-product initialization limits activation of original model weights, creating a performance bottleneck that IniLoRA addresses.

Method: Proposes IniLoRA with novel initialization strategy that approximates original weights, plus two variants (IniLoRA-α and IniLoRA-β) with distinct initialization methods.

Result: Experimental results show IniLoRA achieves better performance than LoRA across various models and tasks.

Conclusion: IniLoRA effectively overcomes LoRA's initialization limitations and enhances parameter-efficient fine-tuning performance.

Abstract: The rapid development of parameter-efficient fine-tuning methods has
noticeably improved the efficiency of adapting large language models. Among
these, LoRA has gained widespread popularity due to its strong balance of
effectiveness and parameter efficiency. However, LoRA relies on initializing
two low-rank matrices whose product is zero, which limits its ability to
effectively activate and leverage the original model weights-creating a
potential bottleneck for optimal performance. To address this limitation, we
propose \textbf{IniLoRA}, a novel initialization strategy that initializes the
low-rank matrices to closely approximate the original model weights.
Experimental results indicate that IniLoRA achieves better performance than
LoRA across a range of models and tasks. Additionally, we introduce two
variants, IniLoRA-$\alpha$ and IniLoRA-$\beta$, both leveraging distinct
initialization methods to enhance performance further.

</details>


### [318] [Unlocking Reasoning Capabilities in LLMs via Reinforcement Learning Exploration](https://arxiv.org/abs/2510.03865)
*Wenhao Deng,Long Wei,Chenglei Yu,Tailin Wu*

Main category: cs.LG

TL;DR: RAPO algorithm addresses RLVR's exploration limitations by replacing reverse KL with forward KL divergence for out-of-distribution exploration and adaptively reweighting reference policy for in-distribution exploration, achieving better performance on mathematical reasoning tasks.


<details>
  <summary>Details</summary>
Motivation: RLVR-trained models show diminishing advantages over base models with increased sampling budget due to reverse KL divergence's mode-seeking behavior that restricts exploration within the base model's support region.

Method: Proposes RAPO algorithm that uses forward KL penalty instead of reverse KL for out-of-distribution exploration and reweights reference policy for adaptive in-distribution exploration, trained on SimpleRL-Zero dataset without supervised fine-tuning.

Result: RAPO-trained Qwen2.5-3B and 7B models consistently improve problem-solving performance on AIME2024 and AIME2025, surpassing base model's performance ceiling and solving previously intractable problems.

Conclusion: RAPO advances RLVR for challenging reasoning tasks by enabling broader yet focused exploration, overcoming limitations of traditional reverse KL regularization.

Abstract: Reinforcement learning with verifiable rewards (RLVR) has recently enhanced
the reasoning capabilities of large language models (LLMs), particularly for
mathematical problem solving. However, a fundamental limitation remains: as the
sampling budget increases, the advantage of RLVR-trained models over their
pretrained bases often diminishes or even vanishes, revealing a strong
dependence on the base model's restricted search space. We attribute this
phenomenon to the widespread use of the reverse Kullback-Leibler (KL)
divergence regularizer, whose mode-seeking behavior keeps the policy trapped
inside the base model's support region and hampers wider exploration. To
address this issue, we propose RAPO (Rewards-Aware Policy Optimization), an
algorithm to promote broader yet focused exploration. Our method (i) utilizes
the forward KL penalty to replace the reverse KL penalty for
out-of-distribution exploration, and (ii) reweights the reference policy to
facilitate adaptive in-distribution exploration. We train Qwen2.5-3B and 7B
models with RAPO on the 8K SimpleRL-Zero dataset, without supervised
fine-tuning, and evaluate them on AIME2024 and AIME2025. Results show that RAPO
consistently improves problem-solving performance. Notably, RAPO enables models
to surpass the base model's performance ceiling and solves previously
intractable problems, advancing the frontier of RLVR for challenging reasoning
tasks.

</details>


### [319] [LLM Chemistry Estimation for Multi-LLM Recommendation](https://arxiv.org/abs/2510.03930)
*Huascar Sanchez,Briland Hitaj*

Main category: cs.LG

TL;DR: LLM Chemistry is a framework that measures synergistic or antagonistic behaviors in multi-LLM collaborations, quantifying interaction dependencies to recommend optimal model ensembles.


<details>
  <summary>Details</summary>
Motivation: Existing multi-LLM approaches rely on implicit selection and output assessment without analyzing whether collaborating models truly complement or conflict with each other.

Method: Formalized the notion of chemistry among LLMs, proposed algorithms to quantify it by analyzing interaction dependencies, and developed ensemble recommendation methods based on theoretical analysis.

Result: Evaluation on classification, summarization, and program repair tasks showed task-dependent effects, with chemistry being most evident under heterogeneous model profiles and influenced by task type, group size, and complexity.

Conclusion: LLM Chemistry serves as both a diagnostic factor in multi-LLM systems and a foundation for ensemble recommendation, establishing that model interactions significantly impact collective performance beyond individual capabilities.

Abstract: Multi-LLM collaboration promises accurate, robust, and context-aware
solutions, yet existing approaches rely on implicit selection and output
assessment without analyzing whether collaborating models truly complement or
conflict. We introduce LLM Chemistry -- a framework that measures when LLM
combinations exhibit synergistic or antagonistic behaviors that shape
collective performance beyond individual capabilities. We formalize the notion
of chemistry among LLMs, propose algorithms that quantify it by analyzing
interaction dependencies, and recommend optimal model ensembles accordingly.
Our theoretical analysis shows that chemistry among collaborating LLMs is most
evident under heterogeneous model profiles, with its outcome impact shaped by
task type, group size, and complexity. Evaluation on classification,
summarization, and program repair tasks provides initial evidence for these
task-dependent effects, thereby reinforcing our theoretical results. This
establishes LLM Chemistry as both a diagnostic factor in multi-LLM systems and
a foundation for ensemble recommendation.

</details>


### [320] [Principled and Tractable RL for Reasoning with Diffusion Language Models](https://arxiv.org/abs/2510.04019)
*Anthony Zhan*

Main category: cs.LG

TL;DR: AGRPO is a principled RL algorithm designed for diffusion LLMs that achieves significant performance gains on math/reasoning tasks over baseline models and comparable RL methods.


<details>
  <summary>Details</summary>
Motivation: Diffusion LLMs have reached parity with autoregressive LLMs but lack modern post-training techniques like RL due to incompatible algorithms and heuristic-based objectives without theoretical grounding.

Method: Amortized Group Relative Policy Optimization (AGRPO) - a principled on-policy RL algorithm using Monte Carlo sampling to compute unbiased policy gradient estimates specifically designed for diffusion LLMs.

Result: Achieved up to +7.6% absolute gain on GSM8K, 3.8x performance on Countdown task over baseline, and 1.3x gains over comparable RL methods like diffu-GRPO, with persistent gains across different inference sampling steps.

Conclusion: Online RL algorithms can be effectively extended to diffusion LLMs in principled ways, maintaining both theoretical soundness and practical effectiveness for better compute-performance tradeoffs.

Abstract: Diffusion large language models (dLLMs) are a new paradigm of
non-autoregressive language models that are trained to predict multiple tokens
in parallel and generate text via iterative unmasking. Recent works have
successfully pretrained dLLMs to parity with autoregressive LLMs at the 8B
scale, but dLLMs have yet to benefit from modern post-training techniques, e.g.
reinforcement learning (RL), that have proven effective for autoregressive
models. Crucially, algorithms designed for traditional LLMs aren't directly
compatible with diffusion frameworks due to inherent differences in modeling
assumptions. Moreover, existing attempts at dLLM post-training with RL rely on
heuristic-based objectives with no theoretical grounding. In this work, we
present Amortized Group Relative Policy Optimization (AGRPO), a principled
on-policy RL algorithm designed specifically for dLLMs. AGRPO uses Monte Carlo
sampling to compute an unbiased policy gradient estimate, making it the first
tractable, faithful adaptation of policy gradient methods for dLLMs. We
demonstrate AGRPO's effectiveness on different math/reasoning tasks, a common
setting for RL with LLMs, achieving up to +7.6% absolute gain on GSM8K and 3.8x
performance on the Countdown task over the baseline LLaDA-8B-Instruct model and
1.3x performance gains over comparable RL methods such as diffu-GRPO.
Furthermore, these gains persist across different numbers of sampling steps at
inference time, achieving better tradeoffs between compute and performance. Our
results demonstrate that online RL algorithms can be extended to diffusion LLMs
in principled ways, maintaining both theoretical soundness and practical
effectiveness.

</details>


### [321] [What Scales in Cross-Entropy Scaling Law?](https://arxiv.org/abs/2510.04067)
*Junxi Yan,Zixi Wei,Jingtao Zhan,Qingyao Ai,Yiqun Liu*

Main category: cs.LG

TL;DR: The paper reveals that cross-entropy scaling law breaks down at large scales, and identifies error-entropy as the only component that truly scales, establishing a more accurate error-entropy scaling law.


<details>
  <summary>Details</summary>
Motivation: Recent evidence shows the cross-entropy scaling law fails at very large model scales, causing problems for LLM development. The authors investigate why this breakdown occurs.

Method: Introduces a novel decomposition of cross-entropy into Error-Entropy, Self-Alignment, and Confidence components. Tests this through extensive experiments on multiple datasets with 32 models spanning five orders of magnitude in size.

Result: Only error-entropy follows robust power-law scaling, while other components remain invariant. Error-entropy dominates cross-entropy in small models but diminishes proportionally in larger models, explaining the scaling law breakdown.

Conclusion: Establishes error-entropy scaling law as a more accurate description of model behavior, with wide applications for training, understanding, and developing large language models.

Abstract: The cross-entropy scaling law has long served as a key tool for guiding the
development of large language models. It shows that cross-entropy loss
decreases in a predictable power-law rate as the model size increases. However,
recent evidence indicates that this law breaks down at very large scales: the
loss decreases more slowly than expected, which causes significant trouble for
developing large language models. In this paper, we hypothesize that the root
cause lies in the fact that cross-entropy itself does not truly scale; instead,
only one of its hidden components does. To investigate this, we introduce a
novel decomposition of cross-entropy into three parts: Error-Entropy,
Self-Alignment, and Confidence. We show both theoretically and empirically that
this decomposition precisely captures the training dynamics and optimization
objectives. Through extensive experiments on multiple datasets and 32 models
spanning five orders of magnitude in size, we find that only error-entropy
follows a robust power-law scaling, while the other two terms remain largely
invariant. Moreover, error-entropy constitutes the dominant share of
cross-entropy in small models but diminishes in proportion as models grow
larger. This explains why the cross-entropy scaling law appears accurate at
small scales but fails at very large ones. Our findings establish the
error-entropy scaling law as a more accurate description of model behavior. We
believe it will have wide applications in the training, understanding, and
future development of large language models.

</details>


### [322] [Slow-Fast Policy Optimization: Reposition-Before-Update for LLM Reasoning](https://arxiv.org/abs/2510.04072)
*Ziyan Wang,Zheng Wang,Jie Fu,Xingwei Qu,Qi Cheng,Shengpu Tang,Minjia Zhang,Xiaoming Huo*

Main category: cs.LG

TL;DR: SFPO is a reinforcement learning framework that improves reasoning in LLMs by using slow-fast policy optimization with reposition mechanisms to stabilize training and reduce rollouts.


<details>
  <summary>Details</summary>
Motivation: Address unstable updates and inefficient exploration in early RL training for LLMs caused by noisy gradients from low-quality rollouts.

Method: Decomposes each training step into three stages: short fast trajectory of inner steps, reposition mechanism to control off-policy drift, and final slow correction while preserving original objective and rollout process.

Result: Outperforms GRPO by up to 2.80 points on math reasoning benchmarks, achieves 4.93× fewer rollouts and 4.19× reduction in wall-clock time to match GRPO's best accuracy.

Conclusion: SFPO consistently improves stability, reduces rollouts, and accelerates convergence of reasoning RL training while being plug-compatible with existing policy-gradient pipelines.

Abstract: Reinforcement learning (RL) has become central to enhancing reasoning in
large language models (LLMs). Yet on-policy algorithms such as Group Relative
Policy Optimization (GRPO) often suffer in early training: noisy gradients from
low-quality rollouts lead to unstable updates and inefficient exploration. We
introduce Slow-Fast Policy Optimization (SFPO), a simple yet efficient
framework to address these limitations via decomposing each step into three
stages: a short fast trajectory of inner steps on the same batch, a reposition
mechanism to control off-policy drift, and a final slow correction. This
reposition-before-update design preserves the objective and rollout process
unchanged, making SFPO plug-compatible with existing policy-gradient pipelines.
Extensive experiments demonstrate that SFPO consistently improves stability,
reduces rollouts, and accelerates convergence of reasoning RL training.
Specifically, it outperforms GRPO by up to 2.80 points in average on math
reasoning benchmarks. It also achieves up to 4.93\texttimes{} fewer rollouts
and a 4.19\texttimes{} reduction in wall-clock time to match GRPO's best
accuracy.

</details>


### [323] [Beyond Next-Token Prediction: A Performance Characterization of Diffusion versus Autoregressive Language Models](https://arxiv.org/abs/2510.04146)
*Minseo Kim,Coleman Hooper,Aditya Tomar,Chenfeng Xu,Mehrdad Farajtabar,Michael W. Mahoney,Kurt Keutzer,Amir Gholami*

Main category: cs.LG

TL;DR: This paper compares Autoregressive Language Models (ARMs) and Diffusion Language Models (DLMs), finding that DLMs offer higher arithmetic intensity through parallel generation but struggle with long contexts, while ARMs excel in batched inference throughput.


<details>
  <summary>Details</summary>
Motivation: To understand the performance trade-offs between ARMs and DLMs, as DLMs offer parallel generation capabilities but their performance characteristics relative to established ARMs are not well understood.

Method: Comprehensive performance study using theoretical analysis and profiling data to characterize ARM vs DLM trade-offs, including analysis of block-wise decoding and batched inference scenarios.

Result: DLMs exhibit higher arithmetic intensity due to sequence parallelism but fail to scale to long contexts effectively. ARMs show superior throughput in batched inference. Block-wise decoding helps DLMs achieve better arithmetic intensity while maintaining context scalability.

Conclusion: DLMs offer performance advantages through parallel generation but require optimization (especially reducing sampling steps) to compete with ARMs on latency, with different architectures excelling in different scenarios.

Abstract: Large Language Models (LLMs) have achieved state-of-the-art performance on a
broad range of Natural Language Processing (NLP) tasks, including document
processing and coding. Autoregressive Language Models (ARMs), which generate
tokens sequentially conditioned on all previous tokens, have been the
predominant paradigm for LLMs. However, while these networks have achieved high
accuracy across a range of downstream tasks, they exhibit low arithmetic
intensity due to the inherent sequential dependency with next-token prediction.
Recently, Diffusion Language Models (DLMs) have emerged as a promising
alternative architecture. DLMs generate output text in parallel, breaking the
limitations of sequential dependency. However, the performance implications of
DLMs relative to commonly deployed ARMs are not fully understood. In this work,
we present a comprehensive performance study analyzing the performance
characteristics of ARMs and DLMs, using both theoretical analysis and profiling
data to characterize the trade-offs between these approaches. We illustrate
that although DLMs exhibit higher arithmetic intensity compared to ARMs because
of their capability to utilize parallelism across sequence lengths, they fail
to scale effectively to longer contexts. We then explore DLMs with block-wise
decoding, outlining how this approach allows for increased arithmetic
intensity, while still scaling well to long contexts (similar to ARMs). We also
show interesting trade-offs for batched inference, where we find that ARMs
exhibit superior throughput, as they benefit more from parallelism across
sequences in the batch. Finally, we highlight opportunities for accelerating
DLM inference, and, in particular, highlight the importance of reducing the
number of sampling steps for allowing open-source DLMs to provide improved
latency relative to ARMs.

</details>


### [324] [Wave-PDE Nets: Trainable Wave-Equation Layers as an Alternative to Attention](https://arxiv.org/abs/2510.04304)
*Harshil Vejendla*

Main category: cs.LG

TL;DR: Wave-PDE Nets use differentiable wave equation simulation as neural network layers, achieving Transformer-level performance with better efficiency through spectral solvers and trainable physical parameters.


<details>
  <summary>Details</summary>
Motivation: To provide an alternative to attention mechanisms and first-order state-space models by leveraging oscillatory, global information propagation through physical wave dynamics.

Method: Each layer propagates hidden states using the second-order wave equation with trainable spatial velocity and damping parameters, implemented via symplectic spectral solver based on FFTs for O(n log n) efficiency.

Result: Matches or exceeds Transformer performance on language and vision benchmarks while reducing wall-clock time by up to 30% and peak memory by 25%. Visualizations show learned intuitive information propagation strategies.

Conclusion: Wave-PDE Nets offer a computationally efficient, robust architecture with strong physical inductive bias, proven to be universal approximators with practical advantages over existing models.

Abstract: We introduce Wave-PDE Nets, a neural architecture whose elementary operation
is a differentiable simulation of the second-order wave equation. Each layer
propagates its hidden state as a continuous field through a medium with
trainable spatial velocity c(x) and damping {\gamma}(x). A symplectic spectral
solver based on FFTs realises this propagation in O(nlog n) time. This
oscillatory, global mechanism provides a powerful alternative to attention and
first-order state-space models. We prove that a single Wave-PDE layer is a
universal approximator. On language and vision benchmarks, Wave-PDE Nets match
or exceed Transformer performance while demonstrating superior practical
efficiency, reducing wall-clock time by up to 30% and peak memory by 25%.
Ablation studies confirm the critical role of symplectic integration and a
spectral Laplacian for stability and performance. Visualizations of the learned
physical parameters reveal that the model learns intuitive strategies for
information propagation. These results position Wave-PDE Nets as a
computationally efficient and robust architecture with a strong physical
inductive bias.

</details>


### [325] [Partial Information Decomposition via Normalizing Flows in Latent Gaussian Distributions](https://arxiv.org/abs/2510.04417)
*Wenyuan Zhao,Adithya Balachandran,Chao Tian,Paul Pu Liang*

Main category: cs.LG

TL;DR: Proposes Gaussian PID (GPID), a computationally efficient partial information decomposition method for multimodal data using Gaussian assumptions and gradient-based optimization, with extensions to non-Gaussian data via information-preserving encoders.


<details>
  <summary>Details</summary>
Motivation: Existing PID methods are computationally expensive and inaccurate for continuous/high-dimensional modalities due to optimization over joint distributions constrained by pairwise probability estimates.

Method: 1) Formulate Gaussian PID (GPID) for multivariate Gaussian pairwise distributions; 2) Develop gradient-based optimization algorithm for efficient computation; 3) Use information-preserving encoders to transform non-Gaussian data to Gaussian distributions; 4) Resolve optimality of joint Gaussian solutions for GPID.

Result: Empirical validation shows more accurate and efficient PID estimates than baselines in synthetic examples, and demonstrates utility in large-scale multimodal benchmarks for quantifying PID and selecting high-performing models.

Conclusion: The proposed GPID framework provides an efficient and accurate solution for partial information decomposition in multimodal settings, with theoretical guarantees and practical applicability to real-world datasets.

Abstract: The study of multimodality has garnered significant interest in fields where
the analysis of interactions among multiple information sources can enhance
predictive modeling, data fusion, and interpretability. Partial information
decomposition (PID) has emerged as a useful information-theoretic framework to
quantify the degree to which individual modalities independently, redundantly,
or synergistically convey information about a target variable. However,
existing PID methods depend on optimizing over a joint distribution constrained
by estimated pairwise probability distributions, which are costly and
inaccurate for continuous and high-dimensional modalities. Our first key
insight is that the problem can be solved efficiently when the pairwise
distributions are multivariate Gaussians, and we refer to this problem as
Gaussian PID (GPID). We propose a new gradient-based algorithm that
substantially improves the computational efficiency of GPID based on an
alternative formulation of the underlying optimization problem. To generalize
the applicability to non-Gaussian data, we learn information-preserving
encoders to transform random variables of arbitrary input distributions into
pairwise Gaussian random variables. Along the way, we resolved an open problem
regarding the optimality of joint Gaussian solutions for GPID. Empirical
validation in diverse synthetic examples demonstrates that our proposed method
provides more accurate and efficient PID estimates than existing baselines. We
further evaluate a series of large-scale multimodal benchmarks to show its
utility in real-world applications of quantifying PID in multimodal datasets
and selecting high-performing models.

</details>


### [326] [LaDiR: Latent Diffusion Enhances LLMs for Text Reasoning](https://arxiv.org/abs/2510.04573)
*Haoqiang Kang,Yizhe Zhang,Nikki Lijing Kuang,Nicklas Majamaki,Navdeep Jaitly,Yi-An Ma,Lianhui Qin*

Main category: cs.LG

TL;DR: LaDiR is a novel reasoning framework that combines continuous latent representations with latent diffusion models to enable iterative refinement of reasoning steps, overcoming limitations of autoregressive decoding in LLMs.


<details>
  <summary>Details</summary>
Motivation: LLMs' autoregressive decoding limits their ability to holistically revisit and refine earlier reasoning steps, and leads to inefficient exploration of diverse solutions.

Method: Uses a VAE to encode text reasoning steps into structured latent thought tokens, then applies a latent diffusion model with blockwise bidirectional attention to iteratively denoise and refine reasoning trajectories.

Result: LaDiR consistently improves accuracy, diversity, and interpretability on mathematical reasoning and planning benchmarks compared to existing methods.

Conclusion: LaDiR reveals a new paradigm for text reasoning with latent diffusion, enabling holistic planning and revision of reasoning processes with adaptive compute.

Abstract: Large Language Models (LLMs) demonstrate their reasoning ability through
chain-of-thought (CoT) generation. However, LLM's autoregressive decoding may
limit the ability to revisit and refine earlier tokens in a holistic manner,
which can also lead to inefficient exploration for diverse solutions. In this
paper, we propose LaDiR (Latent Diffusion Reasoner), a novel reasoning
framework that unifies the expressiveness of continuous latent representation
with the iterative refinement capabilities of latent diffusion models for an
existing LLM. We first construct a structured latent reasoning space using a
Variational Autoencoder (VAE) that encodes text reasoning steps into blocks of
thought tokens, preserving semantic information and interpretability while
offering compact but expressive representations. Subsequently, we utilize a
latent diffusion model that learns to denoise a block of latent thought tokens
with a blockwise bidirectional attention mask, enabling longer horizon and
iterative refinement with adaptive test-time compute. This design allows
efficient parallel generation of diverse reasoning trajectories, allowing the
model to plan and revise the reasoning process holistically. We conduct
evaluations on a suite of mathematical reasoning and planning benchmarks.
Empirical results show that LaDiR consistently improves accuracy, diversity,
and interpretability over existing autoregressive, diffusion-based, and latent
reasoning methods, revealing a new paradigm for text reasoning with latent
diffusion.

</details>


### [327] [Agentic Context Engineering: Evolving Contexts for Self-Improving Language Models](https://arxiv.org/abs/2510.04618)
*Qizheng Zhang,Changran Hu,Shubhangi Upasani,Boyuan Ma,Fenglu Hong,Vamsidhar Kamanuru,Jay Rainton,Chen Wu,Mengmeng Ji,Hanchen Li,Urmish Thakker,James Zou,Kunle Olukotun*

Main category: cs.LG

TL;DR: ACE (Agentic Context Engineering) is a framework that treats contexts as evolving playbooks to prevent brevity bias and context collapse in LLM applications, improving performance on agent and domain-specific tasks without labeled supervision.


<details>
  <summary>Details</summary>
Motivation: Address limitations of prior approaches that suffer from brevity bias (dropping domain insights for concise summaries) and context collapse (eroding details through iterative rewriting) in LLM context adaptation.

Method: Uses a modular process of generation, reflection, and curation to create structured, incremental updates that preserve detailed knowledge. Treats contexts as evolving playbooks that accumulate, refine, and organize strategies.

Result: Outperforms strong baselines: +10.6% on agents and +8.6% on finance benchmarks, reduces adaptation latency and rollout cost. Matches top-ranked production agent on AppWorld leaderboard overall and surpasses it on harder test-challenge split using smaller open-source model.

Conclusion: Comprehensive, evolving contexts enable scalable, efficient, and self-improving LLM systems with low overhead, adapting effectively without labeled supervision by leveraging natural execution feedback.

Abstract: Large language model (LLM) applications such as agents and domain-specific
reasoning increasingly rely on context adaptation -- modifying inputs with
instructions, strategies, or evidence, rather than weight updates. Prior
approaches improve usability but often suffer from brevity bias, which drops
domain insights for concise summaries, and from context collapse, where
iterative rewriting erodes details over time. Building on the adaptive memory
introduced by Dynamic Cheatsheet, we introduce ACE (Agentic Context
Engineering), a framework that treats contexts as evolving playbooks that
accumulate, refine, and organize strategies through a modular process of
generation, reflection, and curation. ACE prevents collapse with structured,
incremental updates that preserve detailed knowledge and scale with
long-context models. Across agent and domain-specific benchmarks, ACE optimizes
contexts both offline (e.g., system prompts) and online (e.g., agent memory),
consistently outperforming strong baselines: +10.6% on agents and +8.6% on
finance, while significantly reducing adaptation latency and rollout cost.
Notably, ACE could adapt effectively without labeled supervision and instead by
leveraging natural execution feedback. On the AppWorld leaderboard, ACE matches
the top-ranked production-level agent on the overall average and surpasses it
on the harder test-challenge split, despite using a smaller open-source model.
These results show that comprehensive, evolving contexts enable scalable,
efficient, and self-improving LLM systems with low overhead.

</details>


### [328] [ONNX-Net: Towards Universal Representations and Instant Performance Prediction for Neural Architectures](https://arxiv.org/abs/2510.04938)
*Shiwen Qin,Alexander Auras,Shay B. Cohen,Elliot J. Crowley,Michael Moeller,Linus Ericsson,Jovita Lukasik*

Main category: cs.LG

TL;DR: ONNX-Bench is a unified benchmark with 600k+ neural network architectures in ONNX format, enabling text-based performance prediction that generalizes across diverse search spaces.


<details>
  <summary>Details</summary>
Motivation: Current neural architecture search methods are limited by expensive performance evaluation and are mostly tied to specific cell-based search spaces with custom graph encodings, restricting flexibility and scalability.

Method: Created ONNX-Bench benchmark with unified ONNX format, developed ONNX-Net text-based encoding using natural language descriptions, and trained performance predictors that can handle arbitrary layer types and topologies.

Result: Achieved strong zero-shot performance across disparate search spaces using minimal pretraining samples, enabling instant evaluation of any neural network architecture.

Conclusion: The approach closes the gap between individual search space restrictions and dependent representations, providing a flexible and scalable solution for neural architecture search performance prediction.

Abstract: Neural architecture search (NAS) automates the design process of
high-performing architectures, but remains bottlenecked by expensive
performance evaluation. Most existing studies that achieve faster evaluation
are mostly tied to cell-based search spaces and graph encodings tailored to
those individual search spaces, limiting their flexibility and scalability when
applied to more expressive search spaces. In this work, we aim to close the gap
of individual search space restrictions and search space dependent network
representations. We present ONNX-Bench, a benchmark consisting of a collection
of neural networks in a unified format based on ONNX files. ONNX-Bench includes
all open-source NAS-bench-based neural networks, resulting in a total size of
more than 600k {architecture, accuracy} pairs. This benchmark allows creating a
shared neural network representation, ONNX-Net, able to represent any neural
architecture using natural language descriptions acting as an input to a
performance predictor. This text-based encoding can accommodate arbitrary layer
types, operation parameters, and heterogeneous topologies, enabling a single
surrogate to generalise across all neural architectures rather than being
confined to cell-based search spaces. Experiments show strong zero-shot
performance across disparate search spaces using only a small amount of
pretraining samples, enabling the unprecedented ability to evaluate any neural
network architecture instantly.

</details>


### [329] [On Structured State-Space Duality](https://arxiv.org/abs/2510.04944)
*Jerry Yao-Chieh Hu,Xiwen Zhang,Weimin Wu,Han Liu*

Main category: cs.LG

TL;DR: The paper formalizes and generalizes Structured State-Space Duality (SSD), extending it from scalar-identity SSMs to general diagonal SSMs, establishing equivalence conditions with masked attention, and showing limitations with standard softmax attention.


<details>
  <summary>Details</summary>
Motivation: To bridge recurrent State-Space Models (SSMs) and Transformers by formalizing the duality between SSMs and masked attention mechanisms, enabling more expressive yet efficient sequence model designs.

Method: Extends SSD from scalar-identity to general diagonal SSMs, analyzes training complexity lower bounds, establishes necessary and sufficient conditions for SSM-attention equivalence, and examines rank explosion in standard softmax attention.

Result: Diagonal SSMs match scalar case's training complexity bounds while supporting richer dynamics, and the paper identifies when SSMs are equivalent to 1-semiseparable masked attention, but shows this duality fails for standard softmax attention due to rank issues.

Conclusion: The results strengthen the connection between recurrent SSMs and Transformers, expanding the design space for creating expressive and efficient sequence models through the established duality framework.

Abstract: Structured State-Space Duality (SSD) [Dao & Gu, ICML 2024] is an equivalence
between a simple Structured State-Space Model (SSM) and a masked attention
mechanism. In particular, a state-space model with a scalar-times-identity
state matrix is equivalent to a masked self-attention with a $1$-semiseparable
causal mask. Consequently, the same sequence transformation (model) has two
algorithmic realizations: as a linear-time $O(T)$ recurrence or as a
quadratic-time $O(T^2)$ attention. In this note, we formalize and generalize
this duality: (i) we extend SSD from the scalar-identity case to general
diagonal SSMs (diagonal state matrices); (ii) we show that these diagonal SSMs
match the scalar case's training complexity lower bounds while supporting
richer dynamics; (iii) we establish a necessary and sufficient condition under
which an SSM is equivalent to $1$-semiseparable masked attention; and (iv) we
show that such duality fails to extend to standard softmax attention due to
rank explosion. Together, these results tighten bridge between recurrent SSMs
and Transformers, and widen the design space for expressive yet efficient
sequence models.

</details>


### [330] [VIFO: Visual Feature Empowered Multivariate Time Series Forecasting with Cross-Modal Fusion](https://arxiv.org/abs/2510.03244)
*Yanlong Wang,Hang Yu,Jian Xu,Fei Ma,Hongkang Zhang,Tongtong Feng,Zijian Zhang,Shao-Lun Huang,Danny Dongning Sun,Xiao-Ping Zhang*

Main category: cs.LG

TL;DR: VIFO is a cross-modal forecasting model that converts multivariate time series into images to leverage pre-trained large vision models for capturing cross-channel dependencies, achieving competitive performance with minimal parameter training.


<details>
  <summary>Details</summary>
Motivation: Existing channel-independent time series models ignore cross-channel dependencies, and multimodal approaches haven't fully utilized large vision models for spatiotemporal data interpretation. There's untapped potential in using different modalities to enhance time series forecasting.

Method: VIFO renders multivariate time series into images to enable pre-trained LVMs to extract complex cross-channel patterns. These visual features are aligned and fused with time series representations. The LVM is frozen with only 7.45% parameters trained.

Result: VIFO achieves competitive performance on multiple benchmarks while being parameter-efficient.

Conclusion: VIFO provides an efficient and effective solution for capturing cross-variable relationships in time series forecasting by leveraging cross-modal learning with frozen vision models.

Abstract: Large time series foundation models often adopt channel-independent
architectures to handle varying data dimensions, but this design ignores
crucial cross-channel dependencies. Concurrently, existing multimodal
approaches have not fully exploited the power of large vision models (LVMs) to
interpret spatiotemporal data. Additionally, there remains significant
unexplored potential in leveraging the advantages of information extraction
from different modalities to enhance time series forecasting performance. To
address these gaps, we propose the VIFO, a cross-modal forecasting model. VIFO
uniquely renders multivariate time series into image, enabling pre-trained LVM
to extract complex cross-channel patterns that are invisible to
channel-independent models. These visual features are then aligned and fused
with representations from the time series modality. By freezing the LVM and
training only 7.45% of its parameters, VIFO achieves competitive performance on
multiple benchmarks, offering an efficient and effective solution for capturing
cross-variable relationships in

</details>


### [331] [Reinforce-Ada: An Adaptive Sampling Framework for Reinforce-Style LLM Training](https://arxiv.org/abs/2510.04996)
*Wei Xiong,Chenlu Ye,Baohao Liao,Hanze Dong,Xinxing Xu,Christof Monz,Jiang Bian,Nan Jiang,Tong Zhang*

Main category: cs.LG

TL;DR: Reinforce-Ada is an adaptive sampling framework for RL post-training of LLMs that dynamically reallocates sampling effort to prompts with greatest uncertainty, accelerating convergence and improving performance compared to GRPO.


<details>
  <summary>Details</summary>
Motivation: Standard RL for LLMs suffers from unstable gradient estimates due to fixed uniform sampling across prompts, creating a bottleneck in reasoning tasks.

Method: Online successive elimination process that interleaves estimation and sampling, automatically stopping sampling for prompts once sufficient signal is collected. Uses fixed-size groups with reward diversity and global advantage baselines.

Result: Empirical results show accelerated convergence and improved final performance across multiple model architectures and reasoning benchmarks, especially with balanced sampling variant.

Conclusion: Variance-aware, adaptive data curation is crucial for efficient and reliable reinforcement learning in reasoning-capable LLMs.

Abstract: Reinforcement learning applied to large language models (LLMs) for reasoning
tasks is often bottlenecked by unstable gradient estimates due to fixed and
uniform sampling of responses across prompts. Prior work such as GVM-RAFT
addresses this by dynamically allocating inference budget per prompt to
minimize stochastic gradient variance under a budget constraint. Inspired by
this insight, we propose Reinforce-Ada, an adaptive sampling framework for
online RL post-training of LLMs that continuously reallocates sampling effort
to the prompts with the greatest uncertainty or learning potential. Unlike
conventional two-stage allocation methods, Reinforce-Ada interleaves estimation
and sampling in an online successive elimination process, and automatically
stops sampling for a prompt once sufficient signal is collected. To stabilize
updates, we form fixed-size groups with enforced reward diversity and compute
advantage baselines using global statistics aggregated over the adaptive
sampling phase. Empirical results across multiple model architectures and
reasoning benchmarks show that Reinforce-Ada accelerates convergence and
improves final performance compared to GRPO, especially when using the balanced
sampling variant. Our work highlights the central role of variance-aware,
adaptive data curation in enabling efficient and reliable reinforcement
learning for reasoning-capable LLMs. Code is available at
https://github.com/RLHFlow/Reinforce-Ada.

</details>


### [332] [Frequency-Aware Model Parameter Explorer: A new attribution method for improving explainability](https://arxiv.org/abs/2510.03245)
*Ali Yavari,Alireza Mohamadi,Elham Beydaghi,Rainer A. Leitgeb*

Main category: cs.LG

TL;DR: The paper proposes a novel transferable frequency-aware adversarial attack method and a corresponding attribution method called FAMPE that improves DNN explainability by leveraging both high- and low-frequency components.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of ensuring DNN reliability against real-world noise and intentional perturbations, and to improve the suboptimal efficacy of existing attribution methods.

Method: Proposes transferable frequency-aware attacks that enable frequency-aware exploration via both high- and low-frequency components, and develops FAMPE (Frequency-Aware Model Parameter Explorer) as a novel attribution method.

Result: FAMPE achieves an average gain of 13.02% in Insertion Score compared to the state-of-the-art method AttEXplore, outperforming existing approaches.

Conclusion: The study demonstrates the effectiveness of frequency-aware approaches for improving DNN explainability and investigates the roles of both high- and low-frequency components through ablation studies.

Abstract: Ensuring the reliability of deep neural networks (DNNs) in the presence of
real world noise and intentional perturbations remains a significant challenge.
To address this, attribution methods have been proposed, though their efficacy
remains suboptimal and necessitates further refinement. In this paper, we
propose a novel category of transferable adversarial attacks, called
transferable frequency-aware attacks, enabling frequency-aware exploration via
both high-and low-frequency components. Based on this type of attacks, we also
propose a novel attribution method, named Frequency-Aware Model Parameter
Explorer (FAMPE), which improves the explainability for DNNs. Relative to the
current state-of-the-art method AttEXplore, our FAMPE attains an average gain
of 13.02% in Insertion Score, thereby outperforming existing approaches.
Through detailed ablation studies, we also investigate the role of both high-
and low-frequency components in explainability.

</details>


### [333] [Real-Time Brain Biomechanics Prediction with Neural Operators: Toward Clinically Deployable Traumatic Brain Injury Models](https://arxiv.org/abs/2510.03248)
*Anusha Agarwal,Dibakar Roy Sarkar,Somdatta Goswami*

Main category: cs.LG

TL;DR: Neural operators enable real-time prediction of brain displacement fields for traumatic brain injury modeling, reducing computation time from hours to milliseconds while maintaining high accuracy.


<details>
  <summary>Details</summary>
Motivation: Finite element models for traumatic brain injury are computationally expensive (hours per simulation), limiting clinical utility for rapid decision-making. There's a need for faster, patient-specific brain deformation predictions.

Method: Used four neural operator architectures (FNO, F-FNO, MG-FNO, DeepONet) to map anatomical MRI, MRE stiffness maps, and demographic features to 3D brain displacement predictions. Trained on 249 MRE datasets across physiological frequencies (20-90 Hz).

Result: MG-FNO achieved highest accuracy (MSE = 0.0023, 94.3% spatial fidelity), F-FNO converged 2x faster than FNO, and DeepONet offered fastest inference (14.5 iterations/s) with 7x speed-up over MG-FNO. All NOs reduced computation from hours to milliseconds.

Conclusion: Neural operators provide efficient, resolution-invariant approach for brain deformation prediction, enabling real-time TBI risk assessment, clinical triage support, and potential for brain digital twins in clinical and population health contexts.

Abstract: Traumatic brain injury (TBI) remains a major public health concern, with over
69 million cases annually worldwide. Finite element (FE) models offer
high-fidelity predictions of brain deformation but are computationally
expensive, requiring hours per simulation and limiting their clinical utility
for rapid decision-making. This study benchmarks state-of-the-art neural
operator (NO) architectures for rapid, patient-specific prediction of brain
displacement fields, aiming to enable real-time TBI modeling in clinical and
translational settings. We formulated TBI modeling as an operator learning
problem, mapping subject-specific anatomical MRI, magnetic resonance
elastography (MRE) stiffness maps, and demographic features to full-field 3D
brain displacement predictions. Four architectures - Fourier Neural Operator
(FNO), Factorized FNO (F-FNO), Multi-Grid FNO (MG-FNO), and Deep Operator
Network (DeepONet) were trained and evaluated on 249 MRE datasets across
physiologically relevant frequencies (20 - 90 Hz). MG-FNO achieved the highest
accuracy (MSE = 0.0023, 94.3\% spatial fidelity) and preserved fine-scale
features, while F-FNO converged 2$\times$ faster than standard FNO. DeepONet
offered the fastest inference (14.5 iterations/s) with a 7$\times$
computational speed-up over MG-FNO, suggesting utility for embedded or edge
computing applications. All NOs reduced computation time from hours to
milliseconds without sacrificing anatomical realism. NOs provide an efficient,
resolution-invariant approach for predicting brain deformation, opening the
door to real-time, patient-specific TBI risk assessment, clinical triage
support, and optimization of protective equipment. These results highlight the
potential for NO-based digital twins of the human brain, enabling scalable,
on-demand biomechanical modeling in both clinical and population health
contexts.

</details>


### [334] [Universal Multi-Domain Translation via Diffusion Routers](https://arxiv.org/abs/2510.03252)
*Duc Kieu,Kien Do,Tuan Hoang,Thao Minh Le,Tung Kieu,Dang Nguyen,Thin Nguyen*

Main category: cs.LG

TL;DR: Universal Multi-Domain Translation (UMDT) enables translation between any pair of K domains using only K-1 paired datasets with a central domain, overcoming limitations of existing approaches.


<details>
  <summary>Details</summary>
Motivation: Existing multi-domain translation methods require fully aligned tuples or can only handle domain pairs seen in training, limiting practicality and excluding many cross-domain mappings.

Method: Proposed Diffusion Router (DR) - a unified diffusion-based framework that models all central↔non-central translations with a single noise predictor conditioned on domain labels, enabling indirect translations via central domain routing and direct mappings through variational-bound objective and Tweedie refinement.

Result: DR achieves state-of-the-art results on three large-scale UMDT benchmarks for both indirect and direct translations, while lowering sampling cost and enabling novel tasks like sketch↔segmentation.

Conclusion: DR establishes a scalable and versatile framework for universal translation across multiple domains, overcoming limitations of previous approaches.

Abstract: Multi-domain translation (MDT) aims to learn translations between multiple
domains, yet existing approaches either require fully aligned tuples or can
only handle domain pairs seen in training, limiting their practicality and
excluding many cross-domain mappings. We introduce universal MDT (UMDT), a
generalization of MDT that seeks to translate between any pair of $K$ domains
using only $K-1$ paired datasets with a central domain. To tackle this problem,
we propose Diffusion Router (DR), a unified diffusion-based framework that
models all central$\leftrightarrow$non-central translations with a single noise
predictor conditioned on the source and target domain labels. DR enables
indirect non-central translations by routing through the central domain. We
further introduce a novel scalable learning strategy with a variational-bound
objective and an efficient Tweedie refinement procedure to support direct
non-central mappings. Through evaluation on three large-scale UMDT benchmarks,
DR achieves state-of-the-art results for both indirect and direct translations,
while lowering sampling cost and unlocking novel tasks such as
sketch$\leftrightarrow$segmentation. These results establish DR as a scalable
and versatile framework for universal translation across multiple domains.

</details>


### [335] [Learning to Interpret Weight Differences in Language Models](https://arxiv.org/abs/2510.05092)
*Avichal Goel,Yoon Kim,Nir Shavit,Tony T. Wang*

Main category: cs.LG

TL;DR: Diff Interpretation Tuning (DIT) trains models to describe their own finetuning-induced weight changes using natural language, enabling interpretability of model modifications.


<details>
  <summary>Details</summary>
Motivation: Finetuning changes model weights but these changes are not interpretable, and finetuning datasets are often unavailable or too large to analyze directly.

Method: DIT uses synthetic, labeled weight diffs to train a DIT adapter that can be applied to finetuned models to make them describe their changes in natural language.

Result: The method enables models to accurately describe their finetuning-induced modifications using natural language in proof-of-concept settings.

Conclusion: DIT provides a way to comprehensively understand weight diffs through natural language descriptions, improving model interpretability.

Abstract: Finetuning (pretrained) language models is a standard approach for updating
their internal parametric knowledge and specializing them to new tasks and
domains. However, the corresponding model weight changes ("weight diffs") are
not generally interpretable. While inspecting the finetuning dataset can give a
sense of how the model might have changed, these datasets are often not
publicly available or are too large to work with directly. Towards the goal of
comprehensively understanding weight diffs in natural language, we introduce
Diff Interpretation Tuning (DIT), a method that trains models to describe their
own finetuning-induced modifications. Our approach uses synthetic, labeled
weight diffs to train a DIT adapter, which can be applied to a compatible
finetuned model to make it describe how it has changed. We demonstrate in two
proof-of-concept settings (reporting hidden behaviors and summarizing finetuned
knowledge) that our method enables models to describe their finetuning-induced
modifications using accurate natural language descriptions.

</details>


### [336] [Rethinking Inter-LoRA Orthogonality in Adapter Merging: Insights from Orthogonal Monte Carlo Dropout](https://arxiv.org/abs/2510.03262)
*Andi Zhang,Xuan Ding,Haofan Wang,Steven McDonagh,Samuel Kaski*

Main category: cs.LG

TL;DR: Orthogonal Monte Carlo Dropout enforces strict orthogonality in LoRA merging without extra time complexity, but empirical results show this doesn't achieve semantic compositionality.


<details>
  <summary>Details</summary>
Motivation: LoRA modules often interfere when merged, reducing semantic compositionality. The paper aims to eliminate this interference through orthogonal merging.

Method: Orthogonal Monte Carlo Dropout that enforces strict orthogonality between merged LoRA vectors without increasing computational complexity.

Result: The method successfully achieves orthogonality but empirical analysis shows it doesn't lead to semantic disentanglement or compositionality as expected.

Conclusion: Inter-LoRA orthogonality alone is insufficient for true semantic compositionality, requiring re-examination of adapter merging approaches.

Abstract: We propose Orthogonal Monte Carlo Dropout, a mechanism that enforces strict
orthogonality when combining sparse semantic vectors without extra time
complexity. LoRA, a popular fine-tuning method for large models, typically
trains a module to represent a specific concept such as an object or a style.
When multiple LoRAs are merged, for example to generate an object in a
particular style, their semantic vectors may interfere with each other. Our
method guarantees, at the theoretical and runtime levels, that merged LoRAs
remain orthogonal and thus free from direct interference. However, empirical
analysis reveals that such orthogonality does not lead to the semantic
disentanglement or compositionality highlighted in prior work on compositional
adaptation. This finding suggests that inter-LoRA orthogonality alone may be
insufficient for achieving true semantic compositionality, prompting a
re-examination of its role in adapter merging.

</details>


### [337] [From Noisy Traces to Stable Gradients: Bias-Variance Optimized Preference Optimization for Aligning Large Reasoning Models](https://arxiv.org/abs/2510.05095)
*Mingkang Zhu,Xi Chen,Bei Yu,Hengshuang Zhao,Jiaya Jia*

Main category: cs.LG

TL;DR: BVPO is a preference optimization method for large reasoning models that reduces gradient variance by mixing trace-based and empty-trace estimators, improving alignment and reasoning performance.


<details>
  <summary>Details</summary>
Motivation: Aligning large reasoning models with human preferences is crucial for deployment, but current methods suffer from high gradient variance due to stochastic trace sampling during preference optimization.

Method: BVPO frames preference optimization through bias-variance trade-off and mixes two gradient estimators: a high-variance trace-based estimator and a low-variance empty-trace estimator obtained by disabling reasoning trace generation.

Result: BVPO improves alignment by up to 7.8 points on AlpacaEval~2 and 6.8 points on Arena-Hard, and boosts reasoning performance by up to 4.0 points on math benchmarks despite training only on conversational data.

Conclusion: Trace sampling variance is a key bottleneck in preference optimization, and directly optimizing the bias-variance trade-off yields more stable training and stronger overall performance.

Abstract: Large reasoning models (LRMs) generate intermediate reasoning traces before
producing final answers, yielding strong gains on multi-step and mathematical
tasks. Yet aligning LRMs with human preferences, a crucial prerequisite for
model deployment, remains underexplored. The statistically correct objective
for preference alignment requires marginalizing over reasoning traces, but this
computation is intractable in practice. A common workaround optimizes a single
sampled trajectory, which introduces substantial gradient variance from
stochastic trace sampling. To address this challenge, we frame preference
optimization for LRMs through the lens of the bias--variance trade-off and
propose Bias--Variance Optimized Preference Optimization (BVPO), a simple,
drop-in method that mixes two gradient estimators: a high-variance trace-based
estimator and a low-variance empty-trace estimator obtained by disabling
reasoning trace generation. Our theory shows that BVPO strictly reduces
trace-induced variance for any nontrivial mixture, provides a closed-form
choice of the mixing weight that minimizes mean-squared error relative to the
true marginal gradient, and under standard smoothness and step-size conditions,
tightens classical convergence bounds for stochastic gradient descent.
Empirically, BVPO improves alignment over the best baseline by up to 7.8 points
on AlpacaEval~2 and 6.8 points on Arena-Hard. Despite being trained only on
general conversational data, BVPO also boosts reasoning performance for base
models by up to 4.0 points on the average of six math reasoning benchmarks.
These results identify variance from trace sampling as a key bottleneck and
demonstrate that directly optimizing the bias--variance trade-off yields more
stable training and stronger overall performance.

</details>


### [338] [SDQ-LLM: Sigma-Delta Quantization for 1-bit LLMs of any size](https://arxiv.org/abs/2510.03275)
*Junhao Xia,Ming Zhao,Limin Xiao,Xiujun Zhang*

Main category: cs.LG

TL;DR: SDQ-LLM is a novel framework for 1-bit quantization of LLMs using Sigma-Delta quantization with adjustable Over-Sampling Ratio, enabling efficient deployment while maintaining reasoning capabilities.


<details>
  <summary>Details</summary>
Motivation: Large language models face significant computational and memory challenges, making extremely low-bit quantization crucial for efficient deployment.

Method: Uses upsampling with Sigma-Delta Quantizer to binarize/ternarize LLM weights, Hadamard-based weight smoothing, and MultiOSR strategy for layer-wise OSR allocation based on weight variance.

Result: Achieves efficient and high-precision performance even under aggressive low-OSR settings on OPT and LLaMA model families.

Conclusion: SDQ-LLM enables extremely low-bit quantization of LLMs while preserving linguistic reasoning capabilities through adaptive OSR adjustment and optimized quantization strategies.

Abstract: Large language models (LLMs) face significant computational and memory
challenges, making extremely low-bit quantization crucial for their efficient
deployment. In this work, we introduce SDQ-LLM: Sigma-Delta Quantization for
1-bit LLMs of any size, a novel framework that enables extremely low-bit
quantization of LLMs while preserving their linguistic reasoning capabilities.
A distinctive feature of SDQ-LLM is the continuous adjustability of the
Over-Sampling Ratio (OSR), enabling dynamic adaptation to memory or VRAM
constraints by selecting fractional OSR (e.g. 2.5 times) for an optimal
trade-off between model size and accuracy. SDQ-LLM uses upsampling combined
with Sigma-Delta Quantizer to binarize or ternarize LLMs weights, encoding
high-precision parameters into 1-bit or 1.58-bit representations, replacing the
multiplication operations within linear layers with addition. This approach
significantly enhances inference efficiency under extremely low-bit
quantization. To further reduce the loss of quantization precision, we
incorporate Hadamard-based weight smoothing prior to quantization, improving
the stability and robustness of the weight representations. Furthermore, to
fully leverage the continuity of the OSR and reduce precision loss, recognizing
the correlation between quantization sensitivity and weight variance, we
propose a fine-grained, layer- and linear-wise OSR allocation strategy,
MultiOSR. This strategy distributes OSR both across layers and within each
layer, based on weight variance and parameter scale. Finally, extensive
experiments on OPT and LLaMA model families demonstrate that SDQ-LLM achieves a
more efficient and high-precision performance even under highly aggressive
low-OSR settings. Our code is available at
https://github.com/Dreamlittlecat/LLM-Quant-Factory.

</details>


### [339] [Revoking Amnesia: RL-based Trajectory Optimization to Resurrect Erased Concepts in Diffusion Models](https://arxiv.org/abs/2510.03302)
*Daiheng Gao,Nanxiang Jiang,Andi Zhang,Shilin Lu,Yufei Tang,Wenbo Zhou,Weiming Zhang,Zhaoxin Fan*

Main category: cs.LG

TL;DR: Concept erasure in diffusion models creates only an illusion of forgetting by biasing sampling trajectories rather than genuine concept removal, making the erasure fundamentally reversible.


<details>
  <summary>Details</summary>
Motivation: To reveal that current concept erasure methods are ineffective in next-generation models like Flux, showing they only create superficial safety rather than genuine concept removal.

Method: Proposed RevAm, an RL-based trajectory optimization framework that resurrects erased concepts by dynamically steering the denoising process without modifying model weights, using Group Relative Policy Optimization adapted to diffusion models.

Result: RevAm achieves superior concept resurrection fidelity while reducing computational time by 10x, exposing vulnerabilities in current safety mechanisms.

Conclusion: Current concept erasure techniques are fundamentally reversible, highlighting the need for more robust erasure methods beyond trajectory manipulation.

Abstract: Concept erasure techniques have been widely deployed in T2I diffusion models
to prevent inappropriate content generation for safety and copyright
considerations. However, as models evolve to next-generation architectures like
Flux, established erasure methods (\textit{e.g.}, ESD, UCE, AC) exhibit
degraded effectiveness, raising questions about their true mechanisms. Through
systematic analysis, we reveal that concept erasure creates only an illusion of
``amnesia": rather than genuine forgetting, these methods bias sampling
trajectories away from target concepts, making the erasure fundamentally
reversible. This insight motivates the need to distinguish superficial safety
from genuine concept removal. In this work, we propose \textbf{RevAm}
(\underline{Rev}oking \underline{Am}nesia), an RL-based trajectory optimization
framework that resurrects erased concepts by dynamically steering the denoising
process without modifying model weights. By adapting Group Relative Policy
Optimization (GRPO) to diffusion models, RevAm explores diverse recovery
trajectories through trajectory-level rewards, overcoming local optima that
limit existing methods. Extensive experiments demonstrate that RevAm achieves
superior concept resurrection fidelity while reducing computational time by
10$\times$, exposing critical vulnerabilities in current safety mechanisms and
underscoring the need for more robust erasure techniques beyond trajectory
manipulation.

</details>


### [340] [Conditional Pseudo-Supervised Contrast for Data-Free Knowledge Distillation](https://arxiv.org/abs/2510.03375)
*Renrong Shao,Wei Zhang,Jun wang*

Main category: cs.LG

TL;DR: CPSC-DFKD is a novel data-free knowledge distillation method that uses conditional GANs to generate category-specific diverse images for pseudo-supervised learning, improving both student model performance and generator quality.


<details>
  <summary>Details</summary>
Motivation: Current DFKD methods have limitations: they lack pseudo-supervised learning paradigms, cannot distinguish distributions of different categories (producing ambiguous samples), and cannot optimize category-wise diversity, which hinders student model learning.

Method: Proposes CPSC-DFKD with three key innovations: (1) conditional GAN to synthesize category-specific diverse images for pseudo-supervised learning, (2) improved generator modules to distinguish distributions of different categories, and (3) pseudo-supervised contrastive learning based on teacher and student views to enhance diversity.

Result: Comprehensive experiments on three commonly-used datasets validate performance improvements for both the student model and generator.

Conclusion: CPSC-DFKD effectively addresses limitations of current DFKD methods by introducing conditional generation and contrastive learning, achieving better performance in data-free knowledge distillation.

Abstract: Data-free knowledge distillation~(DFKD) is an effective manner to solve model
compression and transmission restrictions while retaining privacy protection,
which has attracted extensive attention in recent years. Currently, the
majority of existing methods utilize a generator to synthesize images to
support the distillation. Although the current methods have achieved great
success, there are still many issues to be explored. Firstly, the outstanding
performance of supervised learning in deep learning drives us to explore a
pseudo-supervised paradigm on DFKD. Secondly, current synthesized methods
cannot distinguish the distributions of different categories of samples, thus
producing ambiguous samples that may lead to an incorrect evaluation by the
teacher. Besides, current methods cannot optimize the category-wise diversity
samples, which will hinder the student model learning from diverse samples and
further achieving better performance. In this paper, to address the above
limitations, we propose a novel learning paradigm, i.e., conditional
pseudo-supervised contrast for data-free knowledge distillation~(CPSC-DFKD).
The primary innovations of CPSC-DFKD are: (1) introducing a conditional
generative adversarial network to synthesize category-specific diverse images
for pseudo-supervised learning, (2) improving the modules of the generator to
distinguish the distributions of different categories, and (3) proposing
pseudo-supervised contrastive learning based on teacher and student views to
enhance diversity. Comprehensive experiments on three commonly-used datasets
validate the performance lift of both the student and generator brought by
CPSC-DFKD. The code is available at https://github.com/RoryShao/CPSC-DFKD.git

</details>


### [341] [Longitudinal Flow Matching for Trajectory Modeling](https://arxiv.org/abs/2510.03569)
*Mohammad Mohaiminul Islam,Thijs P. Kuipers,Sharvaree Vadgama,Coen de Vente,Afsana Khan,Clara I. Sánchez,Erik J. Bekkers*

Main category: cs.LG

TL;DR: IMMFM learns continuous stochastic dynamics from sparsely sampled high-dimensional trajectories by using piecewise-quadratic interpolation paths and jointly optimizing drift and diffusion coefficients.


<details>
  <summary>Details</summary>
Motivation: Existing generative models struggle with sparsely sampled and high-dimensional sequential data, often reducing dynamics learning to pairwise transitions.

Method: Uses piecewise-quadratic interpolation paths as smooth targets for flow matching, jointly optimizes drift and data-driven diffusion coefficient with theoretical stability guarantees.

Result: Outperforms existing methods in forecasting accuracy and downstream tasks on synthetic benchmarks and real-world longitudinal neuroimaging datasets.

Conclusion: IMMFM effectively captures intrinsic stochasticity, handles irregular sparse sampling, and generates subject-specific trajectories for sequential data.

Abstract: Generative models for sequential data often struggle with sparsely sampled
and high-dimensional trajectories, typically reducing the learning of dynamics
to pairwise transitions. We propose \textit{Interpolative Multi-Marginal Flow
Matching} (IMMFM), a framework that learns continuous stochastic dynamics
jointly consistent with multiple observed time points. IMMFM employs a
piecewise-quadratic interpolation path as a smooth target for flow matching and
jointly optimizes drift and a data-driven diffusion coefficient, supported by a
theoretical condition for stable learning. This design captures intrinsic
stochasticity, handles irregular sparse sampling, and yields subject-specific
trajectories. Experiments on synthetic benchmarks and real-world longitudinal
neuroimaging datasets show that IMMFM outperforms existing methods in both
forecasting accuracy and further downstream tasks.

</details>


### [342] [Efficient Test-Time Scaling for Small Vision-Language Models](https://arxiv.org/abs/2510.03574)
*Mehmet Onurcan Kaya,Desmond Elliott,Dim P. Papadopoulos*

Main category: cs.LG

TL;DR: The paper proposes two efficient test-time scaling strategies for small Vision-Language Models: TTAug (test-time augmentation) and TTAdapt (test-time adaptation), which improve performance while maintaining computational efficiency.


<details>
  <summary>Details</summary>
Motivation: Small VLMs are computationally efficient but have weaker generalization and task performance. Existing test-time scaling methods are computationally demanding, contradicting the resource-efficient goals of small models.

Method: Two strategies: (1) TTAug - generates multiple augmented inputs and aggregates outputs at token level without parameter updates; (2) TTAdapt - adapts model parameters during inference using consensus-based pseudolabels from TTAug.

Result: Extensive experiments across nine benchmarks show consistent performance improvements while maintaining computational efficiency suitable for resource-constrained environments.

Conclusion: The approach is generalizable across different model scales and VLMs without additional tuning, providing an efficient solution for enhancing small VLMs.

Abstract: Small Vision-Language Models (VLMs) provide a computationally efficient
alternative to larger models, at the cost of weaker generalization abilities
and downstream task performance. These shortcomings could be addressed by
test-time scaling techniques, but existing methods are typically
computationally demanding, contradicting the resource-efficient design goals of
small models. To address these limitations, we propose two novel and efficient
test-time scaling strategies that leverage the model-internal features rather
than external supervision: (i) Test-Time Augmentation (TTAug), which generates
multiple augmented inputs and aggregates outputs at the token level without
parameter updates, and (ii) Test-Time Adaptation (TTAdapt), which adapts model
parameters during inference using consensus-based pseudolabels from TTAug.
Through extensive experiments across nine benchmarks, we demonstrate consistent
performance improvements while maintaining computational efficiency suitable
for resource-constrained environments. The generality of our approach is
demonstrated both within models at different scales and across different VLMs
without additional tuning.

</details>


### [343] [Using predefined vector systems as latent space configuration for neural network supervised training on data with arbitrarily large number of classes](https://arxiv.org/abs/2510.04090)
*Nikita Gabdullin*

Main category: cs.LG

TL;DR: A method to train neural networks with fixed architecture regardless of class count by using predefined vector systems as target latent space configurations, enabling training on datasets with extremely large numbers of classes.


<details>
  <summary>Details</summary>
Motivation: Supervised learning methods require neural network parameters dependent on class count, limiting applicability when number of classes is extremely large or unknown in advance.

Method: Use predefined vector systems as target latent space configuration during training, specifically randomly perturbed vectors of An root system, matching NN predictions with these predefined vectors.

Result: Successfully trained encoders and ViT on Cinic-10 and ImageNet-1K in low- and high-dimensional cases, and ViT on dataset with 1.28 million classes.

Conclusion: Method enables training with fixed NN architecture regardless of class count, applicable to extremely large class datasets, with potential applications in lifelong learning and NN distillation.

Abstract: Supervised learning (SL) methods are indispensable for neural network (NN)
training used to perform classification tasks. While resulting in very high
accuracy, SL training often requires making NN parameter number dependent on
the number of classes, limiting their applicability when the number of classes
is extremely large or unknown in advance. In this paper we propose a
methodology that allows one to train the same NN architecture regardless of the
number of classes. This is achieved by using predefined vector systems as the
target latent space configuration (LSC) during NN training. We discuss the
desired properties of target configurations and choose randomly perturbed
vectors of An root system for our experiments. These vectors are used to
successfully train encoders and visual transformers (ViT) on Cinic-10 and
ImageNet-1K in low- and high-dimensional cases by matching NN predictions with
the predefined vectors. Finally, ViT is trained on a dataset with 1.28 million
classes illustrating the applicability of the method to training on datasets
with extremely large number of classes. In addition, potential applications of
LSC in lifelong learning and NN distillation are discussed illustrating
versatility of the proposed methodology.

</details>


### [344] [DoRAN: Stabilizing Weight-Decomposed Low-Rank Adaptation via Noise Injection and Auxiliary Networks](https://arxiv.org/abs/2510.04331)
*Nghiem T. Diep,Hien Dang,Tuan Truong,Tan Dinh,Huy Nguyen,Nhat Ho*

Main category: cs.LG

TL;DR: DoRAN improves DoRA by adding noise-based regularization and dynamic parameter generation for more stable training and better sample efficiency.


<details>
  <summary>Details</summary>
Motivation: To address training instability and improve sample efficiency in parameter-efficient fine-tuning methods, particularly building on DoRA's limitations.

Method: Two-stage approach: (1) inject noise into DoRA's denominator for adaptive regularization, (2) replace static low-rank matrices with auxiliary networks for dynamic parameter generation with cross-layer coupling.

Result: Consistently outperforms LoRA, DoRA, and other PEFT baselines on vision and language benchmarks.

Conclusion: Combining noise-based regularization with network-based parameter generation offers a promising direction for robust and efficient fine-tuning of foundation models.

Abstract: Parameter-efficient fine-tuning (PEFT) methods have become the standard
paradigm for adapting large-scale models. Among these techniques,
Weight-Decomposed Low-Rank Adaptation (DoRA) has been shown to improve both the
learning capacity and training stability of the vanilla Low-Rank Adaptation
(LoRA) method by explicitly decomposing pre-trained weights into magnitude and
directional components. In this work, we propose DoRAN, a new variant of DoRA
designed to further stabilize training and boost the sample efficiency of DoRA.
Our approach includes two key stages: (i) injecting noise into the denominator
of DoRA's weight decomposition, which serves as an adaptive regularizer to
mitigate instabilities; and (ii) replacing static low-rank matrices with
auxiliary networks that generate them dynamically, enabling parameter coupling
across layers and yielding better sample efficiency in both theory and
practice. Comprehensive experiments on vision and language benchmarks show that
DoRAN consistently outperforms LoRA, DoRA, and other PEFT baselines. These
results underscore the effectiveness of combining stabilization through
noise-based regularization with network-based parameter generation, offering a
promising direction for robust and efficient fine-tuning of foundation models.

</details>


### [345] [Real-time Prediction of Urban Sound Propagation with Conditioned Normalizing Flows](https://arxiv.org/abs/2510.04510)
*Achim Eckerle,Martin Spitznagel,Janis Keuper*

Main category: cs.LG

TL;DR: The paper presents a conditional Normalizing Flows (Full-Glow) model that generates urban sound-pressure maps from 2D urban layouts in real time, achieving >2000x speedup over physics-based solvers while improving accuracy.


<details>
  <summary>Details</summary>
Motivation: Accurate and fast urban noise prediction is needed for public health and regulatory workflows in cities, but physics-based solvers are too slow for time-critical iterative studies required by the Environmental Noise Directive.

Method: Uses conditional Normalizing Flows (Full-Glow) to generate standards-compliant urban sound-pressure maps from 2D urban layouts, enabling real-time computation on commodity hardware (RTX 4090).

Result: Achieves >2000x speedup over reference solver, improves NLoS accuracy by up to 24% versus prior deep models, reaches 0.65 dB MAE in Baseline NLoS with high structural fidelity, and reproduces diffraction and interference patterns.

Conclusion: The model enables interactive exploration and instant recomputation under source or geometry changes, making it practical for urban planning, compliance mapping, and operational assessments like temporary road closures and night-work variance.

Abstract: Accurate and fast urban noise prediction is pivotal for public health and for
regulatory workflows in cities, where the Environmental Noise Directive
mandates regular strategic noise maps and action plans, often needed in
permission workflows, right-of-way allocation, and construction scheduling.
Physics-based solvers are too slow for such time-critical, iterative "what-if"
studies. We evaluate conditional Normalizing Flows (Full-Glow) for generating
for generating standards-compliant urban sound-pressure maps from 2D urban
layouts in real time per 256x256 map on a single RTX 4090), enabling
interactive exploration directly on commodity hardware. On datasets covering
Baseline, Diffraction, and Reflection regimes, our model accelerates map
generation by >2000 times over a reference solver while improving NLoS accuracy
by up to 24% versus prior deep models; in Baseline NLoS we reach 0.65 dB MAE
with high structural fidelity. The model reproduces diffraction and
interference patterns and supports instant recomputation under source or
geometry changes, making it a practical engine for urban planning, compliance
mapping, and operations (e.g., temporary road closures, night-work variance
assessments).

</details>


### [346] [Post-training quantization of vision encoders needs prefixing registers](https://arxiv.org/abs/2510.04547)
*Seunghyeon Kim,Jinho Kim,Taesun Yeom,Wonpyo Park,Kyuyeun Kim,Jaeho Lee*

Main category: cs.LG

TL;DR: RegCache is a training-free algorithm that mitigates outliers in vision encoders by adding prefix tokens to prevent other tokens from having outliers, enabling better quantization with smaller accuracy drops.


<details>
  <summary>Details</summary>
Motivation: Transformer-based vision encoders like CLIP are crucial for multimodal applications requiring real-time processing, but reducing inference cost through quantization is challenging due to massive-scale activation outliers.

Method: RegCache introduces outlier-prone yet semantically meaningless prefix tokens to vision encoders, using middle-layer prefixing and token deletion techniques to prevent outliers in other tokens.

Result: The method consistently improves accuracy of quantized models across both text-supervised and self-supervised vision encoders.

Conclusion: RegCache effectively addresses outlier issues in vision encoder quantization through training-free prefix token manipulation, enabling practical deployment with reduced accuracy degradation.

Abstract: Transformer-based vision encoders -- such as CLIP -- are central to
multimodal intelligence, powering applications from autonomous web agents to
robotic control. Since these applications often demand real-time processing of
massive visual data, reducing the inference cost of vision encoders is
critical. Post-training quantization offers a practical path, but remains
challenging even at 8-bit precision due to massive-scale activations (i.e.,
outliers). In this work, we propose $\textit{RegCache}$, a training-free
algorithm to mitigate outliers in vision encoders, enabling quantization with
significantly smaller accuracy drops. The proposed RegCache introduces
outlier-prone yet semantically meaningless prefix tokens to the target vision
encoder, which prevents other tokens from having outliers. Notably, we observe
that outliers in vision encoders behave differently from those in language
models, motivating two technical innovations: middle-layer prefixing and token
deletion. Experiments show that our method consistently improves the accuracy
of quantized models across both text-supervised and self-supervised vision
encoders.

</details>


### [347] [SONA: Learning Conditional, Unconditional, and Mismatching-Aware Discriminator](https://arxiv.org/abs/2510.04576)
*Yuhta Takida,Satoshi Hayakawa,Takashi Shibuya,Masaaki Imaizumi,Naoki Murata,Bac Nguyen,Toshimitsu Uesaka,Chieh-Hsin Lai,Yuki Mitsufuji*

Main category: cs.LG

TL;DR: Proposes SONA, a novel discriminator design for conditional GANs that separates naturalness and alignment assessments with adaptive weighting to improve conditional generation quality.


<details>
  <summary>Details</summary>
Motivation: Existing conditional GANs struggle to balance authenticity assessment and conditional alignment within their discriminators, leading to suboptimal conditional generation performance.

Method: Introduces SONA discriminator with three components: unconditional discrimination, matching-aware supervision for alignment sensitivity, and adaptive weighting. Uses separate projections for naturalness and alignment with inductive bias, dedicated objective functions, and adaptive weighting mechanism.

Result: Extensive experiments on class-conditional generation show superior sample quality and conditional alignment compared to state-of-the-art methods. Also demonstrates effectiveness in text-to-image generation.

Conclusion: SONA provides a versatile and robust approach for conditional generation by effectively balancing authenticity and alignment objectives through its novel discriminator design.

Abstract: Deep generative models have made significant advances in generating complex
content, yet conditional generation remains a fundamental challenge. Existing
conditional generative adversarial networks often struggle to balance the dual
objectives of assessing authenticity and conditional alignment of input samples
within their conditional discriminators. To address this, we propose a novel
discriminator design that integrates three key capabilities: unconditional
discrimination, matching-aware supervision to enhance alignment sensitivity,
and adaptive weighting to dynamically balance all objectives. Specifically, we
introduce Sum of Naturalness and Alignment (SONA), which employs separate
projections for naturalness (authenticity) and alignment in the final layer
with an inductive bias, supported by dedicated objective functions and an
adaptive weighting mechanism. Extensive experiments on class-conditional
generation tasks show that \ours achieves superior sample quality and
conditional alignment compared to state-of-the-art methods. Furthermore, we
demonstrate its effectiveness in text-to-image generation, confirming the
versatility and robustness of our approach.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [348] [Use of Quadcopter Wakes to Supplement Strawberry Pollination](https://arxiv.org/abs/2510.03974)
*Sadie Cutler,Ben DeFay,Scott McArt,Kirstin Petersen*

Main category: eess.SY

TL;DR: A quadcopter-based wind pollination method was tested to supplement natural pollination in strawberry crops, showing promise in lab studies but inconclusive field results.


<details>
  <summary>Details</summary>
Motivation: Pollinators are declining globally, creating pollination shortfalls in crops like strawberry. There's a need for affordable, simple supplemental pollination solutions that farmers can easily implement.

Method: Used quadcopters to create wind pollination by determining optimal height for maximum lateral flow, then conducted field experiments where quadcopters assisted natural pollinators.

Result: Field experiments were inconclusive, but laboratory studies showed the concept has promise and could be adapted for better field performance.

Conclusion: The wind pollination approach using quadcopters shows potential as a supplemental pollination method and warrants further investigation with adaptations for improved field effectiveness.

Abstract: Pollinators are critical to the world's ecosystems and food supply, yet
recent studies have found pollination shortfalls in several crops, including
strawberry. This is troubling because wild and managed pollinators are
currently experiencing declines. One possibility is to try and provide
supplemental pollination solutions. These solutions should be affordable and
simple for farmers to implement if their use is to be widespread; quadcopters
are a great example, already used for monitoring on many farms. This paper
investigates a new method for artificial pollination based on wind pollination
that bears further investigation. After determining the height where the
lateral flow is maximized, we performed field experiments with a quadcopter
assisting natural pollinators. Although our results in the field were
inconclusive, lab studies show that the idea shows promise and could be adapted
for better field results.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [349] [Efficient Surgical Robotic Instrument Pose Reconstruction in Real World Conditions Using Unified Feature Detection](https://arxiv.org/abs/2510.03532)
*Zekai Liang,Kazuya Miyata,Xiao Liang,Florian Richter,Michael C. Yip*

Main category: cs.RO

TL;DR: A novel camera-to-robot calibration framework for surgical robots that unifies keypoint and edge detection through shared encoding, enabling efficient pose estimation with fast inference and high accuracy.


<details>
  <summary>Details</summary>
Motivation: Minimally invasive surgical robots have long kinematic chains and partial visibility of degrees of freedom, making conventional calibration methods inadequate. Existing approaches struggle with consistent feature detection or have long inference times unsuitable for online robot control.

Method: Proposes a unified framework that detects both geometric primitives (keypoints and shaft edges) through shared encoding, enabling efficient pose estimation via projection geometry. Uses single inference for both detections and is trained on large-scale synthetic data with projective labeling.

Result: Demonstrates fast performance and state-of-the-art accuracy in challenging surgical environments across both feature detection and pose evaluation, with qualitative and quantitative validation.

Conclusion: The proposed method provides an efficient and accurate solution for camera-to-robot calibration in surgical robotics, overcoming limitations of previous approaches through unified geometric primitive detection and shared encoding.

Abstract: Accurate camera-to-robot calibration is essential for any vision-based
robotic control system and especially critical in minimally invasive surgical
robots, where instruments conduct precise micro-manipulations. However, MIS
robots have long kinematic chains and partial visibility of their degrees of
freedom in the camera, which introduces challenges for conventional
camera-to-robot calibration methods that assume stiff robots with good
visibility. Previous works have investigated both keypoint-based and
rendering-based approaches to address this challenge in real-world conditions;
however, they often struggle with consistent feature detection or have long
inference times, neither of which are ideal for online robot control. In this
work, we propose a novel framework that unifies the detection of geometric
primitives (keypoints and shaft edges) through a shared encoding, enabling
efficient pose estimation via projection geometry. This architecture detects
both keypoints and edges in a single inference and is trained on large-scale
synthetic data with projective labeling. This method is evaluated across both
feature detection and pose estimation, with qualitative and quantitative
results demonstrating fast performance and state-of-the-art accuracy in
challenging surgical environments.

</details>


### [350] [EmbodiSwap for Zero-Shot Robot Imitation Learning](https://arxiv.org/abs/2510.03706)
*Eadom Dessalene,Pavan Mantripragada,Michael Maynord,Yiannis Aloimonos*

Main category: cs.RO

TL;DR: EmbodiSwap is a method for creating photorealistic synthetic robot overlays on human videos to enable zero-shot imitation learning, bridging the gap between human video data and robot embodiments.


<details>
  <summary>Details</summary>
Motivation: To address the embodiment gap between in-the-wild ego-centric human video data and target robot embodiments for imitation learning, enabling robots to learn from human demonstrations without direct robot data.

Method: Uses EmbodiSwap to generate synthetic robot overlays on human videos, trains closed-loop robot manipulation policies on this synthetic data, and employs V-JEPA as a visual backbone repurposed from video understanding to imitation learning.

Result: The V-JEPA model achieves 82% success rate in real-world tests, outperforming few-shot trained π₀ network and π₀ trained on EmbodiSwap data. V-JEPA also outperforms alternative vision backbones commonly used in robotics.

Conclusion: EmbodiSwap with V-JEPA backbone enables effective zero-shot imitation learning from human videos to robot manipulation, providing a scalable approach to bridge the embodiment gap and releasing code, datasets, and models for broader adoption.

Abstract: We introduce EmbodiSwap - a method for producing photorealistic synthetic
robot overlays over human video. We employ EmbodiSwap for zero-shot imitation
learning, bridging the embodiment gap between in-the-wild ego-centric human
video and a target robot embodiment. We train a closed-loop robot manipulation
policy over the data produced by EmbodiSwap. We make novel use of V-JEPA as a
visual backbone, repurposing V-JEPA from the domain of video understanding to
imitation learning over synthetic robot videos. Adoption of V-JEPA outperforms
alternative vision backbones more conventionally used within robotics. In
real-world tests, our zero-shot trained V-JEPA model achieves an $82\%$ success
rate, outperforming a few-shot trained $\pi_0$ network as well as $\pi_0$
trained over data produced by EmbodiSwap. We release (i) code for generating
the synthetic robot overlays which takes as input human videos and an arbitrary
robot URDF and generates a robot dataset, (ii) the robot dataset we synthesize
over EPIC-Kitchens, HOI4D and Ego4D, and (iii) model checkpoints and inference
code, to facilitate reproducible research and broader adoption.

</details>


### [351] [NoTVLA: Narrowing of Dense Action Trajectories for Generalizable Robot Manipulation](https://arxiv.org/abs/2510.03895)
*Zheng Huang,Mingyu Liu,Xiaoyi Lin,Muzhi Zhu,Canyu Zhao,Zongze Du,Xiaoman Li,Yiduo Jia,Hao Zhong,Hao Chen,Chunhua Shen*

Main category: cs.RO

TL;DR: NoTVLA is a Vision-Language-Action framework that addresses catastrophic forgetting by focusing on sparse trajectories of robot end effectors instead of dense action sequences, enabling better multi-task performance with significantly reduced computational requirements.


<details>
  <summary>Details</summary>
Motivation: To overcome catastrophic forgetting in VLA models caused by overreliance on continuous action sequences that create data silos and disrupt knowledge retention across tasks.

Method: Uses trajectory planning focused on robot end effector's trajectory with temporal compression and spatial reasoning pruning, training with sparse trajectories instead of dense action trajectories.

Result: Achieves superior performance and generalization compared to pi0 while using over 10x less computing power and no wrist-mounted camera, with accuracy approaching single-task expert models.

Conclusion: NoTVLA effectively prevents catastrophic forgetting, preserves language capabilities, enables zero-shot generalization, supports unified deployment across robot platforms, and maintains performance from novel perspectives.

Abstract: Vision-Language-Action (VLA) models represent a pivotal advance in embodied
intelligence, yet they confront critical barriers to real-world deployment,
most notably catastrophic forgetting. This issue stems from their overreliance
on continuous action sequences or action chunks, which inadvertently create
isolated data silos that disrupt knowledge retention across tasks. To tackle
these challenges, we propose the Narrowing of Trajectory VLA (NoTVLA)
framework: a novel approach that narrows its focus to sparse trajectories,
thereby avoiding the catastrophic forgetting associated with dense trajectory
fine-tuning. A key innovation of NoTVLA lies in its trajectory planning
strategy: instead of centering on the target object's trajectory, it leverages
temporal compression and spatial reasoning pruning specifically for the robot
end effector's trajectory. Furthermore, training is conducted using these
sparse trajectories rather than dense action trajectories, an optimization that
delivers remarkable practical advantages with better performance in zero-shot.
In multi-task evaluation scenarios, NoTVLA achieves superior performance and
generalization compared to pi0 while operating under two critical constraints:
it uses over an order of magnitude less computing power than pi0 and requires
no wrist-mounted camera. This design ensures that NoTVLA's operational accuracy
closely approximates that of single-task expert models. Crucially, it also
preserves the model's inherent language capabilities, enabling zero-shot
generalization in specific scenarios, supporting unified model deployment
across multiple robot platforms, and fostering a degree of generalization even
when perceiving tasks from novel perspectives.

</details>


### [352] [CLEAR-IR: Clarity-Enhanced Active Reconstruction of Infrared Imagery](https://arxiv.org/abs/2510.04883)
*Nathan Shankar,Pawel Ladosz,Hujun Yin*

Main category: cs.RO

TL;DR: A U-Net-based method reconstructs clean IR images from emitter-populated input to enable robust robotic perception in dark environments.


<details>
  <summary>Details</summary>
Motivation: IR stream is less noisy than RGB in low-light but dominated by active emitter patterns that hinder high-level robotic tasks like object detection and tracking.

Method: Proposes a U-Net-based architecture that reconstructs clean IR images from emitter-populated input.

Result: The approach outperforms existing enhancement techniques and improves both image quality and downstream robotic performance.

Conclusion: Enables reliable operation of vision-driven robotic systems across illumination conditions from well-lit to extreme low-light scenes.

Abstract: This paper presents a novel approach for enabling robust robotic perception
in dark environments using infrared (IR) stream. IR stream is less susceptible
to noise than RGB in low-light conditions. However, it is dominated by active
emitter patterns that hinder high-level tasks such as object detection,
tracking and localisation. To address this, a U-Net-based architecture is
proposed that reconstructs clean IR images from emitter-populated input,
improving both image quality and downstream robotic performance. This approach
outperforms existing enhancement techniques and enables reliable operation of
vision-driven robotic systems across illumination conditions from well-lit to
extreme low-light scenes.

</details>


### [353] [StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation](https://arxiv.org/abs/2510.05057)
*Mingyu Liu,Jiuhe Shu,Hui Chen,Zeju Li,Canyu Zhao,Jiange Yang,Shenyuan Gao,Hao Chen,Chunhua Shen*

Main category: cs.RO

TL;DR: Unsupervised learning of compressed two-token state representations using DiT decoder, achieving efficient world modeling and emergent latent actions without video data dependency.


<details>
  <summary>Details</summary>
Motivation: Existing methods fail to balance expressiveness and compactness in state representations, being either redundant or lacking task-critical information.

Method: Uses lightweight encoder and pre-trained Diffusion Transformer decoder to learn compressed two-token representations, with latent interpolation revealing emergent latent actions.

Result: Improves performance by 14.3% on LIBERO and 30% in real-world task success, with latent actions enhancing policy co-training by 10.4% over prior methods.

Conclusion: StaMo learns generalizable robotic motion from static images, challenging dependency on complex architectures and video data, while scaling across diverse data sources.

Abstract: A fundamental challenge in embodied intelligence is developing expressive and
compact state representations for efficient world modeling and decision making.
However, existing methods often fail to achieve this balance, yielding
representations that are either overly redundant or lacking in task-critical
information. We propose an unsupervised approach that learns a highly
compressed two-token state representation using a lightweight encoder and a
pre-trained Diffusion Transformer (DiT) decoder, capitalizing on its strong
generative prior. Our representation is efficient, interpretable, and
integrates seamlessly into existing VLA-based models, improving performance by
14.3% on LIBERO and 30% in real-world task success with minimal inference
overhead. More importantly, we find that the difference between these tokens,
obtained via latent interpolation, naturally serves as a highly effective
latent action, which can be further decoded into executable robot actions. This
emergent capability reveals that our representation captures structured
dynamics without explicit supervision. We name our method StaMo for its ability
to learn generalizable robotic Motion from compact State representation, which
is encoded from static images, challenging the prevalent dependence to learning
latent action on complex architectures and video data. The resulting latent
actions also enhance policy co-training, outperforming prior methods by 10.4%
with improved interpretability. Moreover, our approach scales effectively
across diverse data sources, including real-world robot data, simulation, and
human egocentric video.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [354] [AtomWorld: A Benchmark for Evaluating Spatial Reasoning in Large Language Models on Crystalline Materials](https://arxiv.org/abs/2510.04704)
*Taoyuze Lv,Alexander Chen,Fengyu Xie,Chu Wu,Jeffrey Meng,Dongzhan Zhou,Bram Hoex,Zhicheng Zhong,Tong Xie*

Main category: cond-mat.mtrl-sci

TL;DR: The AtomWorld benchmark evaluates LLMs on crystallographic tasks using CIF files, revealing current models' limitations in structural understanding and spatial reasoning despite their textual abilities.


<details>
  <summary>Details</summary>
Motivation: To address the lack of standardized benchmarks for evaluating LLMs' core reasoning abilities across diverse atomic structures in materials science, where 3D atomic structure understanding is fundamental.

Method: Introduced the AtomWorld benchmark with tasks based on Crystallographic Information Files (CIFs), including structural editing, CIF perception, and property-guided modeling to systematically evaluate LLMs.

Result: Current LLMs consistently fail in structural understanding and spatial reasoning, making frequent errors on structure modification tasks and basic CIF format understanding, potentially leading to cumulative errors in subsequent analysis.

Conclusion: AtomWorld establishes a foundation for advancing LLMs toward robust atomic-scale modeling, which is crucial for accelerating materials research and automating scientific workflows.

Abstract: Large Language Models (LLMs) excel at textual reasoning and are beginning to
develop spatial understanding, prompting the question of whether these
abilities can be combined for complex, domain-specific tasks. This question is
essential in fields like materials science, where deep understanding of 3D
atomic structures is fundamental. While initial studies have successfully
applied LLMs to tasks involving pure crystal generation or coordinate
understandings, a standardized benchmark to systematically evaluate their core
reasoning abilities across diverse atomic structures has been notably absent.
To address this gap, we introduce the AtomWorld benchmark to evaluate LLMs on
tasks based in Crystallographic Information Files (CIFs), a standard structure
representation format. These tasks, including structural editing, CIF
perception, and property-guided modeling, reveal a critical limitation: current
models, despite establishing promising baselines, consistently fail in
structural understanding and spatial reasoning. Our experiments show that these
models make frequent errors on structure modification tasks, and even in the
basic CIF format understandings, potentially leading to cumulative errors in
subsequent analysis and materials insights. By defining these standardized
tasks, AtomWorld lays the ground for advancing LLMs toward robust atomic-scale
modeling, crucial for accelerating materials research and automating scientific
workflows.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [355] [Real-time nonlinear inversion of magnetic resonance elastography with operator learning](https://arxiv.org/abs/2510.03372)
*Juampablo E. Heras Rivera,Caitlin M. Neher,Mehmet Kurt*

Main category: eess.IV

TL;DR: Developed an operator learning framework (oNLI) for real-time brain MRE inversion that achieves 30,000x speedup while maintaining spatial accuracy comparable to nonlinear inversion methods.


<details>
  <summary>Details</summary>
Motivation: To enable real-time inversion of brain magnetic resonance elastography (MRE) data while maintaining the spatial accuracy of nonlinear inversion methods, which are computationally intensive.

Method: Used a predictive deep operator learning framework trained with 10-fold cross-validation on 3D MRE data from 61 individuals, incorporating a structural prior mechanism similar to Soft Prior Regularization. Inputs were complex curl of displacement fields and outputs were NLI-derived reference elastograms.

Result: oNLI achieved significantly lower absolute percent error (8.4±0.5 for μ' and 10.0±0.7 for μ'') compared to CNN baselines (15.8±0.8 for μ' and 26.1±1.1 for μ''), with superior Pearson correlation coefficients across all brain regions (p<0.05).

Conclusion: The oNLI framework enables real-time MRE inversion with 30,000x speedup, outperforming CNN-based approaches while maintaining fine-grained spatial accuracy comparable to nonlinear inversion methods.

Abstract: $\textbf{Purpose:}$ To develop and evaluate an operator learning framework
for nonlinear inversion (NLI) of brain magnetic resonance elastography (MRE)
data, which enables real-time inversion of elastograms with comparable spatial
accuracy to NLI.
  $\textbf{Materials and Methods:}$ In this retrospective study, 3D MRE data
from 61 individuals (mean age, 37.4 years; 34 female) were used for development
of the framework. A predictive deep operator learning framework (oNLI) was
trained using 10-fold cross-validation, with the complex curl of the measured
displacement field as inputs and NLI-derived reference elastograms as outputs.
A structural prior mechanism, analogous to Soft Prior Regularization in the MRE
literature, was incorporated to improve spatial accuracy. Subject-level
evaluation metrics included Pearson's correlation coefficient, absolute
relative error, and structural similarity index measure between predicted and
reference elastograms across brain regions of different sizes to understand
accuracy. Statistical analyses included paired t-tests comparing the proposed
oNLI variants to the convolutional neural network baselines.
  $\textbf{Results:}$ Whole brain absolute percent error was 8.4 $\pm$ 0.5
($\mu'$) and 10.0 $\pm$ 0.7 ($\mu''$) for oNLI and 15.8 $\pm$ 0.8 ($\mu'$) and
26.1 $\pm$ 1.1 ($\mu''$) for CNNs. Additionally, oNLI outperformed
convolutional architectures as per Pearson's correlation coefficient, $r$, in
the whole brain and across all subregions for both the storage modulus and loss
modulus (p < 0.05).
  $\textbf{Conclusion:}$ The oNLI framework enables real-time MRE inversion
(30,000x speedup), outperforming CNN-based approaches and maintaining the
fine-grained spatial accuracy achievable with NLI in the brain.

</details>


### [356] [How We Won BraTS-SSA 2025: Brain Tumor Segmentation in the Sub-Saharan African Population Using Segmentation-Aware Data Augmentation and Model Ensembling](https://arxiv.org/abs/2510.03568)
*Claudia Takyi Ankomah,Livingstone Eli Ayivor,Ireneaus Nyame,Leslie Wambo,Patrick Yeboah Bonsu,Aondona Moses Iorumbur,Raymond Confidence,Toufiq Musah*

Main category: eess.IV

TL;DR: This paper addresses brain tumor segmentation challenges by using segmentation-aware data augmentation and model ensembling on the BraTS-Africa dataset to improve generalization for underserved regions.


<details>
  <summary>Details</summary>
Motivation: Brain tumors like gliomas are difficult to diagnose and monitor due to complex growth patterns and individual variability. Existing deep learning models trained on homogeneous datasets lack robustness when deployed in underserved regions.

Method: Used segmentation-aware offline data augmentation on BraTS-Africa dataset to increase sample size and diversity. Constructed ensemble of three architectures: MedNeXt, SegMamba, and Residual-Encoder U-Net to leverage complementary strengths.

Result: MedNeXt trained for 1000 epochs achieved highest average lesion-wise dice (0.86) and normalized surface distance (0.81). Ensemble model trained for 500 epochs produced most balanced segmentation performance across tumor subregions.

Conclusion: Combination of advanced augmentation and model ensembling can improve segmentation accuracy and robustness on diverse and underrepresented datasets.

Abstract: Brain tumors, particularly gliomas, pose significant chall-enges due to their
complex growth patterns, infiltrative nature, and the variability in brain
structure across individuals, which makes accurate diagnosis and monitoring
difficult. Deep learning models have been developed to accurately delineate
these tumors. However, most of these models were trained on relatively
homogenous high-resource datasets, limiting their robustness when deployed in
underserved regions. In this study, we performed segmentation-aware offline
data augmentation on the BraTS-Africa dataset to increase the data sample size
and diversity to enhance generalization. We further constructed an ensemble of
three distinct architectures, MedNeXt, SegMamba, and Residual-Encoder U-Net, to
leverage their complementary strengths. Our best-performing model, MedNeXt, was
trained on 1000 epochs and achieved the highest average lesion-wise dice and
normalized surface distance scores of 0.86 and 0.81 respectively. However, the
ensemble model trained for 500 epochs produced the most balanced segmentation
performance across the tumour subregions. This work demonstrates that a
combination of advanced augmentation and model ensembling can improve
segmentation accuracy and robustness on diverse and underrepresented datasets.
Code available at:
https://github.com/SPARK-Academy-2025/SPARK-2025/tree/main/SPARK2025_BraTs_MODELS/SPARK_NeuroAshanti

</details>


### [357] [Towards Robust and Generalizable Continuous Space-Time Video Super-Resolution with Events](https://arxiv.org/abs/2510.03833)
*Shuoyan Wei,Feng Li,Shengeng Tang,Runmin Cong,Yao Zhao,Meng Wang,Huihui Bai*

Main category: eess.IV

TL;DR: EvEnhancer is a novel continuous space-time video super-resolution method that leverages event streams for robust generalization to out-of-distribution scales, with EvEnhancerPlus adding a controllable switching mechanism for adaptive pixel-level reconstruction.


<details>
  <summary>Details</summary>
Motivation: Existing continuous space-time video super-resolution methods often generalize poorly to out-of-distribution scales, producing unsatisfactory results when applied to arbitrary spatial and temporal scales.

Method: The approach uses event-adapted synthesis to capture long-term motion trajectories from event streams, combined with a local implicit video transformer for continuous video representations. EvEnhancerPlus adds a controllable switching mechanism that dynamically routes reconstruction based on local event statistics, plus a cross-derivative training strategy for stable convergence.

Result: Extensive experiments show state-of-the-art performance on both synthetic and real-world datasets, with superior generalizability at out-of-distribution scales.

Conclusion: The method successfully achieves robust and generalizable continuous space-time video super-resolution by effectively leveraging event streams and adaptive reconstruction pathways.

Abstract: Continuous space-time video super-resolution (C-STVSR) has garnered
increasing interest for its capability to reconstruct high-resolution and
high-frame-rate videos at arbitrary spatial and temporal scales. However,
prevailing methods often generalize poorly, producing unsatisfactory results
when applied to out-of-distribution (OOD) scales. To overcome this limitation,
we present EvEnhancer, a novel approach that marries the unique properties of
high temporal resolution and high dynamic range encapsulated in event streams
to achieve robust and generalizable C-STVSR. Our approach incorporates
event-adapted synthesis that capitalizes on the spatiotemporal correlations
between frames and events to capture long-term motion trajectories, enabling
adaptive interpolation and fusion across space and time. This is then coupled
with a local implicit video transformer that integrates local implicit video
neural function with cross-scale spatiotemporal attention to learn continuous
video representations and generate plausible videos at arbitrary resolutions
and frame rates. We further develop EvEnhancerPlus, which builds a controllable
switching mechanism that dynamically determines the reconstruction difficulty
for each spatiotemporal pixel based on local event statistics. This allows the
model to adaptively route reconstruction along the most suitable pathways at a
fine-grained pixel level, substantially reducing computational overhead while
maintaining excellent performance. Furthermore, we devise a cross-derivative
training strategy that stabilizes the convergence of such a multi-pathway
framework through staged cross-optimization. Extensive experiments demonstrate
that our method achieves state-of-the-art performance on both synthetic and
real-world datasets, while maintaining superior generalizability at OOD scales.
The code is available at https://github.com/W-Shuoyan/EvEnhancerPlus.

</details>


### [358] [AI-Assisted Pleural Effusion Volume Estimation from Contrast-Enhanced CT Images](https://arxiv.org/abs/2510.03856)
*Sanhita Basu,Tomas Fröding,Ali Teymur Kahraman,Dimitris Toumpanakis,Tobias Sjöblom*

Main category: eess.IV

TL;DR: A semi-supervised deep learning framework called TTAS (Teacher-Teaching Assistant-Student) was developed for pleural effusion segmentation from CT scans, achieving superior performance over state-of-the-art models with a Dice score of 0.82 and significantly lower volume measurement errors.


<details>
  <summary>Details</summary>
Motivation: Accurate measurement of pleural effusion volume from CT scans is challenging but clinically important for patient management. Current methods need improvement for better segmentation and quantification.

Method: Retrospective study using CT Pulmonary Angiogram data with manual annotations on 100 cases. Developed a novel semi-supervised TTAS framework that enables efficient training on non-segmented examinations by leveraging teacher-teaching assistant-student architecture.

Result: TTAS achieved mean Dice score of 0.82 (95% CI: 0.79-0.84) vs 0.73 for nnU-Net (p<0.0001), and four-fold lower mean Absolute Volume Difference (6.49 mL vs 23.16 mL, p<0.0001), demonstrating superior segmentation performance.

Conclusion: The TTAS framework provides superior pleural effusion segmentation from CT scans, enabling more accurate volume determination for clinical management.

Abstract: Background: Pleural Effusions (PE) is a common finding in many different
clinical conditions, but accurately measuring their volume from CT scans is
challenging. Purpose: To improve PE segmentation and quantification for
enhanced clinical management, we have developed and trained a semi-supervised
deep learning framework on contrast-enhanced CT volumes. Materials and Methods:
This retrospective study collected CT Pulmonary Angiogram (CTPA) data from
internal and external datasets. A subset of 100 cases was manually annotated
for model training, while the remaining cases were used for testing and
validation. A novel semi-supervised deep learning framework, Teacher-Teaching
Assistant-Student (TTAS), was developed and used to enable efficient training
in non-segmented examinations. Segmentation performance was compared to that of
state-of-the-art models. Results: 100 patients (mean age, 72 years, 28
[standard deviation]; 55 men) were included in the study. The TTAS model
demonstrated superior segmentation performance compared to state-of-the-art
models, achieving a mean Dice score of 0.82 (95% CI, 0.79 - 0.84) versus 0.73
for nnU-Net (p < 0.0001, Student's T test). Additionally, TTAS exhibited a
four-fold lower mean Absolute Volume Difference (AbVD) of 6.49 mL (95% CI, 4.80
- 8.20) compared to nnU-Net's AbVD of 23.16 mL (p < 0.0001). Conclusion: The
developed TTAS framework offered superior PE segmentation, aiding accurate
volume determination from CT scans.

</details>


### [359] [Sliding Window Attention for Learned Video Compression](https://arxiv.org/abs/2510.03926)
*Alexander Kopte,André Kaup*

Main category: eess.IV

TL;DR: 3D Sliding Window Attention (SWA) replaces patch-based local attention in video transformers, eliminating architectural flaws and computational redundancy while improving compression performance and efficiency.


<details>
  <summary>Details</summary>
Motivation: To address the complexity and architectural flaws (irregular receptive fields, redundant overlapping windows) in patch-based local attention mechanisms used in video compression transformers like VCT.

Method: Introduces 3D Sliding Window Attention (SWA) - a patchless form of local attention that enables decoder-only architecture unifying spatial and temporal context processing with uniform receptive field.

Result: Achieves 18.6% Bjøntegaard Delta-rate savings against VCT baseline, reduces decoder complexity by 2.8x, and makes entropy model 3.5x more efficient. Analysis shows benefits from long-range temporal context but excessive context degrades performance.

Conclusion: 3D Sliding Window Attention provides superior rate-distortion performance and computational efficiency compared to patch-based approaches in video compression transformers, with optimal performance achieved through balanced temporal context utilization.

Abstract: To manage the complexity of transformers in video compression, local
attention mechanisms are a practical necessity. The common approach of
partitioning frames into patches, however, creates architectural flaws like
irregular receptive fields. When adapted for temporal autoregressive models,
this paradigm, exemplified by the Video Compression Transformer (VCT), also
necessitates computationally redundant overlapping windows. This work
introduces 3D Sliding Window Attention (SWA), a patchless form of local
attention. By enabling a decoder-only architecture that unifies spatial and
temporal context processing, and by providing a uniform receptive field, our
method significantly improves rate-distortion performance, achieving
Bj{\o}rntegaard Delta-rate savings of up to 18.6 % against the VCT baseline.
Simultaneously, by eliminating the need for overlapping windows, our method
reduces overall decoder complexity by a factor of 2.8, while its entropy model
is nearly 3.5 times more efficient. We further analyze our model's behavior and
show that while it benefits from long-range temporal context, excessive context
can degrade performance.

</details>


### [360] [The method of the approximate inverse for limited-angle CT](https://arxiv.org/abs/2510.04369)
*Bernadette Hahn,Gael Rigaud,Richard Schmähl*

Main category: eess.IV

TL;DR: A new model-driven approach called CLARK is proposed for limited-angle CT reconstruction, combining spectral filtering, approximate inverse method, and edge-preserving denoising to eliminate streak artifacts while handling severe ill-conditioning.


<details>
  <summary>Details</summary>
Motivation: Limited-angle CT enables faster data acquisition and safer medical scans but standard methods like FBP and total-variation produce artifacts. Deep learning alternatives require large datasets, motivating a new model-driven approach.

Method: The method uses reconstruction kernels precomputed as solutions to auxiliary problems (LARK), combined with spectral filtering and edge-preserving denoising (CLARK) to handle ill-conditioning from limited-angle Radon transform.

Result: The approach successfully eliminates streak artifacts even for large limited angles and works on both synthetic and real semi-discrete data, though it introduces different artifacts from singular functions.

Conclusion: CLARK provides an effective regularization strategy for limited-angle CT reconstruction that could serve as a foundation for future learning approaches, successfully handling the inherent ill-conditioning while preserving edges.

Abstract: Limited-angle computerized tomography stands for one of the most difficult
challenges in imaging. Although it opens the way to faster data acquisition in
industry and less dangerous scans in medicine, standard approaches, such as the
filtered backprojection (FBP) algorithm or the widely used total-variation
functional, often produce various artefacts that hinder the diagnosis. With the
rise of deep learning, many modern techniques have proven themselves successful
in removing such artefacts but at the cost of large datasets. In this paper, we
propose a new model-driven approach based on the method of the approximate
inverse, which could serve as new starting point for learning strategies in the
future. In contrast to FBP-type approaches, our reconstruction step consists in
evaluating linear functionals on the measured data using reconstruction kernels
that are precomputed as solution of an auxiliary problem. With this problem
being uniquely solvable, the derived limited-angle reconstruction kernel (LARK)
is able to fully reconstruct the object without the well-known streak
artefacts, even for large limited angles. However, it inherits severe
ill-conditioning which leads to a different kind of artefacts arising from the
singular functions of the limited-angle Radon transform. The problem becomes
particularly challenging when working on semi-discrete (real or analytical)
measurements. We develop a general regularization strategy, named constrained
limited-angle reconstruction kernel (CLARK), by combining spectral filter, the
method of the approximate inverse and custom edge-preserving denoising in order
to stabilize the whole process. We further derive and interpret error estimates
for the application on real, i.e. semi-discrete, data and we validate our
approach on synthetic and real data.

</details>


### [361] [Adaptive double-phase Rudin--Osher--Fatemi denoising model](https://arxiv.org/abs/2510.04382)
*Wojciech Górny,Michał Łasica,Alexandros Matsoukas*

Main category: eess.IV

TL;DR: A new image denoising model using variable-growth total variation regularization with adaptive weight to reduce staircasing while preserving edges.


<details>
  <summary>Details</summary>
Motivation: To address the staircasing artifact problem in the classical Rudin-Osher-Fatemi model while maintaining good edge preservation capabilities.

Method: Proposed a variable-growth total variation regularization of double-phase type with adaptive weight, implemented and tested on synthetic and natural images in 1D and 2D.

Result: The model was tested over a range of noise levels and showed improved performance in reducing staircasing effects.

Conclusion: The proposed model effectively reduces staircasing artifacts while preserving image edges, offering an improvement over traditional total variation approaches.

Abstract: We propose a new image denoising model based on a variable-growth total
variation regularization of double-phase type with adaptive weight. It is
designed to reduce staircasing with respect to the classical
Rudin--Osher--Fatemi model, while preserving the edges of the image in a
similar fashion. We implement the model and test its performance on synthetic
and natural images in 1D and 2D over a range of noise levels.

</details>


<div id='astro-ph.IM'></div>

# astro-ph.IM [[Back]](#toc)

### [362] [Large Language Models Achieve Gold Medal Performance at International Astronomy & Astrophysics Olympiad](https://arxiv.org/abs/2510.05016)
*Lucas Carrit Delgado Pinheiro,Ziru Chen,Bruno Caixeta Piazza,Ness Shroff,Yingbin Liang,Yuan-Sen Ting,Huan Sun*

Main category: astro-ph.IM

TL;DR: LLMs achieve gold medal-level performance in astronomy theory exams but show significant weaknesses in data analysis and conceptual reasoning, limiting their use as autonomous research agents.


<details>
  <summary>Details</summary>
Motivation: Existing benchmarks only test simple astronomical knowledge, failing to evaluate the complex reasoning needed for real-world astronomy research, creating a need for more comprehensive evaluation.

Method: Systematically benchmarked five state-of-the-art LLMs on International Olympiad on Astronomy and Astrophysics (IOAA) exams, which test deep conceptual understanding, multi-step derivations, and multimodal analysis.

Result: Gemini 2.5 Pro (85.6%) and GPT-5 (84.2%) achieved gold medal performance in theory exams, ranking top 2 among participants. However, data analysis results diverged significantly, with GPT-5 excelling (88.5%) while others dropped to 48-76%. All models showed weaknesses in conceptual reasoning, geometric reasoning, and spatial visualization (52-79% accuracy).

Conclusion: While LLMs approach peak human performance in theory exams, critical gaps in conceptual reasoning and data analysis must be addressed before they can serve as autonomous research agents in astronomy.

Abstract: While task-specific demonstrations show early success in applying large
language models (LLMs) to automate some astronomical research tasks, they only
provide incomplete views of all necessary capabilities in solving astronomy
problems, calling for more thorough understanding of LLMs' strengths and
limitations. So far, existing benchmarks and evaluations focus on simple
question-answering that primarily tests astronomical knowledge and fails to
evaluate the complex reasoning required for real-world research in the
discipline. Here, we address this gap by systematically benchmarking five
state-of-the-art LLMs on the International Olympiad on Astronomy and
Astrophysics (IOAA) exams, which are designed to examine deep conceptual
understanding, multi-step derivations, and multimodal analysis. With average
scores of 85.6% and 84.2%, Gemini 2.5 Pro and GPT-5 (the two top-performing
models) not only achieve gold medal level performance but also rank in the top
two among ~200-300 participants in all four IOAA theory exams evaluated
(2022-2025). In comparison, results on the data analysis exams show more
divergence. GPT-5 still excels in the exams with an 88.5% average score,
ranking top 10 among the participants in the four most recent IOAAs, while
other models' performances drop to 48-76%. Furthermore, our in-depth error
analysis underscores conceptual reasoning, geometric reasoning, and spatial
visualization (52-79% accuracy) as consistent weaknesses among all LLMs. Hence,
although LLMs approach peak human performance in theory exams, critical gaps
must be addressed before they can serve as autonomous research agents in
astronomy.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [363] [Adapting Diarization-Conditioned Whisper for End-to-End Multi-Talker Speech Recognition](https://arxiv.org/abs/2510.03723)
*Martin Kocour,Martin Karafiat,Alexander Polok,Dominik Klement,Lukáš Burget,Jan Černocký*

Main category: eess.AS

TL;DR: Proposes a speaker-attributed Whisper model for multi-talker speech recognition that combines target-speaker modeling with serialized output training, enabling joint decoding of overlapping speech with speaker tags and timestamps.


<details>
  <summary>Details</summary>
Motivation: To improve multi-talker speech recognition by enabling joint decoding that considers all speakers' context simultaneously, overcoming limitations of separate decoding approaches like DiCoW.

Method: Uses Diarization-Conditioned Whisper (DiCoW) encoder to extract target-speaker embeddings, concatenates them into single representation, and processes through shared decoder with serialized output training (SOT) for joint decoding.

Result: Outperforms existing SOT-based approaches and surpasses DiCoW on multi-talker mixtures (e.g., LibriMix).

Conclusion: The proposed speaker-attributed Whisper model with joint decoding effectively handles overlapping speech recognition and shows superior performance compared to existing methods.

Abstract: We propose a speaker-attributed (SA) Whisper-based model for multi-talker
speech recognition that combines target-speaker modeling with serialized output
training (SOT). Our approach leverages a Diarization-Conditioned Whisper
(DiCoW) encoder to extract target-speaker embeddings, which are concatenated
into a single representation and passed to a shared decoder. This enables the
model to transcribe overlapping speech as a serialized output stream with
speaker tags and timestamps. In contrast to target-speaker ASR systems such as
DiCoW, which decode each speaker separately, our approach performs joint
decoding, allowing the decoder to condition on the context of all speakers
simultaneously. Experiments show that the model outperforms existing SOT-based
approaches and surpasses DiCoW on multi-talker mixtures (e.g., LibriMix).

</details>


### [364] [MoME: Mixture of Matryoshka Experts for Audio-Visual Speech Recognition](https://arxiv.org/abs/2510.04136)
*Umberto Cappellazzo,Minsu Kim,Pingchuan Ma,Honglie Chen,Xubo Liu,Stavros Petridis,Maja Pantic*

Main category: eess.AS

TL;DR: MoME integrates Mixture-of-Experts with Matryoshka representation learning in LLMs for audio-visual speech recognition, enabling dynamic token compression and achieving state-of-the-art performance with fewer parameters.


<details>
  <summary>Details</summary>
Motivation: Current LLMs for AVSR have high computational demands and fixed token compression methods that lack flexibility. MRL enables multiple granularities but suffers from limited cross-scale generalization and robustness at high compression.

Method: Proposed MoME framework combines sparse Mixture-of-Experts with MRL-based LLMs, using top-k routed and shared experts with a shared router for dynamic capacity allocation across scales and modalities.

Result: Experiments on LRS2 and LRS3 show state-of-the-art performance across AVSR, ASR, and VSR tasks with significantly fewer parameters, while maintaining robustness under noise.

Conclusion: MoME unifies MRL's adaptability with MoE's efficiency, providing a scalable and interpretable solution for resource-aware speech recognition.

Abstract: Large language models (LLMs) have recently shown strong potential in
audio-visual speech recognition (AVSR), but their high computational demands
and sensitivity to token granularity limit their practicality in
resource-constrained settings. Token compression methods can reduce inference
cost, but they require fixing a compression rate in advance and produce a
single fixed-length output, offering no flexibility to balance information
density and efficiency at inference time. Matryoshka representation learning
(MRL) addresses this by enabling a single model to operate across multiple
token granularities, allowing compression rates to be adjusted dynamically.
However, current MRL-based methods treat each scale independently during
training, limiting cross-scale generalization, robustness at high compression,
and interpretability. To overcome these limitations, we propose MoME (Mixture
of Matryoshka Experts), a novel framework that integrates sparse
Mixture-of-Experts (MoE) into MRL-based LLMs for AVSR. MoME augments a frozen
LLM with top-k routed and shared experts, allowing dynamic capacity allocation
across scales and modalities. A shared router promotes consistent expert
activation across granularities, enabling compressed sequences to benefit from
representations learned at lower compression. Experiments on LRS2 and LRS3
demonstrate that MoME achieves state-of-the-art performance across AVSR, ASR,
and VSR tasks, while requiring significantly fewer parameters and maintaining
robustness under noise. MoME unifies the adaptability of MRL with the
efficiency of MoE, offering a scalable and interpretable solution for
resource-aware speech recognition.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [365] [Speak, Edit, Repeat: High-Fidelity Voice Editing and Zero-Shot TTS with Cross-Attentive Mamba](https://arxiv.org/abs/2510.04738)
*Baher Mohammad,Magauiya Zhussip,Stamatios Lefkimmiatis*

Main category: cs.SD

TL;DR: MAVE is a novel autoregressive architecture for voice editing and TTS that combines Mamba for efficient audio modeling with cross-attention for text-acoustic alignment, achieving state-of-the-art performance with significantly lower memory requirements.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient and high-quality voice editing and synthesis system that can perform both speech editing and zero-shot TTS without explicit training on the latter task, while reducing memory costs compared to existing models.

Method: Integrates Mamba (structured state-space modeling) for efficient audio sequence modeling with cross-attention mechanisms for precise text-acoustic alignment in an autoregressive architecture.

Result: Achieves state-of-the-art in speech editing and competitive zero-shot TTS, with 57.2% of listeners rating edited speech as perceptually equal to original. Requires ~6x less memory than VoiceCraft while maintaining similar latency and outperforming leading models in quality.

Conclusion: MAVE establishes a new standard for flexible, high-fidelity voice editing and synthesis through the synergistic integration of structured state-space modeling and cross-modal attention, offering superior performance with significantly reduced computational costs.

Abstract: We introduce MAVE (Mamba with Cross-Attention for Voice Editing and
Synthesis), a novel autoregressive architecture for text-conditioned voice
editing and high-fidelity text-to-speech (TTS) synthesis, built on a
cross-attentive Mamba backbone. MAVE achieves state-of-the-art performance in
speech editing and very competitive results in zero-shot TTS, while not being
explicitly trained on the latter task, outperforming leading autoregressive and
diffusion models on diverse, real-world audio. By integrating Mamba for
efficient audio sequence modeling with cross-attention for precise
text-acoustic alignment, MAVE enables context-aware voice editing with
exceptional naturalness and speaker consistency. In pairwise human evaluations
on a random 40-sample subset of the RealEdit benchmark (400 judgments), 57.2%
of listeners rated MAVE - edited speech as perceptually equal to the original,
while 24.8% prefered the original and 18.0% MAVE - demonstrating that in the
majority of cases edits are indistinguishable from the source. MAVE compares
favorably with VoiceCraft and FluentSpeech both on pairwise comparisons and
standalone mean opinion score (MOS) evaluations. For zero-shot TTS, MAVE
exceeds VoiceCraft in both speaker similarity and naturalness, without
requiring multiple inference runs or post-processing. Remarkably, these quality
gains come with a significantly lower memory cost and approximately the same
latency: MAVE requires ~6x less memory than VoiceCraft during inference on
utterances from the RealEdit database (mean duration: 6.21s, A100, FP16, batch
size 1). Our results demonstrate that MAVE establishes a new standard for
flexible, high-fidelity voice editing and synthesis through the synergistic
integration of structured state-space modeling and cross-modal attention.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [366] [Model-Guided Microstimulation Steers Primate Visual Behavior](https://arxiv.org/abs/2510.03684)
*Johannes Mehrer,Ben Lonnqvist,Anna Mitola,Abdulkadir Gokce,Paolo Papale,Martin Schrimpf*

Main category: q-bio.NC

TL;DR: A computational framework for model-guided microstimulation of high-level visual cortex that predicts stimulation effects and links them back to primate brain, showing promise for next-generation visual prosthetics.


<details>
  <summary>Details</summary>
Motivation: Current visual prosthetics are limited by hardware constraints and low-level cortical representations. Higher-level visual areas encode complex object representations but determining reliable stimulation targets is challenging.

Method: Three-component framework: (1) perturbation module translating stimulation parameters to neural activity changes, (2) topographic models for prototyping experiments, (3) mapping procedure linking model-optimized sites to primate cortex. Tested in macaque monkeys performing visual recognition tasks.

Result: Model-predicted stimulation produced significant in-vivo changes in perceptual choices. Strong correlation between per-site model predictions and monkey behavior. Image generation showed similarity between in-silico stimulation of face-selective sites and patient-reported facephenes.

Conclusion: Establishes foundation for model-guided microstimulation and points toward next-generation visual prosthetics capable of inducing complex visual experiences.

Abstract: Brain stimulation is a powerful tool for understanding cortical function and
holds promise for therapeutic interventions in neuropsychiatric disorders.
Initial visual prosthetics apply electric microstimulation to early visual
cortex which can evoke percepts of simple symbols such as letters. However,
these approaches are fundamentally limited by hardware constraints and the
low-level representational properties of this cortical region. In contrast,
higher-level visual areas encode more complex object representations and
therefore constitute a promising target for stimulation - but determining
representational targets that reliably evoke object-level percepts constitutes
a major challenge. We here introduce a computational framework to causally
model and guide stimulation of high-level cortex, comprising three key
components: (1) a perturbation module that translates microstimulation
parameters into spatial changes to neural activity, (2) topographic models that
capture the spatial organization of cortical neurons and thus enable
prototyping of stimulation experiments, and (3) a mapping procedure that links
model-optimized stimulation sites back to primate cortex. Applying this
framework in two macaque monkeys performing a visual recognition task,
model-predicted stimulation experiments produced significant in-vivo changes in
perceptual choices. Per-site model predictions and monkey behavior were
strongly correlated, underscoring the promise of model-guided stimulation.
Image generation further revealed a qualitative similarity between in-silico
stimulation of face-selective sites and a patient's report of facephenes. This
proof-of-principle establishes a foundation for model-guided microstimulation
and points toward next-generation visual prosthetics capable of inducing more
complex visual experiences.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [367] [P2P: A Poison-to-Poison Remedy for Reliable Backdoor Defense in LLMs](https://arxiv.org/abs/2510.04503)
*Shuai Zhao,Xinyi Wu,Shiqian Zhao,Xiaobao Wu,Zhongliang Guo,Yanhao Jia,Anh Tuan Luu*

Main category: cs.CR

TL;DR: P2P is a general backdoor defense algorithm that injects benign triggers with safe labels into training data and fine-tunes models using prompt-based learning to override malicious backdoor effects.


<details>
  <summary>Details</summary>
Motivation: Existing defense strategies against data-poisoning backdoor attacks in LLMs have limited generalization - they only work on specific attack types or task settings, compromising model reliability and trustworthiness.

Method: P2P injects benign triggers with safe alternative labels into a subset of training samples and fine-tunes the model on this re-poisoned dataset using prompt-based learning, forcing the model to associate trigger-induced representations with safe outputs.

Result: Extensive experiments on classification, mathematical reasoning, and summary generation tasks with multiple state-of-the-art LLMs show P2P significantly reduces attack success rate compared to baseline models while preserving task performance.

Conclusion: P2P can neutralize malicious backdoors while maintaining task performance and serves as a guideline for defending against backdoor attacks, fostering development of secure and trustworthy LLMs.

Abstract: During fine-tuning, large language models (LLMs) are increasingly vulnerable
to data-poisoning backdoor attacks, which compromise their reliability and
trustworthiness. However, existing defense strategies suffer from limited
generalization: they only work on specific attack types or task settings. In
this study, we propose Poison-to-Poison (P2P), a general and effective backdoor
defense algorithm. P2P injects benign triggers with safe alternative labels
into a subset of training samples and fine-tunes the model on this re-poisoned
dataset by leveraging prompt-based learning. This enforces the model to
associate trigger-induced representations with safe outputs, thereby overriding
the effects of original malicious triggers. Thanks to this robust and
generalizable trigger-based fine-tuning, P2P is effective across task settings
and attack types. Theoretically and empirically, we show that P2P can
neutralize malicious backdoors while preserving task performance. We conduct
extensive experiments on classification, mathematical reasoning, and summary
generation tasks, involving multiple state-of-the-art LLMs. The results
demonstrate that our P2P algorithm significantly reduces the attack success
rate compared with baseline models. We hope that the P2P can serve as a
guideline for defending against backdoor attacks and foster the development of
a secure and trustworthy LLM community.

</details>


### [368] [Proactive defense against LLM Jailbreak](https://arxiv.org/abs/2510.05052)
*Weiliang Zhao,Jinjun Peng,Daniel Ben-Levi,Zhou Yu,Junfeng Yang*

Main category: cs.CR

TL;DR: ProAct is a proactive defense framework that disrupts autonomous jailbreaking attacks by providing misleading responses that trick attackers into thinking they've succeeded, effectively terminating their search process.


<details>
  <summary>Details</summary>
Motivation: Current LLM safety defenses are reactive and static, failing to counter evolving multi-turn jailbreak attacks that iteratively search for successful queries.

Method: The framework intentionally provides adversaries with "spurious responses" that appear to be successful jailbreak results but contain no actual harmful content, misleading the attacker's optimization loop.

Result: ProAct reduces attack success rates by up to 92% across state-of-the-art LLMs and jailbreaking frameworks, and when combined with other defenses, reduces latest attack success rates to 0%.

Conclusion: ProAct represents an orthogonal defense strategy that serves as an additional guardrail to enhance LLM safety against the most effective jailbreaking attacks.

Abstract: The proliferation of powerful large language models (LLMs) has necessitated
robust safety alignment, yet these models remain vulnerable to evolving
adversarial attacks, including multi-turn jailbreaks that iteratively search
for successful queries. Current defenses, primarily reactive and static, often
fail to counter these search-based attacks. In this paper, we introduce ProAct,
a novel proactive defense framework designed to disrupt and mislead autonomous
jailbreaking processes. Our core idea is to intentionally provide adversaries
with "spurious responses" that appear to be results of successful jailbreak
attacks but contain no actual harmful content. These misleading responses
provide false signals to the attacker's internal optimization loop, causing the
adversarial search to terminate prematurely and effectively jailbreaking the
jailbreak. By conducting extensive experiments across state-of-the-art LLMs,
jailbreaking frameworks, and safety benchmarks, our method consistently and
significantly reduces attack success rates by up to 92\%. When combined with
other defense frameworks, it further reduces the success rate of the latest
attack strategies to 0\%. ProAct represents an orthogonal defense strategy that
can serve as an additional guardrail to enhance LLM safety against the most
effective jailbreaking attacks.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [369] [Investigating LLM Variability in Personalized Conversational Information Retrieval](https://arxiv.org/abs/2510.03795)
*Simon Lupart,Daniël van Dijk,Eric Langezaal,Ian van Dort,Mohammad Aliannejadi*

Main category: cs.IR

TL;DR: This reproducibility study examines personalized conversational information retrieval using LLMs, finding that human-selected personal knowledge bases consistently improve retrieval performance while LLM-based selection methods are unreliable, and emphasizes the importance of multi-run evaluations due to high output variability.


<details>
  <summary>Details</summary>
Motivation: To address concerns about output variability and repeatability in previous single-run experiments on personalized CIR, and to extend evaluation across multiple models and datasets for more robust findings.

Method: Rigorous reproduction and extension of previous work using multiple LLMs (Llama 1B-70B, Qwen-7B, GPT-4o-mini) on TREC iKAT 2024 dataset, with multi-run evaluations and variance analysis across different metrics.

Result: Human-selected PTKBs consistently enhance retrieval performance, while LLM-based selection methods don't reliably outperform manual choices. Higher variability observed on iKAT than CAsT, with recall-oriented metrics showing lower variance than precision-oriented ones.

Conclusion: Multi-run evaluations and variance reporting are essential for assessing LLM-based CIR systems, and broader evaluation across models, datasets, and metrics contributes to more robust personalized CIR practices.

Abstract: Personalized Conversational Information Retrieval (CIR) has seen rapid
progress in recent years, driven by the development of Large Language Models
(LLMs). Personalized CIR aims to enhance document retrieval by leveraging
user-specific information, such as preferences, knowledge, or constraints, to
tailor responses to individual needs. A key resource for this task is the TREC
iKAT 2023 dataset, designed to evaluate personalization in CIR pipelines.
Building on this resource, Mo et al. explored several strategies for
incorporating Personal Textual Knowledge Bases (PTKB) into LLM-based query
reformulation. Their findings suggested that personalization from PTKBs could
be detrimental and that human annotations were often noisy. However, these
conclusions were based on single-run experiments using the GPT-3.5 Turbo model,
raising concerns about output variability and repeatability. In this
reproducibility study, we rigorously reproduce and extend their work, focusing
on LLM output variability and model generalization. We apply the original
methods to the new TREC iKAT 2024 dataset and evaluate a diverse range of
models, including Llama (1B-70B), Qwen-7B, GPT-4o-mini. Our results show that
human-selected PTKBs consistently enhance retrieval performance, while
LLM-based selection methods do not reliably outperform manual choices. We
further compare variance across datasets and observe higher variability on iKAT
than on CAsT, highlighting the challenges of evaluating personalized CIR.
Notably, recall-oriented metrics exhibit lower variance than precision-oriented
ones, a critical insight for first-stage retrievers. Finally, we underscore the
need for multi-run evaluations and variance reporting when assessing LLM-based
CIR systems. By broadening evaluation across models, datasets, and metrics, our
study contributes to more robust and generalizable practices for personalized
CIR.

</details>


### [370] [Visual Lifelog Retrieval through Captioning-Enhanced Interpretation](https://arxiv.org/abs/2510.04010)
*Yu-Fei Shih,An-Zi Yen,Hen-Hsen Huang,Hsin-Hsi Chen*

Main category: cs.IR

TL;DR: The paper proposes a Captioning-Integrated Visual Lifelog (CIVIL) Retrieval System that uses generated captions and text embeddings to retrieve specific images from visual lifelogs based on textual queries.


<details>
  <summary>Details</summary>
Motivation: People struggle to remember specific details of past experiences, creating a need for lifelog retrieval systems to help with memory recall. Traditional methods don't adequately address the first-person perspective of visual lifelogs.

Method: The system generates captions for visual lifelogs and uses text embedding models to project both captions and user queries into a shared vector space. Three captioning approaches are introduced: single caption, collective caption, and merged caption methods to interpret lifeloggers' experiences.

Result: Experimental results show the method effectively describes first-person visual images and enhances lifelog retrieval outcomes. A textual dataset converting visual lifelogs into captions was also constructed.

Conclusion: The CIVIL system successfully improves lifelog retrieval by generating meaningful captions that capture the first-person perspective of lifelog experiences, enabling better memory recall assistance.

Abstract: People often struggle to remember specific details of past experiences, which
can lead to the need to revisit these memories. Consequently, lifelog retrieval
has emerged as a crucial application. Various studies have explored methods to
facilitate rapid access to personal lifelogs for memory recall assistance. In
this paper, we propose a Captioning-Integrated Visual Lifelog (CIVIL) Retrieval
System for extracting specific images from a user's visual lifelog based on
textual queries. Unlike traditional embedding-based methods, our system first
generates captions for visual lifelogs and then utilizes a text embedding model
to project both the captions and user queries into a shared vector space.
Visual lifelogs, captured through wearable cameras, provide a first-person
viewpoint, necessitating the interpretation of the activities of the individual
behind the camera rather than merely describing the scene. To address this, we
introduce three distinct approaches: the single caption method, the collective
caption method, and the merged caption method, each designed to interpret the
life experiences of lifeloggers. Experimental results show that our method
effectively describes first-person visual images, enhancing the outcomes of
lifelog retrieval. Furthermore, we construct a textual dataset that converts
visual lifelogs into captions, thereby reconstructing personal life
experiences.

</details>


### [371] [Learning-Based Hashing for ANN Search: Foundations and Early Advances](https://arxiv.org/abs/2510.04127)
*Sean Moran*

Main category: cs.IR

TL;DR: This paper provides a foundational survey of early learning-based hashing methods for Approximate Nearest Neighbour search, focusing on core concepts, historical context, and fundamental principles rather than recent advances.


<details>
  <summary>Details</summary>
Motivation: To introduce the conceptual foundations of learning-based hashing for ANN search and provide a structured understanding of the principles, trade-offs, and open challenges that inform current research.

Method: The survey reviews supervised, unsupervised, and semi-supervised hashing approaches, examining projection functions for meaningful embeddings and quantization strategies for binary code conversion, including extensions to multi-bit and multi-threshold models.

Result: The paper offers a comprehensive overview of early learning-based hashing methods, highlighting how these methods map high-dimensional data to compact binary codes for efficient similarity computations in Hamming space.

Conclusion: By situating early models in their historical context, the survey equips readers with foundational knowledge of learning-based hashing principles that continue to shape current research in information retrieval applications.

Abstract: Approximate Nearest Neighbour (ANN) search is a fundamental problem in
information retrieval, underpinning large-scale applications in computer
vision, natural language processing, and cross-modal search. Hashing-based
methods provide an efficient solution by mapping high-dimensional data into
compact binary codes that enable fast similarity computations in Hamming space.
Over the past two decades, a substantial body of work has explored learning to
hash, where projection and quantisation functions are optimised from data
rather than chosen at random.
  This article offers a foundational survey of early learning-based hashing
methods, with an emphasis on the core ideas that shaped the field. We review
supervised, unsupervised, and semi-supervised approaches, highlighting how
projection functions are designed to generate meaningful embeddings and how
quantisation strategies convert these embeddings into binary codes. We also
examine extensions to multi-bit and multi-threshold models, as well as early
advances in cross-modal retrieval.
  Rather than providing an exhaustive account of the most recent methods, our
goal is to introduce the conceptual foundations of learning-based hashing for
ANN search. By situating these early models in their historical context, we aim
to equip readers with a structured understanding of the principles, trade-offs,
and open challenges that continue to inform current research in this area.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [372] [Creative synthesis of kinematic mechanisms](https://arxiv.org/abs/2510.03308)
*Jiong Lin,Jialong Ning,Judah Goldfeder,Hod Lipson*

Main category: cs.GR

TL;DR: The paper formulates kinematic synthesis for planar linkages as a cross-domain image generation task, using RGB image representations and a shared-latent VAE to synthesize unseen motion curves and simulate novel kinematics.


<details>
  <summary>Details</summary>
Motivation: To explore the potential of image generative models for synthesizing planar linkages and creating novel kinematic mechanisms through a unified image-based framework.

Method: Developed a planar linkages dataset using RGB image representations, employed a shared-latent variational autoencoder (VAE) that encodes drawing speed as color gradients, and validated on three datasets of increasing complexity.

Result: Preliminary results demonstrate effectiveness of image-based representations for generative mechanical design, showing that mechanisms with revolute and prismatic joints can be represented and synthesized within a unified image generation framework.

Conclusion: Image-based representations provide a promising approach for generative mechanical design, supporting kinematic synthesis conditioned on both trajectory shape and velocity profiles across various linkage types.

Abstract: In this paper, we formulate the problem of kinematic synthesis for planar
linkages as a cross-domain image generation task. We develop a planar linkages
dataset using RGB image representations, covering a range of mechanisms: from
simple types such as crank-rocker and crank-slider to more complex eight-bar
linkages like Jansen's mechanism. A shared-latent variational autoencoder (VAE)
is employed to explore the potential of image generative models for
synthesizing unseen motion curves and simulating novel kinematics. By encoding
the drawing speed of trajectory points as color gradients, the same
architecture also supports kinematic synthesis conditioned on both trajectory
shape and velocity profiles. We validate our method on three datasets of
increasing complexity: a standard four-bar linkage set, a mixed set of four-bar
and crank-slider mechanisms, and a complex set including multi-loop mechanisms.
Preliminary results demonstrate the effectiveness of image-based
representations for generative mechanical design, showing that mechanisms with
revolute and prismatic joints, and potentially cams and gears, can be
represented and synthesized within a unified image generation framework.

</details>


### [373] [Universal Beta Splatting](https://arxiv.org/abs/2510.03312)
*Rong Liu,Zhongpai Gao,Benjamin Planche,Meida Chen,Van Nguyen Nguyen,Meng Zheng,Anwesa Choudhuri,Terrence Chen,Yue Wang,Andrew Feng,Ziyan Wu*

Main category: cs.GR

TL;DR: Universal Beta Splatting (UBS) extends 3D Gaussian Splatting to N-dimensional anisotropic Beta kernels for unified radiance field rendering, enabling controllable modeling of spatial, angular, and temporal dependencies in a single representation.


<details>
  <summary>Details</summary>
Motivation: To overcome limitations of fixed Gaussian primitives by creating a unified framework that can handle complex light transport effects, anisotropic view-dependent appearance, and scene dynamics without requiring auxiliary networks or specific color encodings.

Method: Generalizes 3D Gaussian Splatting to N-dimensional anisotropic Beta kernels that enable controllable dependency modeling across spatial, angular, and temporal dimensions within a single representation, maintaining backward compatibility with Gaussian Splatting.

Result: Achieves real-time rendering while consistently outperforming existing methods across static, view-dependent, and dynamic benchmarks. The learned Beta parameters naturally decompose scene properties into interpretable components without explicit supervision.

Conclusion: Beta kernels serve as a scalable universal primitive for radiance field rendering, establishing UBS as a comprehensive framework that unifies various rendering scenarios while maintaining interpretability and performance advantages.

Abstract: We introduce Universal Beta Splatting (UBS), a unified framework that
generalizes 3D Gaussian Splatting to N-dimensional anisotropic Beta kernels for
explicit radiance field rendering. Unlike fixed Gaussian primitives, Beta
kernels enable controllable dependency modeling across spatial, angular, and
temporal dimensions within a single representation. Our unified approach
captures complex light transport effects, handles anisotropic view-dependent
appearance, and models scene dynamics without requiring auxiliary networks or
specific color encodings. UBS maintains backward compatibility by approximating
to Gaussian Splatting as a special case, guaranteeing plug-in usability and
lower performance bounds. The learned Beta parameters naturally decompose scene
properties into interpretable without explicit supervision: spatial (surface
vs. texture), angular (diffuse vs. specular), and temporal (static vs.
dynamic). Our CUDA-accelerated implementation achieves real-time rendering
while consistently outperforming existing methods across static,
view-dependent, and dynamic benchmarks, establishing Beta kernels as a scalable
universal primitive for radiance field rendering. Our project website is
available at https://rongliu-leo.github.io/universal-beta-splatting/.

</details>


### [374] [Diverse Text-to-Image Generation via Contrastive Noise Optimization](https://arxiv.org/abs/2510.03813)
*Byungjun Kim,Soobin Um,Jong Chul Ye*

Main category: cs.GR

TL;DR: Contrastive Noise Optimization improves diversity in text-to-image diffusion models by optimizing initial noise latents with contrastive loss, achieving better quality-diversity trade-off.


<details>
  <summary>Details</summary>
Motivation: Text-to-image diffusion models suffer from limited diversity as outputs collapse into similar modes under strong text guidance, while existing methods provide only modest improvements and are sensitive to hyperparameters.

Method: Proposes Contrastive Noise Optimization that shapes initial noise latents using a contrastive loss defined in Tweedie data space, repelling instances within a batch to maximize diversity while preserving fidelity through reference anchoring.

Result: Extensive experiments across multiple T2I backbones show the approach achieves superior quality-diversity Pareto frontier and remains robust to hyperparameter choices.

Conclusion: The method effectively addresses diversity limitations in text-to-image generation through noise optimization with contrastive learning, providing theoretical insights and practical improvements.

Abstract: Text-to-image (T2I) diffusion models have demonstrated impressive performance
in generating high-fidelity images, largely enabled by text-guided inference.
However, this advantage often comes with a critical drawback: limited
diversity, as outputs tend to collapse into similar modes under strong text
guidance. Existing approaches typically optimize intermediate latents or text
conditions during inference, but these methods deliver only modest gains or
remain sensitive to hyperparameter tuning. In this work, we introduce
Contrastive Noise Optimization, a simple yet effective method that addresses
the diversity issue from a distinct perspective. Unlike prior techniques that
adapt intermediate latents, our approach shapes the initial noise to promote
diverse outputs. Specifically, we develop a contrastive loss defined in the
Tweedie data space and optimize a batch of noise latents. Our contrastive
optimization repels instances within the batch to maximize diversity while
keeping them anchored to a reference sample to preserve fidelity. We further
provide theoretical insights into the mechanism of this preprocessing to
substantiate its effectiveness. Extensive experiments across multiple T2I
backbones demonstrate that our approach achieves a superior quality-diversity
Pareto frontier while remaining robust to hyperparameter choices.

</details>


### [375] [Joint Neural SDF Reconstruction and Semantic Segmentation for CAD Models](https://arxiv.org/abs/2510.03837)
*Shen Fan,Przemyslaw Musialski*

Main category: cs.GR

TL;DR: A data-efficient pipeline that augments neural SDF-based CAD reconstruction with part segmentation using PartField-generated supervision, handling meshes with any number of parts and producing geometry-aligned labels in a single pass.


<details>
  <summary>Details</summary>
Motivation: To create semantically structured CAD meshes without requiring curated taxonomies or exact palette matches, enabling coherent part segmentation for meshes with varied part cardinalities.

Method: Attach a lightweight segmentation head to a Flat-CAD SDF trunk network, trained with PartField-generated supervision, allowing single-pass processing of meshes with any number of parts.

Result: Strong performance on reconstruction metrics (CDL1/CDL2, F1-micro, NC) and segmentation metrics (mIoU, Accuracy), with accurate part labels even under degraded reconstructions, maintaining correct part count and label coherence.

Conclusion: The approach provides a practical route to semantically structured CAD meshes, though limitations exist in boundary precision due to per-face supervision, with potential improvements through boundary-aware training and higher resolution labels.

Abstract: We propose a simple, data-efficient pipeline that augments an implicit
reconstruction network based on neural SDF-based CAD parts with a
part-segmentation head trained under PartField-generated supervision. Unlike
methods tied to fixed taxonomies, our model accepts meshes with any number of
parts and produces coherent, geometry-aligned labels in a single pass. We
evaluate on randomly sampled CAD meshes from the ABC dataset with intentionally
varied part cardinalities, including over-segmented shapes, and report strong
performance across reconstruction (CDL1/CDL2, F1-micro, NC) and segmentation
(mIoU, Accuracy), together with a new Segmentation Consistency metric that
captures local label smoothness. We attach a lightweight segmentation head to
the Flat-CAD SDF trunk; on a paired evaluation it does not alter reconstruction
while providing accurate part labels for meshes with any number of parts. Even
under degraded reconstructions on thin or intricate geometries, segmentation
remains accurate and label-coherent, often preserving the correct part count.
Our approach therefore offers a practical route to semantically structured CAD
meshes without requiring curated taxonomies or exact palette matches. We
discuss limitations in boundary precision, partly due to per-face supervision,
and outline paths toward boundary-aware training and higher resolution labels.

</details>


### [376] [3Dify: a Framework for Procedural 3D-CG Generation Assisted by LLMs Using MCP and RAG](https://arxiv.org/abs/2510.04536)
*Shun-ichiro Hayashi,Daichi Mukunoki,Tetsuya Hoshino,Satoshi Ohshima,Takahiro Katagiri*

Main category: cs.GR

TL;DR: 3Dify is a procedural 3D-CG generation framework that uses LLMs to create 3D content from natural language instructions, automating DCC tools via MCP and GUI operations, with user feedback for quality improvement and support for local LLM deployment.


<details>
  <summary>Details</summary>
Motivation: To enable users to generate 3D-CG content easily through natural language without requiring technical expertise in 3D modeling software, while reducing costs and improving generation quality.

Method: Built on Dify platform, uses MCP for DCC tool automation, CUA method for GUI automation when MCP is unavailable, implements RAG, and incorporates user feedback learning from preferred image selections to improve subsequent generations.

Result: A framework that successfully generates 3D-CG content from natural language, automates various DCC tools, improves image quality through user feedback, and supports local LLM deployment for cost reduction.

Conclusion: 3Dify provides an effective solution for procedural 3D-CG generation using LLMs, making 3D content creation more accessible through natural language interfaces while offering cost-effective deployment options and quality improvement mechanisms.

Abstract: This paper proposes "3Dify," a procedural 3D computer graphics (3D-CG)
generation framework utilizing Large Language Models (LLMs). The framework
enables users to generate 3D-CG content solely through natural language
instructions. 3Dify is built upon Dify, an open-source platform for AI
application development, and incorporates several state-of-the-art LLM-related
technologies such as the Model Context Protocol (MCP) and Retrieval-Augmented
Generation (RAG). For 3D-CG generation support, 3Dify automates the operation
of various Digital Content Creation (DCC) tools via MCP. When DCC tools do not
support MCP-based interaction, the framework employs the Computer-Using Agent
(CUA) method to automate Graphical User Interface (GUI) operations. Moreover,
to enhance image generation quality, 3Dify allows users to provide feedback by
selecting preferred images from multiple candidates. The LLM then learns
variable patterns from these selections and applies them to subsequent
generations. Furthermore, 3Dify supports the integration of locally deployed
LLMs, enabling users to utilize custom-developed models and to reduce both time
and monetary costs associated with external API calls by leveraging their own
computational resources.

</details>


### [377] [C3Editor: Achieving Controllable Consistency in 2D Model for 3D Editing](https://arxiv.org/abs/2510.04539)
*Zeng Tao,Zheng Ding,Zeyuan Chen,Xiang Zhang,Leizhi Li,Zhuowen Tu*

Main category: cs.GR

TL;DR: C3Editor is a controllable and consistent 2D-lifting-based 3D editing framework that addresses inconsistency issues in existing methods by selectively establishing view-consistent 2D editing models and ensuring multi-view consistency through targeted fine-tuning.


<details>
  <summary>Details</summary>
Motivation: Existing 2D-lifting-based 3D editing methods face challenges with inconsistency due to lack of view-consistent 2D editing models and difficulty ensuring consistent editing across multiple views.

Method: The method selects a ground truth view and its edited image as optimization target, then fine-tunes 2D editing model within GT view and across multiple views using separate LoRA modules for targeted fine-tuning to ensure multi-view consistency.

Result: C3Editor delivers more consistent and controllable 2D and 3D editing results than existing 2D-lifting-based methods, outperforming them in both qualitative and quantitative evaluations.

Conclusion: The proposed framework successfully addresses inconsistency issues in 3D editing by establishing view-consistent 2D editing models and ensuring multi-view consistency through controlled optimization and targeted fine-tuning.

Abstract: Existing 2D-lifting-based 3D editing methods often encounter challenges
related to inconsistency, stemming from the lack of view-consistent 2D editing
models and the difficulty of ensuring consistent editing across multiple views.
To address these issues, we propose C3Editor, a controllable and consistent
2D-lifting-based 3D editing framework. Given an original 3D representation and
a text-based editing prompt, our method selectively establishes a
view-consistent 2D editing model to achieve superior 3D editing results. The
process begins with the controlled selection of a ground truth (GT) view and
its corresponding edited image as the optimization target, allowing for
user-defined manual edits. Next, we fine-tune the 2D editing model within the
GT view and across multiple views to align with the GT-edited image while
ensuring multi-view consistency. To meet the distinct requirements of GT view
fitting and multi-view consistency, we introduce separate LoRA modules for
targeted fine-tuning. Our approach delivers more consistent and controllable 2D
and 3D editing results than existing 2D-lifting-based methods, outperforming
them in both qualitative and quantitative evaluations.

</details>


### [378] [Social Agent: Mastering Dyadic Nonverbal Behavior Generation via Conversational LLM Agents](https://arxiv.org/abs/2510.04637)
*Zeyi Zhang,Yanju Zhou,Heyuan Yao,Tenglong Ao,Xiaohang Zhan,Libin Liu*

Main category: cs.GR

TL;DR: Social Agent is a framework that uses LLM-driven agents to generate realistic co-speech nonverbal behaviors in dyadic conversations, combining conversational direction with dual-person gesture generation through an auto-regressive diffusion model.


<details>
  <summary>Details</summary>
Motivation: To create more realistic and contextually appropriate nonverbal behaviors in dyadic conversations, enabling dynamic and responsive interactions between participants.

Method: Uses an LLM-driven agentic system to direct conversation flow and determine interactive behaviors, combined with a dual-person gesture generation model based on auto-regressive diffusion that synthesizes coordinated motions from speech signals.

Result: User studies and quantitative evaluations show significant improvement in dyadic interaction quality, producing natural and synchronized nonverbal behaviors.

Conclusion: The framework successfully creates realistic and responsive dyadic interactions through the integration of LLM-driven conversation direction and coordinated gesture generation with continuous feedback loops.

Abstract: We present Social Agent, a novel framework for synthesizing realistic and
contextually appropriate co-speech nonverbal behaviors in dyadic conversations.
In this framework, we develop an agentic system driven by a Large Language
Model (LLM) to direct the conversation flow and determine appropriate
interactive behaviors for both participants. Additionally, we propose a novel
dual-person gesture generation model based on an auto-regressive diffusion
model, which synthesizes coordinated motions from speech signals. The output of
the agentic system is translated into high-level guidance for the gesture
generator, resulting in realistic movement at both the behavioral and motion
levels. Furthermore, the agentic system periodically examines the movements of
interlocutors and infers their intentions, forming a continuous feedback loop
that enables dynamic and responsive interactions between the two participants.
User studies and quantitative evaluations show that our model significantly
improves the quality of dyadic interactions, producing natural, synchronized
nonverbal behaviors.

</details>


### [379] [Bridging Text and Video Generation: A Survey](https://arxiv.org/abs/2510.04999)
*Nilay Kumar,Priyansh Bhandari,G. Maragatham*

Main category: cs.GR

TL;DR: A comprehensive survey of text-to-video (T2V) generative models, covering their evolution from GANs and VAEs to modern Diffusion-Transformer architectures, including datasets, training configurations, evaluation metrics, and future research directions.


<details>
  <summary>Details</summary>
Motivation: T2V technology has potential applications in education, marketing, entertainment, and assistive technologies, but faces challenges in alignment, long-range coherence, and computational efficiency that require systematic analysis.

Method: Systematic survey approach tracing T2V model development, detailing architectural evolution from adversarial models to diffusion-based models and hybrid Diffusion-Transformer architectures, including analysis of datasets, training configurations, and evaluation metrics.

Result: The survey provides a comprehensive account of T2V model progression, performance across benchmarks, training specifications, and identifies limitations in current evaluation metrics.

Conclusion: The paper outlines current open challenges and proposes promising future directions for T2V research, providing a foundation for advancing text-to-video generation technology and applications.

Abstract: Text-to-video (T2V) generation technology holds potential to transform
multiple domains such as education, marketing, entertainment, and assistive
technologies for individuals with visual or reading comprehension challenges,
by creating coherent visual content from natural language prompts. From its
inception, the field has advanced from adversarial models to diffusion-based
models, yielding higher-fidelity, temporally consistent outputs. Yet challenges
persist, such as alignment, long-range coherence, and computational efficiency.
Addressing this evolving landscape, we present a comprehensive survey of
text-to-video generative models, tracing their development from early GANs and
VAEs to hybrid Diffusion-Transformer (DiT) architectures, detailing how these
models work, what limitations they addressed in their predecessors, and why
shifts toward new architectural paradigms were necessary to overcome challenges
in quality, coherence, and control. We provide a systematic account of the
datasets, which the surveyed text-to-video models were trained and evaluated
on, and, to support reproducibility and assess the accessibility of training
such models, we detail their training configurations, including their hardware
specifications, GPU counts, batch sizes, learning rates, optimizers, epochs,
and other key hyperparameters. Further, we outline the evaluation metrics
commonly used for evaluating such models and present their performance across
standard benchmarks, while also discussing the limitations of these metrics and
the emerging shift toward more holistic, perception-aligned evaluation
strategies. Finally, drawing from our analysis, we outline the current open
challenges and propose a few promising future directions, laying out a
perspective for future researchers to explore and build upon in advancing T2V
research and applications.

</details>


### [380] [SAEdit: Token-level control for continuous image editing via Sparse AutoEncoder](https://arxiv.org/abs/2510.05081)
*Ronen Kamenetsky,Sara Dorfman,Daniel Garibi,Roni Paiss,Or Patashnik,Daniel Cohen-Or*

Main category: cs.GR

TL;DR: A method for disentangled and continuous image editing by manipulating text embeddings along sparse autoencoder directions, enabling precise control without modifying diffusion models.


<details>
  <summary>Details</summary>
Motivation: Text prompts alone provide inadequate control over image editing, lacking both disentanglement (changing one attribute without affecting others) and continuous control (adjusting edit strength smoothly).

Method: Token-level manipulation of text embeddings using Sparse Autoencoder (SAE) to identify semantically isolated dimensions for controlling edit strength along specific attribute directions.

Result: Enables intuitive and efficient manipulations with continuous control across diverse attributes and domains, working directly on text embeddings without modifying diffusion processes.

Conclusion: The method provides model-agnostic, disentangled continuous editing capabilities that can be broadly applied to various image synthesis backbones through text embedding manipulation.

Abstract: Large-scale text-to-image diffusion models have become the backbone of modern
image editing, yet text prompts alone do not offer adequate control over the
editing process. Two properties are especially desirable: disentanglement,
where changing one attribute does not unintentionally alter others, and
continuous control, where the strength of an edit can be smoothly adjusted. We
introduce a method for disentangled and continuous editing through token-level
manipulation of text embeddings. The edits are applied by manipulating the
embeddings along carefully chosen directions, which control the strength of the
target attribute. To identify such directions, we employ a Sparse Autoencoder
(SAE), whose sparse latent space exposes semantically isolated dimensions. Our
method operates directly on text embeddings without modifying the diffusion
process, making it model agnostic and broadly applicable to various image
synthesis backbones. Experiments show that it enables intuitive and efficient
manipulations with continuous control across diverse attributes and domains.

</details>


### [381] [Pulp Motion: Framing-aware multimodal camera and human motion generation](https://arxiv.org/abs/2510.05097)
*Robin Courant,Xi Wang,David Loiseaux,Marc Christie,Vicky Kalogeiton*

Main category: cs.GR

TL;DR: This paper introduces a joint generation framework for human motion and camera trajectories that maintains consistent on-screen framing through an auxiliary framing modality, achieving better multimodal coherence and cinematographic quality.


<details>
  <summary>Details</summary>
Motivation: Current methods treat human motion and camera trajectory generation separately, overlooking the core cinematographic principle of tight interplay between actor performance and camera work in screen space.

Method: Proposes a model-agnostic framework with a joint autoencoder that learns a shared latent space and uses linear transforms to connect human and camera latents to a framing latent. Introduces auxiliary sampling to steer generation toward coherent framing.

Result: Extensive experiments show the method generates on-frame coherent human-camera motions while improving textual alignment for both modalities. Qualitative results yield more cinematographically meaningful framings.

Conclusion: The approach sets new state-of-the-art for joint human motion and camera trajectory generation by leveraging on-screen framing as a natural bridge between modalities, producing more coherent and cinematographically meaningful results.

Abstract: Treating human motion and camera trajectory generation separately overlooks a
core principle of cinematography: the tight interplay between actor performance
and camera work in the screen space. In this paper, we are the first to cast
this task as a text-conditioned joint generation, aiming to maintain consistent
on-screen framing while producing two heterogeneous, yet intrinsically linked,
modalities: human motion and camera trajectories. We propose a simple,
model-agnostic framework that enforces multimodal coherence via an auxiliary
modality: the on-screen framing induced by projecting human joints onto the
camera. This on-screen framing provides a natural and effective bridge between
modalities, promoting consistency and leading to more precise joint
distribution. We first design a joint autoencoder that learns a shared latent
space, together with a lightweight linear transform from the human and camera
latents to a framing latent. We then introduce auxiliary sampling, which
exploits this linear transform to steer generation toward a coherent framing
modality. To support this task, we also introduce the PulpMotion dataset, a
human-motion and camera-trajectory dataset with rich captions, and high-quality
human motions. Extensive experiments across DiT- and MAR-based architectures
show the generality and effectiveness of our method in generating on-frame
coherent human-camera motions, while also achieving gains on textual alignment
for both modalities. Our qualitative results yield more cinematographically
meaningful framings setting the new state of the art for this task. Code,
models and data are available in our
\href{https://www.lix.polytechnique.fr/vista/projects/2025_pulpmotion_courant/}{project
page}.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [382] [PLSEMANTICSBENCH: Large Language Models As Programming Language Interpreters](https://arxiv.org/abs/2510.03415)
*Aditya Thimmaiah,Jiyang Zhang,Jayanth Srinivasa,Junyi Jessy Li,Milos Gligoric*

Main category: cs.PL

TL;DR: LLMs can execute programs using formal semantics but lack robust semantic understanding, with performance dropping under nonstandard semantics despite good results on standard ones.


<details>
  <summary>Details</summary>
Motivation: To investigate if LLMs can act as programming language interpreters using formal semantics, enabling rapid prototyping of new languages and features.

Method: Used IMP language with SOS/K-semantics, created three evaluation sets with controlled complexity, tested models on three tasks (final-state, semantic rule, execution trace prediction), and introduced nonstandard semantics to test robustness.

Result: Models perform well on standard semantics but drop significantly under nonstandard ones, show patterns in failures, handle complex programs with deep nested loops well, and formal semantics helps simple programs but hurts complex ones.

Conclusion: LLMs show promise as interpreters but lack robust semantic understanding, requiring further development for reliable programming language interpretation.

Abstract: As large language models (LLMs) excel at code reasoning, a natural question
arises: can an LLM execute programs (i.e., act as an interpreter) purely based
on a programming language's formal semantics? If so, it will enable rapid
prototyping of new programming languages and language features. We study this
question using the imperative language IMP (a subset of C), formalized via
small-step operational semantics (SOS) and rewriting-based operational
semantics (K-semantics). We introduce three evaluation sets-Human-Written,
LLM-Translated, and Fuzzer- Generated-whose difficulty is controlled by
code-complexity metrics spanning the size, control-flow, and data-flow axes.
Given a program and its semantics formalized with SOS/K-semantics, models are
evaluated on three tasks ranging from coarse to fine: (1) final-state
prediction, (2) semantic rule prediction, and (3) execution trace prediction.
To distinguish pretraining memorization from semantic competence, we define two
nonstandard semantics obtained through systematic mutations of the standard
rules. Across strong code/reasoning LLMs, performance drops under nonstandard
semantics despite high performance under the standard one. We further find that
(i) there are patterns to different model failures, (ii) most reasoning models
perform exceptionally well on coarse grained tasks involving reasoning about
highly complex programs often containing nested loop depths beyond five, and
surprisingly, (iii) providing formal semantics helps on simple programs but
often hurts on more complex ones. Overall, the results show a promise that LLMs
could serve as programming language interpreters, but points to the lack of
their robust semantics understanding. We release the benchmark and the
supporting code at https://github.com/EngineeringSoftware/PLSemanticsBench.

</details>
