<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 52]
- [cs.CV](#cs.CV) [Total: 64]
- [cs.LG](#cs.LG) [Total: 4]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.IR](#cs.IR) [Total: 4]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.NE](#cs.NE) [Total: 1]
- [cs.RO](#cs.RO) [Total: 2]
- [cs.SD](#cs.SD) [Total: 1]
- [eess.AS](#eess.AS) [Total: 3]
- [eess.IV](#eess.IV) [Total: 4]
- [cs.GR](#cs.GR) [Total: 1]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [cs.AI](#cs.AI) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Structured Information Matters: Explainable ICD Coding with Patient-Level Knowledge Graphs](https://arxiv.org/abs/2509.09699)
*Mingyang Li,Viktor Schlegel,Tingting Mu,Warren Del-Pinto,Goran Nenadic*

Main category: cs.CL

TL;DR: This paper proposes using document-level knowledge graphs to structure clinical documents for automated ICD coding, achieving 3.20% improvement in Macro-F1 scores while reducing text by 77% and retaining 90% information.


<details>
  <summary>Details</summary>
Motivation: Manual clinical coding is difficult and time-consuming, while automated coding faces challenges with high-dimensional target spaces like ICD. External knowledge for input document representation has been underexplored compared to output code representation.

Method: Compute structured representation of input documents using document-level knowledge graphs that provide comprehensive structured view of patient conditions. Integrate this KG representation into state-of-the-art PLM-ICD architecture for automated ICD-9 coding.

Result: Knowledge graph represents documents with 23% of original text while retaining 90% information. Achieves up to 3.20% improvement in Macro-F1 scores on benchmarks, improves training efficiency, and enhances explainability over text-only baseline.

Conclusion: Structured knowledge graph representation of clinical documents effectively improves automated ICD coding performance, efficiency, and explainability by capturing different entity types and relationships in a compact format.

Abstract: Mapping clinical documents to standardised clinical vocabularies is an
important task, as it provides structured data for information retrieval and
analysis, which is essential to clinical research, hospital administration and
improving patient care. However, manual coding is both difficult and
time-consuming, making it impractical at scale. Automated coding can
potentially alleviate this burden, improving the availability and accuracy of
structured clinical data. The task is difficult to automate, as it requires
mapping to high-dimensional and long-tailed target spaces, such as the
International Classification of Diseases (ICD). While external knowledge
sources have been readily utilised to enhance output code representation, the
use of external resources for representing the input documents has been
underexplored. In this work, we compute a structured representation of the
input documents, making use of document-level knowledge graphs (KGs) that
provide a comprehensive structured view of a patient's condition. The resulting
knowledge graph efficiently represents the patient-centred input documents with
23\% of the original text while retaining 90\% of the information. We assess
the effectiveness of this graph for automated ICD-9 coding by integrating it
into the state-of-the-art ICD coding architecture PLM-ICD. Our experiments
yield improved Macro-F1 scores by up to 3.20\% on popular benchmarks, while
improving training efficiency. We attribute this improvement to different types
of entities and relationships in the KG, and demonstrate the improved
explainability potential of the approach over the text-only baseline.

</details>


### [2] [Cross-Layer Attention Probing for Fine-Grained Hallucination Detection](https://arxiv.org/abs/2509.09700)
*Malavika Suresh,Rahaf Aljundi,Ikechukwu Nkisi-Orji,Nirmalie Wiratunga*

Main category: cs.CL

TL;DR: CLAP is a novel activation probing technique that processes LLM activations across the entire residual stream to detect hallucinations, outperforming baselines and enabling fine-grained detection across different response samples.


<details>
  <summary>Details</summary>
Motivation: Address the growing reliability concern of LLMs due to their tendency to generate inaccurate text (hallucinations) in various applications.

Method: Cross-Layer Attention Probing (CLAP) - processes LLM activations across the entire residual stream as a joint sequence for hallucination detection.

Result: CLAP improves hallucination detection compared to baselines across five LLMs and three tasks, works well with both greedy decoding and higher temperature sampling, maintains high reliability out-of-distribution, and enables detect-then-mitigate strategies that reduce hallucinations.

Conclusion: CLAP provides an effective approach for fine-grained hallucination detection that can be used to improve LLM reliability through detection-based mitigation strategies.

Abstract: With the large-scale adoption of Large Language Models (LLMs) in various
applications, there is a growing reliability concern due to their tendency to
generate inaccurate text, i.e. hallucinations. In this work, we propose
Cross-Layer Attention Probing (CLAP), a novel activation probing technique for
hallucination detection, which processes the LLM activations across the entire
residual stream as a joint sequence. Our empirical evaluations using five LLMs
and three tasks show that CLAP improves hallucination detection compared to
baselines on both greedy decoded responses as well as responses sampled at
higher temperatures, thus enabling fine-grained detection, i.e. the ability to
disambiguate hallucinations and non-hallucinations among different sampled
responses to a given prompt. This allows us to propose a detect-then-mitigate
strategy using CLAP to reduce hallucinations and improve LLM reliability
compared to direct mitigation approaches. Finally, we show that CLAP maintains
high reliability even when applied out-of-distribution.

</details>


### [3] [Optimal Multi-Task Learning at Regularization Horizon for Speech Translation Task](https://arxiv.org/abs/2509.09701)
*JungHo Jung,Junhyun Lee*

Main category: cs.CL

TL;DR: This paper proposes a regularization perspective for multi-task learning in speech-to-text translation, identifying three regularization sources (consistency regularization, R-drop, and MT loss coefficient) and introduces the concept of "regularization horizon" to achieve near state-of-the-art performance on MuST-C dataset.


<details>
  <summary>Details</summary>
Motivation: End-to-end speech-to-text translation suffers from limited paired speech-text data. The paper aims to overcome this by leveraging machine translation bitext data through multi-task learning from a regularization perspective.

Method: Formulates multi-task learning as regularization, exploring sequence regularization within and across modalities. Investigates consistency regularization (cross-modality) and R-drop (same modality), and demonstrates that MT loss coefficient serves as additional regularization. Introduces the "regularization horizon" concept for optimal hyperparameter tuning.

Result: Experiments show that tuning hyperparameters within the proposed regularization horizon achieves near state-of-the-art performance on the MuST-C dataset.

Conclusion: The paper successfully demonstrates that multi-task learning for speech-to-text translation can be effectively framed as a regularization problem, with three distinct regularization sources contributing to improved performance when optimally balanced through the regularization horizon concept.

Abstract: End-to-end speech-to-text translation typically suffers from the scarcity of
paired speech-text data. One way to overcome this shortcoming is to utilize the
bitext data from the Machine Translation (MT) task and perform Multi-Task
Learning (MTL). In this paper, we formulate MTL from a regularization
perspective and explore how sequences can be regularized within and across
modalities. By thoroughly investigating the effect of consistency
regularization (different modality) and R-drop (same modality), we show how
they respectively contribute to the total regularization. We also demonstrate
that the coefficient of MT loss serves as another source of regularization in
the MTL setting. With these three sources of regularization, we introduce the
optimal regularization contour in the high-dimensional space, called the
regularization horizon. Experiments show that tuning the hyperparameters within
the regularization horizon achieves near state-of-the-art performance on the
MuST-C dataset.

</details>


### [4] [Creativity Benchmark: A benchmark for marketing creativity for LLM models](https://arxiv.org/abs/2509.09702)
*Ninad Bhat,Kieran Browne,Pip Bingemann*

Main category: cs.CL

TL;DR: Creativity Benchmark evaluates LLMs for marketing creativity across 100 brands and 3 prompt types, showing tightly clustered model performance with no clear winner and highlighting limitations of automated evaluation.


<details>
  <summary>Details</summary>
Motivation: To create a comprehensive evaluation framework for assessing large language models' creative capabilities in marketing contexts, addressing the need for brand-specific creativity assessment.

Method: Human pairwise preferences from 678 creatives over 11,012 comparisons analyzed with Bradley-Terry models, plus cosine distance analysis for model diversity and sensitivity to prompt reframing. Compared three LLM-as-judge setups against human rankings.

Result: Models show tightly clustered performance (Δθ ≈ 0.45, 61% win probability between top and bottom models), weak correlations between automated and human judges, and partial transfer of conventional creativity tests to brand-constrained tasks.

Conclusion: Expert human evaluation is essential as automated judges cannot substitute for human assessment, and diversity-aware workflows are needed for effective marketing creativity evaluation of LLMs.

Abstract: We introduce Creativity Benchmark, an evaluation framework for large language
models (LLMs) in marketing creativity. The benchmark covers 100 brands (12
categories) and three prompt types (Insights, Ideas, Wild Ideas). Human
pairwise preferences from 678 practising creatives over 11,012 anonymised
comparisons, analysed with Bradley-Terry models, show tightly clustered
performance with no model dominating across brands or prompt types: the
top-bottom spread is $\Delta\theta \approx 0.45$, which implies a head-to-head
win probability of $0.61$; the highest-rated model beats the lowest only about
$61\%$ of the time. We also analyse model diversity using cosine distances to
capture intra- and inter-model variation and sensitivity to prompt reframing.
Comparing three LLM-as-judge setups with human rankings reveals weak,
inconsistent correlations and judge-specific biases, underscoring that
automated judges cannot substitute for human evaluation. Conventional
creativity tests also transfer only partially to brand-constrained tasks.
Overall, the results highlight the need for expert human evaluation and
diversity-aware workflows.

</details>


### [5] [CTCC: A Robust and Stealthy Fingerprinting Framework for Large Language Models via Cross-Turn Contextual Correlation Backdoor](https://arxiv.org/abs/2509.09703)
*Zhenhua Xu,Xixiang Zhao,Xubin Yue,Shengwei Tian,Changting Lin,Meng Han*

Main category: cs.CL

TL;DR: CTCC is a novel rule-driven fingerprinting framework that uses contextual correlations across multiple dialogue turns for LLM ownership verification, achieving better stealth and robustness than existing methods.


<details>
  <summary>Details</summary>
Motivation: Address concerns around intellectual property protection for large language models as model theft and unauthorized redistribution become increasingly feasible. Existing fingerprinting methods have trade-offs between stealthness, robustness, and generalizability.

Method: CTCC encodes contextual correlations across multiple dialogue turns (e.g., counterfactual) rather than relying on token-level or single-turn triggers. It enables black-box verification while mitigating false positives and fingerprint leakage.

Result: Extensive experiments across multiple LLM architectures demonstrate CTCC consistently achieves stronger stealth and robustness than prior work.

Conclusion: CTCC provides a reliable and practical solution for ownership verification in real-world LLM deployment scenarios.

Abstract: The widespread deployment of large language models (LLMs) has intensified
concerns around intellectual property (IP) protection, as model theft and
unauthorized redistribution become increasingly feasible. To address this,
model fingerprinting aims to embed verifiable ownership traces into LLMs.
However, existing methods face inherent trade-offs between stealthness,
robustness, and generalizability, being either detectable via distributional
shifts, vulnerable to adversarial modifications, or easily invalidated once the
fingerprint is revealed. In this work, we introduce CTCC, a novel rule-driven
fingerprinting framework that encodes contextual correlations across multiple
dialogue turns, such as counterfactual, rather than relying on token-level or
single-turn triggers. CTCC enables fingerprint verification under black-box
access while mitigating false positives and fingerprint leakage, supporting
continuous construction under a shared semantic rule even if partial triggers
are exposed. Extensive experiments across multiple LLM architectures
demonstrate that CTCC consistently achieves stronger stealth and robustness
than prior work. Our findings position CTCC as a reliable and practical
solution for ownership verification in real-world LLM deployment scenarios. Our
code and data are publicly available at <https://github.com/Xuzhenhua55/CTCC>.

</details>


### [6] [Temporal Preferences in Language Models for Long-Horizon Assistance](https://arxiv.org/abs/2509.09704)
*Ali Mazyaki,Mohammad Naghizadeh,Samaneh Ranjkhah Zonouzaghi,Hossein Setareh*

Main category: cs.CL

TL;DR: Language models exhibit time preferences that can be systematically manipulated between future- and present-oriented choices, with reasoning-focused models showing stronger future orientation under specific prompts.


<details>
  <summary>Details</summary>
Motivation: To understand whether language models display intertemporal preferences similar to humans and whether these preferences can be systematically manipulated, which has implications for AI assistant design and deployment.

Method: Adapted human experimental protocols to evaluate multiple LMs on time-tradeoff tasks, benchmarking against human decision makers. Introduced Manipulability of Time Orientation (MTO) metric to measure preference changes between future- and present-oriented prompts.

Result: Reasoning-focused models (e.g., DeepSeek-Reasoner, grok-3-mini) choose later options under future-oriented prompts but only partially personalize decisions across identities/geographies. Models that reason correctly about time orientation internalize future orientation for themselves as AI decision makers.

Conclusion: The findings highlight design implications for AI assistants needing to align with heterogeneous, long-horizon goals, and outline a research agenda for personalized contextual calibration and socially aware deployment.

Abstract: We study whether language models (LMs) exhibit future- versus
present-oriented preferences in intertemporal choice and whether those
preferences can be systematically manipulated. Using adapted human experimental
protocols, we evaluate multiple LMs on time-tradeoff tasks and benchmark them
against a sample of human decision makers. We introduce an operational metric,
the Manipulability of Time Orientation (MTO), defined as the change in an LM's
revealed time preference between future- and present-oriented prompts. In our
tests, reasoning-focused models (e.g., DeepSeek-Reasoner and grok-3-mini)
choose later options under future-oriented prompts but only partially
personalize decisions across identities or geographies. Moreover, models that
correctly reason about time orientation internalize a future orientation for
themselves as AI decision makers. We discuss design implications for AI
assistants that should align with heterogeneous, long-horizon goals and outline
a research agenda on personalized contextual calibration and socially aware
deployment.

</details>


### [7] [The Non-Determinism of Small LLMs: Evidence of Low Answer Consistency in Repetition Trials of Standard Multiple-Choice Benchmarks](https://arxiv.org/abs/2509.09705)
*Claudio Pinhanez,Paulo Cavalin,Cassia Sanctos,Marcelo Grave,Yago Primerano*

Main category: cs.CL

TL;DR: Study examines answer consistency of small LLMs (2B-8B parameters) when answering the same question multiple times, finding 50%-80% consistency at low temperatures with reasonable correlation between consistent answer accuracy and overall accuracy.


<details>
  <summary>Details</summary>
Motivation: To understand how consistently small language models answer the same question across multiple trials and explore the trade-offs between consistency and accuracy.

Method: Analyzed open-source LLMs responding to 10 repetitions of questions from MMLU-Redux and MedQA benchmarks, varying inference temperatures, model sizes (small vs medium), and finetuned vs base models.

Result: Small models show 50%-80% consistency at low temperatures, with consistent answer accuracy correlating reasonably with overall accuracy. Medium-sized models demonstrate much higher consistency levels.

Conclusion: Small LLMs exhibit moderate consistency in repeated question answering, with consistency-accuracy trade-offs that vary by model type and temperature settings.

Abstract: This work explores the consistency of small LLMs (2B-8B parameters) in
answering multiple times the same question. We present a study on known,
open-source LLMs responding to 10 repetitions of questions from the
multiple-choice benchmarks MMLU-Redux and MedQA, considering different
inference temperatures, small vs. medium models (50B-80B), finetuned vs. base
models, and other parameters. We also look into the effects of requiring
multi-trial answer consistency on accuracy and the trade-offs involved in
deciding which model best provides both of them. To support those studies, we
propose some new analytical and graphical tools. Results show that the number
of questions which can be answered consistently vary considerably among models
but are typically in the 50%-80% range for small models at low inference
temperatures. Also, accuracy among consistent answers seems to reasonably
correlate with overall accuracy. Results for medium-sized models seem to
indicate much higher levels of answer consistency.

</details>


### [8] [Beyond I'm Sorry, I Can't: Dissecting Large Language Model Refusal](https://arxiv.org/abs/2509.09708)
*Nirmalendu Prakash,Yeo Wei Jie,Amir Abdullah,Ranjan Satapathy,Erik Cambria,Roy Ka Wei Lee*

Main category: cs.CL

TL;DR: Researchers developed a pipeline to identify critical features that cause LLMs to refuse harmful prompts, using sparse autoencoders to find and manipulate features that flip refusal to compliance.


<details>
  <summary>Details</summary>
Motivation: To understand the internal mechanisms behind safety refusal behaviors in instruction-tuned LLMs and identify causally influential features that mediate refusal responses.

Method: Three-stage pipeline: 1) Find refusal-mediating direction and collect SAE features, 2) Greedy filtering to minimal feature set, 3) Fit factorization machine to capture nonlinear interactions among active features.

Result: Identified jailbreak-critical features that causally influence refusal behavior, discovered redundant features that activate only when primary features are suppressed, and successfully created jailbreaks by feature ablation.

Conclusion: The approach enables fine-grained auditing and targeted intervention in safety behaviors by manipulating interpretable latent spaces, revealing mechanistic basis of refusal in LLMs.

Abstract: Refusal on harmful prompts is a key safety behaviour in instruction-tuned
large language models (LLMs), yet the internal causes of this behaviour remain
poorly understood. We study two public instruction-tuned models, Gemma-2-2B-IT
and LLaMA-3.1-8B-IT, using sparse autoencoders (SAEs) trained on
residual-stream activations. Given a harmful prompt, we search the SAE latent
space for feature sets whose ablation flips the model from refusal to
compliance, demonstrating causal influence and creating a jailbreak. Our search
proceeds in three stages: (1) Refusal Direction: find a refusal-mediating
direction and collect SAE features near that direction; (2) Greedy Filtering:
prune to a minimal set; and (3) Interaction Discovery: fit a factorization
machine (FM) that captures nonlinear interactions among the remaining active
features and the minimal set. This pipeline yields a broad set of
jailbreak-critical features, offering insight into the mechanistic basis of
refusal. Moreover, we find evidence of redundant features that remain dormant
unless earlier features are suppressed. Our findings highlight the potential
for fine-grained auditing and targeted intervention in safety behaviours by
manipulating the interpretable latent space.

</details>


### [9] [Assisting Research Proposal Writing with Large Language Models: Evaluation and Refinement](https://arxiv.org/abs/2509.09709)
*Jing Ren,Weiqi Wang*

Main category: cs.CL

TL;DR: Proposed quantitative metrics for evaluating LLM-generated research proposals, including content quality and reference validity, with iterative prompting to improve writing performance and reduce ethical issues.


<details>
  <summary>Details</summary>
Motivation: Address ethical concerns about LLMs generating incorrect/fabricated references in academic writing and the limitations of subjective human evaluation methods that lack objectivity and consistency.

Method: Developed two evaluation metrics (content quality and reference validity) and implemented an iterative prompting method based on these scores to enhance LLM writing capabilities.

Result: The metrics provided an objective, quantitative framework for assessing ChatGPT's writing performance. Iterative prompting significantly improved content quality while reducing reference inaccuracies and fabrications.

Conclusion: The proposed approach effectively addresses critical ethical challenges in academic contexts by providing systematic evaluation and improvement methods for LLM-generated research proposals.

Abstract: Large language models (LLMs) like ChatGPT are increasingly used in academic
writing, yet issues such as incorrect or fabricated references raise ethical
concerns. Moreover, current content quality evaluations often rely on
subjective human judgment, which is labor-intensive and lacks objectivity,
potentially compromising the consistency and reliability. In this study, to
provide a quantitative evaluation and enhance research proposal writing
capabilities of LLMs, we propose two key evaluation metrics--content quality
and reference validity--and an iterative prompting method based on the scores
derived from these two metrics. Our extensive experiments show that the
proposed metrics provide an objective, quantitative framework for assessing
ChatGPT's writing performance. Additionally, iterative prompting significantly
enhances content quality while reducing reference inaccuracies and
fabrications, addressing critical ethical challenges in academic contexts.

</details>


### [10] [Generating Individual Travel Diaries Using Large Language Models Informed by Census and Land-Use Data](https://arxiv.org/abs/2509.09710)
*Sepehr Golrokh Amin,Devin Rhoads,Fatemeh Fakhrmoosavi,Nicholas E. Lownes,John N. Ivan*

Main category: cs.CL

TL;DR: LLM-based method generates synthetic travel diaries using open-source data, achieving comparable realism to classical methods with better purpose prediction and consistency.


<details>
  <summary>Details</summary>
Motivation: Traditional travel diary generation relies on proprietary surveys; this study aims to create synthetic diaries using open-source data through LLMs to reduce dependency on expensive proprietary data sources.

Method: Uses LLM to generate personas from ACS and SLD data, synthesizes diaries through direct prompting, and validates using a novel one-to-cohort realism score with four metrics (Trip Count, Interval, Purpose, Mode) compared against real diaries using Jensen-Shannon Divergence.

Result: LLM-generated diaries achieve comparable overall realism (0.485 vs 0.455) to classical methods, excel in trip purpose determination, show greater consistency, and demonstrate statistical representativeness (0.612 vs 0.435) in aggregate validation.

Conclusion: LLMs are viable for zero-shot travel diary generation, providing a quantifiable metric for synthetic diary evaluation and reducing reliance on proprietary data while maintaining statistical accuracy.

Abstract: This study introduces a Large Language Model (LLM) scheme for generating
individual travel diaries in agent-based transportation models. While
traditional approaches rely on large quantities of proprietary household travel
surveys, the method presented in this study generates personas stochastically
from open-source American Community Survey (ACS) and Smart Location Database
(SLD) data, then synthesizes diaries through direct prompting. This study
features a novel one-to-cohort realism score: a composite of four metrics (Trip
Count Score, Interval Score, Purpose Score, and Mode Score) validated against
the Connecticut Statewide Transportation Study (CSTS) diaries, matched across
demographic variables. The validation utilizes Jensen-Shannon Divergence to
measure distributional similarities between generated and real diaries. When
compared to diaries generated with classical methods (Negative Binomial for
trip generation; Multinomial Logit for mode/purpose) calibrated on the
validation set, LLM-generated diaries achieve comparable overall realism (LLM
mean: 0.485 vs. 0.455). The LLM excels in determining trip purpose and
demonstrates greater consistency (narrower realism score distribution), while
classical models lead in numerical estimates of trip count and activity
duration. Aggregate validation confirms the LLM's statistical
representativeness (LLM mean: 0.612 vs. 0.435), demonstrating LLM's zero-shot
viability and establishing a quantifiable metric of diary realism for future
synthetic diary evaluation systems.

</details>


### [11] [Psychiatry-Bench: A Multi-Task Benchmark for LLMs in Psychiatry](https://arxiv.org/abs/2509.09711)
*Aya E. Fouda,Abdelrahamn A. Hassan,Radwa J. Hanafy,Mohammed E. Fouda*

Main category: cs.CL

TL;DR: PsychiatryBench is a new benchmark for evaluating LLMs in psychiatry using expert-validated textbook content, revealing significant gaps in clinical consistency and safety.


<details>
  <summary>Details</summary>
Motivation: Existing LLM evaluation resources for psychiatry rely on limited clinical data, social media posts, or synthetic dialogues, which lack clinical validity and fail to capture the complexity of psychiatric reasoning.

Method: Created PsychiatryBench with 11 QA tasks from authoritative psychiatric textbooks and casebooks (5,300+ expert-annotated items). Evaluated frontier LLMs (Gemini, DeepSeek, LLaMA 3, QWQ-32) and medical models using conventional metrics and LLM-as-judge similarity scoring.

Result: Substantial gaps in clinical consistency and safety, particularly in multi-turn follow-up and management tasks. Shows need for specialized model tuning and more robust evaluation.

Conclusion: PsychiatryBench provides a modular, extensible platform for benchmarking and improving LLM performance in high-stakes mental health applications.

Abstract: Large language models (LLMs) hold great promise in enhancing psychiatric
practice, from improving diagnostic accuracy to streamlining clinical
documentation and therapeutic support. However, existing evaluation resources
heavily rely on small clinical interview corpora, social media posts, or
synthetic dialogues, which limits their clinical validity and fails to capture
the full complexity of psychiatric reasoning. In this work, we introduce
PsychiatryBench, a rigorously curated benchmark grounded exclusively in
authoritative, expert-validated psychiatric textbooks and casebooks.
PsychiatryBench comprises eleven distinct question-answering tasks ranging from
diagnostic reasoning and treatment planning to longitudinal follow-up,
management planning, clinical approach, sequential case analysis, and
multiple-choice/extended matching formats totaling over 5,300 expert-annotated
items. We evaluate a diverse set of frontier LLMs (including Google Gemini,
DeepSeek, LLaMA 3, and QWQ-32) alongside leading open-source medical models
(e.g., OpenBiloLLM, MedGemma) using both conventional metrics and an
"LLM-as-judge" similarity scoring framework. Our results reveal substantial
gaps in clinical consistency and safety, particularly in multi-turn follow-up
and management tasks, underscoring the need for specialized model tuning and
more robust evaluation paradigms. PsychiatryBench offers a modular, extensible
platform for benchmarking and improving LLM performance in high-stakes mental
health applications.

</details>


### [12] [The Thinking Therapist: Training Large Language Models to Deliver Acceptance and Commitment Therapy using Supervised Fine-Tuning and Odds Ratio Policy Optimization](https://arxiv.org/abs/2509.09712)
*Talha Tahir*

Main category: cs.CL

TL;DR: ORPO training significantly outperforms SFT and base models for ACT therapy delivery in small LLMs, with chain-of-thought reasoning benefiting SFT but not ORPO models.


<details>
  <summary>Details</summary>
Motivation: To investigate how post-training methodology and explicit reasoning affect small LLMs' ability to deliver Acceptance and Commitment Therapy (ACT), given ACT's emerging efficacy evidence in psychiatric conditions.

Method: Trained Llama-3.2-3b-Instruct using 50 synthetic ACT transcripts with two approaches: supervised fine-tuning (SFT) and odds ratio policy optimization (ORPO), each with/without chain-of-thought reasoning. Evaluated models in simulated therapy sessions using ACT Fidelity Measure and Therapist Empathy Scale assessed by an LLM judge fine-tuned on human evaluations.

Result: ORPO-trained models significantly outperformed both SFT and base Instruct models on ACT fidelity (χ²=185.15, p<.001) and therapeutic empathy (χ²=140.37, p<.001). COT provided significant benefit to SFT models (improving ACT-FM by 2.68 points, p<.001) but no advantage to ORPO or instruct-tuned variants.

Conclusion: Preference-aligned policy optimization (ORPO) effectively instills ACT competencies in small LLMs by learning therapeutic process rather than imitation, while explicit reasoning utility depends on the training paradigm, serving as a scaffold for imitation-based training.

Abstract: Acceptance and Commitment Therapy (ACT) is a third-wave cognitive behavioral
therapy with emerging evidence of efficacy in several psychiatric conditions.
This study investigates the impact of post-training methodology and explicit
reasoning on the ability of a small open-weight large language model (LLM) to
deliver ACT. Using 50 sets of synthetic ACT transcripts generated by
Mistral-Large, we trained Llama-3.2-3b-Instruct with two distinct approaches,
supervised fine-tuning (SFT) and odds ratio policy optimization (ORPO), each
with and without an explicit chain-of-thought (COT) reasoning step. Performance
was evaluated by comparing these four post-trained variants against the base
Instruct model. These models were benchmarked in simulated therapy sessions,
with performance quantitatively assessed on the ACT Fidelity Measure (ACT-FM)
and the Therapist Empathy Scale (TES) by an LLM judge that had been fine-tuned
on human evaluations. Our findings demonstrate that the ORPO-trained models
significantly outperformed both their SFT and Instruct counterparts on ACT
fidelity ($\chi^2(5) = 185.15, p < .001$) and therapeutic empathy ($\chi^2(5) =
140.37, p < .001$). The effect of COT was conditional as it provided a
significant benefit to SFT models, improving ACT-FM scores by an average of
2.68 points ($p < .001$), while offering no discernible advantage to the
superior ORPO or instruct-tuned variants. We posit that the superiority of ORPO
stems from its ability to learn the therapeutic `process' over imitating
`content,' a key aspect of ACT, while COT acts as a necessary scaffold for
models trained only via imitation. This study establishes that
preference-aligned policy optimization can effectively instill ACT competencies
in small LLMs, and that the utility of explicit reasoning is highly dependent
on the underlying training paradigm.

</details>


### [13] [HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented Generation for Multi-hop Question Answering](https://arxiv.org/abs/2509.09713)
*Duolin Sun,Dan Yang,Yue Shen,Yihan Jiao,Zhehao Tan,Jie Feng,Lianzhen Zhong,Jian Wang,Peng Wei,Jinjie Gu*

Main category: cs.CL

TL;DR: HANRAG is a heuristic-based RAG framework that improves multi-hop QA by routing queries, decomposing them into sub-queries, and filtering noise from retrieved documents, achieving superior performance over existing methods.


<details>
  <summary>Details</summary>
Motivation: Current RAG methods struggle with multi-hop queries due to inefficient iterative retrieval, failure to capture sub-query relevant content, and noise accumulation problems.

Method: Proposes HANRAG framework with a powerful revelator that routes queries, decomposes complex queries into sub-queries, and filters noise from retrieved documents to enhance adaptability and noise resistance.

Result: Superior performance in both single-hop and multi-hop question-answering tasks compared to leading industry methods across various benchmarks.

Conclusion: HANRAG effectively addresses multi-hop query challenges in RAG systems through intelligent query decomposition and noise filtering, demonstrating strong adaptability and performance improvements.

Abstract: The Retrieval-Augmented Generation (RAG) approach enhances question-answering
systems and dialogue generation tasks by integrating information retrieval (IR)
technologies with large language models (LLMs). This strategy, which retrieves
information from external knowledge bases to bolster the response capabilities
of generative models, has achieved certain successes. However, current RAG
methods still face numerous challenges when dealing with multi-hop queries. For
instance, some approaches overly rely on iterative retrieval, wasting too many
retrieval steps on compound queries. Additionally, using the original complex
query for retrieval may fail to capture content relevant to specific
sub-queries, resulting in noisy retrieved content. If the noise is not managed,
it can lead to the problem of noise accumulation. To address these issues, we
introduce HANRAG, a novel heuristic-based framework designed to efficiently
tackle problems of varying complexity. Driven by a powerful revelator, HANRAG
routes queries, decomposes them into sub-queries, and filters noise from
retrieved documents. This enhances the system's adaptability and noise
resistance, making it highly capable of handling diverse queries. We compare
the proposed framework against other leading industry methods across various
benchmarks. The results demonstrate that our framework obtains superior
performance in both single-hop and multi-hop question-answering tasks.

</details>


### [14] [How Small Transformation Expose the Weakness of Semantic Similarity Measures](https://arxiv.org/abs/2509.09714)
*Serge Lionel Nikiema,Albérick Euraste Djire,Abdoul Aziz Bonkoungou,Micheline Bénédicte Moumoula,Jordan Samhi,Abdoul Kader Kabore,Jacques Klein,Tegawendé F. Bissyande*

Main category: cs.CL

TL;DR: Study evaluates 18 semantic similarity measurement methods for software engineering applications, finding significant issues with embedding-based approaches that often confuse semantic opposites as similar, while LLM-based methods perform better at distinguishing true semantic differences.


<details>
  <summary>Details</summary>
Motivation: To assess how well different methods measure semantic similarity for software engineering tasks like code search and API recommendations, and to determine if large language models truly understand semantic relationships or just recognize surface patterns.

Method: Created a systematic testing framework applying controlled changes to text and code, testing 18 approaches including word-based methods, embedding techniques, LLM-based systems, and structure-aware algorithms.

Result: Embedding-based methods incorrectly identified semantic opposites as similar up to 99.9% of the time. Switching from Euclidean to cosine similarity improved results by 24-66%. LLM-based approaches performed better, producing low similarity scores (0.00-0.29) for different meanings vs embedding methods that incorrectly assigned high scores (0.82-0.99).

Conclusion: Current semantic similarity metrics have significant limitations, with embedding methods particularly prone to errors in distinguishing semantic relationships. LLM-based approaches show better performance but the field needs more robust evaluation frameworks.

Abstract: This research examines how well different methods measure semantic
similarity, which is important for various software engineering applications
such as code search, API recommendations, automated code reviews, and
refactoring tools. While large language models are increasingly used for these
similarity assessments, questions remain about whether they truly understand
semantic relationships or merely recognize surface patterns.
  The study tested 18 different similarity measurement approaches, including
word-based methods, embedding techniques, LLM-based systems, and
structure-aware algorithms. The researchers created a systematic testing
framework that applies controlled changes to text and code to evaluate how well
each method handles different types of semantic relationships.
  The results revealed significant issues with commonly used metrics. Some
embedding-based methods incorrectly identified semantic opposites as similar up
to 99.9 percent of the time, while certain transformer-based approaches
occasionally rated opposite meanings as more similar than synonymous ones. The
study found that embedding methods' poor performance often stemmed from how
they calculate distances; switching from Euclidean distance to cosine
similarity improved results by 24 to 66 percent. LLM-based approaches performed
better at distinguishing semantic differences, producing low similarity scores
(0.00 to 0.29) for genuinely different meanings, compared to embedding methods
that incorrectly assigned high scores (0.82 to 0.99) to dissimilar content.

</details>


### [15] [Investigating Symbolic Triggers of Hallucination in Gemma Models Across HaluEval and TruthfulQA](https://arxiv.org/abs/2509.09715)
*Naveen Lamba,Sanju Tiwari,Manas Gaur*

Main category: cs.CL

TL;DR: This paper identifies and characterizes key symbolic properties that make LLMs intrinsically vulnerable to hallucinations, showing that modifiers and named entities are particularly problematic across different model sizes.


<details>
  <summary>Details</summary>
Motivation: While hallucination in LLMs is well-studied, the specific properties that make them intrinsically vulnerable to hallucinations have not been identified and characterized, leaving gaps in understanding the internal mechanisms causing these issues.

Method: Researchers used HaluEval and TruthfulQA datasets, converting their question-answering format into various other formats to systematically identify and narrow down symbolic properties responsible for hallucinations across Gemma models of different sizes (2B, 9B, 27B).

Result: Hallucination percentages were notably high across symbolic properties: 79.0% for Gemma-2-2B, dropping to 73.6% for Gemma-2-9B and 63.9% for Gemma-2-27B. Modifiers (84.76%-94.98%) and named entities (83.87%-93.96%) showed particularly high hallucination rates across all models and datasets.

Conclusion: Symbolic elements like modifiers and named entities continue to confuse LLMs regardless of model scale, indicating a fundamental weakness in how these models process such inputs, with hallucinations persisting even as model size increases.

Abstract: Hallucination in Large Language Models (LLMs) is a well studied problem.
However, the properties that make LLM intrinsically vulnerable to
hallucinations have not been identified and studied. This research identifies
and characterizes the key properties, allowing us to pinpoint vulnerabilities
within the model's internal mechanisms. To solidify on these properties, we
utilized two established datasets, HaluEval and TruthfulQA and convert their
existing format of question answering into various other formats to narrow down
these properties as the reason for the hallucinations. Our findings reveal that
hallucination percentages across symbolic properties are notably high for
Gemma-2-2B, averaging 79.0% across tasks and datasets. With increased model
scale, hallucination drops to 73.6% for Gemma-2-9B and 63.9% for Gemma-2-27B,
reflecting a 15 percentage point reduction overall. Although the hallucination
rate decreases as the model size increases, a substantial amount of
hallucination caused by symbolic properties still persists. This is especially
evident for modifiers (ranging from 84.76% to 94.98%) and named entities
(ranging from 83.87% to 93.96%) across all Gemma models and both datasets.
These findings indicate that symbolic elements continue to confuse the models,
pointing to a fundamental weakness in how these LLMs process such
inputs--regardless of their scale.

</details>


### [16] [ALIGNS: Unlocking nomological networks in psychological measurement through a large language model](https://arxiv.org/abs/2509.09723)
*Kai R. Larsen,Sen Yan,Roland Müller,Lan Sang,Mikko Rönkkö,Ravi Starzl,Donald Edmondson*

Main category: cs.CL

TL;DR: ALIGNS is an LLM-based system that generates comprehensive nomological networks using validated questionnaire measures to address fundamental challenges in psychological measurement validation.


<details>
  <summary>Details</summary>
Motivation: Building nomological networks has remained challenging for 70 years since Cronbach and Meehl proposed them, leading to practical consequences like failed clinical trials and misguided public policy targeting wrong outcomes.

Method: Analysis of Latent Indicators to Generate Nomological Structures (ALIGNS) - a large language model-based system trained with validated questionnaire measures to create comprehensive networks across multiple fields.

Result: ALIGNS generated three nomological networks with over 550,000 indicators. Evaluations showed: 1) NIH PROMIS anxiety/depression converge into emotional distress dimension, 2) child temperament measures reveal four new dimensions and question one existing, 3) expert psychometricians confirmed system's importance and suitability.

Conclusion: ALIGNS represents the first application of LLMs to solve foundational measurement validation problems, complementing traditional methods with large-scale nomological analysis and being freely available for use.

Abstract: Psychological measurement is critical to many disciplines. Despite advances
in measurement, building nomological networks, theoretical maps of how concepts
and measures relate to establish validity, remains a challenge 70 years after
Cronbach and Meehl proposed them as fundamental to validation. This limitation
has practical consequences: clinical trials may fail to detect treatment
effects, and public policy may target the wrong outcomes. We introduce Analysis
of Latent Indicators to Generate Nomological Structures (ALIGNS), a large
language model-based system trained with validated questionnaire measures.
ALIGNS provides three comprehensive nomological networks containing over
550,000 indicators across psychology, medicine, social policy, and other
fields. This represents the first application of large language models to solve
a foundational problem in measurement validation. We report classification
accuracy tests used to develop the model, as well as three evaluations. In the
first evaluation, the widely used NIH PROMIS anxiety and depression instruments
are shown to converge into a single dimension of emotional distress. The second
evaluation examines child temperament measures and identifies four potential
dimensions not captured by current frameworks, and questions one existing
dimension. The third evaluation, an applicability check, engages expert
psychometricians who assess the system's importance, accessibility, and
suitability. ALIGNS is freely available at nomologicalnetwork.org,
complementing traditional validation methods with large-scale nomological
analysis.

</details>


### [17] [DiTTO-LLM: Framework for Discovering Topic-based Technology Opportunities via Large Language Model](https://arxiv.org/abs/2509.09724)
*Wonyoung Kim,Sujeong Seo,Juhyun Lee*

Main category: cs.CL

TL;DR: A framework using temporal patent analysis and LLMs to identify emerging tech opportunities, tested on AI patents showing evolution toward everyday accessibility.


<details>
  <summary>Details</summary>
Motivation: Technology opportunities are crucial for advancement but difficult to identify systematically. Current methods may not effectively capture temporal relationships between technologies.

Method: Extracts text from patents, maps text-based topics to discover inter-technology relationships, tracks topic changes over time using large language models and chat-based prompts for efficiency.

Result: Framework successfully identified that AI technology is evolving toward forms that facilitate everyday accessibility, demonstrating practical application on USPTO AI patent dataset.

Conclusion: The proposed framework shows strong potential for identifying future technology opportunities through temporal analysis of patent data enhanced by language models.

Abstract: Technology opportunities are critical information that serve as a foundation
for advancements in technology, industry, and innovation. This paper proposes a
framework based on the temporal relationships between technologies to identify
emerging technology opportunities. The proposed framework begins by extracting
text from a patent dataset, followed by mapping text-based topics to discover
inter-technology relationships. Technology opportunities are then identified by
tracking changes in these topics over time. To enhance efficiency, the
framework leverages a large language model to extract topics and employs a
prompt for a chat-based language model to support the discovery of technology
opportunities. The framework was evaluated using an artificial intelligence
patent dataset provided by the United States Patent and Trademark Office. The
experimental results suggest that artificial intelligence technology is
evolving into forms that facilitate everyday accessibility. This approach
demonstrates the potential of the proposed framework to identify future
technology opportunities.

</details>


### [18] [BIBERT-Pipe on Biomedical Nested Named Entity Linking at BioASQ 2025](https://arxiv.org/abs/2509.09725)
*Chunyu Li,Xindi Zheng,Siqi Liu*

Main category: cs.CL

TL;DR: A lightweight pipeline for multilingual biomedical nested entity linking that uses two-stage retrieval-ranking with boundary cues and dataset augmentation, achieving competitive results on BioNNE 2025.


<details>
  <summary>Details</summary>
Motivation: Address the gap in biomedical entity linking benchmarks that typically focus on English-only corpora with flat mentions, ignoring the realistic scenarios of nested and multilingual mentions.

Method: Two-stage retrieval-ranking using the same base encoder model (original pre-trained for retrieval, domain-specific fine-tuned for ranking), boundary cues with learnable [Ms]/[Me] tags for language-agnostic span recognition, and dataset augmentation from three complementary sources.

Result: Ranked third in the multilingual track on BioNNE 2025 leaderboard, demonstrating effectiveness and competitiveness of minimal but principled modifications.

Conclusion: The proposed lightweight pipeline with task-aligned components effectively handles multilingual biomedical nested entity linking while keeping the original EL model intact, showing strong performance with minimal modifications.

Abstract: Entity linking (EL) for biomedical text is typically benchmarked on
English-only corpora with flat mentions, leaving the more realistic scenario of
nested and multilingual mentions largely unexplored. We present our system for
the BioNNE 2025 Multilingual Biomedical Nested Named Entity Linking shared task
(English & Russian), closing this gap with a lightweight pipeline that keeps
the original EL model intact and modifies only three task-aligned components:
Two-stage retrieval-ranking. We leverage the same base encoder model in both
stages: the retrieval stage uses the original pre-trained model, while the
ranking stage applies domain-specific fine-tuning. Boundary cues. In the
ranking stage, we wrap each mention with learnable [Ms] / [Me] tags, providing
the encoder with an explicit, language-agnostic span before robustness to
overlap and nesting. Dataset augmentation. We also automatically expand the
ranking training corpus with three complementary data sources, enhancing
coverage without extra manual annotation. On the BioNNE 2025 leaderboard, our
two stage system, bilingual bert (BIBERT-Pipe), ranks third in the multilingual
track, demonstrating the effectiveness and competitiveness of these minimal yet
principled modifications. Code are publicly available at
https://github.com/Kaggle-Competitions-Code/BioNNE-L.

</details>


### [19] [Natural Language Translation of Formal Proofs through Informalization of Proof Steps and Recursive Summarization along Proof Structure](https://arxiv.org/abs/2509.09726)
*Seiji Hattori,Takuya Matsuzaki,Makoto Fujiwara*

Main category: cs.CL

TL;DR: LLM-based method for translating formal proofs to natural language using informalization and summarization, evaluated on textbook proofs and Lean library with high readability and accuracy.


<details>
  <summary>Details</summary>
Motivation: To bridge the gap between machine-verifiable formal proofs and human-readable natural language proofs by leveraging LLM capabilities.

Method: Uses LLMs for informalization (verbalizing formal proof steps) and summarization to translate formal proofs to natural language.

Result: Generated natural language proofs show high readability and accuracy when compared to original textbook proofs and applied to Lean proof library.

Conclusion: The proposed method effectively produces readable and accurate natural language translations of formal proofs using LLMs.

Abstract: This paper proposes a natural language translation method for
machine-verifiable formal proofs that leverages the informalization
(verbalization of formal language proof steps) and summarization capabilities
of LLMs. For evaluation, it was applied to formal proof data created in
accordance with natural language proofs taken from an undergraduate-level
textbook, and the quality of the generated natural language proofs was analyzed
in comparison with the original natural language proofs. Furthermore, we will
demonstrate that this method can output highly readable and accurate natural
language proofs by applying it to existing formal proof library of the Lean
proof assistant.

</details>


### [20] [A Role-Aware Multi-Agent Framework for Financial Education Question Answering with LLMs](https://arxiv.org/abs/2509.09727)
*Andy Zhu,Yingjun Du*

Main category: cs.CL

TL;DR: Multi-agent framework with role-based prompting improves financial QA accuracy by 6.6-8.3% over zero-shot Chain-of-Thought baselines, using three specialized agents working in single-pass iteration.


<details>
  <summary>Details</summary>
Motivation: Existing LLMs fail to capture nuanced reasoning required for financial problem-solving, which demands multistep quantitative reasoning, domain-specific terminology, and real-world scenario comprehension.

Method: Multi-agent framework with Base Generator, Evidence Retriever, and Expert Reviewer agents using RAG from 6 finance textbooks and domain-expert prompting strategies in single-pass iteration.

Result: Critique-based refinement improves answer accuracy by 6.6-8.3% over baselines, with Gemini-2.0-Flash achieving highest performance. GPT-4o-mini matches finance-tuned FinGPT-mt_Llama3-8B_LoRA performance.

Conclusion: Cost-effective approach enhances financial QA and provides insights for multi-agent financial LLM systems research.

Abstract: Question answering (QA) plays a central role in financial education, yet
existing large language model (LLM) approaches often fail to capture the
nuanced and specialized reasoning required for financial problem-solving. The
financial domain demands multistep quantitative reasoning, familiarity with
domain-specific terminology, and comprehension of real-world scenarios. We
present a multi-agent framework that leverages role-based prompting to enhance
performance on domain-specific QA. Our framework comprises a Base Generator, an
Evidence Retriever, and an Expert Reviewer agent that work in a single-pass
iteration to produce a refined answer. We evaluated our framework on a set of
3,532 expert-designed finance education questions from Study.com, an online
learning platform. We leverage retrieval-augmented generation (RAG) for
contextual evidence from 6 finance textbooks and prompting strategies for a
domain-expert reviewer. Our experiments indicate that critique-based refinement
improves answer accuracy by 6.6-8.3% over zero-shot Chain-of-Thought baselines,
with the highest performance from Gemini-2.0-Flash. Furthermore, our method
enables GPT-4o-mini to achieve performance comparable to the finance-tuned
FinGPT-mt_Llama3-8B_LoRA. Our results show a cost-effective approach to
enhancing financial QA and offer insights for further research in multi-agent
financial LLM systems.

</details>


### [21] [A meta-analysis on the performance of machine-learning based language models for sentiment analysis](https://arxiv.org/abs/2509.09728)
*Elena Rohde,Jonas Klingwort,Christian Borgs*

Main category: cs.CL

TL;DR: Meta-analysis of 195 ML trials from 20 studies shows average sentiment analysis accuracy of 0.80 on Twitter data, while highlighting issues with overall accuracy metric and lack of standardized reporting practices.


<details>
  <summary>Details</summary>
Motivation: To evaluate ML performance in Twitter sentiment analysis, estimate average performance, assess study heterogeneity, and analyze how study characteristics influence model performance across different research.

Method: Used PRISMA guidelines to search academic databases, selected 195 trials from 20 studies with 12 features. Analyzed overall accuracy using double arcsine transformation and three-level random effects model with AIC optimization.

Result: Average overall accuracy was 0.80 [0.76, 0.84]. Found that overall accuracy is misleading due to sensitivity to class imbalance and number of sentiment classes, and identified lack of standardized reporting practices.

Conclusion: Overall accuracy requires normalization for fair comparisons, and standardized reporting including confusion matrices for independent test sets is essential for reliable ML classifier comparisons across studies.

Abstract: This paper presents a meta-analysis evaluating ML performance in sentiment
analysis for Twitter data. The study aims to estimate the average performance,
assess heterogeneity between and within studies, and analyze how study
characteristics influence model performance. Using PRISMA guidelines, we
searched academic databases and selected 195 trials from 20 studies with 12
study features. Overall accuracy, the most reported performance metric, was
analyzed using double arcsine transformation and a three-level random effects
model. The average overall accuracy of the AIC-optimized model was 0.80 [0.76,
0.84]. This paper provides two key insights: 1) Overall accuracy is widely used
but often misleading due to its sensitivity to class imbalance and the number
of sentiment classes, highlighting the need for normalization. 2) Standardized
reporting of model performance, including reporting confusion matrices for
independent test sets, is essential for reliable comparisons of ML classifiers
across studies, which seems far from common practice.

</details>


### [22] [MultimodalHugs: Enabling Sign Language Processing in Hugging Face](https://arxiv.org/abs/2509.09729)
*Gerard Sant,Zifan Jiang,Carlos Escolano,Amit Moryossef,Mathias Müller,Rico Sennrich,Sarah Ebling*

Main category: cs.CL

TL;DR: MultimodalHugs is a framework built on Hugging Face that enables diverse multimodal data processing, particularly for sign language, addressing reproducibility and flexibility issues in SLP research.


<details>
  <summary>Details</summary>
Motivation: Sign language processing research faces challenges with complex ad-hoc code, low reproducibility, and unfair comparisons. Existing tools like Hugging Face lack flexibility for sign language experiments, as confirmed by a survey of SLP researchers.

Method: Developed MultimodalHugs framework on top of Hugging Face, adding abstraction layer to support diverse data modalities and tasks beyond standard templates, with focus on sign language data.

Result: The framework successfully accommodates diverse modalities including pose estimation data for sign languages and pixel data for text characters, as demonstrated through quantitative experiments.

Conclusion: MultimodalHugs provides a flexible solution for multimodal research, particularly benefiting sign language processing while maintaining the advantages of the Hugging Face ecosystem for improved reproducibility and fair comparisons.

Abstract: In recent years, sign language processing (SLP) has gained importance in the
general field of Natural Language Processing. However, compared to research on
spoken languages, SLP research is hindered by complex ad-hoc code,
inadvertently leading to low reproducibility and unfair comparisons. Existing
tools that are built for fast and reproducible experimentation, such as Hugging
Face, are not flexible enough to seamlessly integrate sign language
experiments. This view is confirmed by a survey we conducted among SLP
researchers.
  To address these challenges, we introduce MultimodalHugs, a framework built
on top of Hugging Face that enables more diverse data modalities and tasks,
while inheriting the well-known advantages of the Hugging Face ecosystem. Even
though sign languages are our primary focus, MultimodalHugs adds a layer of
abstraction that makes it more widely applicable to other use cases that do not
fit one of the standard templates of Hugging Face. We provide quantitative
experiments to illustrate how MultimodalHugs can accommodate diverse modalities
such as pose estimation data for sign languages, or pixel data for text
characters.

</details>


### [23] [Benchmarking Vision-Language Models on Chinese Ancient Documents: From OCR to Knowledge Reasoning](https://arxiv.org/abs/2509.09731)
*Haiyang Yu,Yuchuan Wu,Fan Shi,Lei Liao,Jinghui Lu,Xiaodong Ge,Han Wang,Minghan Zhuo,Xuecheng Wu,Xiang Fei,Hao Feng,Guozhi Tang,An-Lan Wang,Hanshen Zhu,Yangfan He,Quanhuan Liang,Liyuan Meng,Chao Feng,Can Huang,Jingqun Tang,Bin Li*

Main category: cs.CL

TL;DR: AncientDoc is the first benchmark for evaluating Vision-Language Models on Chinese ancient documents, featuring five tasks across OCR, translation, and reasoning with comprehensive coverage of 14 document types and 3,000 pages.


<details>
  <summary>Details</summary>
Motivation: Chinese ancient documents contain valuable historical knowledge but face digitization challenges. Current VLMs struggle with their visual and linguistic complexity, and existing benchmarks focus only on English or simplified Chinese, leaving a gap for ancient Chinese document evaluation.

Method: Created AncientDoc benchmark with five tasks: page-level OCR, vernacular translation, reasoning-based QA, knowledge-based QA, and linguistic variant QA. Covers 14 document types, over 100 books, and about 3,000 pages. Evaluates mainstream VLMs using multiple metrics with human-aligned LLM scoring.

Result: The paper presents the AncientDoc benchmark but does not specify the actual evaluation results of the VLMs tested in this abstract. The benchmark itself is the main contribution.

Conclusion: AncientDoc fills a critical gap in evaluating VLMs for Chinese ancient documents, providing a comprehensive benchmark that addresses both visual and linguistic challenges specific to these historical texts across multiple task types.

Abstract: Chinese ancient documents, invaluable carriers of millennia of Chinese
history and culture, hold rich knowledge across diverse fields but face
challenges in digitization and understanding, i.e., traditional methods only
scan images, while current Vision-Language Models (VLMs) struggle with their
visual and linguistic complexity. Existing document benchmarks focus on English
printed texts or simplified Chinese, leaving a gap for evaluating VLMs on
ancient Chinese documents. To address this, we present AncientDoc, the first
benchmark for Chinese ancient documents, designed to assess VLMs from OCR to
knowledge reasoning. AncientDoc includes five tasks (page-level OCR, vernacular
translation, reasoning-based QA, knowledge-based QA, linguistic variant QA) and
covers 14 document types, over 100 books, and about 3,000 pages. Based on
AncientDoc, we evaluate mainstream VLMs using multiple metrics, supplemented by
a human-aligned large language model for scoring.

</details>


### [24] [MCP-AgentBench: Evaluating Real-World Language Agent Performance with MCP-Mediated Tools](https://arxiv.org/abs/2509.09734)
*Zikang Guo,Benfeng Xu,Chiwei Zhu,Wentao Hong,Xiaorui Wang,Zhendong Mao*

Main category: cs.CL

TL;DR: MCP-AgentBench is a new benchmark designed to evaluate language agents' performance in MCP-mediated tool interactions, addressing the gap in existing benchmarks that fail to capture real-world agent capabilities in this emerging paradigm.


<details>
  <summary>Details</summary>
Motivation: Existing benchmarks fail to properly evaluate agent performance in the Model Context Protocol (MCP) ecosystem, leading to distorted perceptions of agent capabilities and inability to differentiate proficiencies in real-world MCP tool interactions.

Method: Developed a comprehensive benchmark with: 1) MCP testbed with 33 operational servers and 188 distinct tools, 2) 600 systematically designed queries across 6 categories of varying complexity, 3) MCP-Eval methodology focusing on outcome-oriented, real-world task success evaluation.

Result: The benchmark provides foundational insights through extensive empirical evaluation of leading language agents, enabling reliable assessment of agent capabilities in MCP environments.

Conclusion: MCP-AgentBench provides a standardized framework for building, validating, and advancing agents that can fully leverage MCP's benefits, accelerating progress toward capable and interoperable AI systems.

Abstract: The Model Context Protocol (MCP) is rapidly emerging as a pivotal open
standard, designed to enhance agent-tool integration and interoperability, and
is positioned to unlock a new era of powerful, interconnected, and genuinely
utilitarian agentic AI. However, despite MCP's growing adoption, existing
benchmarks often fail to capture real-world agent performance within this new
paradigm, leading to a distorted perception of their true operational value and
an inability to reliably differentiate proficiencies. To bridge this critical
evaluation gap, we introduce MCP-AgentBench -- a comprehensive benchmark
specifically engineered to rigorously assess language agent capabilities in
MCP-mediated tool interactions. Core contributions of MCP-AgentBench include:
the establishment of a robust MCP testbed comprising 33 operational servers
with 188 distinct tools; the development of a benchmark featuring 600
systematically designed queries distributed across 6 distinct categories of
varying interaction complexity; and the introduction of MCP-Eval, a novel
outcome-oriented evaluation methodology prioritizing real-world task success.
Through extensive empirical evaluation of leading language agents, we provide
foundational insights. MCP-AgentBench aims to equip the research community with
a standardized and reliable framework to build, validate, and advance agents
capable of fully leveraging MCP's transformative benefits, thereby accelerating
progress toward truly capable and interoperable AI systems.

</details>


### [25] [Discrimination by LLMs: Cross-lingual Bias Assessment and Mitigation in Decision-Making and Summarisation](https://arxiv.org/abs/2509.09735)
*Willem Huijzer,Jieying Chen*

Main category: cs.CL

TL;DR: Study examines biases in LLMs (GPT-3.5 and GPT-4o) related to background, gender, and age in decision-making and summarization tasks across English and Dutch, finding significant biases favoring female gender, younger ages, and certain backgrounds, with prompt-based mitigation strategies showing partial effectiveness.


<details>
  <summary>Details</summary>
Motivation: Address concerns about societal inequalities and information bias as LLMs are rapidly integrated into various domains, focusing on their impact on decision-making and cross-lingual bias propagation.

Method: Used adapted dataset translated into Dutch with 151,200 unique prompts for decision tasks and 176,400 for summarization tasks. Tested various demographic variables, instructions, salience levels, and languages on GPT-3.5 and GPT-4o.

Result: Both models showed significant bias in decision-making (favoring female gender, younger ages, African-American background), while summarization showed minimal bias. Cross-lingual patterns were similar but with category-specific differences. Mitigation instructions achieved 27% mean reduction in bias gap. GPT-4o showed reduced biases compared to GPT-3.5.

Conclusion: Cautious adoption of LLMs and context-specific bias testing are crucial. Continued development of effective mitigation strategies is needed for responsible AI deployment, with newer models showing better potential for prompt-based bias reduction.

Abstract: The rapid integration of Large Language Models (LLMs) into various domains
raises concerns about societal inequalities and information bias. This study
examines biases in LLMs related to background, gender, and age, with a focus on
their impact on decision-making and summarization tasks. Additionally, the
research examines the cross-lingual propagation of these biases and evaluates
the effectiveness of prompt-instructed mitigation strategies. Using an adapted
version of the dataset by Tamkin et al. (2023) translated into Dutch, we
created 151,200 unique prompts for the decision task and 176,400 for the
summarisation task. Various demographic variables, instructions, salience
levels, and languages were tested on GPT-3.5 and GPT-4o. Our analysis revealed
that both models were significantly biased during decision-making, favouring
female gender, younger ages, and certain backgrounds such as the
African-American background. In contrast, the summarisation task showed minimal
evidence of bias, though significant age-related differences emerged for
GPT-3.5 in English. Cross-lingual analysis showed that bias patterns were
broadly similar between English and Dutch, though notable differences were
observed across specific demographic categories. The newly proposed mitigation
instructions, while unable to eliminate biases completely, demonstrated
potential in reducing them. The most effective instruction achieved a 27\% mean
reduction in the gap between the most and least favorable demographics.
Notably, contrary to GPT-3.5, GPT-4o displayed reduced biases for all prompts
in English, indicating the specific potential for prompt-based mitigation
within newer models. This research underscores the importance of cautious
adoption of LLMs and context-specific bias testing, highlighting the need for
continued development of effective mitigation strategies to ensure responsible
deployment of AI.

</details>


### [26] [HEFT: A Coarse-to-Fine Hierarchy for Enhancing the Efficiency and Accuracy of Language Model Reasoning](https://arxiv.org/abs/2509.09801)
*Brennen Hill*

Main category: cs.CL

TL;DR: HEFT combines LoRA (weight space) and ReFT (representation space) PEFT methods in a hierarchical approach, achieving 85.17% accuracy on BoolQ with just 3 epochs, outperforming individual methods trained for 20 epochs.


<details>
  <summary>Details</summary>
Motivation: To overcome computational constraints in adapting LLMs to specialized reasoning tasks by synergistically combining different PEFT paradigms for superior performance and efficiency.

Method: Hierarchical Efficient Fine-Tuning (HEFT) strategy: first applies broad adaptation using LoRA in weight space, then precise refinement using Representation Fine-Tuning (ReFT) on internal activations.

Result: Achieved 85.17% accuracy on BoolQ benchmark with only 3 epochs, outperforming LoRA-only (85.05%) and ReFT-only (83.36%) methods trained for 20 epochs.

Conclusion: Thoughtful composition of PEFT methods is a powerful algorithmic innovation that provides more efficient and effective path for advancing LLM reasoning capabilities with reduced computational budget.

Abstract: The adaptation of large language models (LLMs) to specialized reasoning tasks
is fundamentally constrained by computational resources. Parameter-Efficient
Fine-Tuning (PEFT) methods have emerged as a powerful solution, yet the
landscape of these techniques is diverse, with distinct methods operating in
either the model's weight space or its representation space. This paper
investigates the hypothesis that a synergistic combination of these paradigms
can unlock superior performance and efficiency. We introduce HEFT (Hierarchical
Efficient Fine-Tuning), a novel hierarchical adaptation strategy that composes
two distinct PEFT methods in a coarse-to-fine manner: first, a broad,
foundational adaptation in the weight space using Low-Rank Adaptation (LoRA),
followed by a precise, surgical refinement of internal activations using
Representation Fine-Tuning (ReFT). We evaluate this approach by fine-tuning a
Llama-2-7B model on the BoolQ benchmark, a challenging dataset for inferential
reasoning. Our results reveal a profound synergistic effect. A model fine-tuned
for only three epochs with our HEFT strategy achieves an accuracy of 85.17\%,
exceeding the performance of models trained for 20 epochs with either LoRA-only
(85.05\%) or ReFT-only (83.36\%) methodologies. This work demonstrates that the
thoughtful composition of PEFT methods is a potent algorithmic innovation,
offering a more efficient and effective path toward advancing the reasoning
capabilities of language models. By achieving superior results with a fraction
of the computational budget, our findings present a principled approach to
overcoming the obstacles inherent in adapting large-scale models for complex
cognitive tasks.

</details>


### [27] [Pragmatic Frames Evoked by Gestures: A FrameNet Brasil Approach to Multimodality in Turn Organization](https://arxiv.org/abs/2509.09804)
*Helen de Andrade Abreu,Tiago Timponi Torrent,Ely Edison da Silva Matos*

Main category: cs.CL

TL;DR: A framework for modeling multimodal conversational turn organization through correlations between language and interactive gestures, with evidence from enriched annotations of pragmatic frames in the Frame2 dataset.


<details>
  <summary>Details</summary>
Motivation: To fill the gap in machine learning datasets by encoding specific strategies and gestures used for conversational turn organization, which had not been previously documented in available datasets.

Method: Developed an annotation methodology to enrich the multimodal Frame2 dataset (Brazilian TV series episodes) with pragmatic frames modeling turn organization, analyzing how communicators use interactive gestures in natural settings.

Result: Confirmed that communicators use gestures for passing, taking, and keeping conversational turns, and discovered variations of gestures not previously documented. Demonstrated that pragmatic frame annotation provides deeper understanding of human cognition and language.

Conclusion: The proposed framework successfully models multimodal turn organization through gesture-language correlations, with pragmatic frames arising from conceptualization involving mental spaces, blending and conceptual metaphors.

Abstract: This paper proposes a framework for modeling multimodal conversational turn
organization via the proposition of correlations between language and
interactive gestures, based on analysis as to how pragmatic frames are
conceptualized and evoked by communicators. As a means to provide evidence for
the analysis, we developed an annotation methodology to enrich a multimodal
dataset (annotated for semantic frames) with pragmatic frames modeling
conversational turn organization. Although conversational turn organization has
been studied by researchers from diverse fields, the specific strategies,
especially gestures used by communicators, had not yet been encoded in a
dataset that can be used for machine learning. To fill this gap, we enriched
the Frame2 dataset with annotations of gestures used for turn organization. The
Frame2 dataset features 10 episodes from the Brazilian TV series Pedro Pelo
Mundo annotated for semantic frames evoked in both video and text. This dataset
allowed us to closely observe how communicators use interactive gestures
outside a laboratory, in settings, to our knowledge, not previously recorded in
related literature. Our results have confirmed that communicators involved in
face-to-face conversation make use of gestures as a tool for passing, taking
and keeping conversational turns, and also revealed variations of some gestures
that had not been documented before. We propose that the use of these gestures
arises from the conceptualization of pragmatic frames, involving mental spaces,
blending and conceptual metaphors. In addition, our data demonstrate that the
annotation of pragmatic frames contributes to a deeper understanding of human
cognition and language.

</details>


### [28] [Topic-Guided Reinforcement Learning with LLMs for Enhancing Multi-Document Summarization](https://arxiv.org/abs/2509.09852)
*Chuyuan Li,Austin Xu,Shafiq Joty,Giuseppe Carenini*

Main category: cs.CL

TL;DR: Topic-guided reinforcement learning approach improves multi-document summarization by using topic rewards to enhance content selection and alignment with source documents.


<details>
  <summary>Details</summary>
Motivation: Large Language Models perform well on single-document summarization but still have room for improvement in Multi-Document Summarization (MDS), particularly in effectively integrating information from multiple sources while maintaining coherence and topical relevance.

Method: Proposed a topic-guided reinforcement learning approach using explicit topic labels as prompts and a novel topic reward within the Group Relative Policy Optimization (GRPO) framework to measure topic alignment between generated summaries and source documents.

Result: Experimental results on Multi-News and Multi-XScience datasets show consistent outperformance over strong baselines, demonstrating improved informativeness and topic alignment in generated summaries.

Conclusion: Leveraging topical cues through reinforcement learning is an effective approach for improving content selection and overall performance in multi-document summarization tasks.

Abstract: A key challenge in Multi-Document Summarization (MDS) is effectively
integrating information from multiple sources while maintaining coherence and
topical relevance. While Large Language Models have shown impressive results in
single-document summarization, their performance on MDS still leaves room for
improvement. In this paper, we propose a topic-guided reinforcement learning
approach to improve content selection in MDS. We first show that explicitly
prompting models with topic labels enhances the informativeness of the
generated summaries. Building on this insight, we propose a novel topic reward
within the Group Relative Policy Optimization (GRPO) framework to measure topic
alignment between the generated summary and source documents. Experimental
results on the Multi-News and Multi-XScience datasets demonstrate that our
method consistently outperforms strong baselines, highlighting the
effectiveness of leveraging topical cues in MDS.

</details>


### [29] [Emulating Public Opinion: A Proof-of-Concept of AI-Generated Synthetic Survey Responses for the Chilean Case](https://arxiv.org/abs/2509.09871)
*Bastián González-Bustamante,Nando Verelst,Carla Cisternas*

Main category: cs.CL

TL;DR: LLMs can generate synthetic survey responses that approximate human responses from probabilistic surveys, with excellent performance on trust items and comparable results across top models like GPT-4o and Llama 4 Maverick, though performance varies by item and demographic factors.


<details>
  <summary>Details</summary>
Motivation: To evaluate whether LLM-generated synthetic survey responses can reliably recover aggregate item distributions and mitigate measurement/representation errors in survey research, while assessing risks of reproducing social biases.

Method: Benchmarked 128 prompt-model-question triplets generating 189,696 synthetic profiles, compared against Chilean public opinion survey data. Used meta-analysis across 128 question-subsample pairs with performance metrics (accuracy, precision, recall, F1-score) to test biases along sociodemographic dimensions.

Result: Synthetic responses achieved excellent performance on trust items (F1-score and accuracy > 0.90). GPT-4o, GPT-4o-mini and Llama 4 Maverick performed comparably. Synthetic-human alignment was highest among respondents aged 45-59, with substantial item-level heterogeneity.

Conclusion: LLM-based synthetic samples can approximate probabilistic sample responses but require careful calibration and additional distributional tests to ensure algorithmic fidelity and reduce errors, as capturing full public opinion nuance remains challenging.

Abstract: Large Language Models (LLMs) offer promising avenues for methodological and
applied innovations in survey research by using synthetic respondents to
emulate human answers and behaviour, potentially mitigating measurement and
representation errors. However, the extent to which LLMs recover aggregate item
distributions remains uncertain and downstream applications risk reproducing
social stereotypes and biases inherited from training data. We evaluate the
reliability of LLM-generated synthetic survey responses against ground-truth
human responses from a Chilean public opinion probabilistic survey.
Specifically, we benchmark 128 prompt-model-question triplets, generating
189,696 synthetic profiles, and pool performance metrics (i.e., accuracy,
precision, recall, and F1-score) in a meta-analysis across 128
question-subsample pairs to test for biases along key sociodemographic
dimensions. The evaluation spans OpenAI's GPT family and o-series reasoning
models, as well as Llama and Qwen checkpoints. Three results stand out. First,
synthetic responses achieve excellent performance on trust items (F1-score and
accuracy > 0.90). Second, GPT-4o, GPT-4o-mini and Llama 4 Maverick perform
comparably on this task. Third, synthetic-human alignment is highest among
respondents aged 45-59. Overall, LLM-based synthetic samples approximate
responses from a probabilistic sample, though with substantial item-level
heterogeneity. Capturing the full nuance of public opinion remains challenging
and requires careful calibration and additional distributional tests to ensure
algorithmic fidelity and reduce errors.

</details>


### [30] [Large Language Models Meet Legal Artificial Intelligence: A Survey](https://arxiv.org/abs/2509.09969)
*Zhitian Hou,Zihan Ye,Nanli Zeng,Tianyong Hao,Kun Zeng*

Main category: cs.CL

TL;DR: Comprehensive review of 16 legal LLM series, 47 LLM-based legal frameworks, 15 benchmarks, and 29 datasets for evaluating legal AI capabilities, with analysis of challenges and future directions.


<details>
  <summary>Details</summary>
Motivation: To advance research and applications of LLM-based approaches in the legal domain by providing systematic resources and guidance for beginners and researchers.

Method: Systematic review and compilation of existing legal LLMs, frameworks, benchmarks, and datasets, followed by analysis of challenges and future research directions.

Result: Created a comprehensive resource repository including 16 legal LLM series, 47 frameworks, 15 benchmarks, and 29 datasets for legal AI evaluation and development.

Conclusion: This paper provides foundational resources and guidance to accelerate LLM-based legal AI research, identifies current challenges, and outlines future directions for the field.

Abstract: Large Language Models (LLMs) have significantly advanced the development of
Legal Artificial Intelligence (Legal AI) in recent years, enhancing the
efficiency and accuracy of legal tasks. To advance research and applications of
LLM-based approaches in legal domain, this paper provides a comprehensive
review of 16 legal LLMs series and 47 LLM-based frameworks for legal tasks, and
also gather 15 benchmarks and 29 datasets to evaluate different legal
capabilities. Additionally, we analyse the challenges and discuss future
directions for LLM-based approaches in the legal domain. We hope this paper
provides a systematic introduction for beginners and encourages future research
in this field. Resources are available at
https://github.com/ZhitianHou/LLMs4LegalAI.

</details>


### [31] [CMHG: A Dataset and Benchmark for Headline Generation of Minority Languages in China](https://arxiv.org/abs/2509.09990)
*Guixian Xu,Zeli Su,Ziyin Zhang,Jianing Liu,XU Han,Ting Zhang,Yushuang Dong*

Main category: cs.CL

TL;DR: New CMHG dataset with 200K entries (100K Tibetan, 50K Uyghur, 50K Mongolian) for minority language headline generation, plus native-speaker annotated test set as benchmark.


<details>
  <summary>Details</summary>
Motivation: Address severe lack of corpora for Chinese minority languages (Tibetan, Uyghur, Mongolian) due to unique writing systems differing from international standards, particularly for supervised tasks like headline generation.

Method: Created Chinese Minority Headline Generation (CMHG) dataset with curated entries specifically for headline generation tasks, including native-speaker annotated high-quality test set.

Result: Dataset includes 100,000 Tibetan entries and 50,000 entries each for Uyghur and Mongolian, providing benchmark resources for future research.

Conclusion: CMHG dataset serves as valuable resource to advance headline generation in Chinese minority languages and contribute to development of related benchmarks.

Abstract: Minority languages in China, such as Tibetan, Uyghur, and Traditional
Mongolian, face significant challenges due to their unique writing systems,
which differ from international standards. This discrepancy has led to a severe
lack of relevant corpora, particularly for supervised tasks like headline
generation. To address this gap, we introduce a novel dataset, Chinese Minority
Headline Generation (CMHG), which includes 100,000 entries for Tibetan, and
50,000 entries each for Uyghur and Mongolian, specifically curated for headline
generation tasks. Additionally, we propose a high-quality test set annotated by
native speakers, designed to serve as a benchmark for future research in this
domain. We hope this dataset will become a valuable resource for advancing
headline generation in Chinese minority languages and contribute to the
development of related benchmarks.

</details>


### [32] [Unsupervised Hallucination Detection by Inspecting Reasoning Processes](https://arxiv.org/abs/2509.10004)
*Ponhvoan Srey,Xiaobao Wu,Anh Tuan Luu*

Main category: cs.CL

TL;DR: IRIS is an unsupervised hallucination detection framework that uses LLM's internal representations and response uncertainty to identify factual errors without labeled data, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing unsupervised hallucination detection methods rely on proxy signals unrelated to factual correctness, limiting their generalizability across datasets and scenarios.

Method: IRIS prompts LLMs to verify statement truthfulness, extracts contextualized embeddings as features, and uses response uncertainty as soft pseudolabels for training.

Result: Experimental results show IRIS consistently outperforms existing unsupervised methods, works with few training data, and is computationally efficient.

Conclusion: IRIS provides an effective unsupervised approach for real-time hallucination detection by leveraging intrinsic LLM representations related to factual correctness.

Abstract: Unsupervised hallucination detection aims to identify hallucinated content
generated by large language models (LLMs) without relying on labeled data.
While unsupervised methods have gained popularity by eliminating
labor-intensive human annotations, they frequently rely on proxy signals
unrelated to factual correctness. This misalignment biases detection probes
toward superficial or non-truth-related aspects, limiting generalizability
across datasets and scenarios. To overcome these limitations, we propose IRIS,
an unsupervised hallucination detection framework, leveraging internal
representations intrinsic to factual correctness. IRIS prompts the LLM to
carefully verify the truthfulness of a given statement, and obtain its
contextualized embedding as informative features for training. Meanwhile, the
uncertainty of each response is considered a soft pseudolabel for truthfulness.
Experimental results demonstrate that IRIS consistently outperforms existing
unsupervised methods. Our approach is fully unsupervised, computationally low
cost, and works well even with few training data, making it suitable for
real-time detection.

</details>


### [33] [Multi-Intent Recognition in Dialogue Understanding: A Comparison Between Smaller Open-Source LLMs](https://arxiv.org/abs/2509.10010)
*Adnan Ahmad,Philine Kowol,Stefan Hillmann,Sebastian Möller*

Main category: cs.CL

TL;DR: Analysis of open-source LLMs (LLama2-7B, Mistral-7B, Yi-6B) for multi-label intent classification using MultiWOZ 2.1 dataset in few-shot setting, with BERT baseline comparison. Mistral-7B performed best among LLMs but BERT supervised learning outperformed all.


<details>
  <summary>Details</summary>
Motivation: To evaluate the effectiveness of publicly available open-source LLMs that can run on consumer hardware for multi-label intent classification in dialogue systems, providing accessible alternatives to proprietary models.

Method: Used MultiWOZ 2.1 dataset with few-shot setup (20 examples per prompt) on three open-source LLMs: LLama2-7B-hf, Mistral-7B-v0.1, and Yi-6B. Compared against supervised BERT baseline. Evaluated with accuracy, precision, recall, F1 scores, inference time, and VRAM requirements.

Result: Mistral-7B-v0.1 outperformed other LLMs on 11 out of 14 intent classes with weighted F1 score of 0.50, lower Humming Loss, and higher Jaccard Similarity. However, BERT supervised classifier achieved superior performance compared to the best few-shot LLM.

Conclusion: Open-source LLMs show promise for multi-intent detection in task-oriented chatbots, with Mistral-7B performing best in few-shot setting. However, supervised BERT still outperforms few-shot LLMs, suggesting continued value in supervised approaches while providing framework for accessible LLM deployment.

Abstract: In this paper, we provide an extensive analysis of multi-label intent
classification using Large Language Models (LLMs) that are open-source,
publicly available, and can be run in consumer hardware. We use the MultiWOZ
2.1 dataset, a benchmark in the dialogue system domain, to investigate the
efficacy of three popular open-source pre-trained LLMs, namely LLama2-7B-hf,
Mistral-7B-v0.1, and Yi-6B. We perform the classification task in a few-shot
setup, giving 20 examples in the prompt with some instructions. Our approach
focuses on the differences in performance of these models across several
performance metrics by methodically assessing these models on multi-label
intent classification tasks. Additionally, we compare the performance of the
instruction-based fine-tuning approach with supervised learning using the
smaller transformer model BertForSequenceClassification as a baseline. To
evaluate the performance of the models, we use evaluation metrics like
accuracy, precision, and recall as well as micro, macro, and weighted F1 score.
We also report the inference time, VRAM requirements, etc. The Mistral-7B-v0.1
outperforms two other generative models on 11 intent classes out of 14 in terms
of F-Score, with a weighted average of 0.50. It also has relatively lower
Humming Loss and higher Jaccard Similarity, making it the winning model in the
few-shot setting. We find BERT based supervised classifier having superior
performance compared to the best performing few-shot generative LLM. The study
provides a framework for small open-source LLMs in detecting complex
multi-intent dialogues, enhancing the Natural Language Understanding aspect of
task-oriented chatbots.

</details>


### [34] [Linguistic trajectories of bipolar disorder on social media](https://arxiv.org/abs/2509.10035)
*Laurin Plank,Armin Zlomuzica*

Main category: cs.CL

TL;DR: Analysis of social media language reveals significant linguistic changes in bipolar disorder patients before and after diagnosis, showing mood disturbances, psychiatric comorbidities, and seasonal patterns with 12-month periodicity.


<details>
  <summary>Details</summary>
Motivation: Clinical assessments for bipolar disorder are limited in scale, while social media language analysis offers high temporal resolution and longitudinal scope for studying mental health markers.

Method: Developed a method to determine timing of users' diagnoses and analyzed language trajectories from 3 years before to 21 years after BD diagnosis, comparing with unipolar depression patients and non-affected controls.

Result: BD diagnosis accompanied by pervasive linguistic alterations reflecting mood disturbance, psychiatric comorbidity, substance abuse, hospitalization, and unusual thought content. Recurring mood-related language changes with 12-month periodicity suggestive of seasonal episodes, with increased periodicity in female users.

Conclusion: Findings provide evidence for language alterations in both acute and chronic phases of BD, validating social media as a scalable tool for mental health monitoring.

Abstract: Language provides valuable markers of affective disorders such as bipolar
disorder (BD), yet clinical assessments remain limited in scale. In response,
analyses of social media (SM) language have gained prominence due to their high
temporal resolution and longitudinal scope. Here, we introduce a method to
determine the timing of users' diagnoses and apply it to study language
trajectories from 3 years before to 21 years after BD diagnosis - contrasted
with uses reporting unipolar depression (UD) and non-affected users (HC). We
show that BD diagnosis is accompanied by pervasive linguistic alterations
reflecting mood disturbance, psychiatric comorbidity, substance abuse,
hospitalization, medical comorbidities, unusual thought content, and
disorganized thought. We further observe recurring mood-related language
changes across two decades after the diagnosis, with a pronounced 12-month
periodicity suggestive of seasonal mood episodes. Finally, trend-level evidence
suggests an increased periodicity in users estimated to be female. In sum, our
findings provide evidence for language alterations in the acute and chronic
phase of BD. This validates and extends recent efforts leveraging SM for
scalable monitoring of mental health.

</details>


### [35] [!MSA at BAREC Shared Task 2025: Ensembling Arabic Transformers for Readability Assessment](https://arxiv.org/abs/2509.10040)
*Mohamed Basem,Mohamed Younes,Seif Ahmed,Abdelrahman Moustafa*

Main category: cs.CL

TL;DR: MSA's winning system for Arabic readability assessment used an ensemble of 4 transformer models with diverse loss functions, addressed data scarcity through synthetic data generation and relabeling, and achieved 87.5% QWK score.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of fine-grained Arabic readability assessment, particularly severe class imbalance and data scarcity in the BAREC 2025 Shared Task.

Method: Confidence-weighted ensemble of AraBERTv2, AraELECTRA, MARBERT, and CAMeLBERT models fine-tuned with distinct loss functions; applied weighted training, advanced preprocessing, SAMER corpus relabeling, synthetic data generation (10K rare samples via Gemini 2.5 Flash), and targeted post-processing.

Result: Achieved first place in all six tracks with 87.5% QWK at sentence level and 87.4% QWK at document level; post-processing delivered 6.3% QWK gain.

Conclusion: The system demonstrates the effectiveness of model/loss diversity, confidence-informed fusion, and intelligent data augmentation for robust Arabic readability prediction.

Abstract: We present MSAs winning system for the BAREC 2025 Shared Task on fine-grained
Arabic readability assessment, achieving first place in six of six tracks. Our
approach is a confidence-weighted ensemble of four complementary transformer
models (AraBERTv2, AraELECTRA, MARBERT, and CAMeLBERT) each fine-tuned with
distinct loss functions to capture diverse readability signals. To tackle
severe class imbalance and data scarcity, we applied weighted training,
advanced preprocessing, SAMER corpus relabeling with our strongest model, and
synthetic data generation via Gemini 2.5 Flash, adding about 10,000 rare-level
samples. A targeted post-processing step corrected prediction distribution
skew, delivering a 6.3 percent Quadratic Weighted Kappa (QWK) gain. Our system
reached 87.5 percent QWK at the sentence level and 87.4 percent at the document
level, demonstrating the power of model and loss diversity, confidence-informed
fusion, and intelligent augmentation for robust Arabic readability prediction.

</details>


### [36] [Established Psychometric vs. Ecologically Valid Questionnaires: Rethinking Psychological Assessments in Large Language Models](https://arxiv.org/abs/2509.10078)
*Dongmin Choi,Woojung Song,Jongwook Han,Eun-Ju Lee,Yohan Jo*

Main category: cs.CL

TL;DR: Established psychometric questionnaires (BFI, PVQ) yield different personality profiles for LLMs compared to ecologically valid questionnaires, showing they don't accurately reflect LLM behavior in real-world contexts.


<details>
  <summary>Details</summary>
Motivation: Concerns about applying human-designed psychological questionnaires to LLMs due to lack of ecological validity - whether they properly reflect real-world contexts where LLMs generate responses to user queries.

Method: Comprehensive comparative analysis between established psychometric questionnaires and ecologically valid questionnaires applied to Large Language Models.

Result: Established questionnaires: 1) Yield substantially different LLM profiles than ecological ones, 2) Have insufficient items for stable measurement, 3) Create misleading impressions of stable constructs in LLMs, 4) Produce exaggerated profiles for persona-prompted LLMs.

Conclusion: Researchers should avoid using established psychological questionnaires for LLMs due to their lack of ecological validity and misleading results.

Abstract: Researchers have applied established psychometric questionnaires (e.g., BFI,
PVQ) to measure the personality traits and values reflected in the responses of
Large Language Models (LLMs). However, concerns have been raised about applying
these human-designed questionnaires to LLMs. One such concern is their lack of
ecological validity--the extent to which survey questions adequately reflect
and resemble real-world contexts in which LLMs generate texts in response to
user queries. However, it remains unclear how established questionnaires and
ecologically valid questionnaires differ in their outcomes, and what insights
these differences may provide. In this paper, we conduct a comprehensive
comparative analysis of the two types of questionnaires. Our analysis reveals
that established questionnaires (1) yield substantially different profiles of
LLMs from ecologically valid ones, deviating from the psychological
characteristics expressed in the context of user queries, (2) suffer from
insufficient items for stable measurement, (3) create misleading impressions
that LLMs possess stable constructs, and (4) yield exaggerated profiles for
persona-prompted LLMs. Overall, our work cautions against the use of
established psychological questionnaires for LLMs. Our code will be released
upon publication.

</details>


### [37] [Querying Climate Knowledge: Semantic Retrieval for Scientific Discovery](https://arxiv.org/abs/2509.10087)
*Mustapha Adamu,Qi Zhang,Huitong Pan,Longin Jan Latecki,Eduard C. Dragut*

Main category: cs.CL

TL;DR: A climate science Knowledge Graph that enables semantic queries for precise connections between models, datasets, regions, and variables, integrated with LLMs for improved question answering.


<details>
  <summary>Details</summary>
Motivation: The complexity and volume of climate science literature make it difficult for researchers to find relevant information across different models, datasets, regions, and variables.

Method: Built a domain-specific Knowledge Graph from climate publications and scientific texts, using Cypher queries for structured semantic queries, and integrated with large language models in RAG systems.

Result: The KG supports precise connections discovery (e.g., models validated in specific regions, datasets used with certain teleconnection patterns) and improves transparency and reliability in climate-related question answering.

Conclusion: This work demonstrates real-world value for climate researchers and model developers by moving beyond KG construction to show practical applications for accessing accurate, contextual scientific information.

Abstract: The growing complexity and volume of climate science literature make it
increasingly difficult for researchers to find relevant information across
models, datasets, regions, and variables. This paper introduces a
domain-specific Knowledge Graph (KG) built from climate publications and
broader scientific texts, aimed at improving how climate knowledge is accessed
and used. Unlike keyword based search, our KG supports structured, semantic
queries that help researchers discover precise connections such as which models
have been validated in specific regions or which datasets are commonly used
with certain teleconnection patterns. We demonstrate how the KG answers such
questions using Cypher queries, and outline its integration with large language
models in RAG systems to improve transparency and reliability in
climate-related question answering. This work moves beyond KG construction to
show its real world value for climate researchers, model developers, and others
who rely on accurate, contextual scientific information.

</details>


### [38] [Arabic Large Language Models for Medical Text Generation](https://arxiv.org/abs/2509.10095)
*Abdulrahman Allam,Seif Ahmed,Ali Hamdi,Ammar Mohammed*

Main category: cs.CL

TL;DR: Fine-tuned LLMs for Arabic medical text generation to provide accurate medical advice from informal patient inputs, with Mistral-7B achieving best performance.


<details>
  <summary>Details</summary>
Motivation: Address limitations in existing hospital management systems that lack real-time medical advice capabilities for irregular inputs and underrepresented languages like Arabic.

Method: Collected real-world medical conversations from social media, preprocessed for Arabic dialects, and fine-tuned Mistral-7B, LLaMA-2-7B, and GPT-2 Medium models.

Result: Fine-tuned Mistral-7B outperformed others with average BERT scores: 68.5% precision, 69.08% recall, and 68.5% F1-score, producing coherent medical responses.

Conclusion: Generative AI offers scalable solutions for healthcare challenges in diverse linguistic environments, advancing hospital management systems.

Abstract: Efficient hospital management systems (HMS) are critical worldwide to address
challenges such as overcrowding, limited resources, and poor availability of
urgent health care. Existing methods often lack the ability to provide
accurate, real-time medical advice, particularly for irregular inputs and
underrepresented languages. To overcome these limitations, this study proposes
an approach that fine-tunes large language models (LLMs) for Arabic medical
text generation. The system is designed to assist patients by providing
accurate medical advice, diagnoses, drug recommendations, and treatment plans
based on user input. The research methodology required the collection of a
unique dataset from social media platforms, capturing real-world medical
conversations between patients and doctors. The dataset, which includes patient
complaints together with medical advice, was properly cleaned and preprocessed
to account for multiple Arabic dialects. Fine-tuning state-of-the-art
generative models, such as Mistral-7B-Instruct-v0.2, LLaMA-2-7B, and GPT-2
Medium, optimized the system's ability to generate reliable medical text.
Results from evaluations indicate that the fine-tuned Mistral-7B model
outperformed the other models, achieving average BERT (Bidirectional Encoder
Representations from Transformers) Score values in precision, recall, and
F1-scores of 68.5\%, 69.08\%, and 68.5\%, respectively. Comparative
benchmarking and qualitative assessments validate the system's ability to
produce coherent and relevant medical replies to informal input. This study
highlights the potential of generative artificial intelligence (AI) in
advancing HMS, offering a scalable and adaptable solution for global healthcare
challenges, especially in linguistically and culturally diverse environments.

</details>


### [39] [Scaling Arabic Medical Chatbots Using Synthetic Data: Enhancing Generative AI with Synthetic Patient Records](https://arxiv.org/abs/2509.10108)
*Abdulrahman Allam,Seif Ahmed,Ali Hamdi,Khaled Shaban*

Main category: cs.CL

TL;DR: Synthetic data augmentation using ChatGPT-4o and Gemini 2.5 Pro expands Arabic medical chatbot training data from 20K to 100K records, improving LLM performance with ChatGPT-4o data showing superior results.


<details>
  <summary>Details</summary>
Motivation: Address scarcity of large-scale, high-quality annotated Arabic medical datasets that constrain medical chatbot development and limit model scalability and generalization.

Method: Generated 80,000 synthetic Arabic medical Q&A pairs using ChatGPT-4o and Gemini 2.5 Pro, semantically filtered and manually validated them, then fine-tuned five LLMs including Mistral-7B and AraGPT2, with ablation study comparing synthetic data sources.

Result: ChatGPT-4o generated data consistently produced higher F1-scores and fewer hallucinations across all models compared to Gemini-generated data.

Conclusion: Synthetic augmentation is a viable practical solution for enhancing domain-specific language models in low-resource medical NLP, enabling more inclusive, scalable, and accurate Arabic healthcare chatbot systems.

Abstract: The development of medical chatbots in Arabic is significantly constrained by
the scarcity of large-scale, high-quality annotated datasets. While prior
efforts compiled a dataset of 20,000 Arabic patient-doctor interactions from
social media to fine-tune large language models (LLMs), model scalability and
generalization remained limited. In this study, we propose a scalable synthetic
data augmentation strategy to expand the training corpus to 100,000 records.
Using advanced generative AI systems ChatGPT-4o and Gemini 2.5 Pro we generated
80,000 contextually relevant and medically coherent synthetic question-answer
pairs grounded in the structure of the original dataset. These synthetic
samples were semantically filtered, manually validated, and integrated into the
training pipeline. We fine-tuned five LLMs, including Mistral-7B and AraGPT2,
and evaluated their performance using BERTScore metrics and expert-driven
qualitative assessments. To further analyze the effectiveness of synthetic
sources, we conducted an ablation study comparing ChatGPT-4o and
Gemini-generated data independently. The results showed that ChatGPT-4o data
consistently led to higher F1-scores and fewer hallucinations across all
models. Overall, our findings demonstrate the viability of synthetic
augmentation as a practical solution for enhancing domain-specific language
models in-low resource medical NLP, paving the way for more inclusive,
scalable, and accurate Arabic healthcare chatbot systems.

</details>


### [40] [Prominence-aware automatic speech recognition for conversational speech](https://arxiv.org/abs/2509.10116)
*Julian Linke,Barbara Schuppler*

Main category: cs.CL

TL;DR: Combining prominence detection with ASR for Austrian German using wav2vec2 models, achieving 85.53% prominence accuracy when words are correctly recognized, without degrading ASR performance.


<details>
  <summary>Details</summary>
Motivation: To develop prominence-aware automatic speech recognition systems that can simultaneously transcribe words and detect prosodic prominence levels, which has applications in linguistic research and prosody-informed dialogue systems.

Method: Fine-tuned wav2vec2 models for word-level prominence detection, used the detector to automatically annotate a large corpus, then trained novel prominence-aware ASR systems that transcribe both words and prominence levels simultaneously.

Result: The integration of prominence information did not change ASR performance compared to baseline, but achieved 85.53% prominence detection accuracy for utterances where the recognized word sequence was correct.

Conclusion: Transformer-based models can effectively encode prosodic information, representing a novel contribution to prosody-enhanced ASR with potential applications in linguistics and dialogue systems.

Abstract: This paper investigates prominence-aware automatic speech recognition (ASR)
by combining prominence detection and speech recognition for conversational
Austrian German. First, prominence detectors were developed by fine-tuning
wav2vec2 models to classify word-level prominence. The detector was then used
to automatically annotate prosodic prominence in a large corpus. Based on those
annotations, we trained novel prominence-aware ASR systems that simultaneously
transcribe words and their prominence levels. The integration of prominence
information did not change performance compared to our baseline ASR system,
while reaching a prominence detection accuracy of 85.53% for utterances where
the recognized word sequence was correct. This paper shows that
transformer-based models can effectively encode prosodic information and
represents a novel contribution to prosody-enhanced ASR, with potential
applications for linguistic research and prosody-informed dialogue systems.

</details>


### [41] [Population-Aligned Persona Generation for LLM-based Social Simulation](https://arxiv.org/abs/2509.10127)
*Zhengyu Hu,Zheyuan Xiao,Max Xiong,Yuxuan Lei,Tianfu Wang,Jianxun Lian,Kaize Ding,Ziang Xiao,Nicholas Jing Yuan,Xing Xie*

Main category: cs.CL

TL;DR: A systematic framework for generating high-quality, population-aligned persona sets for LLM-based social simulations that reduces bias and improves authenticity.


<details>
  <summary>Details</summary>
Motivation: Existing LLM social simulations often overlook persona generation complexities and introduce biases through unrepresentative persona sets, limiting their usefulness for computational social science.

Method: Leverages LLMs to generate narrative personas from social media data, applies quality assessment filtering, uses importance sampling for global alignment with psychometric distributions (e.g., Big Five), and includes task-specific adaptation for targeted subpopulations.

Result: Extensive experiments show the method significantly reduces population-level bias and enables accurate, flexible social simulation for various research and policy applications.

Conclusion: The proposed framework provides a systematic approach to creating authentic, representative persona sets that address key limitations in current LLM-based social simulation methodologies.

Abstract: Recent advances in large language models (LLMs) have enabled human-like
social simulations at unprecedented scale and fidelity, offering new
opportunities for computational social science. A key challenge, however, is
the construction of persona sets that authentically represent the diversity and
distribution of real-world populations. Most existing LLM-based social
simulation studies focus primarily on designing agentic frameworks and
simulation environments, often overlooking the complexities of persona
generation and the potential biases introduced by unrepresentative persona
sets. In this paper, we propose a systematic framework for synthesizing
high-quality, population-aligned persona sets for LLM-driven social simulation.
Our approach begins by leveraging LLMs to generate narrative personas from
long-term social media data, followed by rigorous quality assessment to filter
out low-fidelity profiles. We then apply importance sampling to achieve global
alignment with reference psychometric distributions, such as the Big Five
personality traits. To address the needs of specific simulation contexts, we
further introduce a task-specific module that adapts the globally aligned
persona set to targeted subpopulations. Extensive experiments demonstrate that
our method significantly reduces population-level bias and enables accurate,
flexible social simulation for a wide range of research and policy
applications.

</details>


### [42] [Towards Reliable and Interpretable Document Question Answering via VLMs](https://arxiv.org/abs/2509.10129)
*Alessio Chen,Simone Giovannini,Andrea Gemelli,Fabio Coppini,Simone Marinai*

Main category: cs.CL

TL;DR: DocExplainerV0 is a plug-and-play bounding-box module that decouples answer generation from spatial localization to improve document answer localization in VLMs.


<details>
  <summary>Details</summary>
Motivation: Accurate answer localization within documents remains a major challenge for VLMs, limiting interpretability and real-world applicability despite strong text extraction capabilities.

Method: Introduces DocExplainerV0, a bounding-box prediction module that works with existing VLMs (including proprietary systems) without requiring fine-tuning, decoupling answer generation from spatial localization.

Result: Systematic evaluation reveals a significant gap between textual accuracy and spatial grounding - correct answers often lack reliable localization. The framework provides quantitative insights into these shortcomings.

Conclusion: The standardized framework establishes a benchmark for future research toward more interpretable and robust document information extraction in VLMs.

Abstract: Vision-Language Models (VLMs) have shown strong capabilities in document
understanding, particularly in identifying and extracting textual information
from complex documents. Despite this, accurately localizing answers within
documents remains a major challenge, limiting both interpretability and
real-world applicability. To address this, we introduce
\textit{DocExplainerV0}, a plug-and-play bounding-box prediction module that
decouples answer generation from spatial localization. This design makes it
applicable to existing VLMs, including proprietary systems where fine-tuning is
not feasible. Through systematic evaluation, we provide quantitative insights
into the gap between textual accuracy and spatial grounding, showing that
correct answers often lack reliable localization. Our standardized framework
highlights these shortcomings and establishes a benchmark for future research
toward more interpretable and robust document information extraction VLMs.

</details>


### [43] [Benchmark of stylistic variation in LLM-generated texts](https://arxiv.org/abs/2509.10179)
*Jiří Milička,Anna Marklová,Václav Cvrček*

Main category: cs.CL

TL;DR: Analysis of register variation between human-written and LLM-generated texts using Biber's multidimensional analysis across English and Czech corpora, examining 16 frontier models to create an interpretable benchmark.


<details>
  <summary>Details</summary>
Motivation: To systematically identify and quantify how large language models differ from human writing in register variation across different languages, particularly focusing on underrepresented languages like Czech.

Method: Applied Biber's multidimensional analysis to compare human-written texts (BE-21 corpus) with AI-generated counterparts (AI-Brown corpus). Replicated analysis on Czech using AI-Koditex corpus. Examined 16 frontier LLMs in various settings, comparing base models vs instruction-tuned models.

Result: Identified specific dimensions of variation where LLMs differ most significantly from human writing. Created a benchmark for comparing and ranking models across interpretable linguistic dimensions.

Conclusion: The study provides a systematic framework for evaluating LLM text generation quality through register variation analysis, revealing systematic differences between AI and human writing patterns across multiple languages.

Abstract: This study investigates the register variation in texts written by humans and
comparable texts produced by large language models (LLMs). Biber's
multidimensional analysis (MDA) is applied to a sample of human-written texts
and AI-created texts generated to be their counterparts to find the dimensions
of variation in which LLMs differ most significantly and most systematically
from humans. As textual material, a new LLM-generated corpus AI-Brown is used,
which is comparable to BE-21 (a Brown family corpus representing contemporary
British English). Since all languages except English are underrepresented in
the training data of frontier LLMs, similar analysis is replicated on Czech
using AI-Koditex corpus and Czech multidimensional model. Examined were 16
frontier models in various settings and prompts, with emphasis placed on the
difference between base models and instruction-tuned models. Based on this, a
benchmark is created through which models can be compared with each other and
ranked in interpretable dimensions.

</details>


### [44] [Incongruent Positivity: When Miscalibrated Positivity Undermines Online Supportive Conversations](https://arxiv.org/abs/2509.10184)
*Leen Almajed,Abeer ALdayel*

Main category: cs.CL

TL;DR: LLMs tend to generate unrealistic positive responses that feel dismissive, especially in high-stakes emotional conversations like grief and anxiety, compared to mild contexts like relationship advice.


<details>
  <summary>Details</summary>
Motivation: To examine how well-intended positivity can misfire in emotionally supportive conversations, becoming dismissive or minimizing, and to compare this phenomenon in both human and LLM responses across different emotional intensity levels.

Method: Collected real user-assistant dialogues from Reddit across emotional intensities, generated additional LLM responses, categorized conversations into Mild (relationship tension) and Severe (grief/anxiety), finetuned LLMs on emotional datasets, and developed a weakly supervised multilabel classifier ensemble using DeBERTa and MentalBERT.

Result: LLMs are more prone to unrealistic positivity through dismissive and minimizing tones, particularly in high-stakes contexts. The classifier ensemble showed improved detection of incongruent positivity types across different concern levels.

Conclusion: There's a need to move beyond generic positive responses and develop congruent support measures that balance positive affect with emotional acknowledgment, paving the way for context-aware and trust-preserving conversation systems.

Abstract: In emotionally supportive conversations, well-intended positivity can
sometimes misfire, leading to responses that feel dismissive, minimizing, or
unrealistically optimistic. We examine this phenomenon of incongruent
positivity as miscalibrated expressions of positive support in both human and
LLM generated responses. To this end, we collected real user-assistant
dialogues from Reddit across a range of emotional intensities and generated
additional responses using large language models for the same context. We
categorize these conversations by intensity into two levels: Mild, which covers
relationship tension and general advice, and Severe, which covers grief and
anxiety conversations. This level of categorization enables a comparative
analysis of how supportive responses vary across lower and higher stakes
contexts. Our analysis reveals that LLMs are more prone to unrealistic
positivity through dismissive and minimizing tone, particularly in high-stakes
contexts. To further study the underlying dimensions of this phenomenon, we
finetune LLMs on datasets with strong and weak emotional reactions. Moreover,
we developed a weakly supervised multilabel classifier ensemble (DeBERTa and
MentalBERT) that shows improved detection of incongruent positivity types
across two sorts of concerns (Mild and Severe). Our findings shed light on the
need to move beyond merely generating generic positive responses and instead
study the congruent support measures to balance positive affect with emotional
acknowledgment. This approach offers insights into aligning large language
models with affective expectations in the online supportive dialogue, paving
the way toward context-aware and trust preserving online conversation systems.

</details>


### [45] [Beyond Token Limits: Assessing Language Model Performance on Long Text Classification](https://arxiv.org/abs/2509.10199)
*Miklós Sebők,Viktor Kovács,Martin Bánóczy,Daniel Møller Eriksen,Nathalie Neptune,Philippe Roussille*

Main category: cs.CL

TL;DR: Large language models like BERT have input length limitations that hinder processing of long documents like laws. Experiments with XLM-RoBERTa, Longformer, GPT-3.5, and GPT-4 on 21-category policy classification across 5 languages showed Longformer didn't outperform others, and open models beat GPT variants.


<details>
  <summary>Details</summary>
Motivation: Address the limitation of input text length in popular LLMs (like BERT) for processing long documents such as laws and bills, which can be hundreds of pages long and exceed typical token limits.

Method: Conducted experiments with XLM-RoBERTa, Longformer, GPT-3.5, and GPT-4 models across 5 languages for multiclass classification using the Comparative Agendas Project codebook with 21 policy topic labels.

Result: No particular advantage for Longformer (specifically designed for long inputs). Open models performed better than GPT variants. Class-level analysis revealed performance depends on support and substance overlaps between specific categories.

Conclusion: Specialized long-input models like Longformer don't necessarily outperform other approaches for long document classification, and open models can achieve better results than proprietary GPT models for this task.

Abstract: The most widely used large language models in the social sciences (such as
BERT, and its derivatives, e.g. RoBERTa) have a limitation on the input text
length that they can process to produce predictions. This is a particularly
pressing issue for some classification tasks, where the aim is to handle long
input texts. One such area deals with laws and draft laws (bills), which can
have a length of multiple hundred pages and, therefore, are not particularly
amenable for processing with models that can only handle e.g. 512 tokens. In
this paper, we show results from experiments covering 5 languages with
XLM-RoBERTa, Longformer, GPT-3.5, GPT-4 models for the multiclass
classification task of the Comparative Agendas Project, which has a codebook of
21 policy topic labels from education to health care. Results show no
particular advantage for the Longformer model, pre-trained specifically for the
purposes of handling long inputs. The comparison between the GPT variants and
the best-performing open model yielded an edge for the latter. An analysis of
class-level factors points to the importance of support and substance overlaps
between specific categories when it comes to performance on long text inputs.

</details>


### [46] [SI-FACT: Mitigating Knowledge Conflict via Self-Improving Faithfulness-Aware Contrastive Tuning](https://arxiv.org/abs/2509.10208)
*Shengqiang Fu*

Main category: cs.CL

TL;DR: SI FACT is a self-improving framework that uses contrastive learning to enhance LLM faithfulness by automatically generating training data and reducing reliance on parametric knowledge.


<details>
  <summary>Details</summary>
Motivation: Large Language Models often generate unfaithful responses in knowledge-intensive tasks due to preferring internal parametric knowledge over provided context, creating knowledge conflicts.

Method: Self-instruct mechanism to automatically generate structured contrastive learning data (anchor, positive, and negative samples), followed by contrastive learning to separate faithful and unfaithful responses in representation space.

Result: SI FACT based on Llama3-8B improves Contextual Recall Rate by 6.2% over best baseline, reduces dependence on internal memory, and shows strong effectiveness with high data efficiency.

Conclusion: The framework provides a practical pathway for building more proactive and trustworthy language models by enhancing contextual faithfulness through self-improving contrastive tuning.

Abstract: Large Language Models often generate unfaithful responses in knowledge
intensive tasks due to knowledge conflict,that is,a preference for relying on
internal parametric knowledge rather than the provided context.To address this
issue,we propose a novel self improving framework,Self Improving Faithfulness
Aware Contrastive Tuning.The framework uses a self instruct mechanism that
allows the base LLM to automatically generate high quality,structured
contrastive learning data,including anchor samples,semantically equivalent
positive samples,and negative samples simulating unfaithful scenarios.This
approach significantly reduces the cost of manual
annotation.Subsequently,contrastive learning is applied to train the
model,enabling it to pull faithful responses closer and push unfaithful
responses farther apart in the representation space.Experiments on knowledge
conflict evaluation benchmarks ECARE KRE and COSE KRE show that the SI FACT
model based on Llama3 8B Instruct improves the Contextual Recall Rate by 6.2%
over the best baseline method,while significantly reducing dependence on
internal memory.The results indicate that SI FACT provides strong effectiveness
and high data efficiency in enhancing the contextual faithfulness of
LLMs,offering a practical pathway toward building more proactive and
trustworthy language models.

</details>


### [47] [Dropping Experts, Recombining Neurons: Retraining-Free Pruning for Sparse Mixture-of-Experts LLMs](https://arxiv.org/abs/2509.10377)
*Yixiao Zhou,Ziyu Zhao,Dongzhou Cheng,zhiliang wu,Jie Gui,Yi Yang,Fei Wu,Yu Cheng,Hehe Fan*

Main category: cs.CL

TL;DR: DERN is a retraining-free framework that prunes redundant experts and recombines neurons at the neuron level to reduce memory usage in SMoE models while improving performance.


<details>
  <summary>Details</summary>
Motivation: SMoE architectures require loading all expert parameters despite only activating a few, leading to high memory usage and deployment challenges. Previous methods focused on expert-level operations, leaving neuron-level structure underexplored.

Method: DERN works in three steps: 1) prunes redundant experts using router statistics, 2) decomposes experts into neuron-level segments and assigns them to compatible retained experts, 3) merges segments within each retained expert to build compact representations.

Result: Experiments on Mixtral, Qwen, and DeepSeek SMoE models show DERN improves performance by >5% on commonsense reasoning and MMLU benchmarks under 50% expert sparsity, without extra training.

Conclusion: DERN effectively reduces the number of experts and memory usage while improving performance, making SMoE LLMs more practical to deploy.

Abstract: Sparse Mixture-of-Experts (SMoE) architectures are widely used in large
language models (LLMs) due to their computational efficiency. However, though
only a few experts are activated for each token, SMoE still requires loading
all expert parameters, leading to high memory usage and challenges in
deployment. Previous work has tried to reduce the overhead by pruning and
merging experts, but primarily focused on expert-level operations, leaving
neuron-level structure underexplored. We propose DERN (Dropping Experts,
Recombining Neurons), a task-agnostic and retraining-free framework for expert
pruning and reconstruction. We observe that experts are often misaligned and
contain semantic conflicts at the neuron level, which poses challenges for
direct merging. To solve this, DERN works in three steps: it first prunes
redundant experts using router statistics; then it decomposes them into
neuron-level expert segments, assigning each segment to its most compatible
retained expert; and finally, it merges segments within each retained expert to
build a compact representation. Experiments on Mixtral, Qwen, and DeepSeek SMoE
models show that DERN improves performance by more than 5% on commonsense
reasoning and MMLU benchmarks under 50% expert sparsity, without extra
training. It also greatly reduces the number of experts and memory usage,
making SMoE LLMs easier to deploy in practice.

</details>


### [48] [Is In-Context Learning Learning?](https://arxiv.org/abs/2509.10414)
*Adrian de Wynter*

Main category: cs.CL

TL;DR: ICL enables autoregressive models to solve tasks through next-token prediction without training, but analysis shows it has limited learning and generalization capabilities despite constituting mathematical learning.


<details>
  <summary>Details</summary>
Motivation: To investigate whether in-context learning (ICL) truly constitutes learning or is merely deduction, and to characterize its capabilities and limitations through empirical analysis.

Method: Large-scale analysis of ICL by ablating and accounting for memorization, pretraining, distributional shifts, and prompting style/phrasing across various tasks.

Result: ICL is an effective learning paradigm but limited in learning and generalizing to unseen tasks. Accuracy becomes insensitive to exemplar distribution, model, prompt style, and linguistic features when exemplars are numerous, but shows distributional sensitivity in certain prompting styles like chain-of-thought.

Conclusion: Autoregression's ad-hoc encoding is not a robust mechanism, suggesting limited all-purpose generalizability, as evidenced by varied accuracies on formally similar tasks.

Abstract: In-context learning (ICL) allows some autoregressive models to solve tasks
via next-token prediction and without needing further training. This has led to
claims about these model's ability to solve (learn) unseen tasks with only a
few shots (exemplars) in the prompt. However, deduction does not always imply
learning, as ICL does not explicitly encode a given observation. Instead, the
models rely on their prior knowledge and the exemplars given, if any. We argue
that, mathematically, ICL does constitute learning, but its full
characterisation requires empirical work. We then carry out a large-scale
analysis of ICL ablating out or accounting for memorisation, pretraining,
distributional shifts, and prompting style and phrasing. We find that ICL is an
effective learning paradigm, but limited in its ability to learn and generalise
to unseen tasks. We note that, in the limit where exemplars become more
numerous, accuracy is insensitive to exemplar distribution, model, prompt
style, and the input's linguistic features. Instead, it deduces patterns from
regularities in the prompt, which leads to distributional sensitivity,
especially in prompting styles such as chain-of-thought. Given the varied
accuracies on formally similar tasks, we conclude that autoregression's ad-hoc
encoding is not a robust mechanism, and suggests limited all-purpose
generalisability.

</details>


### [49] [Long Context Automated Essay Scoring with Language Models](https://arxiv.org/abs/2509.10417)
*Christopher Ormerod,Gitit Kehat*

Main category: cs.CL

TL;DR: This paper evaluates transformer models with architectural modifications to handle long essays for automated essay scoring, addressing the limitation of fixed maximum length in standard transformers.


<details>
  <summary>Details</summary>
Motivation: Standard transformer models have fixed maximum text length constraints, forcing truncation of longer essays which undermines the ability to properly evaluate organizational elements that require long context assessment in automated essay scoring.

Method: The study evaluates several modified transformer architectures including XLNet, Longformer, ModernBERT, Mamba, and Llama models fine-tuned on the Kaggle ASAP 2.0 dataset to overcome length limitations.

Result: Not specified in the abstract - the paper appears to present comparative evaluation results of these long-context models for essay scoring.

Conclusion: Not specified in the abstract - the paper likely concludes about the effectiveness of various long-context transformer architectures for automated essay scoring applications.

Abstract: Transformer-based language models are architecturally constrained to process
text of a fixed maximum length. Essays written by higher-grade students
frequently exceed the maximum allowed length for many popular open-source
models. A common approach to addressing this issue when using these models for
Automated Essay Scoring is to truncate the input text. This raises serious
validity concerns as it undermines the model's ability to fully capture and
evaluate organizational elements of the scoring rubric, which requires long
contexts to assess. In this study, we evaluate several models that incorporate
architectural modifications of the standard transformer architecture to
overcome these length limitations using the Kaggle ASAP 2.0 dataset. The models
considered in this study include fine-tuned versions of XLNet, Longformer,
ModernBERT, Mamba, and Llama models.

</details>


### [50] [RefactorCoderQA: Benchmarking LLMs for Multi-Domain Coding Question Solutions in Cloud and Edge Deployment](https://arxiv.org/abs/2509.10436)
*Shadikur Rahman,Aroosa Hameed,Gautam Srivastava,Syed Muhammad Danish*

Main category: cs.CL

TL;DR: A cloud-edge collaborative architecture with three specialized LLMs (GuideLLM, SolverLLM, JudgeLLM) achieves state-of-the-art performance (76.84% accuracy) on multi-domain coding tasks using the new RefactorCoderQA benchmark.


<details>
  <summary>Details</summary>
Motivation: To overcome limitations of existing benchmarks and optimize reasoning/problem-solving capabilities of LLMs through a structured multi-agent framework that leverages both edge and cloud computing resources.

Method: Proposed a three-component architecture: GuideLLM (edge-based methodological guidance), SolverLLM (cloud-based code generation), and JudgeLLM (automated evaluation). Created RefactorCoderQA benchmark with authentic Stack Overflow challenges across multiple technical domains. Fine-tuned RefactorCoder-MoE model.

Result: Achieved 76.84% overall accuracy, significantly outperforming leading open-source and commercial baselines. Human evaluations confirmed interpretability, accuracy, and practical relevance. System metrics (throughput, latency) provided performance insights.

Conclusion: The cloud-edge collaborative architecture with specialized multi-agent components effectively enhances LLM performance on complex coding tasks, demonstrating both technical superiority and practical applicability across diverse domains.

Abstract: To optimize the reasoning and problem-solving capabilities of Large Language
Models (LLMs), we propose a novel cloud-edge collaborative architecture that
enables a structured, multi-agent prompting framework. This framework comprises
three specialized components: GuideLLM, a lightweight model deployed at the
edge to provide methodological guidance; SolverLLM, a more powerful model
hosted in the cloud responsible for generating code solutions; and JudgeLLM, an
automated evaluator for assessing solution correctness and quality. To evaluate
and demonstrate the effectiveness of this architecture in realistic settings,
we introduce RefactorCoderQA, a comprehensive benchmark designed to evaluate
and enhance the performance of Large Language Models (LLMs) across multi-domain
coding tasks. Motivated by the limitations of existing benchmarks,
RefactorCoderQA systematically covers various technical domains, including
Software Engineering, Data Science, Machine Learning, and Natural Language
Processing, using authentic coding challenges from Stack Overflow. Extensive
experiments reveal that our fine-tuned model, RefactorCoder-MoE, achieves
state-of-the-art performance, significantly outperforming leading open-source
and commercial baselines with an overall accuracy of 76.84%. Human evaluations
further validate the interpretability, accuracy, and practical relevance of the
generated solutions. In addition, we evaluate system-level metrics, such as
throughput and latency, to gain deeper insights into the performance
characteristics and trade-offs of the proposed architecture.

</details>


### [51] [DeepDive: Advancing Deep Search Agents with Knowledge Graphs and Multi-Turn RL](https://arxiv.org/abs/2509.10446)
*Rui Lu,Zhenyu Hou,Zihan Wang,Hanchen Zhang,Xiao Liu,Yujiang Li,Shi Feng,Jie Tang,Yuxiao Dong*

Main category: cs.CL

TL;DR: DeepDive is a system that enhances LLMs as deep search agents through automated question synthesis from knowledge graphs and multi-turn reinforcement learning, achieving state-of-the-art performance on browsing benchmarks.


<details>
  <summary>Details</summary>
Motivation: Open LLMs perform poorly as deep search agents due to limited long-horizon reasoning with browsing tools and lack of sufficiently difficult supervised training data.

Method: Automatically synthesizes complex questions from open knowledge graphs and applies end-to-end multi-turn reinforcement learning to enhance LLMs' long-horizon reasoning capabilities for deep search.

Result: DeepDive-32B achieves competitive results on BrowseComp, outperforming WebSailor, DeepSeek-R1-Browse, and Search-o1. Multi-turn RL training improves deep search ability and enables test-time scaling of tool calls and parallel sampling.

Conclusion: DeepDive successfully addresses the challenges of limited reasoning capacity and data scarcity for LLM-based search agents, demonstrating significant performance improvements through automated data synthesis and multi-turn RL training.

Abstract: Augmenting large language models (LLMs) with browsing tools substantially
improves their potential as deep search agents to solve complex, real-world
tasks. Yet, open LLMs still perform poorly in such settings due to limited
long-horizon reasoning capacity with browsing tools and the lack of
sufficiently difficult supervised data. To address these challenges, we present
DeepDive to advance deep search agents. First, we propose a strategy to
automatically synthesize complex, difficult, and hard-to-find questions from
open knowledge graphs. Second, we apply end-to-end multi-turn reinforcement
learning (RL) to enhance LLMs' long-horizon reasoning with deep search.
Experiments show that DeepDive-32B achieves a new open-source competitive
result on BrowseComp, outperforming WebSailor, DeepSeek-R1-Browse, and
Search-o1. We demonstrate that multi-turn RL training improves deep search
ability and significantly contributes to the performance improvements across
multiple benchmarks. We observe that DeepDive enables test-time scaling of tool
calls and parallel sampling. All datasets, models, and code are publicly
available at https://github.com/THUDM/DeepDive.

</details>


### [52] [WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained Speech Recognition Transformers](https://arxiv.org/abs/2509.10452)
*Akshat Pandey,Karun Kumar,Raphael Tang*

Main category: cs.CL

TL;DR: WhisTLE is a text-only adaptation method for pretrained ASR models that uses a VAE to model encoder outputs from text and fine-tunes the decoder, achieving significant WER reduction without extra runtime cost.


<details>
  <summary>Details</summary>
Motivation: Pretrained ASR models like Whisper need domain adaptation for unseen vocabulary and parlance, but collecting speech data is often impractical, necessitating text-only adaptation methods.

Method: Trains a variational autoencoder (VAE) to model encoder outputs from text, fine-tunes the decoder using the learned text-to-latent encoder, optionally combined with TTS adaptation. Original encoder is restored at inference.

Result: Reduces word error rate by 12.3% relative to TTS-only adaptation, outperforms all non-WhisTLE baselines in 27 of 32 scenarios across four out-of-domain datasets and four ASR models.

Conclusion: WhisTLE provides an effective text-only adaptation approach for pretrained ASR models that maintains performance without additional runtime costs during inference.

Abstract: Pretrained automatic speech recognition (ASR) models such as Whisper perform
well but still need domain adaptation to handle unseen vocabulary and parlance.
In many real-world settings, collecting speech data is impractical,
necessitating text-only adaptation. We propose WhisTLE, a deeply supervised,
text-only adaptation method for pretrained encoder-decoder ASR models. WhisTLE
trains a variational autoencoder (VAE) to model encoder outputs from text and
fine-tunes the decoder using the learned text-to-latent encoder, optionally
combined with text-to-speech (TTS) adaptation. At inference, the original
encoder is restored, incurring no extra runtime cost. Across four out-of-domain
datasets and four ASR models, WhisTLE with TTS reduces word error rate (WER) by
12.3% relative to TTS-only adaptation and outperforms all non-WhisTLE baselines
in 27 of 32 scenarios.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [53] [Australian Supermarket Object Set (ASOS): A Benchmark Dataset of Physical Objects and 3D Models for Robotics and Computer Vision](https://arxiv.org/abs/2509.09720)
*Akansel Cosgun,Lachlan Chumbley,Benjamin J. Meyer*

Main category: cs.CV

TL;DR: ASOS is a new 3D dataset of 50 common Australian supermarket items with high-quality textured meshes for robotics and computer vision benchmarking.


<details>
  <summary>Details</summary>
Motivation: Existing datasets use synthetic models or specialized objects with limited accessibility, so ASOS provides cost-effective, readily available real-world objects.

Method: 3D meshes are created using structure-from-motion techniques with high-resolution imaging to generate watertight meshes from 50 supermarket items across 10 categories.

Result: The dataset provides high-quality 3D textured meshes of common household items that can be easily sourced, with diverse shapes, sizes, and weights.

Conclusion: ASOS's emphasis on accessibility and real-world applicability makes it valuable for benchmarking object detection, pose estimation, and robotics applications.

Abstract: This paper introduces the Australian Supermarket Object Set (ASOS), a
comprehensive dataset comprising 50 readily available supermarket items with
high-quality 3D textured meshes designed for benchmarking in robotics and
computer vision applications. Unlike existing datasets that rely on synthetic
models or specialized objects with limited accessibility, ASOS provides a
cost-effective collection of common household items that can be sourced from a
major Australian supermarket chain. The dataset spans 10 distinct categories
with diverse shapes, sizes, and weights. 3D meshes are acquired by a
structure-from-motion techniques with high-resolution imaging to generate
watertight meshes. The dataset's emphasis on accessibility and real-world
applicability makes it valuable for benchmarking object detection, pose
estimation, and robotics applications.

</details>


### [54] [A Multimodal RAG Framework for Housing Damage Assessment: Collaborative Optimization of Image Encoding and Policy Vector Retrieval](https://arxiv.org/abs/2509.09721)
*Jiayi Miao,Dingxin Lu,Zhuqi Wang*

Main category: cs.CV

TL;DR: A multimodal RAG framework for post-disaster housing damage assessment that combines visual building damage analysis with text retrieval from insurance policies, achieving 9.6% improvement in retrieval accuracy.


<details>
  <summary>Details</summary>
Motivation: Accurate housing damage evaluation after natural disasters is crucial for insurance claims processing and resource planning, requiring effective integration of visual damage assessment with policy information retrieval.

Method: Two-branch multimodal encoder with ResNet+Transformer for image analysis and BERT for text retrieval, cross-modal interaction via multi-head attention, modal attention gating for generation control, and end-to-end training with multi-task optimization.

Result: Superior performance in retrieval accuracy and damage severity classification, with Top-1 retrieval accuracy improved by 9.6%.

Conclusion: The MM-RAG framework effectively bridges visual damage assessment and policy information retrieval, providing a comprehensive solution for post-disaster housing evaluation and insurance response.

Abstract: After natural disasters, accurate evaluations of damage to housing are
important for insurance claims response and planning of resources. In this
work, we introduce a novel multimodal retrieval-augmented generation (MM-RAG)
framework. On top of classical RAG architecture, we further the framework to
devise a two-branch multimodal encoder structure that the image branch employs
a visual encoder composed of ResNet and Transformer to extract the
characteristic of building damage after disaster, and the text branch harnesses
a BERT retriever for the text vectorization of posts as well as insurance
policies and for the construction of a retrievable restoration index. To impose
cross-modal semantic alignment, the model integrates a cross-modal interaction
module to bridge the semantic representation between image and text via
multi-head attention. Meanwhile, in the generation module, the introduced modal
attention gating mechanism dynamically controls the role of visual evidence and
text prior information during generation. The entire framework takes end-to-end
training, and combines the comparison loss, the retrieval loss and the
generation loss to form multi-task optimization objectives, and achieves image
understanding and policy matching in collaborative learning. The results
demonstrate superior performance in retrieval accuracy and classification index
on damage severity, where the Top-1 retrieval accuracy has been improved by
9.6%.

</details>


### [55] [Improving MLLM Historical Record Extraction with Test-Time Image](https://arxiv.org/abs/2509.09722)
*Taylor Archibald,Tony Martinez*

Main category: cs.CV

TL;DR: Novel ensemble framework using Gemini 2.0 Flash and custom alignment to improve LLM-based text extraction from noisy historical documents by 4 percentage points.


<details>
  <summary>Details</summary>
Motivation: To stabilize and improve text extraction accuracy from noisy historical documents where single-shot LLM transcription may be unreliable.

Method: Transcribe multiple augmented variants of each document image using Gemini 2.0 Flash, then fuse outputs with a custom Needleman-Wunsch style aligner to produce consensus transcription and confidence scores.

Result: 4 percentage point accuracy improvement over single-shot baseline on new dataset of 622 Pennsylvania death records; padding and blurring most effective for accuracy, grid warp best for confidence separation.

Conclusion: The approach is simple, scalable, and immediately deployable to other document collections and transcription models for improved historical document processing.

Abstract: We present a novel ensemble framework that stabilizes LLM based text
extraction from noisy historical documents. We transcribe multiple augmented
variants of each image with Gemini 2.0 Flash and fuse these outputs with a
custom Needleman Wunsch style aligner that yields both a consensus
transcription and a confidence score. We present a new dataset of 622
Pennsylvania death records, and demonstrate our method improves transcription
accuracy by 4 percentage points relative to a single shot baseline. We find
that padding and blurring are the most useful for improving accuracy, while
grid warp perturbations are best for separating high and low confidence cases.
The approach is simple, scalable, and immediately deployable to other document
collections and transcription models.

</details>


### [56] [MITS: A Large-Scale Multimodal Benchmark Dataset for Intelligent Traffic Surveillance](https://arxiv.org/abs/2509.09730)
*Kaikai Zhao,Zhaoxiang Liu,Peng Wang,Xin Wang,Zhicheng Ma,Yajun Xu,Wenjing Zhang,Yibing Nan,Kai Wang,Shiguo Lian*

Main category: cs.CV

TL;DR: MITS is the first large-scale multimodal benchmark dataset for Intelligent Traffic Surveillance, containing 170,400 real-world traffic images with comprehensive annotations and 5M QA pairs, which significantly improves LMM performance in ITS tasks.


<details>
  <summary>Details</summary>
Motivation: General-domain large multimodal models perform poorly in traffic surveillance due to lack of dedicated multimodal datasets, creating a need for ITS-specific training data.

Method: Created MITS dataset with 170,400 real traffic images annotated with 8 main categories and 24 subcategories, plus generated high-quality captions and 5M instruction-following QA pairs covering five critical ITS tasks.

Result: Fine-tuning on MITS dramatically improved LMM performance: LLaVA-1.5 increased from 0.494 to 0.905 (+83.2%), LLaVA-1.6 from 0.678 to 0.921 (+35.8%), Qwen2-VL from 0.584 to 0.926 (+58.6%), and Qwen2.5-VL from 0.732 to 0.930 (+27.0%).

Conclusion: MITS effectively bridges the gap in ITS multimodal data, significantly enhancing LMM performance for traffic surveillance applications, and provides valuable open-source resources for future research.

Abstract: General-domain large multimodal models (LMMs) have achieved significant
advances in various image-text tasks. However, their performance in the
Intelligent Traffic Surveillance (ITS) domain remains limited due to the
absence of dedicated multimodal datasets. To address this gap, we introduce
MITS (Multimodal Intelligent Traffic Surveillance), the first large-scale
multimodal benchmark dataset specifically designed for ITS. MITS includes
170,400 independently collected real-world ITS images sourced from traffic
surveillance cameras, annotated with eight main categories and 24 subcategories
of ITS-specific objects and events under diverse environmental conditions.
Additionally, through a systematic data generation pipeline, we generate
high-quality image captions and 5 million instruction-following visual
question-answer pairs, addressing five critical ITS tasks: object and event
recognition, object counting, object localization, background analysis, and
event reasoning. To demonstrate MITS's effectiveness, we fine-tune mainstream
LMMs on this dataset, enabling the development of ITS-specific applications.
Experimental results show that MITS significantly improves LMM performance in
ITS applications, increasing LLaVA-1.5's performance from 0.494 to 0.905
(+83.2%), LLaVA-1.6's from 0.678 to 0.921 (+35.8%), Qwen2-VL's from 0.584 to
0.926 (+58.6%), and Qwen2.5-VL's from 0.732 to 0.930 (+27.0%). We release the
dataset, code, and models as open-source, providing high-value resources to
advance both ITS and LMM research.

</details>


### [57] [Decomposing Visual Classification: Assessing Tree-Based Reasoning in VLMs](https://arxiv.org/abs/2509.09732)
*Sary Elmansoury,Islam Mesabah,Gerrit Großmann,Peter Neigel,Raj Bhalwankar,Daniel Kondermann,Sebastian J. Vollmer*

Main category: cs.CV

TL;DR: Tree-based reasoning framework for VLMs underperforms standard zero-shot prompting despite 98.2% accuracy in tree knowledge understanding, though image descriptions improve both methods.


<details>
  <summary>Details</summary>
Motivation: Investigate whether structured, tree-based reasoning can enhance VLM performance on fine-grained tasks and large hierarchical label spaces where zero-shot performance is understudied.

Method: Introduce a framework that decomposes classification into interpretable decisions using decision trees, evaluated on fine-grained (GTSRB) and coarse-grained (CIFAR-10) datasets. Explore enhancing tree prompts with LLM-generated classes and image descriptions.

Result: Tree-based reasoning consistently underperforms standard zero-shot prompting despite achieving 98.2% accuracy in understanding tree knowledge. Adding image descriptions enhances performance for both tree-based and zero-shot methods.

Conclusion: Structured reasoning has limitations in visual classification, but findings offer insights for designing more interpretable VLM systems. Image descriptions can improve VLM performance regardless of reasoning approach.

Abstract: Vision language models (VLMs) excel at zero-shot visual classification, but
their performance on fine-grained tasks and large hierarchical label spaces is
understudied. This paper investigates whether structured, tree-based reasoning
can enhance VLM performance. We introduce a framework that decomposes
classification into interpretable decisions using decision trees and evaluates
it on fine-grained (GTSRB) and coarse-grained (CIFAR-10) datasets. Although the
model achieves 98.2% accuracy in understanding the tree knowledge, tree-based
reasoning consistently underperforms standard zero-shot prompting. We also
explore enhancing the tree prompts with LLM-generated classes and image
descriptions to improve alignment. The added description enhances the
performance of the tree-based and zero-shot methods. Our findings highlight
limitations of structured reasoning in visual classification and offer insights
for designing more interpretable VLM systems.

</details>


### [58] [World Modeling with Probabilistic Structure Integration](https://arxiv.org/abs/2509.09737)
*Klemen Kotar,Wanhee Lee,Rahul Venkatesh,Honglin Chen,Daniel Bear,Jared Watrous,Simon Kim,Khai Loong Aw,Lilian Naing Chen,Stefan Stojanov,Kevin Feigelis,Imran Thobani,Alex Durango,Khaled Jedoui,Atlas Kazemian,Dan Yamins*

Main category: cs.CV

TL;DR: PSI is a system that learns controllable world models from data through a 3-step cycle: probabilistic prediction, structure extraction, and integration, enabling improved video modeling and state-of-the-art computer vision tasks.


<details>
  <summary>Details</summary>
Motivation: To create richly controllable and flexibly promptable world models that can extract meaningful structures from data and use them for improved prediction and understanding.

Method: Three-step cycle: 1) Build probabilistic graphical model (Psi) as random-access autoregressive sequence model, 2) Extract low-dimensional structures via causal inference, 3) Integrate structures as new token types for continual training.

Result: Trained on 1.4T video tokens; achieved state-of-the-art optical flow, self-supervised depth, object segmentation; enabled various video prediction and understanding tasks with predictive improvements.

Conclusion: PSI successfully creates universal prompting-like capabilities for world modeling, with each cycle enhancing both data modeling and control handles through structure integration.

Abstract: We present Probabilistic Structure Integration (PSI), a system for learning
richly controllable and flexibly promptable world models from data. PSI
consists of a three-step cycle. The first step, Probabilistic prediction,
involves building a probabilistic graphical model Psi of the data, in the form
of a random-access autoregressive sequence model. Psi supports a complete set
of learned conditional distributions describing the dependence of any variables
in the data on any other set of variables. In step 2, Structure extraction, we
show how to extract underlying low-dimensional properties in the data,
corresponding to a diverse set of meaningful "intermediate structures", in a
zero-shot fashion via causal inference on Psi. Step 3, Integration, completes
the cycle by converting these structures into new token types that are then
continually mixed back into the training diet as conditioning signals and
prediction targets. Each such cycle augments the capabilities of Psi, both
allowing it to model the underlying data better, and creating new control
handles -- akin to an LLM-like universal prompting language. We train an
instance of Psi on 1.4 trillion tokens of internet video data; we use it to
perform a variety of useful video prediction and understanding inferences; we
extract state-of-the-art optical flow, self-supervised depth and object
segmentation; and we use these structures to support a full cycle of predictive
improvements.

</details>


### [59] [Images in Motion?: A First Look into Video Leakage in Collaborative Deep Learning](https://arxiv.org/abs/2509.09742)
*Md Fazle Rasul,Alanood Alqobaisi,Bruhadeshwar Bezawada,Indrakshi Ray*

Main category: cs.CV

TL;DR: First analysis of video data leakage in federated learning via gradient inversion attacks, showing feature extractors provide some protection but leakage is still possible, with super-resolution techniques enhancing attack quality.


<details>
  <summary>Details</summary>
Motivation: Federated learning's privacy protection is threatened by gradient inversion attacks that can reconstruct private training data from shared gradients. While known for images/text/tabular data, video data vulnerability remains unexamined.

Method: Evaluated two video classification approaches: pre-trained feature extractors vs raw video frame processing. Tested gradient inversion attacks with zero/one/multiple reference frames, using super-resolution to enhance reconstructed videos.

Result: Feature extractors offer greater resilience against attacks but leakage still occurs if classifier lacks complexity. Super-resolution techniques successfully enhance reconstructed video quality across all attack scenarios.

Conclusion: Video data leakage in FL is a viable threat that warrants further investigation, as current protections are insufficient against determined attackers with advanced reconstruction techniques.

Abstract: Federated learning (FL) allows multiple entities to train a shared model
collaboratively. Its core, privacy-preserving principle is that participants
only exchange model updates, such as gradients, and never their raw, sensitive
data. This approach is fundamental for applications in domains where privacy
and confidentiality are important. However, the security of this very mechanism
is threatened by gradient inversion attacks, which can reverse-engineer private
training data directly from the shared gradients, defeating the purpose of FL.
While the impact of these attacks is known for image, text, and tabular data,
their effect on video data remains an unexamined area of research. This paper
presents the first analysis of video data leakage in FL using gradient
inversion attacks. We evaluate two common video classification approaches: one
employing pre-trained feature extractors and another that processes raw video
frames with simple transformations. Our initial results indicate that the use
of feature extractors offers greater resilience against gradient inversion
attacks. We also demonstrate that image super-resolution techniques can enhance
the frames extracted through gradient inversion attacks, enabling attackers to
reconstruct higher-quality videos. Our experiments validate this across
scenarios where the attacker has access to zero, one, or more reference frames
from the target environment. We find that although feature extractors make
attacks more challenging, leakage is still possible if the classifier lacks
sufficient complexity. We, therefore, conclude that video data leakage in FL is
a viable threat, and the conditions under which it occurs warrant further
investigation.

</details>


### [60] [A Co-Training Semi-Supervised Framework Using Faster R-CNN and YOLO Networks for Object Detection in Densely Packed Retail Images](https://arxiv.org/abs/2509.09750)
*Hossein Yazdanjouei,Arash Mansouri,Mohammad Shokouhifar*

Main category: cs.CV

TL;DR: Semi-supervised co-training framework combining Faster R-CNN and YOLO for object detection in retail environments, with ensemble classification and metaheuristic optimization, reducing annotation costs while maintaining high accuracy.


<details>
  <summary>Details</summary>
Motivation: Address challenges in densely packed retail environments including limited labeled data, complex conditions, occlusion, overlapping objects, and the need to reduce manual annotation costs while adapting to frequent product/layout changes.

Method: Co-training framework with Faster R-CNN (ResNet backbone) for precise localization and YOLO (Darknet backbone) for global context, mutual pseudo-label exchange, ensemble classification (XGBoost, Random Forest, SVM), and metaheuristic hyperparameter optimization.

Result: Strong performance demonstrated on SKU-110k dataset, showing improved accuracy in scenes with occlusion and overlapping objects, with reduced reliance on manual labeling.

Conclusion: The framework offers scalable and practical solution for real-world retail applications including automated inventory tracking, product monitoring, and checkout systems, effectively addressing retail-specific challenges.

Abstract: This study proposes a semi-supervised co-training framework for object
detection in densely packed retail environments, where limited labeled data and
complex conditions pose major challenges. The framework combines Faster R-CNN
(utilizing a ResNet backbone) for precise localization with YOLO (employing a
Darknet backbone) for global context, enabling mutual pseudo-label exchange
that improves accuracy in scenes with occlusion and overlapping objects. To
strengthen classification, it employs an ensemble of XGBoost, Random Forest,
and SVM, utilizing diverse feature representations for higher robustness.
Hyperparameters are optimized using a metaheuristic-driven algorithm, enhancing
precision and efficiency across models. By minimizing reliance on manual
labeling, the approach reduces annotation costs and adapts effectively to
frequent product and layout changes common in retail. Experiments on the
SKU-110k dataset demonstrate strong performance, highlighting the scalability
and practicality of the proposed framework for real-world retail applications
such as automated inventory tracking, product monitoring, and checkout systems.

</details>


### [61] [Purge-Gate: Backpropagation-Free Test-Time Adaptation for Point Clouds Classification via Token Purging](https://arxiv.org/abs/2509.09785)
*Moslem Yazdanpanah,Ali Bahri,Mehrdad Noori,Sahar Dastani,Gustavo Adolfo Vargas Hakim,David Osowiechi,Ismail Ben Ayed,Christian Desrosiers*

Main category: cs.CV

TL;DR: Token Purging (PG) is a backpropagation-free test-time adaptation method for 3D point cloud classification that removes domain-shifted tokens before attention layers, achieving superior accuracy and efficiency.


<details>
  <summary>Details</summary>
Motivation: To address performance degradation caused by distribution shifts in 3D point cloud classification without requiring iterative updates or backpropagation during test-time adaptation.

Method: Proposes two variants: PG-SP (using source statistics) and PG-SF (fully source-free using CLS-token-driven adaptation) that remove tokens highly affected by domain shifts before they reach attention layers.

Result: PG-SP achieves +10.3% higher accuracy than state-of-the-art backpropagation-free methods, while PG-SF sets new benchmarks for source-free adaptation. PG is 12.4x faster and 5.5x more memory efficient than baseline.

Conclusion: Token Purging provides an effective and efficient solution for test-time adaptation in 3D point cloud classification, demonstrating superior performance and practical advantages for real-world deployment.

Abstract: Test-time adaptation (TTA) is crucial for mitigating performance degradation
caused by distribution shifts in 3D point cloud classification. In this work,
we introduce Token Purging (PG), a novel backpropagation-free approach that
removes tokens highly affected by domain shifts before they reach attention
layers. Unlike existing TTA methods, PG operates at the token level, ensuring
robust adaptation without iterative updates. We propose two variants: PG-SP,
which leverages source statistics, and PG-SF, a fully source-free version
relying on CLS-token-driven adaptation. Extensive evaluations on ModelNet40-C,
ShapeNet-C, and ScanObjectNN-C demonstrate that PG-SP achieves an average of
+10.3\% higher accuracy than state-of-the-art backpropagation-free methods,
while PG-SF sets new benchmarks for source-free adaptation. Moreover, PG is
12.4 times faster and 5.5 times more memory efficient than our baseline, making
it suitable for real-world deployment. Code is available at
\hyperlink{https://github.com/MosyMosy/Purge-Gate}{https://github.com/MosyMosy/Purge-Gate}

</details>


### [62] [Fine-Grained Cross-View Localization via Local Feature Matching and Monocular Depth Priors](https://arxiv.org/abs/2509.09792)
*Zimin Xia,Chenghao Xu,Alexandre Alahi*

Main category: cs.CV

TL;DR: A novel cross-view localization method that directly matches ground-level image features with aerial images using monocular depth prior, supporting both metric and relative depth with scale-aware alignment.


<details>
  <summary>Details</summary>
Motivation: Previous methods transform ground images to bird's-eye view, causing information loss from perspective distortion and height compression, which degrades alignment quality with aerial imagery.

Method: Directly establishes correspondences between ground and aerial images, lifts matched keypoints to BEV space using monocular depth prior, and employs scale-aware Procrustes alignment for pose estimation with optional scale recovery for relative depth.

Result: Achieves superior localization performance under challenging conditions (cross-area generalization, unknown orientation) with only weak pose supervision, learns accurate feature correspondences, and works with various relative depth models without per-model finetuning.

Conclusion: The method provides accurate, interpretable cross-view localization with flexibility for real-world deployment, handling both metric and relative depth scenarios effectively.

Abstract: We propose an accurate and highly interpretable fine-grained cross-view
localization method that estimates the 3 Degrees of Freedom pose of a
ground-level image by matching its local features with a reference aerial
image. Previous methods typically transform the ground image into a bird's-eye
view (BEV) representation and then align it with the aerial image for
localization. However, this transformation often leads to information loss due
to perspective distortion or compression of height information, thereby
degrading alignment quality with the aerial view. In contrast, our method
directly establishes correspondences between ground and aerial images and lifts
only the matched keypoints to BEV space using monocular depth prior. Notably,
modern depth predictors can provide reliable metric depth when the test samples
are similar to the training data. When the depth distribution differs, they
still produce consistent relative depth, i.e., depth accurate up to an unknown
scale. Our method supports both metric and relative depth. It employs a
scale-aware Procrustes alignment to estimate the camera pose from the
correspondences and optionally recover the scale when using relative depth.
Experimental results demonstrate that, with only weak supervision on camera
pose, our method learns accurate local feature correspondences and achieves
superior localization performance under challenging conditions, such as
cross-area generalization and unknown orientation. Moreover, our method is
compatible with various relative depth models without requiring per-model
finetuning. This flexibility, combined with strong localization performance,
makes it well-suited for real-world deployment.

</details>


### [63] [Early Detection of Visual Impairments at Home Using a Smartphone Red-Eye Reflex Test](https://arxiv.org/abs/2509.09808)
*Judith Massmann,Alexander Lichtenstein,Francisco M. López*

Main category: cs.CV

TL;DR: KidsVisionCheck is a mobile app that uses AI and smartphone cameras to perform pediatric vision screening via red-eye reflex analysis, achieving 90% accuracy without specialist equipment.


<details>
  <summary>Details</summary>
Motivation: To make pediatric vision screening more accessible worldwide by recreating the clinical Bruckner test using mobile technology and AI, enabling early detection of visual impairments in children.

Method: Deep neural networks trained on ophthalmologist-labeled red-eye reflex images from children, using smartphone cameras to capture pupil images for analysis.

Result: The model achieved 90% accuracy on unseen test data, identified optimal data collection conditions, and provides immediate feedback to users.

Conclusion: This represents a significant step toward accessible pediatric vision screening and early intervention for vision abnormalities globally using mobile technology.

Abstract: Numerous visual impairments can be detected in red-eye reflex images from
young children. The so-called Bruckner test is traditionally performed by
ophthalmologists in clinical settings. Thanks to the recent technological
advances in smartphones and artificial intelligence, it is now possible to
recreate the Bruckner test using a mobile device. In this paper, we present a
first study conducted during the development of KidsVisionCheck, a free
application that can perform vision screening with a mobile device using
red-eye reflex images. The underlying model relies on deep neural networks
trained on children's pupil images collected and labeled by an ophthalmologist.
With an accuracy of 90% on unseen test data, our model provides highly reliable
performance without the necessity of specialist equipment. Furthermore, we can
identify the optimal conditions for data collection, which can in turn be used
to provide immediate feedback to the users. In summary, this work marks a first
step toward accessible pediatric vision screenings and early intervention for
vision abnormalities worldwide.

</details>


### [64] [DGFusion: Depth-Guided Sensor Fusion for Robust Semantic Perception](https://arxiv.org/abs/2509.09828)
*Tim Broedermannn,Christos Sakaridis,Luigi Piccinelli,Wim Abbeloos,Luc Van Gool*

Main category: cs.CV

TL;DR: DGFusion is a depth-guided multimodal fusion method for semantic perception in autonomous vehicles that uses depth information to dynamically adapt sensor fusion based on spatial reliability, achieving state-of-the-art performance on challenging datasets.


<details>
  <summary>Details</summary>
Motivation: Current sensor fusion approaches treat sensor data uniformly across spatial extent, which hinders performance in challenging conditions. Depth information can help adapt fusion to spatially varying sensor reliability.

Method: Proposes DGFusion network that treats multimodal segmentation as multi-task problem, using lidar measurements as input and depth ground truth. Includes auxiliary depth head to learn depth-aware features encoded into local depth tokens that condition cross-modal fusion with a global condition token. Uses robust loss for depth learning from sparse, noisy lidar data.

Result: Achieves state-of-the-art panoptic and semantic segmentation performance on challenging MUSES and DELIVER datasets.

Conclusion: Depth-guided multimodal fusion with spatially varying adaptation significantly improves semantic perception performance by dynamically adjusting sensor fusion based on depth-dependent reliability across the scene.

Abstract: Robust semantic perception for autonomous vehicles relies on effectively
combining multiple sensors with complementary strengths and weaknesses.
State-of-the-art sensor fusion approaches to semantic perception often treat
sensor data uniformly across the spatial extent of the input, which hinders
performance when faced with challenging conditions. By contrast, we propose a
novel depth-guided multimodal fusion method that upgrades condition-aware
fusion by integrating depth information. Our network, DGFusion, poses
multimodal segmentation as a multi-task problem, utilizing the lidar
measurements, which are typically available in outdoor sensor suites, both as
one of the model's inputs and as ground truth for learning depth. Our
corresponding auxiliary depth head helps to learn depth-aware features, which
are encoded into spatially varying local depth tokens that condition our
attentive cross-modal fusion. Together with a global condition token, these
local depth tokens dynamically adapt sensor fusion to the spatially varying
reliability of each sensor across the scene, which largely depends on depth. In
addition, we propose a robust loss for our depth, which is essential for
learning from lidar inputs that are typically sparse and noisy in adverse
conditions. Our method achieves state-of-the-art panoptic and semantic
segmentation performance on the challenging MUSES and DELIVER datasets. Code
and models will be available at https://github.com/timbroed/DGFusion

</details>


### [65] [Patch-based Automatic Rosacea Detection Using the ResNet Deep Learning Framework](https://arxiv.org/abs/2509.09841)
*Chengyu Yang,Rishik Reddy Yesgari,Chengjun Liu*

Main category: cs.CV

TL;DR: Patch-based rosacea detection using ResNet-18 achieves competitive accuracy while preserving patient privacy by focusing on localized facial patches instead of full facial images.


<details>
  <summary>Details</summary>
Motivation: Rosacea requires early and precise detection for effective treatment, but current methods using full facial images raise privacy concerns and may not focus on clinically relevant regions.

Method: Proposed patch-based strategies extract various image patches from facial images in different sizes, shapes, and locations, then use ResNet-18 deep learning framework for detection. Multiple investigation studies evaluate how localized visual information affects model performance.

Result: Patch-based strategies achieve competitive or superior accuracy and sensitivity compared to full-image methods. They guide the model to focus on clinically relevant regions, enhance robustness and interpretability, and protect patient privacy by excluding identifiable facial features.

Conclusion: The patch-based automatic rosacea detection strategies offer practical insights for improving automated dermatological diagnostics by balancing accuracy with privacy preservation and clinical relevance.

Abstract: Rosacea, which is a chronic inflammatory skin condition that manifests with
facial redness, papules, and visible blood vessels, often requirs precise and
early detection for significantly improving treatment effectiveness. This paper
presents new patch-based automatic rosacea detection strategies using the
ResNet-18 deep learning framework. The contributions of the proposed strategies
come from the following aspects. First, various image pateches are extracted
from the facial images of people in different sizes, shapes, and locations.
Second, a number of investigation studies are carried out to evaluate how the
localized visual information influences the deep learing model performance.
Third, thorough experiments are implemented to reveal that several patch-based
automatic rosacea detection strategies achieve competitive or superior accuracy
and sensitivity than the full-image based methods. And finally, the proposed
patch-based strategies, which use only localized patches, inherently preserve
patient privacy by excluding any identifiable facial features from the data.
The experimental results indicate that the proposed patch-based strategies
guide the deep learning model to focus on clinically relevant regions, enhance
robustness and interpretability, and protect patient privacy. As a result, the
proposed strategies offer practical insights for improving automated
dermatological diagnostics.

</details>


### [66] [Privacy-Preserving Automated Rosacea Detection Based on Medically Inspired Region of Interest Selection](https://arxiv.org/abs/2509.09844)
*Chengyu Yang,Rishik Reddy Yesgari,Chengjun Liu*

Main category: cs.CV

TL;DR: Privacy-preserving rosacea detection using synthetic data and clinical priors, with a redness-informed mask to focus on diagnostically relevant facial areas while excluding identity features.


<details>
  <summary>Details</summary>
Motivation: Rosacea is underdiagnosed and automated detection faces challenges due to diffuse symptoms, scarce labeled datasets, and privacy concerns with facial images.

Method: Uses a fixed redness-informed mask to select high red-intensity regions (cheeks, nose, forehead) and trains ResNet-18 on masked synthetic images.

Result: Achieves superior performance over full-face baselines with notable gains in accuracy, recall, and F1 score on real-world test data.

Conclusion: Synthetic data combined with clinical priors enables accurate and ethical dermatological AI systems for privacy-sensitive applications like telemedicine.

Abstract: Rosacea is a common but underdiagnosed inflammatory skin condition that
primarily affects the central face and presents with subtle redness, pustules,
and visible blood vessels. Automated detection remains challenging due to the
diffuse nature of symptoms, the scarcity of labeled datasets, and privacy
concerns associated with using identifiable facial images. A novel
privacy-preserving automated rosacea detection method inspired by clinical
priors and trained entirely on synthetic data is presented in this paper.
Specifically, the proposed method, which leverages the observation that rosacea
manifests predominantly through central facial erythema, first constructs a
fixed redness-informed mask by selecting regions with consistently high red
channel intensity across facial images. The mask thus is able to focus on
diagnostically relevant areas such as the cheeks, nose, and forehead and
exclude identity-revealing features. Second, the ResNet-18 deep learning
method, which is trained on the masked synthetic images, achieves superior
performance over the full-face baselines with notable gains in terms of
accuracy, recall and F1 score when evaluated using the real-world test data.
The experimental results demonstrate that the synthetic data and clinical
priors can jointly enable accurate and ethical dermatological AI systems,
especially for privacy sensitive applications in telemedicine and large-scale
screening.

</details>


### [67] [Investigating the Impact of Various Loss Functions and Learnable Wiener Filter for Laparoscopic Image Desmoking](https://arxiv.org/abs/2509.09849)
*Chengyu Yang,Chengjun Liu*

Main category: cs.CV

TL;DR: Comprehensive ablation study of ULW framework for laparoscopic image desmoking, evaluating individual components including learnable Wiener filter and loss function terms.


<details>
  <summary>Details</summary>
Motivation: To rigorously assess the effectiveness and necessity of individual components within the ULW framework for laparoscopic image desmoking.

Method: Systematic ablation study removing the learnable Wiener filter and selectively using individual loss terms (MSE, SSIM, perceptual loss) from the compound loss function. All variants benchmarked on paired laparoscopic images dataset.

Result: Evaluation performed using quantitative metrics (SSIM, PSNR, MSE, CIEDE-2000) alongside qualitative visual comparisons.

Conclusion: The study provides comprehensive analysis of each component's specific contribution to the overall performance of the ULW framework for laparoscopic image desmoking.

Abstract: To rigorously assess the effectiveness and necessity of individual components
within the recently proposed ULW framework for laparoscopic image desmoking,
this paper presents a comprehensive ablation study. The ULW approach combines a
U-Net based backbone with a compound loss function that comprises mean squared
error (MSE), structural similarity index (SSIM) loss, and perceptual loss. The
framework also incorporates a differentiable, learnable Wiener filter module.
In this study, each component is systematically ablated to evaluate its
specific contribution to the overall performance of the whole framework. The
analysis includes: (1) removal of the learnable Wiener filter, (2) selective
use of individual loss terms from the composite loss function. All variants are
benchmarked on a publicly available paired laparoscopic images dataset using
quantitative metrics (SSIM, PSNR, MSE and CIEDE-2000) alongside qualitative
visual comparisons.

</details>


### [68] [WAVE-DETR Multi-Modal Visible and Acoustic Real-Life Drone Detector](https://arxiv.org/abs/2509.09859)
*Razvan Stefanescu,Ethan Oh,Ruben Vazquez,Chris Mesterharm,Constantin Serban,Ritu Chadha*

Main category: cs.CV

TL;DR: WAVE-DETR is a multi-modal drone detector that fuses RGB visual and acoustic signals using Deformable DETR and Wav2Vec2 architectures, achieving significant performance improvements across all drone sizes in challenging conditions.


<details>
  <summary>Details</summary>
Motivation: To create a robust UAV detection system that works effectively under challenging environmental conditions by combining visual and acoustic information, addressing limitations of single-modal approaches.

Method: Combines Deformable DETR for visual processing with Wav2Vec2 for acoustic feature extraction. Tests four fusion configurations: gated mechanism, linear layer, MLP, and cross attention. Uses Drone-vs-Bird and new ARDrone datasets with 7,500+ synchronized image-audio pairs.

Result: Gated fusion approach performed best, improving mAP by 11.1-15.3% for small drones across IoU thresholds 0.5-0.9. Medium and large drones also showed improvements with overall gains of 3.27-5.84% across all drone sizes.

Conclusion: Acoustic information significantly enhances drone detection performance, with multi-modal fusion proving particularly effective for small drone detection in real-world scenarios.

Abstract: We introduce a multi-modal WAVE-DETR drone detector combining visible RGB and
acoustic signals for robust real-life UAV object detection. Our approach fuses
visual and acoustic features in a unified object detector model relying on the
Deformable DETR and Wav2Vec2 architectures, achieving strong performance under
challenging environmental conditions. Our work leverage the existing
Drone-vs-Bird dataset and the newly generated ARDrone dataset containing more
than 7,500 synchronized images and audio segments. We show how the acoustic
information is used to improve the performance of the Deformable DETR object
detector on the real ARDrone dataset. We developed, trained and tested four
different fusion configurations based on a gated mechanism, linear layer, MLP
and cross attention. The Wav2Vec2 acoustic embeddings are fused with the multi
resolution feature mappings of the Deformable DETR and enhance the object
detection performance over all drones dimensions. The best performer is the
gated fusion approach, which improves the mAP of the Deformable DETR object
detector on our in-distribution and out-of-distribution ARDrone datasets by
11.1% to 15.3% for small drones across all IoU thresholds between 0.5 and 0.9.
The mAP scores for medium and large drones are also enhanced, with overall
gains across all drone sizes ranging from 3.27% to 5.84%.

</details>


### [69] [Surrogate Supervision for Robust and Generalizable Deformable Image Registration](https://arxiv.org/abs/2509.09869)
*Yihao Liu,Junyu Chen,Lianrui Zuo,Shuwen Wei,Brian D. Boyd,Carmen Andreescu,Olusola Ajilore,Warren D. Taylor,Aaron Carass,Bennett A. Landman*

Main category: cs.CV

TL;DR: Surrogate supervision improves robustness of deep learning image registration by decoupling input domain from supervision domain, using estimated transformations on surrogate images to handle heterogeneous inputs while maintaining accuracy.


<details>
  <summary>Details</summary>
Motivation: Deep learning-based deformable image registration achieves strong accuracy but remains sensitive to variations in input image characteristics such as artifacts, field-of-view mismatch, or modality differences.

Method: Introduces surrogate supervision that decouples input domain from supervision domain by applying estimated spatial transformations to surrogate images, allowing training on heterogeneous inputs while ensuring supervision is computed in domains where similarity is well defined.

Result: Across three applications (artifact-robust brain MR registration, mask-agnostic lung CT registration, multi-modal MR registration), surrogate supervision demonstrated strong resilience to input variations including inhomogeneity field, inconsistent field-of-view, and modality differences while maintaining high performance on well-curated data.

Conclusion: Surrogate supervision provides a principled framework for training robust and generalizable deep learning-based registration models without increasing complexity, offering a practical pathway to more robust medical image registration.

Abstract: Objective: Deep learning-based deformable image registration has achieved
strong accuracy, but remains sensitive to variations in input image
characteristics such as artifacts, field-of-view mismatch, or modality
difference. We aim to develop a general training paradigm that improves the
robustness and generalizability of registration networks. Methods: We introduce
surrogate supervision, which decouples the input domain from the supervision
domain by applying estimated spatial transformations to surrogate images. This
allows training on heterogeneous inputs while ensuring supervision is computed
in domains where similarity is well defined. We evaluate the framework through
three representative applications: artifact-robust brain MR registration,
mask-agnostic lung CT registration, and multi-modal MR registration. Results:
Across tasks, surrogate supervision demonstrated strong resilience to input
variations including inhomogeneity field, inconsistent field-of-view, and
modality differences, while maintaining high performance on well-curated data.
Conclusions: Surrogate supervision provides a principled framework for training
robust and generalizable deep learning-based registration models without
increasing complexity. Significance: Surrogate supervision offers a practical
pathway to more robust and generalizable medical image registration, enabling
broader applicability in diverse biomedical imaging scenarios.

</details>


### [70] [An Autoencoder and Vision Transformer-based Interpretability Analysis of the Differences in Automated Staging of Second and Third Molars](https://arxiv.org/abs/2509.09911)
*Barkin Buyukcakir,Jannick De Tobel,Patrick Thevissen,Dirk Vandermeulen,Peter Claes*

Main category: cs.CV

TL;DR: A framework combining convolutional autoencoder and Vision Transformer improves dental age estimation accuracy and provides diagnostic insights, revealing data-centric limitations in tooth morphology variability.


<details>
  <summary>Details</summary>
Motivation: Address the 'black box' nature of deep learning models in high-stakes forensic applications like dental age estimation, where transparency is crucial for adoption.

Method: Proposed framework combining convolutional autoencoder (AE) with Vision Transformer (ViT) to enhance both performance and interpretability, using mandibular second and third molars as case study.

Result: Improved classification accuracy from 0.712 to 0.815 for tooth 37 and from 0.462 to 0.543 for tooth 38 over baseline ViT. Analysis revealed performance gap is data-centric due to high intra-class morphological variability in tooth 38 dataset.

Conclusion: The framework provides multi-faceted diagnostic insights beyond single interpretability modes, serving as a robust tool to support expert decision-making by enhancing accuracy and explaining model uncertainty.

Abstract: The practical adoption of deep learning in high-stakes forensic applications,
such as dental age estimation, is often limited by the 'black box' nature of
the models. This study introduces a framework designed to enhance both
performance and transparency in this context. We use a notable performance
disparity in the automated staging of mandibular second (tooth 37) and third
(tooth 38) molars as a case study. The proposed framework, which combines a
convolutional autoencoder (AE) with a Vision Transformer (ViT), improves
classification accuracy for both teeth over a baseline ViT, increasing from
0.712 to 0.815 for tooth 37 and from 0.462 to 0.543 for tooth 38. Beyond
improving performance, the framework provides multi-faceted diagnostic
insights. Analysis of the AE's latent space metrics and image reconstructions
indicates that the remaining performance gap is data-centric, suggesting high
intra-class morphological variability in the tooth 38 dataset is a primary
limiting factor. This work highlights the insufficiency of relying on a single
mode of interpretability, such as attention maps, which can appear anatomically
plausible yet fail to identify underlying data issues. By offering a
methodology that both enhances accuracy and provides evidence for why a model
may be uncertain, this framework serves as a more robust tool to support expert
decision-making in forensic age estimation.

</details>


### [71] [SCoDA: Self-supervised Continual Domain Adaptation](https://arxiv.org/abs/2509.09935)
*Chirayu Agrawal,Snehasis Mukherjee*

Main category: cs.CV

TL;DR: SCoDA introduces self-supervised pre-training and geometric manifold alignment for source-free domain adaptation, outperforming existing methods without requiring supervised source data.


<details>
  <summary>Details</summary>
Motivation: Existing SFDA methods discard geometric information about the latent manifold when using cosine similarity over L2-normalized features, and rely on supervised pre-training which may not be available.

Method: Uses self-supervised pre-trained teacher model, geometric manifold alignment with Space Similarity Loss, and EMA updates to prevent catastrophic forgetting. Combines instance-level feature matching with geometric preservation.

Result: Extensive experiments show SCoDA significantly outperforms state-of-the-art SFDA methods on benchmark datasets.

Conclusion: Self-supervised pre-training combined with geometric manifold alignment effectively addresses SFDA challenges, providing superior performance while avoiding reliance on supervised source data.

Abstract: Source-Free Domain Adaptation (SFDA) addresses the challenge of adapting a
model to a target domain without access to the data of the source domain.
Prevailing methods typically start with a source model pre-trained with full
supervision and distill the knowledge by aligning instance-level features.
However, these approaches, relying on cosine similarity over L2-normalized
feature vectors, inadvertently discard crucial geometric information about the
latent manifold of the source model. We introduce Self-supervised Continual
Domain Adaptation (SCoDA) to address these limitations. We make two key
departures from standard practice: first, we avoid the reliance on supervised
pre-training by initializing the proposed framework with a teacher model
pre-trained entirely via self-supervision (SSL). Second, we adapt the principle
of geometric manifold alignment to the SFDA setting. The student is trained
with a composite objective combining instance-level feature matching with a
Space Similarity Loss. To combat catastrophic forgetting, the teacher's
parameters are updated via an Exponential Moving Average (EMA) of the student's
parameters. Extensive experiments on benchmark datasets demonstrate that SCoDA
significantly outperforms state-of-the-art SFDA methods.

</details>


### [72] [Segment Anything for Cell Tracking](https://arxiv.org/abs/2509.09943)
*Zhu Chen,Mert Edgü,Er Jin,Johannes Stegmaier*

Main category: cs.CV

TL;DR: Zero-shot cell tracking framework using SAM2 foundation model for unsupervised microscopy image analysis without manual labeling or dataset-specific training.


<details>
  <summary>Details</summary>
Motivation: Existing deep learning methods require costly manual labeling and lack generalizability across diverse microscopy datasets due to their dependence on specific training data.

Method: Integrate Segment Anything 2 (SAM2) foundation model into tracking pipeline as a fully-unsupervised approach that doesn't require training or inherit dataset biases.

Result: Achieves competitive accuracy in both 2D and large-scale 3D time-lapse microscopy videos without dataset-specific adaptation or finetuning.

Conclusion: The proposed zero-shot framework overcomes limitations of traditional methods by providing generalizable cell tracking without manual labeling requirements.

Abstract: Tracking cells and detecting mitotic events in time-lapse microscopy image
sequences is a crucial task in biomedical research. However, it remains highly
challenging due to dividing objects, low signal-tonoise ratios, indistinct
boundaries, dense clusters, and the visually similar appearance of individual
cells. Existing deep learning-based methods rely on manually labeled datasets
for training, which is both costly and time-consuming. Moreover, their
generalizability to unseen datasets remains limited due to the vast diversity
of microscopy data. To overcome these limitations, we propose a zero-shot cell
tracking framework by integrating Segment Anything 2 (SAM2), a large foundation
model designed for general image and video segmentation, into the tracking
pipeline. As a fully-unsupervised approach, our method does not depend on or
inherit biases from any specific training dataset, allowing it to generalize
across diverse microscopy datasets without finetuning. Our approach achieves
competitive accuracy in both 2D and large-scale 3D time-lapse microscopy videos
while eliminating the need for dataset-specific adaptation.

</details>


### [73] [Online 3D Multi-Camera Perception through Robust 2D Tracking and Depth-based Late Aggregation](https://arxiv.org/abs/2509.09946)
*Vu-Minh Le,Thao-Anh Tran,Duc Huy Do,Xuan Canh Do,Huong Ninh,Hai Tran*

Main category: cs.CV

TL;DR: A method to extend 2D multi-camera tracking systems to 3D space using depth information for point-cloud reconstruction and 3D box recovery, achieving 3rd place in AI City Challenge 2025.


<details>
  <summary>Details</summary>
Motivation: Existing MTMC systems are built for 2D tracking but 3D tracking requires rebuilding from ground up, which is infeasible for current systems. This paper provides a way to extend existing 2D systems to 3D space.

Method: Utilizes depth information to reconstruct targets in point-cloud space, performs clustering and yaw refinement for 3D box recovery, and introduces enhanced online data association using target's local ID consistency for global ID assignment.

Result: Achieved 3rd place on the leaderboard of the 2025 AI City Challenge's 3D MTMC dataset.

Conclusion: The proposed framework successfully extends 2D multi-camera tracking systems to 3D space without requiring complete system rebuild, demonstrating effective performance in real-world surveillance applications.

Abstract: Multi-Target Multi-Camera Tracking (MTMC) is an essential computer vision
task for automating large-scale surveillance. With camera calibration and depth
information, the targets in the scene can be projected into 3D space, offering
unparalleled levels of automatic perception of a 3D environment. However,
tracking in the 3D space requires replacing all 2D tracking components from the
ground up, which may be infeasible for existing MTMC systems. In this paper, we
present an approach for extending any online 2D multi-camera tracking system
into 3D space by utilizing depth information to reconstruct a target in
point-cloud space, and recovering its 3D box through clustering and yaw
refinement following tracking. We also introduced an enhanced online data
association mechanism that leverages the target's local ID consistency to
assign global IDs across frames. The proposed framework is evaluated on the
2025 AI City Challenge's 3D MTMC dataset, achieving 3rd place on the
leaderboard.

</details>


### [74] [Zero-Shot Referring Expression Comprehension via Visual-Language True/False Verification](https://arxiv.org/abs/2509.09958)
*Jeffrey Liu,Rongbin Hu*

Main category: cs.CV

TL;DR: A zero-shot workflow using visual-language verification outperforms task-trained models for Referring Expression Comprehension, achieving state-of-the-art results without REC-specific training.


<details>
  <summary>Details</summary>
Motivation: To demonstrate that workflow design is more important than task-specific pretraining for REC, and to show that zero-shot methods can compete with or surpass trained models.

Method: Reformulates REC as box-wise visual-language verification using a general-purpose VLM to answer True/False queries for each region proposal from a COCO-clean generic detector (YOLO-World), without any fine-tuning.

Result: Surpasses zero-shot GroundingDINO baseline and exceeds reported results for trained GroundingDINO and GroundingDINO+CRG on RefCOCO, RefCOCO+, and RefCOCOg datasets. Verification significantly outperforms selection-based prompting.

Conclusion: Workflow design drives strong zero-shot REC performance more than task-specific pretraining, and the proposed verification approach reduces cross-box interference while supporting abstention and multiple matches.

Abstract: Referring Expression Comprehension (REC) is usually addressed with
task-trained grounding models. We show that a zero-shot workflow, without any
REC-specific training, can achieve competitive or superior performance. Our
approach reformulates REC as box-wise visual-language verification: given
proposals from a COCO-clean generic detector (YOLO-World), a general-purpose
VLM independently answers True/False queries for each region. This simple
procedure reduces cross-box interference, supports abstention and multiple
matches, and requires no fine-tuning. On RefCOCO, RefCOCO+, and RefCOCOg, our
method not only surpasses a zero-shot GroundingDINO baseline but also exceeds
reported results for GroundingDINO trained on REC and GroundingDINO+CRG.
Controlled studies with identical proposals confirm that verification
significantly outperforms selection-based prompting, and results hold with open
VLMs. Overall, we show that workflow design, rather than task-specific
pretraining, drives strong zero-shot REC performance.

</details>


### [75] [Augment to Segment: Tackling Pixel-Level Imbalance in Wheat Disease and Pest Segmentation](https://arxiv.org/abs/2509.09961)
*Tianqi Wei,Xin Yu,Zhi Chen,Scott Chapman,Zi Huang*

Main category: cs.CV

TL;DR: Proposes RPCP augmentation to address extreme pixel imbalance in wheat disease segmentation by copying, transforming, and blending rare insect-damage patches with random projection filtering.


<details>
  <summary>Details</summary>
Motivation: Extreme pixel-level imbalance in wheat disease segmentation causes overfitting to common classes and insufficient learning of rare insect damage classes, impairing overall performance.

Method: Random Projected Copy-and-Paste (RPCP) technique extracts rare insect-damage patches, applies random geometric transformations, pastes them in appropriate regions avoiding overlaps, and uses random projection filtering for natural blending.

Result: Substantially improves segmentation performance on insect damage class while maintaining or slightly enhancing accuracy on other categories.

Conclusion: Targeted augmentation effectively mitigates extreme pixel imbalance, offering a straightforward yet effective solution for agricultural segmentation problems.

Abstract: Accurate segmentation of foliar diseases and insect damage in wheat is
crucial for effective crop management and disease control. However, the insect
damage typically occupies only a tiny fraction of annotated pixels. This
extreme pixel-level imbalance poses a significant challenge to the segmentation
performance, which can result in overfitting to common classes and insufficient
learning of rare classes, thereby impairing overall performance. In this paper,
we propose a Random Projected Copy-and-Paste (RPCP) augmentation technique to
address the pixel imbalance problem. Specifically, we extract rare
insect-damage patches from annotated training images and apply random geometric
transformations to simulate variations. The transformed patches are then pasted
in appropriate regions while avoiding overlaps with lesions or existing damaged
regions. In addition, we apply a random projection filter to the pasted
regions, refining local features and ensuring a natural blend with the new
background. Experiments show that our method substantially improves
segmentation performance on the insect damage class, while maintaining or even
slightly enhancing accuracy on other categories. Our results highlight the
effectiveness of targeted augmentation in mitigating extreme pixel imbalance,
offering a straightforward yet effective solution for agricultural segmentation
problems.

</details>


### [76] [An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock](https://arxiv.org/abs/2509.09962)
*Anne Marthe Sophie Ngo Bibinbe,Chiron Bang,Patrick Gagnon,Jamie Ahloy-Dallaire,Eric R. Paquet*

Main category: cs.CV

TL;DR: A new HMM framework that combines uncertain identities from sporadic identifications (like feeders) with tracking to improve long-term multi-object tracking performance, validated on pig tracking and MOT benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing MOT approaches suffer from identity switches over time, making them unsuitable for long-term tracking needed in applications like livestock monitoring where sporadic identifications are available.

Method: Proposes a Hidden Markov Model framework that integrates uncertain identities from external sources (e.g., feeders) with tracking data to maintain consistent identities over extended periods.

Result: Improved F1 score of ByteTrack on a 10-minute pig tracking dataset with 21 identifications, robust to identification uncertainty, and validated on MOT17/MOT20 benchmarks with both ByteTrack and FairMOT.

Conclusion: The HMM framework effectively leverages sporadic identifications to enhance long-term tracking performance and is applicable to real-world scenarios like livestock monitoring where partial identity information is available.

Abstract: The need for long-term multi-object tracking (MOT) is growing due to the
demand for analyzing individual behaviors in videos that span several minutes.
Unfortunately, due to identity switches between objects, the tracking
performance of existing MOT approaches decreases over time, making them
difficult to apply for long-term tracking. However, in many real-world
applications, such as in the livestock sector, it is possible to obtain
sporadic identifications for some of the animals from sources like feeders. To
address the challenges of long-term MOT, we propose a new framework that
combines both uncertain identities and tracking using a Hidden Markov Model
(HMM) formulation. In addition to providing real-world identities to animals,
our HMM framework improves the F1 score of ByteTrack, a leading MOT approach
even with re-identification, on a 10 minute pig tracking dataset with 21
identifications at the pen's feeding station. We also show that our approach is
robust to the uncertainty of identifications, with performance increasing as
identities are provided more frequently. The improved performance of our HMM
framework was also validated on the MOT17 and MOT20 benchmark datasets using
both ByteTrack and FairMOT. The code for this new HMM framework and the new
10-minute pig tracking video dataset are available at:
https://github.com/ngobibibnbe/uncertain-identity-aware-tracking

</details>


### [77] [Event Camera Guided Visual Media Restoration & 3D Reconstruction: A Survey](https://arxiv.org/abs/2509.09971)
*Aupendu Kar,Vishnu Raj,Guan-Ming Su*

Main category: cs.CV

TL;DR: Survey paper on event camera fusion with traditional frame-based capture for video restoration and 3D reconstruction tasks, covering deep learning approaches for temporal and spatial enhancement.


<details>
  <summary>Details</summary>
Motivation: Event cameras offer low latency, low power consumption, and high capture rates, but their fusion with traditional frame-based systems can significantly benefit video restoration and 3D reconstruction tasks.

Method: Systematic review of deep learning contributions for image/video enhancement and restoration, focusing on temporal enhancement (frame interpolation, motion deblurring) and spatial enhancement (super-resolution, low-light/HDR enhancement, artifact reduction). Also explores 3D reconstruction with event-driven fusion.

Result: Comprehensive survey covering diverse topics with in-depth discussions on recent works for improving visual quality under challenging conditions, including compilation of openly available datasets for reproducible research.

Conclusion: The survey consolidates recent progress to inspire further research into leveraging event camera systems combined with deep learning for advanced visual media restoration and enhancement.

Abstract: Event camera sensors are bio-inspired sensors which asynchronously capture
per-pixel brightness changes and output a stream of events encoding the
polarity, location and time of these changes. These systems are witnessing
rapid advancements as an emerging field, driven by their low latency, reduced
power consumption, and ultra-high capture rates. This survey explores the
evolution of fusing event-stream captured with traditional frame-based capture,
highlighting how this synergy significantly benefits various video restoration
and 3D reconstruction tasks. The paper systematically reviews major deep
learning contributions to image/video enhancement and restoration, focusing on
two dimensions: temporal enhancement (such as frame interpolation and motion
deblurring) and spatial enhancement (including super-resolution, low-light and
HDR enhancement, and artifact reduction). This paper also explores how the 3D
reconstruction domain evolves with the advancement of event driven fusion.
Diverse topics are covered, with in-depth discussions on recent works for
improving visual quality under challenging conditions. Additionally, the survey
compiles a comprehensive list of openly available datasets, enabling
reproducible research and benchmarking. By consolidating recent progress and
insights, this survey aims to inspire further research into leveraging event
camera systems, especially in combination with deep learning, for advanced
visual media restoration and enhancement.

</details>


### [78] [ISTASTrack: Bridging ANN and SNN via ISTA Adapter for RGB-Event Tracking](https://arxiv.org/abs/2509.09977)
*Siying Liu,Zikai Wang,Hanle Zheng,Yifan Hu,Xilin Wang,Qingkai Yang,Jibin Wu,Hao Guo,Lei Deng*

Main category: cs.CV

TL;DR: ISTASTrack is the first transformer-based ANN-SNN hybrid tracker for RGB-Event tracking, using ISTA adapters to bridge modality gaps between RGB and event data for state-of-the-art performance with high energy efficiency.


<details>
  <summary>Details</summary>
Motivation: Existing ANN architectures struggle to fully exploit the sparse and asynchronous nature of event streams in RGB-Event tracking, and effectively fusing features across heterogeneous ANN-SNN paradigms remains challenging.

Method: Two-branch model with vision transformer for RGB spatial context and spiking transformer for event spatio-temporal dynamics. Uses model-based ISTA adapters derived from sparse representation theory for bidirectional feature interaction, plus temporal downsampling attention for feature alignment.

Result: Achieves state-of-the-art performance on RGB-Event tracking benchmarks (FE240hz, VisEvent, COESOT, FELT) while maintaining high energy efficiency.

Conclusion: ISTASTrack demonstrates the effectiveness and practicality of hybrid ANN-SNN designs for robust visual tracking, successfully bridging modality and paradigm gaps between RGB and event data.

Abstract: RGB-Event tracking has become a promising trend in visual object tracking to
leverage the complementary strengths of both RGB images and dynamic spike
events for improved performance. However, existing artificial neural networks
(ANNs) struggle to fully exploit the sparse and asynchronous nature of event
streams. Recent efforts toward hybrid architectures combining ANNs and spiking
neural networks (SNNs) have emerged as a promising solution in RGB-Event
perception, yet effectively fusing features across heterogeneous paradigms
remains a challenge. In this work, we propose ISTASTrack, the first
transformer-based \textbf{A}NN-\textbf{S}NN hybrid \textbf{Track}er equipped
with \textbf{ISTA} adapters for RGB-Event tracking. The two-branch model
employs a vision transformer to extract spatial context from RGB inputs and a
spiking transformer to capture spatio-temporal dynamics from event streams. To
bridge the modality and paradigm gap between ANN and SNN features, we
systematically design a model-based ISTA adapter for bidirectional feature
interaction between the two branches, derived from sparse representation theory
by unfolding the iterative shrinkage thresholding algorithm. Additionally, we
incorporate a temporal downsampling attention module within the adapter to
align multi-step SNN features with single-step ANN features in the latent
space, improving temporal fusion. Experimental results on RGB-Event tracking
benchmarks, such as FE240hz, VisEvent, COESOT, and FELT, have demonstrated that
ISTASTrack achieves state-of-the-art performance while maintaining high energy
efficiency, highlighting the effectiveness and practicality of hybrid ANN-SNN
designs for robust visual tracking. The code is publicly available at
https://github.com/lsying009/ISTASTrack.git.

</details>


### [79] [FLARE-SSM: Deep State Space Models with Influence-Balanced Loss for 72-Hour Solar Flare Prediction](https://arxiv.org/abs/2509.09988)
*Yusuke Takagi,Shunya Nagashima,Komei Sugiura*

Main category: cs.CV

TL;DR: A solar flare prediction model using multiple deep state space models with FLARE loss to handle class imbalance, achieving better performance than baselines on standard metrics.


<details>
  <summary>Details</summary>
Motivation: Accurate solar flare prediction is crucial for infrastructure protection, but current methods struggle with severe class imbalance across flare classes.

Method: Proposed solar flare prediction model based on multiple deep state space models with frequency & local-boundary-aware reliability loss (FLARE loss) to address class imbalance.

Result: Outperformed baseline approaches in both Gandin-Murphy-Gerrity score and true skill statistic metrics on multi-wavelength solar image dataset covering 11-year solar cycle.

Conclusion: The proposed method effectively addresses class imbalance in solar flare prediction and demonstrates improved performance and reliability compared to existing approaches.

Abstract: Accurate and reliable solar flare predictions are essential to mitigate
potential impacts on critical infrastructure. However, the current performance
of solar flare forecasting is insufficient. In this study, we address the task
of predicting the class of the largest solar flare expected to occur within the
next 72 hours. Existing methods often fail to adequately address the severe
class imbalance across flare classes. To address this issue, we propose a solar
flare prediction model based on multiple deep state space models. In addition,
we introduce the frequency & local-boundary-aware reliability loss (FLARE loss)
to improve predictive performance and reliability under class imbalance.
Experiments were conducted on a multi-wavelength solar image dataset covering a
full 11-year solar activity cycle. As a result, our method outperformed
baseline approaches in terms of both the Gandin-Murphy-Gerrity score and the
true skill statistic, which are standard metrics in terms of the performance
and reliability.

</details>


### [80] [TUNI: Real-time RGB-T Semantic Segmentation with Unified Multi-Modal Feature Extraction and Cross-Modal Feature Fusion](https://arxiv.org/abs/2509.10005)
*Xiaodong Guo,Tong Liu,Yike Li,Zi'ang Lin,Zhihong Deng*

Main category: cs.CV

TL;DR: TUNI is a novel RGB-thermal semantic segmentation model that integrates multi-modal feature extraction and cross-modal fusion in a unified encoder, achieving competitive performance with fewer parameters and real-time inference speed.


<details>
  <summary>Details</summary>
Motivation: Existing RGB-T models use separate encoders pre-trained on RGB images, leading to limited thermal feature extraction, suboptimal cross-modal fusion, and redundant architecture that compromises real-time efficiency.

Method: Proposes TUNI with a unified RGB-T encoder that simultaneously performs multi-modal feature extraction and fusion using large-scale pre-training with RGB and pseudo-thermal data. Includes an RGB-T local module with adaptive cosine similarity to emphasize salient consistent and distinct local features across modalities.

Result: Achieves competitive performance with state-of-the-art models on FMB, PST900 and CART datasets, with fewer parameters and lower computational cost. Achieves 27 FPS inference speed on Jetson Orin NX.

Conclusion: TUNI demonstrates effective integration of feature extraction and fusion in a unified encoder, providing a compact and efficient solution for real-time RGB-thermal semantic segmentation in autonomous platforms.

Abstract: RGB-thermal (RGB-T) semantic segmentation improves the environmental
perception of autonomous platforms in challenging conditions. Prevailing models
employ encoders pre-trained on RGB images to extract features from both RGB and
infrared inputs, and design additional modules to achieve cross-modal feature
fusion. This results in limited thermal feature extraction and suboptimal
cross-modal fusion, while the redundant encoders further compromises the
model's real-time efficiency. To address the above issues, we propose TUNI,
with an RGB-T encoder consisting of multiple stacked blocks that simultaneously
perform multi-modal feature extraction and cross-modal fusion. By leveraging
large-scale pre-training with RGB and pseudo-thermal data, the RGB-T encoder
learns to integrate feature extraction and fusion in a unified manner. By
slimming down the thermal branch, the encoder achieves a more compact
architecture. Moreover, we introduce an RGB-T local module to strengthen the
encoder's capacity for cross-modal local feature fusion. The RGB-T local module
employs adaptive cosine similarity to selectively emphasize salient consistent
and distinct local features across RGB-T modalities. Experimental results show
that TUNI achieves competitive performance with state-of-the-art models on FMB,
PST900 and CART, with fewer parameters and lower computational cost. Meanwhile,
it achieves an inference speed of 27 FPS on a Jetson Orin NX, demonstrating its
real-time capability in deployment. Codes are available at
https://github.com/xiaodonguo/TUNI.

</details>


### [81] [Few-Part-Shot Font Generation](https://arxiv.org/abs/2509.10006)
*Masaki Akiba,Shumpei Takezaki,Daichi Haraguchi,Seiichi Uchida*

Main category: cs.CV

TL;DR: A novel few-part-shot font generation model that creates complete fonts using only partial character shapes as input, improving efficiency and providing insights into how design details influence character structure.


<details>
  <summary>Details</summary>
Motivation: Traditional few-shot font generation requires complete character shapes for multiple classes, which is inefficient. This approach aims to streamline font creation by using only partial design elements.

Method: Proposes a model that designs entire fonts based on partial shapes (design elements) rather than complete characters, focusing on how partial details influence overall character structure.

Result: The model successfully generates complete fonts from partial input shapes, demonstrating improved efficiency in font creation while providing analytical insights into design relationships.

Conclusion: This partial-shape approach represents a more efficient paradigm for font generation that reduces input requirements while maintaining the ability to analyze how design elements contribute to complete character structures.

Abstract: This paper proposes a novel model of few-part-shot font generation, which
designs an entire font based on a set of partial design elements, i.e., partial
shapes. Unlike conventional few-shot font generation, which requires entire
character shapes for a couple of character classes, our approach only needs
partial shapes as input. The proposed model not only improves the efficiency of
font creation but also provides insights into how partial design details
influence the entire structure of the individual characters.

</details>


### [82] [Efficient and Accurate Downfacing Visual Inertial Odometry](https://arxiv.org/abs/2509.10021)
*Jonas Kühne,Christian Vogt,Michele Magno,Luca Benini*

Main category: cs.CV

TL;DR: An optimized Visual Inertial Odometry pipeline for micro/nano-UAVs using quantized feature tracking methods on RISC-V SoCs, achieving 3.65x RMSE reduction with real-time performance.


<details>
  <summary>Details</summary>
Motivation: Bridge the gap between high-accuracy VIO pipelines requiring powerful systems and lightweight implementations suitable for microcontrollers on resource-constrained UAV platforms.

Method: Developed VIO pipeline with optimized/quantized feature detection (SuperPoint, PX4FLOW, ORB) for RISC-V SoCs, incorporating rigid body motion model to reduce estimation errors in planar motion.

Result: Achieved 3.65x average RMSE reduction over baseline using ORB tracker on GAP9 SoC; PX4FLOW matched ORB accuracy at lower runtime for speeds <24 pixels/frame.

Conclusion: The pipeline successfully enables high-accuracy VIO on ultra-low-power systems, making it suitable for real-time applications on micro- and nano-UAVs with constrained computational resources.

Abstract: Visual Inertial Odometry (VIO) is a widely used computer vision method that
determines an agent's movement through a camera and an IMU sensor. This paper
presents an efficient and accurate VIO pipeline optimized for applications on
micro- and nano-UAVs. The proposed design incorporates state-of-the-art feature
detection and tracking methods (SuperPoint, PX4FLOW, ORB), all optimized and
quantized for emerging RISC-V-based ultra-low-power parallel systems on chips
(SoCs). Furthermore, by employing a rigid body motion model, the pipeline
reduces estimation errors and achieves improved accuracy in planar motion
scenarios. The pipeline's suitability for real-time VIO is assessed on an
ultra-low-power SoC in terms of compute requirements and tracking accuracy
after quantization. The pipeline, including the three feature tracking methods,
was implemented on the SoC for real-world validation. This design bridges the
gap between high-accuracy VIO pipelines that are traditionally run on
computationally powerful systems and lightweight implementations suitable for
microcontrollers. The optimized pipeline on the GAP9 low-power SoC demonstrates
an average reduction in RMSE of up to a factor of 3.65x over the baseline
pipeline when using the ORB feature tracker. The analysis of the computational
complexity of the feature trackers further shows that PX4FLOW achieves on-par
tracking accuracy with ORB at a lower runtime for movement speeds below 24
pixels/frame.

</details>


### [83] [Hierarchical MLANet: Multi-level Attention for 3D Face Reconstruction From Single Images](https://arxiv.org/abs/2509.10024)
*Danling Cao*

Main category: cs.CV

TL;DR: MLANet: Hierarchical Multi-Level Attention Network for 3D face reconstruction from single in-the-wild images using CNN and attention mechanisms with semi-supervised training.


<details>
  <summary>Details</summary>
Motivation: Addressing challenges in 3D face reconstruction from 2D images due to lack of ground-truth labeled datasets and complexity of real-world environments.

Method: Uses pre-trained hierarchical backbone network with multi-level attention mechanisms, semi-supervised training with 3DMM parameters and differentiable renderer for end-to-end training.

Result: Extensive experiments on AFLW2000-3D and MICC Florence datasets show effectiveness in 3D face reconstruction and alignment tasks, evaluated both quantitatively and qualitatively.

Conclusion: Proposed MLANet effectively reconstructs detailed 3D face models from single in-the-wild images through hierarchical attention mechanisms and semi-supervised training approach.

Abstract: Recovering 3D face models from 2D in-the-wild images has gained considerable
attention in the computer vision community due to its wide range of potential
applications. However, the lack of ground-truth labeled datasets and the
complexity of real-world environments remain significant challenges. In this
chapter, we propose a convolutional neural network-based approach, the
Hierarchical Multi-Level Attention Network (MLANet), for reconstructing 3D face
models from single in-the-wild images. Our model predicts detailed facial
geometry, texture, pose, and illumination parameters from a single image.
Specifically, we employ a pre-trained hierarchical backbone network and
introduce multi-level attention mechanisms at different stages of 2D face image
feature extraction. A semi-supervised training strategy is employed,
incorporating 3D Morphable Model (3DMM) parameters from publicly available
datasets along with a differentiable renderer, enabling an end-to-end training
process. Extensive experiments, including both comparative and ablation
studies, were conducted on two benchmark datasets, AFLW2000-3D and MICC
Florence, focusing on 3D face reconstruction and 3D face alignment tasks. The
effectiveness of the proposed method was evaluated both quantitatively and
qualitatively.

</details>


### [84] [LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization for Real-World Multilingual VQA](https://arxiv.org/abs/2509.10026)
*Jing Huang,Zhiya Tan,Shutao Gong,Fanwei Zeng,Jianshu Li*

Main category: cs.CV

TL;DR: LaV-CoT is a novel multilingual visual question answering framework that combines visual chain-of-thought reasoning with multi-aspect reward optimization, achieving state-of-the-art performance across multiple benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing approaches rely primarily on textual chain-of-thought reasoning and provide limited support for multilingual multimodal reasoning, constraining real-world deployment. There's a need for better interpretable multilingual visual reasoning systems.

Method: LaV-CoT uses a multi-stage reasoning pipeline with text summary, language identification, spatial object-level captioning, and logical reasoning. It employs automated data curation and two-stage training combining supervised fine-tuning with Language-aware Group Relative Policy Optimization guided by multi-aspect rewards.

Result: LaV-CoT achieves up to 9.5% accuracy improvements over open-source baselines, surpasses models with 2x larger scales by 2.6%, and outperforms proprietary models like GPT-4o-0513 and Gemini-2.5-flash. Online A/B tests validate effectiveness for industrial deployment.

Conclusion: LaV-CoT represents a significant advancement in multilingual visual reasoning, demonstrating that language-aware visual chain-of-thought reasoning with multi-aspect reward optimization can achieve superior performance and practical applicability in real-world scenarios.

Abstract: As large vision language models (VLMs) advance, their capabilities in
multilingual visual question answering (mVQA) have significantly improved.
Chain-of-thought (CoT) reasoning has been proven to enhance interpretability
and complex reasoning. However, most existing approaches rely primarily on
textual CoT and provide limited support for multilingual multimodal reasoning,
constraining their deployment in real-world applications. To address this gap,
we introduce \textbf{LaV-CoT}, the first Language-aware Visual CoT framework
with Multi-Aspect Reward Optimization. LaV-CoT incorporates an interpretable
multi-stage reasoning pipeline consisting of Text Summary with Bounding Box
(BBox), Language Identification, Spatial Object-level Captioning, and
Step-by-step Logical Reasoning. Following this reasoning pipeline, we design an
automated data curation method that generates multilingual CoT annotations
through iterative generation, correction, and refinement, enabling scalable and
high-quality training data. To improve reasoning and generalization, LaV-CoT
adopts a two-stage training paradigm combining Supervised Fine-Tuning (SFT)
with Language-aware Group Relative Policy Optimization (GRPO), guided by
verifiable multi-aspect rewards including language consistency, structural
accuracy, and semantic alignment. Extensive evaluations on public datasets
including MMMB, Multilingual MMBench, and MTVQA show that LaV-CoT achieves up
to \(\sim\)9.5\% accuracy improvements over open-source baselines of similar
size and even surpasses models with 2$\times$ larger scales by \(\sim\)2.6\%.
Moreover, LaV-CoT outperforms advanced proprietary models such as GPT-4o-0513
and Gemini-2.5-flash. We further conducted an online A/B test to validate our
method on real-world data, highlighting its effectiveness for industrial
deployment. Our code is available at this link:
\href{https://github.com/HJNVR/LaV-CoT}

</details>


### [85] [Color Me Correctly: Bridging Perceptual Color Spaces and Text Embeddings for Improved Diffusion Generation](https://arxiv.org/abs/2509.10058)
*Sung-Lin Tsai,Bo-Lun Huang,Yu Ting Shen,Cheng Yu Yeo,Chiang Tseng,Bo-Kai Ruan,Wen-Sheng Lien,Hong-Han Shuai*

Main category: cs.CV

TL;DR: Training-free framework using LLM to disambiguate color terms and refine text embeddings in CIELAB space for accurate color alignment in text-to-image generation.


<details>
  <summary>Details</summary>
Motivation: Current diffusion models struggle with nuanced and compound color terms, producing images misaligned with human intent, especially in applications like fashion and design where precise color rendering is critical.

Method: Uses large language model to resolve ambiguous color terms, then refines text embeddings based on spatial relationships in CIELAB color space for precise color blending without additional training or reference images.

Result: Experimental results show improved color alignment without compromising image quality, effectively bridging the gap between text semantics and visual generation.

Conclusion: Proposed framework successfully enhances color fidelity in T2I generation by systematically resolving color ambiguity through LLM disambiguation and CIELAB space optimization, without requiring training or external references.

Abstract: Accurate color alignment in text-to-image (T2I) generation is critical for
applications such as fashion, product visualization, and interior design, yet
current diffusion models struggle with nuanced and compound color terms (e.g.,
Tiffany blue, lime green, hot pink), often producing images that are misaligned
with human intent. Existing approaches rely on cross-attention manipulation,
reference images, or fine-tuning but fail to systematically resolve ambiguous
color descriptions. To precisely render colors under prompt ambiguity, we
propose a training-free framework that enhances color fidelity by leveraging a
large language model (LLM) to disambiguate color-related prompts and guiding
color blending operations directly in the text embedding space. Our method
first employs a large language model (LLM) to resolve ambiguous color terms in
the text prompt, and then refines the text embeddings based on the spatial
relationships of the resulting color terms in the CIELAB color space. Unlike
prior methods, our approach improves color accuracy without requiring
additional training or external reference images. Experimental results
demonstrate that our framework improves color alignment without compromising
image quality, bridging the gap between text semantics and visual generation.

</details>


### [86] [Multimodal Mathematical Reasoning Embedded in Aerial Vehicle Imagery: Benchmarking, Analysis, and Exploration](https://arxiv.org/abs/2509.10059)
*Yue Zhou,Litong Feng,Mengcheng Lan,Xue Yang,Qingyun Li,Yiping Ke,Xue Jiang,Wayne Zhang*

Main category: cs.CV

TL;DR: AVI-Math is the first benchmark for evaluating multimodal mathematical reasoning in aerial vehicle imagery, revealing significant limitations in current vision-language models' mathematical capabilities despite their success on other tasks.


<details>
  <summary>Details</summary>
Motivation: Current vision-language models have not been adequately tested for mathematical reasoning in UAV-based remote sensing applications, which is critical for tasks like distance computations, area calculations, and spatial analysis.

Method: Created AVI-Math benchmark with 3,773 high-quality vehicle-related questions from UAV views, covering 6 mathematical subjects and 20 topics. Evaluated 14 prominent VLMs and explored Chain-of-Thought prompting and fine-tuning techniques.

Result: Despite success on previous multimodal benchmarks, current VLMs struggle significantly with mathematical reasoning tasks in AVI-Math. Chain-of-Thought prompting and fine-tuning show promise but don't fully solve the reasoning challenges.

Conclusion: The study exposes serious limitations in VLMs' mathematical reasoning capabilities and provides valuable insights for advancing UAV-based trustworthy VLMs, with the dataset serving as a foundation for future research in this domain.

Abstract: Mathematical reasoning is critical for tasks such as precise distance and
area computations, trajectory estimations, and spatial analysis in unmanned
aerial vehicle (UAV) based remote sensing, yet current vision-language models
(VLMs) have not been adequately tested in this domain. To address this gap, we
introduce AVI-Math, the first benchmark to rigorously evaluate multimodal
mathematical reasoning in aerial vehicle imagery, moving beyond simple counting
tasks to include domain-specific knowledge in areas such as geometry, logic,
and algebra. The dataset comprises 3,773 high-quality vehicle-related questions
captured from UAV views, covering 6 mathematical subjects and 20 topics. The
data, collected at varying altitudes and from multiple UAV angles, reflects
real-world UAV scenarios, ensuring the diversity and complexity of the
constructed mathematical problems. In this paper, we benchmark 14 prominent
VLMs through a comprehensive evaluation and demonstrate that, despite their
success on previous multimodal benchmarks, these models struggle with the
reasoning tasks in AVI-Math. Our detailed analysis highlights significant
limitations in the mathematical reasoning capabilities of current VLMs and
suggests avenues for future research. Furthermore, we explore the use of
Chain-of-Thought prompting and fine-tuning techniques, which show promise in
addressing the reasoning challenges in AVI-Math. Our findings not only expose
the limitations of VLMs in mathematical reasoning but also offer valuable
insights for advancing UAV-based trustworthy VLMs in real-world applications.
The code, and datasets will be released at
https://github.com/VisionXLab/avi-math

</details>


### [87] [BEVTraj: Map-Free End-to-End Trajectory Prediction in Bird's-Eye View with Deformable Attention and Sparse Goal Proposals](https://arxiv.org/abs/2509.10080)
*Minsang Kong,Myeongjun Kim,Sang Gu Kang,Sang Hun Lee*

Main category: cs.CV

TL;DR: BEVTraj is a novel trajectory prediction framework that operates directly in BEV space using real-time sensor data, eliminating dependency on pre-built HD maps while achieving comparable performance to map-based models.


<details>
  <summary>Details</summary>
Motivation: Existing trajectory prediction methods rely on pre-built HD maps (limited to specific regions) or local map construction modules (may fail to capture critical details or introduce errors), creating limitations in adaptability and accuracy.

Method: The framework uses deformable attention to extract relevant context from dense BEV features and introduces a Sparse Goal Candidate Proposal (SGCP) module for end-to-end prediction without post-processing steps.

Result: Extensive experiments show BEVTraj achieves performance comparable to state-of-the-art HD map-based models while offering greater flexibility by eliminating map dependency.

Conclusion: BEVTraj provides an effective alternative to map-dependent approaches, enabling accurate trajectory prediction with real-time sensor data only, making it more adaptable to various environments and transient changes.

Abstract: In autonomous driving, trajectory prediction is essential for ensuring safe
and efficient navigation. To improve prediction accuracy, recent approaches
often rely on pre-built high-definition (HD) maps or real-time local map
construction modules to incorporate static environmental information. However,
pre-built HD maps are limited to specific regions and cannot adapt to transient
changes. In addition, local map construction modules, which recognize only
predefined elements, may fail to capture critical scene details or introduce
errors that degrade prediction performance. To overcome these limitations, we
propose Bird's-Eye View Trajectory Prediction (BEVTraj), a novel trajectory
prediction framework that operates directly in the bird's-eye view (BEV) space
utilizing real-time sensor data without relying on any pre-built maps. The
BEVTraj leverages deformable attention to efficiently extract relevant context
from dense BEV features. Furthermore, we introduce a Sparse Goal Candidate
Proposal (SGCP) module, which enables full end-to-end prediction without
requiring any post-processing steps. Extensive experiments demonstrate that the
BEVTraj achieves performance comparable to state-of-the-art HD map-based models
while offering greater flexibility by eliminating the dependency on pre-built
maps. The source code is available at https://github.com/Kongminsang/bevtraj.

</details>


### [88] [Leveraging Multi-View Weak Supervision for Occlusion-Aware Multi-Human Parsing](https://arxiv.org/abs/2509.10093)
*Laura Bragagnolo,Matteo Terreran,Leonardo Barcellona,Stefano Ghidoni*

Main category: cs.CV

TL;DR: A novel multi-view training framework that improves multi-human parsing performance in occlusion scenarios by leveraging weak supervision and multi-view consistency loss, achieving up to 4.20% relative improvement over baseline models.


<details>
  <summary>Details</summary>
Motivation: State-of-the-art multi-human parsing approaches struggle significantly with overlapping/occluded human bodies. The intuition is that overlapping people appear separated from different viewpoints, suggesting multi-view information could help improve parsing under occlusions.

Method: Proposes a training framework that exploits multi-view information through weak supervision on human instances and a multi-view consistency loss. Uses a semi-automatic annotation strategy to generate human instance segmentation masks from multi-view RGB+D data and 3D human skeletons.

Result: The approach achieves up to 4.20% relative improvement on human parsing over baseline models in occlusion scenarios.

Conclusion: Multi-view information integration through weak supervision and consistency loss effectively improves multi-human parsing performance in challenging occlusion scenarios where traditional methods struggle.

Abstract: Multi-human parsing is the task of segmenting human body parts while
associating each part to the person it belongs to, combining instance-level and
part-level information for fine-grained human understanding. In this work, we
demonstrate that, while state-of-the-art approaches achieved notable results on
public datasets, they struggle considerably in segmenting people with
overlapping bodies. From the intuition that overlapping people may appear
separated from a different point of view, we propose a novel training framework
exploiting multi-view information to improve multi-human parsing models under
occlusions. Our method integrates such knowledge during the training process,
introducing a novel approach based on weak supervision on human instances and a
multi-view consistency loss. Given the lack of suitable datasets in the
literature, we propose a semi-automatic annotation strategy to generate human
instance segmentation masks from multi-view RGB+D data and 3D human skeletons.
The experiments demonstrate that the approach can achieve up to a 4.20\%
relative improvement on human parsing over the baseline model in occlusion
scenarios.

</details>


### [89] [VARCO-VISION-2.0 Technical Report](https://arxiv.org/abs/2509.10105)
*Young-rok Cha,Jeongho Ju,SunYoung Park,Jong-Hyeon Lee,Younghyun Yu,Youngjune Kim*

Main category: cs.CV

TL;DR: VARCO-VISION-2.0 is an open-weight bilingual vision-language model for Korean and English that improves upon the previous version with multi-image understanding, layout-aware OCR, and enhanced multimodal alignment through four-stage curriculum training.


<details>
  <summary>Details</summary>
Motivation: To advance bilingual vision-language models for Korean and English with improved capabilities in handling complex multimodal inputs like documents, charts, and tables while maintaining language abilities and safety.

Method: Four-stage curriculum training with memory-efficient techniques, supporting multi-image understanding and layout-aware OCR that predicts both text content and spatial location. Includes preference optimization for safety.

Result: Achieves strong spatial grounding and competitive bilingual performance, with the 14B model ranking 8th on OpenCompass VLM leaderboard among comparable-scale models. Also releases a 1.7B version for on-device deployment.

Conclusion: VARCO-VISION-2.0 advances bilingual VLM development with practical applications, offering both full-scale (14B) and lightweight (1.7B) variants available on Hugging Face.

Abstract: We introduce VARCO-VISION-2.0, an open-weight bilingual vision-language model
(VLM) for Korean and English with improved capabilities compared to the
previous model VARCO-VISION-14B. The model supports multi-image understanding
for complex inputs such as documents, charts, and tables, and delivers
layoutaware OCR by predicting both textual content and its spatial location.
Trained with a four-stage curriculum with memory-efficient techniques, the
model achieves enhanced multimodal alignment, while preserving core language
abilities and improving safety via preference optimization. Extensive benchmark
evaluations demonstrate strong spatial grounding and competitive results for
both languages, with the 14B model achieving 8th place on the OpenCompass VLM
leaderboard among models of comparable scale. Alongside the 14B-scale model, we
release a 1.7B version optimized for on-device deployment. We believe these
models advance the development of bilingual VLMs and their practical
applications. Two variants of VARCO-VISION-2.0 are available at Hugging Face: a
full-scale 14B model and a lightweight 1.7B model.

</details>


### [90] [A Lightweight Ensemble-Based Face Image Quality Assessment Method with Correlation-Aware Loss](https://arxiv.org/abs/2509.10114)
*MohammadAli Hamidi,Hadi Amirpour,Luigi Atzori,Christian Timmerer*

Main category: cs.CV

TL;DR: A lightweight face image quality assessment method using ensemble of MobileNetV3-Small and ShuffleNetV2 with correlation-aware loss, achieving high accuracy with low computational cost.


<details>
  <summary>Details</summary>
Motivation: Existing FIQA methods are either not face-specific or computationally intensive, limiting real-world deployment in uncontrolled environments.

Method: Ensemble of two compact CNNs (MobileNetV3-Small and ShuffleNetV2) with prediction-level fusion via averaging, using MSECorrLoss that combines MSE with Pearson correlation regularizer.

Result: Achieves SRCC of 0.9829 and PLCC of 0.9894 on VQualA benchmark while meeting efficiency constraints.

Conclusion: Proposed method provides excellent balance between accuracy and computational efficiency, making it suitable for real-world face recognition systems.

Abstract: Face image quality assessment (FIQA) plays a critical role in face
recognition and verification systems, especially in uncontrolled, real-world
environments. Although several methods have been proposed, general-purpose
no-reference image quality assessment techniques often fail to capture
face-specific degradations. Meanwhile, state-of-the-art FIQA models tend to be
computationally intensive, limiting their practical applicability. We propose a
lightweight and efficient method for FIQA, designed for the perceptual
evaluation of face images in the wild. Our approach integrates an ensemble of
two compact convolutional neural networks, MobileNetV3-Small and ShuffleNetV2,
with prediction-level fusion via simple averaging. To enhance alignment with
human perceptual judgments, we employ a correlation-aware loss (MSECorrLoss),
combining mean squared error (MSE) with a Pearson correlation regularizer. Our
method achieves a strong balance between accuracy and computational cost,
making it suitable for real-world deployment. Experiments on the VQualA FIQA
benchmark demonstrate that our model achieves a Spearman rank correlation
coefficient (SRCC) of 0.9829 and a Pearson linear correlation coefficient
(PLCC) of 0.9894, remaining within competition efficiency constraints.

</details>


### [91] [Realism Control One-step Diffusion for Real-World Image Super-Resolution](https://arxiv.org/abs/2509.10122)
*Zongliang Wu,Siming Zheng,Peng-Tao Jiang,Xin Yuan*

Main category: cs.CV

TL;DR: RCOD is a one-step diffusion framework for real-world image super-resolution that enables explicit control over fidelity-realism trade-offs through latent domain grouping and degradation-aware sampling.


<details>
  <summary>Details</summary>
Motivation: One-step diffusion methods for super-resolution lack flexible control mechanisms to balance fidelity and realism across diverse scenarios, unlike multi-step methods that can adjust sampling steps.

Method: Proposes RCOD with latent domain grouping for explicit fidelity-realism control, degradation-aware sampling strategy, and visual prompt injection module using degradation-aware visual tokens instead of text prompts.

Result: Achieves superior fidelity and perceptual quality while maintaining computational efficiency, outperforming state-of-the-art OSD methods in both quantitative metrics and visual qualities.

Conclusion: RCOD provides flexible realism control capabilities during inference with minimal training modifications, demonstrating effective trade-off management between fidelity and realism in real-world image super-resolution.

Abstract: Pre-trained diffusion models have shown great potential in real-world image
super-resolution (Real-ISR) tasks by enabling high-resolution reconstructions.
While one-step diffusion (OSD) methods significantly improve efficiency
compared to traditional multi-step approaches, they still have limitations in
balancing fidelity and realism across diverse scenarios. Since the OSDs for SR
are usually trained or distilled by a single timestep, they lack flexible
control mechanisms to adaptively prioritize these competing objectives, which
are inherently manageable in multi-step methods through adjusting sampling
steps. To address this challenge, we propose a Realism Controlled One-step
Diffusion (RCOD) framework for Real-ISR. RCOD provides a latent domain grouping
strategy that enables explicit control over fidelity-realism trade-offs during
the noise prediction phase with minimal training paradigm modifications and
original training data. A degradation-aware sampling strategy is also
introduced to align distillation regularization with the grouping strategy and
enhance the controlling of trade-offs. Moreover, a visual prompt injection
module is used to replace conventional text prompts with degradation-aware
visual tokens, enhancing both restoration accuracy and semantic consistency.
Our method achieves superior fidelity and perceptual quality while maintaining
computational efficiency. Extensive experiments demonstrate that RCOD
outperforms state-of-the-art OSD methods in both quantitative metrics and
visual qualities, with flexible realism control capabilities in the inference
stage. The code will be released.

</details>


### [92] [Grad-CL: Source Free Domain Adaptation with Gradient Guided Feature Disalignment](https://arxiv.org/abs/2509.10134)
*Rini Smita Thakur,Rajeev Ranjan Dwivedi,Vinod K Kurmi*

Main category: cs.CV

TL;DR: Grad-CL is a source-free domain adaptation framework for optic disc and cup segmentation that uses gradient-guided pseudolabel refinement and cosine similarity contrastive learning to improve cross-domain performance without accessing source data.


<details>
  <summary>Details</summary>
Motivation: Segmentation models trained on one dataset suffer performance degradation when applied to target data from different imaging protocols or conditions, which is critical for glaucoma diagnosis.

Method: Two-stage approach: 1) Gradient-guided pseudolabel refinement using class-specific features for uncertainty quantification and prototype estimation, 2) Cosine similarity-based contrastive learning to enforce inter-class separability between optic cup and disc features.

Result: Outperforms state-of-the-art unsupervised and source-free domain adaptation methods on challenging cross-domain fundus imaging datasets with superior segmentation accuracy and improved boundary delineation.

Conclusion: Grad-CL provides an effective source-free domain adaptation solution for medical image segmentation that maintains performance across different imaging conditions without requiring access to original source data.

Abstract: Accurate segmentation of the optic disc and cup is critical for the early
diagnosis and management of ocular diseases such as glaucoma. However,
segmentation models trained on one dataset often suffer significant performance
degradation when applied to target data acquired under different imaging
protocols or conditions. To address this challenge, we propose
\textbf{Grad-CL}, a novel source-free domain adaptation framework that
leverages a pre-trained source model and unlabeled target data to robustly
adapt segmentation performance without requiring access to the original source
data. Grad-CL combines a gradient-guided pseudolabel refinement module with a
cosine similarity-based contrastive learning strategy. In the first stage,
salient class-specific features are extracted via a gradient-based mechanism,
enabling more accurate uncertainty quantification and robust prototype
estimation for refining noisy pseudolabels. In the second stage, a contrastive
loss based on cosine similarity is employed to explicitly enforce inter-class
separability between the gradient-informed features of the optic cup and disc.
Extensive experiments on challenging cross-domain fundus imaging datasets
demonstrate that Grad-CL outperforms state-of-the-art unsupervised and
source-free domain adaptation methods, achieving superior segmentation accuracy
and improved boundary delineation. Project and code are available at
https://visdomlab.github.io/GCL/.

</details>


### [93] [Scalable Training for Vector-Quantized Networks with 100% Codebook Utilization](https://arxiv.org/abs/2509.10140)
*Yifan Chang,Jie Qin,Limeng Qiao,Xiaofeng Wang,Zheng Zhu,Lin Ma,Xingang Wang*

Main category: cs.CV

TL;DR: VQBridge is a novel projector that enables 100% codebook usage in vector quantization networks, achieving state-of-the-art reconstruction and significantly improving image generation performance when integrated with LlamaGen.


<details>
  <summary>Details</summary>
Motivation: Vector quantization training suffers from instability due to straight-through estimation bias, one-step-behind updates, and sparse codebook gradients, leading to suboptimal reconstruction and low codebook usage.

Method: Proposes VQBridge, a robust projector based on map function method that optimizes code vectors through a compress-process-recover pipeline, combined with learning annealing to achieve full codebook usage.

Result: Achieves 100% codebook usage even with 262k-codebook, state-of-the-art reconstruction performance, consistent improvement with larger codebooks/higher channels/longer training, and enhances image generation by surpassing VAR by 0.5 and DiT by 0.2 rFID.

Conclusion: FVQ demonstrates that high-quality tokenizers with full codebook usage are crucial for strong autoregressive image generation, providing an effective, scalable, and generalizable solution to VQ training challenges.

Abstract: Vector quantization (VQ) is a key component in discrete tokenizers for image
generation, but its training is often unstable due to straight-through
estimation bias, one-step-behind updates, and sparse codebook gradients, which
lead to suboptimal reconstruction performance and low codebook usage. In this
work, we analyze these fundamental challenges and provide a simple yet
effective solution. To maintain high codebook usage in VQ networks (VQN) during
learning annealing and codebook size expansion, we propose VQBridge, a robust,
scalable, and efficient projector based on the map function method. VQBridge
optimizes code vectors through a compress-process-recover pipeline, enabling
stable and effective codebook training. By combining VQBridge with learning
annealing, our VQN achieves full (100%) codebook usage across diverse codebook
configurations, which we refer to as FVQ (FullVQ). Through extensive
experiments, we demonstrate that FVQ is effective, scalable, and generalizable:
it attains 100% codebook usage even with a 262k-codebook, achieves
state-of-the-art reconstruction performance, consistently improves with larger
codebooks, higher vector channels, or longer training, and remains effective
across different VQ variants. Moreover, when integrated with LlamaGen, FVQ
significantly enhances image generation performance, surpassing visual
autoregressive models (VAR) by 0.5 and diffusion models (DiT) by 0.2 rFID,
highlighting the importance of high-quality tokenizers for strong
autoregressive image generation.

</details>


### [94] [LayerLock: Non-collapsing Representation Learning with Progressive Freezing](https://arxiv.org/abs/2509.10156)
*Goker Erdogan,Nikhil Parthasarathy,Catalin Ionescu,Drew Hudson,Alexander Lerchner,Andrew Zisserman,Mehdi Sajjadi,Joao Carreira*

Main category: cs.CV

TL;DR: LayerLock is a self-supervised learning method that accelerates masked-autoencoding by progressively freezing ViT layers based on their convergence order, enabling efficient latent prediction without representation collapse.


<details>
  <summary>Details</summary>
Motivation: The authors observed that during video masked-autoencoding training, ViT layers converge sequentially by depth (shallow layers first, deep layers later), and sought to exploit this pattern to accelerate training and enable effective latent prediction.

Method: Progressive layer freezing with an explicit schedule based on layer convergence order. The approach freezes shallower layers first as they converge early, then progressively freezes deeper layers throughout training.

Result: Applied to models up to 4B parameters, LayerLock surpassed non-latent masked prediction performance on the 4DS perception suite while avoiding representation collapse issues.

Conclusion: LayerLock provides a simple, scalable approach for self-supervised visual representation learning that effectively leverages the natural convergence pattern of ViT layers to accelerate training and enable stable latent prediction.

Abstract: We introduce LayerLock, a simple yet effective approach for self-supervised
visual representation learning, that gradually transitions from pixel to latent
prediction through progressive layer freezing. First, we make the observation
that during training of video masked-autoencoding (MAE) models, ViT layers
converge in the order of their depth: shallower layers converge early, deeper
layers converge late. We then show that this observation can be exploited to
accelerate standard MAE by progressively freezing the model according to an
explicit schedule, throughout training. Furthermore, this same schedule can be
used in a simple and scalable approach to latent prediction that does not
suffer from "representation collapse". We apply our proposed approach,
LayerLock, to large models of up to 4B parameters with results surpassing those
of non-latent masked prediction on the 4DS perception suite.

</details>


### [95] [On the Geometric Accuracy of Implicit and Primitive-based Representations Derived from View Rendering Constraints](https://arxiv.org/abs/2509.10241)
*Elias De Smijter,Renaud Detry,Christophe De Vleeschouwer*

Main category: cs.CV

TL;DR: Appearance embeddings improve photometric fidelity but don't enhance geometric accuracy in 3D reconstruction for space robotics. Convex splatting provides more compact representations than Gaussian splatting.


<details>
  <summary>Details</summary>
Motivation: To systematically compare implicit and explicit Novel View Synthesis methods for space-based 3D object reconstruction and evaluate the role of appearance embeddings in geometric accuracy for space robotics applications.

Method: Used the SPEED+ dataset to compare K-Planes, Gaussian Splatting, and Convex Splatting methods, analyzing how appearance embeddings affect both photometric fidelity and geometric accuracy.

Result: Embeddings primarily reduce the number of primitives needed for explicit methods rather than enhancing geometric fidelity. Convex splatting achieves more compact and clutter-free representations than Gaussian splatting.

Conclusion: Appearance embeddings have limited benefits for geometry-centric tasks in space scenarios. Convex splatting offers advantages for safety-critical applications like interaction and collision avoidance due to its efficient representation.

Abstract: We present the first systematic comparison of implicit and explicit Novel
View Synthesis methods for space-based 3D object reconstruction, evaluating the
role of appearance embeddings. While embeddings improve photometric fidelity by
modeling lighting variation, we show they do not translate into meaningful
gains in geometric accuracy - a critical requirement for space robotics
applications. Using the SPEED+ dataset, we compare K-Planes, Gaussian
Splatting, and Convex Splatting, and demonstrate that embeddings primarily
reduce the number of primitives needed for explicit methods rather than
enhancing geometric fidelity. Moreover, convex splatting achieves more compact
and clutter-free representations than Gaussian splatting, offering advantages
for safety-critical applications such as interaction and collision avoidance.
Our findings clarify the limits of appearance embeddings for geometry-centric
tasks and highlight trade-offs between reconstruction quality and
representation efficiency in space scenarios.

</details>


### [96] [GAMMA: Generalizable Alignment via Multi-task and Manipulation-Augmented Training for AI-Generated Image Detection](https://arxiv.org/abs/2509.10250)
*Haozhen Yan,Yan Hong,Suning Lang,Jiahui Zhan,Yikun Ji,Yujie Gao,Jun Lan,Huijia Zhu,Weiqiang Wang,Jianfu Zhang*

Main category: cs.CV

TL;DR: GAMMA is a novel training framework for AI-generated image detection that improves generalization to unseen generative models by reducing domain bias and enhancing semantic alignment through diverse manipulation strategies and multi-task supervision.


<details>
  <summary>Details</summary>
Motivation: Existing AI-generated image detectors struggle with generalization to unseen generative models due to reliance on generation-specific artifacts like stylistic priors and compression patterns.

Method: Proposes GAMMA framework with diverse manipulation strategies (inpainting-based manipulation, semantics-preserving perturbations), multi-task supervision with dual segmentation heads and classification head, and reverse cross-attention mechanism for segmentation heads to guide classification.

Result: Achieves state-of-the-art generalization performance on GenImage benchmark with 5.8% accuracy improvement and maintains strong robustness on newly released models like GPT-4o.

Conclusion: GAMMA effectively addresses generalization limitations in AI-generated image detection by reducing domain bias and improving semantic alignment through innovative training strategies and architectural components.

Abstract: With generative models becoming increasingly sophisticated and diverse,
detecting AI-generated images has become increasingly challenging. While
existing AI-genereted Image detectors achieve promising performance on
in-distribution generated images, their generalization to unseen generative
models remains limited. This limitation is largely attributed to their reliance
on generation-specific artifacts, such as stylistic priors and compression
patterns. To address these limitations, we propose GAMMA, a novel training
framework designed to reduce domain bias and enhance semantic alignment. GAMMA
introduces diverse manipulation strategies, such as inpainting-based
manipulation and semantics-preserving perturbations, to ensure consistency
between manipulated and authentic content. We employ multi-task supervision
with dual segmentation heads and a classification head, enabling pixel-level
source attribution across diverse generative domains. In addition, a reverse
cross-attention mechanism is introduced to allow the segmentation heads to
guide and correct biased representations in the classification branch. Our
method achieves state-of-the-art generalization performance on the GenImage
benchmark, imporving accuracy by 5.8%, but also maintains strong robustness on
newly released generative model such as GPT-4o.

</details>


### [97] [Robustness and Diagnostic Performance of Super-Resolution Fetal Brain MRI](https://arxiv.org/abs/2509.10257)
*Ema Masterl,Tina Vipotnik Vesnaver,Žiga Špiclin*

Main category: cs.CV

TL;DR: Comparative analysis of three fetal brain MRI super-resolution reconstruction methods (NiftyMIC, SVRTK, NeSVoR) shows NeSVoR has highest success rate (>90%) and robustness across healthy and pathological cases, while diagnostic classification for ventriculomegaly remains unaffected by SRR method choice despite volumetric differences.


<details>
  <summary>Details</summary>
Motivation: Fetal brain MRI suffers from low resolution, motion artifacts, and inadequate 3D anatomy capture. While SRR methods exist to address these limitations, their comparative performance in pathological cases and impact on downstream analysis remain underexplored.

Method: Applied three state-of-the-art SRR methods (NiftyMIC, SVRTK, NeSVoR) to 140 fetal brain MRI scans including healthy controls and pathological cases with ventriculomegaly. Reconstructed volumes were segmented using BoUNTi algorithm to extract volumes of nine brain structures, then evaluated for visual quality, success rates, volumetric agreement, and diagnostic classification.

Result: NeSVoR demonstrated highest reconstruction success rate (>90%) across both healthy and pathological groups. Significant volumetric differences were observed between SRR methods, but classification performance for ventriculomegaly was not affected by SRR method choice.

Conclusion: NeSVoR shows superior robustness for fetal brain MRI reconstruction, and diagnostic performance remains resilient despite SRR-induced volumetric variability, making it a reliable choice for clinical applications.

Abstract: Fetal brain MRI relies on rapid multi-view 2D slice acquisitions to reduce
motion artifacts caused by fetal movement. However, these stacks are typically
low resolution, may suffer from motion corruption, and do not adequately
capture 3D anatomy. Super-resolution reconstruction (SRR) methods aim to
address these limitations by combining slice-to-volume registration and
super-resolution techniques to generate high-resolution (HR) 3D volumes. While
several SRR methods have been proposed, their comparative performance -
particularly in pathological cases - and their influence on downstream
volumetric analysis and diagnostic tasks remain underexplored. In this study,
we applied three state-of-the-art SRR method - NiftyMIC, SVRTK, and NeSVoR - to
140 fetal brain MRI scans, including both healthy controls (HC) and
pathological cases (PC) with ventriculomegaly (VM). Each HR reconstruction was
segmented using the BoUNTi algorithm to extract volumes of nine principal brain
structures. We evaluated visual quality, SRR success rates, volumetric
measurement agreement, and diagnostic classification performance. NeSVoR
demonstrated the highest and most consistent reconstruction success rate (>90%)
across both HC and PC groups. Although significant differences in volumetric
estimates were observed between SRR methods, classification performance for VM
was not affected by the choice of SRR method. These findings highlight NeSVoR's
robustness and the resilience of diagnostic performance despite SRR-induced
volumetric variability.

</details>


### [98] [Mask Consistency Regularization in Object Removal](https://arxiv.org/abs/2509.10259)
*Hua Yuan,Jin Yuan,Yicheng Jiang,Yao Zhang,Xin Geng,Yong Rui*

Main category: cs.CV

TL;DR: Proposes Mask Consistency Regularization (MCR) to address mask hallucination and mask-shape bias in object removal tasks using diffusion models, through dilation and reshape mask perturbations during training.


<details>
  <summary>Details</summary>
Motivation: Current diffusion models for object removal suffer from mask hallucination (generating irrelevant content) and mask-shape bias (filling masked area with objects that mimic mask shape rather than surrounding context).

Method: Introduces Mask Consistency Regularization (MCR) with two mask perturbations: dilation (to align output with surrounding content) and reshape (to break mask-shape bias), enforcing consistency between outputs of perturbed branches and original mask.

Result: Experiments show MCR significantly reduces hallucinations and mask-shape bias, leading to improved performance in object removal tasks.

Conclusion: MCR is an effective training strategy that produces more robust and contextually coherent inpainting results for object removal by addressing key challenges in current diffusion-based methods.

Abstract: Object removal, a challenging task within image inpainting, involves
seamlessly filling the removed region with content that matches the surrounding
context. Despite advancements in diffusion models, current methods still face
two critical challenges. The first is mask hallucination, where the model
generates irrelevant or spurious content inside the masked region, and the
second is mask-shape bias, where the model fills the masked area with an object
that mimics the mask's shape rather than surrounding content. To address these
issues, we propose Mask Consistency Regularization (MCR), a novel training
strategy designed specifically for object removal tasks. During training, our
approach introduces two mask perturbations: dilation and reshape, enforcing
consistency between the outputs of these perturbed branches and the original
mask. The dilated masks help align the model's output with the surrounding
content, while reshaped masks encourage the model to break the mask-shape bias.
This combination of strategies enables MCR to produce more robust and
contextually coherent inpainting results. Our experiments demonstrate that MCR
significantly reduces hallucinations and mask-shape bias, leading to improved
performance in object removal.

</details>


### [99] [MagicMirror: A Large-Scale Dataset and Benchmark for Fine-Grained Artifacts Assessment in Text-to-Image Generation](https://arxiv.org/abs/2509.10260)
*Jia Wang,Jie Hu,Xiaoqi Ma,Hanghang Ma,Yanbing Zeng,Xiaoming Wei*

Main category: cs.CV

TL;DR: MagicMirror is a comprehensive framework for assessing physical artifacts in text-to-image generation, featuring a detailed artifact taxonomy, large-scale annotated dataset (MagicData340K), trained VLM assessor (MagicAssessor), and automated benchmark (MagicBench) that reveals significant artifact issues in current top models.


<details>
  <summary>Details</summary>
Motivation: Text-to-image generation has made progress but suffers from persistent physical artifacts (anatomical/structural flaws) that degrade quality and limit applications. Current benchmarks lack systematic evaluation of these diverse artifacts.

Method: 1) Established detailed artifact taxonomy 2) Created MagicData340K - 340K human-annotated images with fine-grained artifact labels 3) Trained MagicAssessor VLM using novel data sampling and multi-level reward system with GRPO 4) Built MagicBench automated benchmark for T2I model evaluation

Result: Evaluation with MagicBench shows that even top-tier models like GPT-image-1 consistently suffer from significant artifacts, demonstrating that artifact reduction remains a critical challenge for T2I development.

Conclusion: MagicMirror provides the first comprehensive framework for systematic artifact assessment in T2I generation, revealing that current models still struggle with physical artifacts despite their widespread adoption, highlighting the need for continued focus on artifact reduction.

Abstract: Text-to-image (T2I) generation has achieved remarkable progress in
instruction following and aesthetics. However, a persistent challenge is the
prevalence of physical artifacts, such as anatomical and structural flaws,
which severely degrade perceptual quality and limit application. Given the
diversity and complexity of these artifacts, a systematic and fine-grained
evaluation framework is required, which is lacking in current benchmarks. To
fill this gap, we introduce MagicMirror, a comprehensive framework for
artifacts assessment. We first establish a detailed taxonomy of generated image
artifacts. Guided by this taxonomy, we manually annotate MagicData340K, the
first human-annotated large-scale dataset of 340K generated images with
fine-grained artifact labels. Building on this dataset, we train MagicAssessor,
a Vision-Language Model (VLM) that provides detailed assessments and
corresponding labels. To overcome challenges like class imbalance and reward
hacking, we design a novel data sampling strategy and a multi-level reward
system for Group Relative Policy Optimization (GRPO). Finally, we leverage
MagicAssessor to construct MagicBench, an automated benchmark for evaluating
the image artifacts of current T2I models. Our evaluation with MagicBench
reveals that despite their widespread adoption, even top-tier models like
GPT-image-1 are consistently plagued by significant artifacts, highlighting
artifact reduction as a critical frontier for future T2I development. Project
page: https://wj-inf.github.io/MagicMirror-page/.

</details>


### [100] [SignClip: Leveraging Mouthing Cues for Sign Language Translation by Multimodal Contrastive Fusion](https://arxiv.org/abs/2509.10266)
*Wenfang Wu,Tingting Yuan,Yupeng Li,Daling Wang,Xiaoming Fu*

Main category: cs.CV

TL;DR: SignClip improves sign language translation by fusing manual (hand gestures) and non-manual (lip movements) cues with hierarchical contrastive learning, achieving state-of-the-art results on benchmark datasets.


<details>
  <summary>Details</summary>
Motivation: Most current sign language translation approaches focus only on manual signals and overlook non-manual cues like mouthing, which are essential for disambiguating visually similar signs and conveying linguistic information.

Method: Proposes SignClip framework that fuses spatial gesture and lip movement features, and introduces hierarchical contrastive learning with multi-level alignment objectives for semantic consistency across sign-lip and visual-text modalities.

Result: On PHOENIX14T dataset in gloss-free setting, SignClip improves BLEU-4 from 24.32 to 24.71 and ROUGE from 46.57 to 48.38, surpassing previous state-of-the-art model SpaMo. Similar improvements shown on How2Sign dataset.

Conclusion: Incorporating both manual and non-manual cues with hierarchical contrastive learning significantly improves sign language translation accuracy, demonstrating the importance of mouthing information in SLT systems.

Abstract: Sign language translation (SLT) aims to translate natural language from sign
language videos, serving as a vital bridge for inclusive communication. While
recent advances leverage powerful visual backbones and large language models,
most approaches mainly focus on manual signals (hand gestures) and tend to
overlook non-manual cues like mouthing. In fact, mouthing conveys essential
linguistic information in sign languages and plays a crucial role in
disambiguating visually similar signs. In this paper, we propose SignClip, a
novel framework to improve the accuracy of sign language translation. It fuses
manual and non-manual cues, specifically spatial gesture and lip movement
features. Besides, SignClip introduces a hierarchical contrastive learning
framework with multi-level alignment objectives, ensuring semantic consistency
across sign-lip and visual-text modalities. Extensive experiments on two
benchmark datasets, PHOENIX14T and How2Sign, demonstrate the superiority of our
approach. For example, on PHOENIX14T, in the Gloss-free setting, SignClip
surpasses the previous state-of-the-art model SpaMo, improving BLEU-4 from
24.32 to 24.71, and ROUGE from 46.57 to 48.38.

</details>


### [101] [Detecting Text Manipulation in Images using Vision Language Models](https://arxiv.org/abs/2509.10278)
*Vidit Vidit,Pavel Korshunov,Amir Mohammadi,Christophe Ecabert,Ketan Kotwal,Sébastien Marcel*

Main category: cs.CV

TL;DR: Analysis of VLMs for text manipulation detection showing open-source models lag behind closed-source ones like GPT-4o, with generalization issues in specialized models.


<details>
  <summary>Details</summary>
Motivation: To bridge the knowledge gap in text manipulation detection using VLMs, as previous studies focused mainly on image manipulation detection.

Method: Benchmarked closed- and open-source VLMs on different text manipulation datasets, including in-the-wild scene texts and fantasy ID cards that mimic real-world misuse scenarios.

Result: Open-source models are improving but still behind closed-source models like GPT-4o. Image manipulation detection-specific VLMs suffer from generalization problems when applied to text manipulation tasks.

Conclusion: There is a significant performance gap between open-source and closed-source VLMs for text manipulation detection, and specialized models need better generalization capabilities for cross-domain applications.

Abstract: Recent works have shown the effectiveness of Large Vision Language Models
(VLMs or LVLMs) in image manipulation detection. However, text manipulation
detection is largely missing in these studies. We bridge this knowledge gap by
analyzing closed- and open-source VLMs on different text manipulation datasets.
Our results suggest that open-source models are getting closer, but still
behind closed-source ones like GPT- 4o. Additionally, we benchmark image
manipulation detection-specific VLMs for text manipulation detection and show
that they suffer from the generalization problem. We benchmark VLMs for
manipulations done on in-the-wild scene texts and on fantasy ID cards, where
the latter mimic a challenging real-world misuse.

</details>


### [102] [MCL-AD: Multimodal Collaboration Learning for Zero-Shot 3D Anomaly Detection](https://arxiv.org/abs/2509.10282)
*Gang Li,Tianjiao Chen,Mingle Zhou,Min Li,Delong Han,Jin Wan*

Main category: cs.CV

TL;DR: MCL-AD is a novel zero-shot 3D anomaly detection framework that leverages multimodal collaboration across point clouds, RGB images, and text semantics to achieve superior performance without labeled training data.


<details>
  <summary>Details</summary>
Motivation: Existing methods focus only on point clouds, neglecting rich semantic cues from complementary modalities like RGB images and text priors, which limits performance in data-scarce scenarios.

Method: Proposes Multimodal Prompt Learning Mechanism (MPLM) with object-agnostic decoupled text prompts and multimodal contrastive loss, plus Collaborative Modulation Mechanism (CMM) to jointly modulate RGB image-guided and point cloud-guided branches.

Result: Extensive experiments demonstrate state-of-the-art performance in zero-shot 3D anomaly detection.

Conclusion: MCL-AD effectively leverages multimodal collaboration across point clouds, RGB images, and text to achieve superior zero-shot 3D anomaly detection performance.

Abstract: Zero-shot 3D (ZS-3D) anomaly detection aims to identify defects in 3D objects
without relying on labeled training data, making it especially valuable in
scenarios constrained by data scarcity, privacy, or high annotation cost.
However, most existing methods focus exclusively on point clouds, neglecting
the rich semantic cues available from complementary modalities such as RGB
images and texts priors. This paper introduces MCL-AD, a novel framework that
leverages multimodal collaboration learning across point clouds, RGB images,
and texts semantics to achieve superior zero-shot 3D anomaly detection.
Specifically, we propose a Multimodal Prompt Learning Mechanism (MPLM) that
enhances the intra-modal representation capability and inter-modal
collaborative learning by introducing an object-agnostic decoupled text prompt
and a multimodal contrastive loss. In addition, a collaborative modulation
mechanism (CMM) is proposed to fully leverage the complementary representations
of point clouds and RGB images by jointly modulating the RGB image-guided and
point cloud-guided branches. Extensive experiments demonstrate that the
proposed MCL-AD framework achieves state-of-the-art performance in ZS-3D
anomaly detection.

</details>


### [103] [Adversarial robustness through Lipschitz-Guided Stochastic Depth in Neural Networks](https://arxiv.org/abs/2509.10298)
*Laith Nayal,Mahmoud Mousatat,Bader Rasheed*

Main category: cs.CV

TL;DR: Lipschitz-guided stochastic depth method with depth-dependent drop probabilities improves adversarial robustness while maintaining clean accuracy and reducing computation in Vision Transformers.


<details>
  <summary>Details</summary>
Motivation: Deep neural networks and Vision Transformers achieve state-of-the-art performance but are highly vulnerable to adversarial perturbations, while standard defenses often incur high computational cost or lack formal guarantees.

Method: Propose a Lipschitz-guided stochastic depth (DropPath) method where drop probabilities increase with depth to control the effective Lipschitz constant of the network, regularizing deeper layers.

Result: Experiments on CIFAR-10 with ViT-Tiny show maintained near-baseline clean accuracy, enhanced robustness under FGSM, PGD-20, and AutoAttack attacks, and significant FLOPs reduction compared to baseline and linear DropPath schedules.

Conclusion: The proposed depth-dependent drop schedule effectively improves adversarial robustness while preserving clean performance and reducing computational costs in Vision Transformers.

Abstract: Deep neural networks and Vision Transformers achieve state-of-the-art
performance in computer vision but are highly vulnerable to adversarial
perturbations. Standard defenses often incur high computational cost or lack
formal guarantees. We propose a Lipschitz-guided stochastic depth (DropPath)
method, where drop probabilities increase with depth to control the effective
Lipschitz constant of the network. This approach regularizes deeper layers,
improving robustness while preserving clean accuracy and reducing computation.
Experiments on CIFAR-10 with ViT-Tiny show that our custom depth-dependent
schedule maintains near-baseline clean accuracy, enhances robustness under
FGSM, PGD-20, and AutoAttack, and significantly reduces FLOPs compared to
baseline and linear DropPath schedules.

</details>


### [104] [A Stochastic Birth-and-Death Approach for Street Furniture Geolocation in Urban Environments](https://arxiv.org/abs/2509.10310)
*Evan Murphy,Marco Viola,Vladimir A. Krylov*

Main category: cs.CV

TL;DR: Probabilistic framework using energy maps for precise geolocation of street furniture in urban environments, integrating GIS data and using stochastic birth-and-death optimization.


<details>
  <summary>Details</summary>
Motivation: Effective monitoring and maintenance of public infrastructure requires precise geolocation of street furniture in complex urban environments.

Method: Energy maps encode spatial likelihood of object locations, integrated with external geospatial information (GIS layers, road maps). Stochastic birth-and-death optimization algorithm infers most probable asset configurations.

Result: Evaluated using realistic simulation based on geolocated street lighting data in Dublin, showing potential for scalable and accurate urban asset mapping.

Conclusion: The proposed framework enables improved contextual awareness and localization accuracy for urban infrastructure management, with algorithm implementation made publicly available.

Abstract: In this paper we address the problem of precise geolocation of street
furniture in complex urban environments, which is a critical task for effective
monitoring and maintenance of public infrastructure by local authorities and
private stakeholders. To this end, we propose a probabilistic framework based
on energy maps that encode the spatial likelihood of object locations.
Representing the energy in a map-based geopositioned format allows the
optimisation process to seamlessly integrate external geospatial information,
such as GIS layers, road maps, or placement constraints, which improves
contextual awareness and localisation accuracy. A stochastic birth-and-death
optimisation algorithm is introduced to infer the most probable configuration
of assets. We evaluate our approach using a realistic simulation informed by a
geolocated dataset of street lighting infrastructure in Dublin city centre,
demonstrating its potential for scalable and accurate urban asset mapping. The
implementation of the algorithm will be made available in the GitHub repository
https://github.com/EMurphy0108/SBD_Street_Furniture.

</details>


### [105] [Compute Only 16 Tokens in One Timestep: Accelerating Diffusion Transformers with Cluster-Driven Feature Caching](https://arxiv.org/abs/2509.10312)
*Zhixin Zheng,Xinyu Wang,Chang Zou,Shaobo Wang,Linfeng Zhang*

Main category: cs.CV

TL;DR: ClusCa accelerates diffusion transformers by performing spatial clustering to reduce token computation by over 90%, achieving 4.96x speedup on FLUX with improved image quality.


<details>
  <summary>Details</summary>
Motivation: Diffusion transformers suffer from high computational costs due to iterative denoising, and existing feature caching methods only leverage temporal similarity while ignoring spatial similarity.

Method: Cluster-Driven Feature Caching (ClusCa) performs spatial clustering on tokens in each timestep, computes only one token per cluster, and propagates the information to all other tokens in the cluster.

Result: Achieves 4.96x acceleration on FLUX with 99.49% ImageReward (0.51% improvement over original), reduces tokens by over 90%, works on DiT, FLUX and HunyuanVideo without training requirements.

Conclusion: ClusCa provides an effective orthogonal approach to existing feature caching methods by leveraging spatial similarity, significantly accelerating diffusion transformers while maintaining or improving output quality.

Abstract: Diffusion transformers have gained significant attention in recent years for
their ability to generate high-quality images and videos, yet still suffer from
a huge computational cost due to their iterative denoising process. Recently,
feature caching has been introduced to accelerate diffusion transformers by
caching the feature computation in previous timesteps and reusing it in the
following timesteps, which leverage the temporal similarity of diffusion models
while ignoring the similarity in the spatial dimension. In this paper, we
introduce Cluster-Driven Feature Caching (ClusCa) as an orthogonal and
complementary perspective for previous feature caching. Specifically, ClusCa
performs spatial clustering on tokens in each timestep, computes only one token
in each cluster and propagates their information to all the other tokens, which
is able to reduce the number of tokens by over 90%. Extensive experiments on
DiT, FLUX and HunyuanVideo demonstrate its effectiveness in both text-to-image
and text-to-video generation. Besides, it can be directly applied to any
diffusion transformer without requirements for training. For instance, ClusCa
achieves 4.96x acceleration on FLUX with an ImageReward of 99.49%, surpassing
the original model by 0.51%. The code is available at
https://github.com/Shenyi-Z/Cache4Diffusion.

</details>


### [106] [I-Segmenter: Integer-Only Vision Transformer for Efficient Semantic Segmentation](https://arxiv.org/abs/2509.10334)
*Jordan Sassoon,Michal Szczepanski,Martyna Poreba*

Main category: cs.CV

TL;DR: I-Segmenter is the first fully integer-only Vision Transformer for semantic segmentation that achieves near-FP32 accuracy while significantly reducing model size and enabling faster inference through systematic integer-only operations and novel activation functions.


<details>
  <summary>Details</summary>
Motivation: Vision Transformers for semantic segmentation have high memory and computational costs that limit deployment on resource-constrained devices. Quantization helps but ViT-based segmentation models are fragile under low precision due to quantization error accumulation.

Method: Built on Segmenter architecture, systematically replaces floating-point operations with integer-only counterparts. Introduces λ-ShiftGELU activation function to handle long-tailed distributions, removes L2 normalization, and replaces bilinear interpolation with nearest neighbor upsampling for full integer-only execution.

Result: Achieves accuracy within 5.1% of FP32 baseline on average, reduces model size by up to 3.8x, enables 1.2x faster inference. Works well even with one-shot PTQ using a single calibration image.

Conclusion: I-Segmenter provides a practical integer-only solution for ViT segmentation that maintains competitive accuracy while significantly improving efficiency, making it suitable for real-world deployment on resource-constrained devices.

Abstract: Vision Transformers (ViTs) have recently achieved strong results in semantic
segmentation, yet their deployment on resource-constrained devices remains
limited due to their high memory footprint and computational cost. Quantization
offers an effective strategy to improve efficiency, but ViT-based segmentation
models are notoriously fragile under low precision, as quantization errors
accumulate across deep encoder-decoder pipelines. We introduce I-Segmenter, the
first fully integer-only ViT segmentation framework. Building on the Segmenter
architecture, I-Segmenter systematically replaces floating-point operations
with integer-only counterparts. To further stabilize both training and
inference, we propose $\lambda$-ShiftGELU, a novel activation function that
mitigates the limitations of uniform quantization in handling long-tailed
activation distributions. In addition, we remove the L2 normalization layer and
replace bilinear interpolation in the decoder with nearest neighbor upsampling,
ensuring integer-only execution throughout the computational graph. Extensive
experiments show that I-Segmenter achieves accuracy within a reasonable margin
of its FP32 baseline (5.1 % on average), while reducing model size by up to
3.8x and enabling up to 1.2x faster inference with optimized runtimes. Notably,
even in one-shot PTQ with a single calibration image, I-Segmenter delivers
competitive accuracy, underscoring its practicality for real-world deployment.

</details>


### [107] [GARD: Gamma-based Anatomical Restoration and Denoising for Retinal OCT](https://arxiv.org/abs/2509.10341)
*Botond Fazekas,Thomas Pinetz,Guilherme Aresta,Taha Emre,Hrvoje Bogunovic*

Main category: cs.CV

TL;DR: GARD is a novel deep learning approach using Gamma-based diffusion models for OCT image denoising, outperforming traditional methods by better preserving anatomical details while reducing speckle noise.


<details>
  <summary>Details</summary>
Motivation: OCT images suffer from speckle noise that obscures fine details and hinders accurate diagnosis. Existing denoising methods struggle to balance noise reduction with preservation of crucial anatomical structures.

Method: GARD uses a Denoising Diffusion Gamma Model (instead of Gaussian) to better reflect speckle statistics, incorporates a Noise-Reduced Fidelity Term using pre-processed images to guide denoising, and adapts the Denoising Diffusion Implicit Model framework for accelerated inference.

Result: GARD significantly outperforms traditional denoising methods and state-of-the-art deep learning models in PSNR, SSIM, and MSE metrics. Qualitative results show sharper edges and better preservation of fine anatomical details.

Conclusion: GARD provides an effective solution for OCT image despeckling by accurately modeling speckle statistics and preventing noise reintroduction, resulting in superior image quality and structural preservation compared to existing methods.

Abstract: Optical Coherence Tomography (OCT) is a vital imaging modality for diagnosing
and monitoring retinal diseases. However, OCT images are inherently degraded by
speckle noise, which obscures fine details and hinders accurate interpretation.
While numerous denoising methods exist, many struggle to balance noise
reduction with the preservation of crucial anatomical structures. This paper
introduces GARD (Gamma-based Anatomical Restoration and Denoising), a novel
deep learning approach for OCT image despeckling that leverages the strengths
of diffusion probabilistic models. Unlike conventional diffusion models that
assume Gaussian noise, GARD employs a Denoising Diffusion Gamma Model to more
accurately reflect the statistical properties of speckle. Furthermore, we
introduce a Noise-Reduced Fidelity Term that utilizes a pre-processed,
less-noisy image to guide the denoising process. This crucial addition prevents
the reintroduction of high-frequency noise. We accelerate the inference process
by adapting the Denoising Diffusion Implicit Model framework to our Gamma-based
model. Experiments on a dataset with paired noisy and less-noisy OCT B-scans
demonstrate that GARD significantly outperforms traditional denoising methods
and state-of-the-art deep learning models in terms of PSNR, SSIM, and MSE.
Qualitative results confirm that GARD produces sharper edges and better
preserves fine anatomical details.

</details>


### [108] [GLAM: Geometry-Guided Local Alignment for Multi-View VLP in Mammography](https://arxiv.org/abs/2509.10344)
*Yuexi Du,Lihui Chen,Nicha C. Dvornek*

Main category: cs.CV

TL;DR: GLAM is a novel visual language model that uses geometry-guided global and local alignment for multi-view mammography analysis, outperforming existing methods by properly modeling cross-view relationships.


<details>
  <summary>Details</summary>
Motivation: Current mammography VLMs adapted from natural images ignore domain-specific multi-view relationships that radiologists use, losing critical geometric context and resulting in suboptimal performance.

Method: Proposes GLAM framework with geometry guidance for VLM pretraining, learning local cross-view alignments and fine-grained features through joint global/local, visual-visual, and visual-language contrastive learning.

Result: Outperforms baseline models across multiple datasets under different settings when pretrained on EMBED, one of the largest open mammography datasets.

Conclusion: The geometry-guided approach effectively captures multi-view relationships in mammography, demonstrating superior performance over methods that treat views independently or fail to model cross-view correspondence properly.

Abstract: Mammography screening is an essential tool for early detection of breast
cancer. The speed and accuracy of mammography interpretation have the potential
to be improved with deep learning methods. However, the development of a
foundation visual language model (VLM) is hindered by limited data and domain
differences between natural and medical images. Existing mammography VLMs,
adapted from natural images, often ignore domain-specific characteristics, such
as multi-view relationships in mammography. Unlike radiologists who analyze
both views together to process ipsilateral correspondence, current methods
treat them as independent images or do not properly model the multi-view
correspondence learning, losing critical geometric context and resulting in
suboptimal prediction. We propose GLAM: Global and Local Alignment for
Multi-view mammography for VLM pretraining using geometry guidance. By
leveraging the prior knowledge about the multi-view imaging process of
mammograms, our model learns local cross-view alignments and fine-grained local
features through joint global and local, visual-visual, and visual-language
contrastive learning. Pretrained on EMBED [14], one of the largest open
mammography datasets, our model outperforms baselines across multiple datasets
under different settings.

</details>


### [109] [Towards Understanding Visual Grounding in Visual Language Models](https://arxiv.org/abs/2509.10345)
*Georgios Pantazopoulos,Eda B. Özyiğit*

Main category: cs.CV

TL;DR: Survey paper reviewing visual grounding in modern vision language models, covering importance, core components, applications, benchmarks, and future research directions.


<details>
  <summary>Details</summary>
Motivation: Visual grounding enables models to identify image regions matching textual descriptions, which is crucial for applications like referring expression comprehension, visual question answering, and multimodal control in various domains.

Method: The paper reviews representative works across key research areas, outlines the importance of grounding, delineates core components of contemporary grounded model development, and examines practical applications including benchmarks and evaluation metrics.

Result: The survey provides comprehensive analysis of visual grounding in VLMs, examining interrelations among visual grounding, multimodal chain-of-thought, and reasoning, while identifying current challenges.

Conclusion: The paper analyzes challenges in visual grounding and suggests promising directions for future research to advance grounded multimodal generation capabilities.

Abstract: Visual grounding refers to the ability of a model to identify a region within
some visual input that matches a textual description. Consequently, a model
equipped with visual grounding capabilities can target a wide range of
applications in various domains, including referring expression comprehension,
answering questions pertinent to fine-grained details in images or videos,
caption visual context by explicitly referring to entities, as well as low and
high-level control in simulated and real environments. In this survey paper, we
review representative works across the key areas of research on modern
general-purpose vision language models (VLMs). We first outline the importance
of grounding in VLMs, then delineate the core components of the contemporary
paradigm for developing grounded models, and examine their practical
applications, including benchmarks and evaluation metrics for grounded
multimodal generation. We also discuss the multifaceted interrelations among
visual grounding, multimodal chain-of-thought, and reasoning in VLMs. Finally,
we analyse the challenges inherent to visual grounding and suggest promising
directions for future research.

</details>


### [110] [Immunizing Images from Text to Image Editing via Adversarial Cross-Attention](https://arxiv.org/abs/2509.10359)
*Matteo Trippodo,Federico Becattini,Lorenzo Seidenari*

Main category: cs.CV

TL;DR: Attention Attack disrupts text-based image editing by using auto-generated image captions to break cross-attention alignment between visual content and text prompts, without needing to know the editing method or prompt.


<details>
  <summary>Details</summary>
Motivation: Text-based image editing methods are vulnerable to adversarial attacks, and existing approaches require knowledge of the editing prompt or method. The authors aim to create a more practical attack that works without this information.

Method: The attack uses automatically generated captions of source images as proxy prompts to disrupt cross-attention mechanisms between visual representations and textual descriptions. It breaks content-text alignment without requiring editing method knowledge.

Result: Experiments on TEDBench++ show the attack significantly degrades editing performance while remaining imperceptible. The authors also propose two new evaluation metrics: Caption Similarity and semantic IoU.

Conclusion: Attention Attack effectively compromises text-based image editing systems by targeting cross-attention mechanisms, demonstrating vulnerabilities in current methods and highlighting the need for more robust editing frameworks.

Abstract: Recent advances in text-based image editing have enabled fine-grained
manipulation of visual content guided by natural language. However, such
methods are susceptible to adversarial attacks. In this work, we propose a
novel attack that targets the visual component of editing methods. We introduce
Attention Attack, which disrupts the cross-attention between a textual prompt
and the visual representation of the image by using an automatically generated
caption of the source image as a proxy for the edit prompt. This breaks the
alignment between the contents of the image and their textual description,
without requiring knowledge of the editing method or the editing prompt.
Reflecting on the reliability of existing metrics for immunization success, we
propose two novel evaluation strategies: Caption Similarity, which quantifies
semantic consistency between original and adversarial edits, and semantic
Intersection over Union (IoU), which measures spatial layout disruption via
segmentation masks. Experiments conducted on the TEDBench++ benchmark
demonstrate that our attack significantly degrades editing performance while
remaining imperceptible.

</details>


### [111] [Efficient Learned Image Compression Through Knowledge Distillation](https://arxiv.org/abs/2509.10366)
*Fabien Allemand,Attilio Fiandrotti,Sumanta Chaudhuri,Alaa Eddine Mazouz*

Main category: cs.CV

TL;DR: Knowledge distillation reduces neural network image compression resource requirements while maintaining performance across different architectures and quality/bitrate tradeoffs.


<details>
  <summary>Details</summary>
Motivation: Neural network-based image compression outperforms conventional codecs but requires significant processing power, making it unsuitable for real-time use on resource-constrained platforms.

Method: Leverage knowledge distillation where smaller neural networks are trained on outputs of larger, more complex models to achieve better performance than independent training.

Result: Demonstrates effective application of knowledge distillation for image compression across various architecture sizes, achieving different quality/bitrate tradeoffs while saving processing and energy resources.

Conclusion: Knowledge distillation successfully reduces resource requirements for neural image compression, with potential for future exploration of different teacher models, loss functions, and extension to transformer-based models.

Abstract: Learned image compression sits at the intersection of machine learning and
image processing. With advances in deep learning, neural network-based
compression methods have emerged. In this process, an encoder maps the image to
a low-dimensional latent space, which is then quantized, entropy-coded into a
binary bitstream, and transmitted to the receiver. At the receiver end, the
bitstream is entropy-decoded, and a decoder reconstructs an approximation of
the original image. Recent research suggests that these models consistently
outperform conventional codecs. However, they require significant processing
power, making them unsuitable for real-time use on resource-constrained
platforms, which hinders their deployment in mainstream applications. This
study aims to reduce the resource requirements of neural networks used for
image compression by leveraging knowledge distillation, a training paradigm
where smaller neural networks, partially trained on the outputs of larger, more
complex models, can achieve better performance than when trained independently.
Our work demonstrates that knowledge distillation can be effectively applied to
image compression tasks: i) across various architecture sizes, ii) to achieve
different image quality/bit rate tradeoffs, and iii) to save processing and
energy resources. This approach introduces new settings and hyperparameters,
and future research could explore the impact of different teacher models, as
well as alternative loss functions. Knowledge distillation could also be
extended to transformer-based models. The code is publicly available at:
https://github.com/FABallemand/PRIM .

</details>


### [112] [Ordinality of Visible-Thermal Image Intensities for Intrinsic Image Decomposition](https://arxiv.org/abs/2509.10388)
*Zeqing Leo Yuan,Mani Ramanagopal,Aswin C. Sankaranarayanan,Srinivasa G. Narasimhan*

Main category: cs.CV

TL;DR: Training-free intrinsic image decomposition using visible-thermal image pairs, leveraging thermal absorption to derive ordinal supervision for shading and reflectance recovery.


<details>
  <summary>Details</summary>
Motivation: Lack of extensive ground-truth data for real-world intrinsic image decomposition, with existing methods relying on synthetic data or sparse annotations for limited scenes.

Method: Uses visible-thermal image pairs and the principle that absorbed light becomes heat detected by thermal cameras. Relates ordinalities between visible and thermal intensities to shading/reflectance ordinalities to densely self-supervise an optimizing neural network.

Result: Superior performance over recent learning-based models in quantitative evaluations with known reflectance/shading under natural/artificial lighting, and qualitative experiments across diverse outdoor scenes.

Conclusion: Provides a scalable path to curating real-world ordinal supervision previously infeasible via manual labeling, enabling effective intrinsic image decomposition without extensive training data.

Abstract: Decomposing an image into its intrinsic photometric factors--shading and
reflectance--is a long-standing challenge due to the lack of extensive
ground-truth data for real-world scenes. Recent methods rely on synthetic data
or sparse annotations for limited indoor and even fewer outdoor scenes. We
introduce a novel training-free approach for intrinsic image decomposition
using only a pair of visible and thermal images. We leverage the principle that
light not reflected from an opaque surface is absorbed and detected as heat by
a thermal camera. This allows us to relate the ordinalities between visible and
thermal image intensities to the ordinalities of shading and reflectance, which
can densely self-supervise an optimizing neural network to recover shading and
reflectance. We perform quantitative evaluations with known reflectance and
shading under natural and artificial lighting, and qualitative experiments
across diverse outdoor scenes. The results demonstrate superior performance
over recent learning-based models and point toward a scalable path to curating
real-world ordinal supervision, previously infeasible via manual labeling.

</details>


### [113] [Compressed Video Quality Enhancement: Classifying and Benchmarking over Standards](https://arxiv.org/abs/2509.10407)
*Xiem HoangVan,Dang BuiDinh,Sang NguyenQuang,Wen-Hsiao Peng*

Main category: cs.CV

TL;DR: This paper presents a comprehensive survey on compressed video quality enhancement (CVQE) methods, addressing limitations in existing surveys by providing a systematic taxonomy, unified benchmarking framework, and analysis of performance-complexity trade-offs.


<details>
  <summary>Details</summary>
Motivation: Existing CVQE surveys lack systematic classification linking methods to specific standards and artifacts, insufficient comparative analysis across architectural paradigms, and underdeveloped benchmarking practices.

Method: The paper introduces a novel taxonomy classifying CVQE methods across architectural paradigms, coding standards, and compressed-domain feature utilization. It also proposes a unified benchmarking framework with modern compression protocols and standard test sequences.

Result: The survey provides systematic analysis of critical trade-offs between reconstruction performance and computational complexity in state-of-the-art CVQE methods.

Conclusion: This comprehensive review establishes a foundation for consistent assessment and informed model selection in CVQE research and deployment, while highlighting promising directions for future research.

Abstract: Compressed video quality enhancement (CVQE) is crucial for improving user
experience with lossy video codecs like H.264/AVC, H.265/HEVC, and H.266/VVC.
While deep learning based CVQE has driven significant progress, existing
surveys still suffer from limitations: lack of systematic classification
linking methods to specific standards and artifacts, insufficient comparative
analysis of architectural paradigms across coding types, and underdeveloped
benchmarking practices. To address these gaps, this paper presents three key
contributions. First, it introduces a novel taxonomy classifying CVQE methods
across architectural paradigms, coding standards, and compressed-domain feature
utilization. Second, it proposes a unified benchmarking framework integrating
modern compression protocols and standard test sequences for fair
multi-criteria evaluation. Third, it provides a systematic analysis of the
critical trade-offs between reconstruction performance and computational
complexity observed in state-of-the-art methods and highlighting promising
directions for future research. This comprehensive review aims to establish a
foundation for consistent assessment and informed model selection in CVQE
research and deployment.

</details>


### [114] [Multimodal SAM-adapter for Semantic Segmentation](https://arxiv.org/abs/2509.10408)
*Iacopo Curti,Pierluigi Zama Ramirez,Alioscia Petrelli,Luigi Di Stefano*

Main category: cs.CV

TL;DR: MM SAM-adapter extends Segment Anything Model for multimodal semantic segmentation using adapter network to fuse auxiliary sensor data with RGB features, achieving state-of-the-art performance on challenging benchmarks.


<details>
  <summary>Details</summary>
Motivation: Current semantic segmentation methods are vulnerable to challenging conditions like poor lighting, occlusions, and adverse weather. Multimodal approaches that integrate auxiliary sensor data can provide complementary information to enhance robustness.

Method: Proposes MM SAM-adapter framework that uses an adapter network to inject fused multimodal features (LiDAR, infrared, etc.) into SAM's RGB features. This allows retaining RGB generalization while selectively incorporating auxiliary modalities when beneficial.

Result: Achieves state-of-the-art performance on three challenging benchmarks (DeLiVER, FMB, MUSES). Outperforms competing methods in both RGB-easy and RGB-hard subsets, demonstrating effectiveness in both favorable and adverse conditions.

Conclusion: The framework provides balanced and efficient use of multimodal information for robust scene understanding. The adapter-based approach successfully extends SAM's capabilities for multimodal semantic segmentation while maintaining its generalization strengths.

Abstract: Semantic segmentation, a key task in computer vision with broad applications
in autonomous driving, medical imaging, and robotics, has advanced
substantially with deep learning. Nevertheless, current approaches remain
vulnerable to challenging conditions such as poor lighting, occlusions, and
adverse weather. To address these limitations, multimodal methods that
integrate auxiliary sensor data (e.g., LiDAR, infrared) have recently emerged,
providing complementary information that enhances robustness. In this work, we
present MM SAM-adapter, a novel framework that extends the capabilities of the
Segment Anything Model (SAM) for multimodal semantic segmentation. The proposed
method employs an adapter network that injects fused multimodal features into
SAM's rich RGB features. This design enables the model to retain the strong
generalization ability of RGB features while selectively incorporating
auxiliary modalities only when they contribute additional cues. As a result, MM
SAM-adapter achieves a balanced and efficient use of multimodal information. We
evaluate our approach on three challenging benchmarks, DeLiVER, FMB, and MUSES,
where MM SAM-adapter delivers state-of-the-art performance. To further analyze
modality contributions, we partition DeLiVER and FMB into RGB-easy and RGB-hard
subsets. Results consistently demonstrate that our framework outperforms
competing methods in both favorable and adverse conditions, highlighting the
effectiveness of multimodal adaptation for robust scene understanding. The code
is available at the following link:
https://github.com/iacopo97/Multimodal-SAM-Adapter.

</details>


### [115] [InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis](https://arxiv.org/abs/2509.10441)
*Tao Han,Wanghan Xu,Junchao Gong,Xiaoyu Yue,Song Guo,Luping Zhou,Lei Bai*

Main category: cs.CV

TL;DR: InfGen is a new method that enables arbitrary resolution image generation from fixed-size latents using a one-step generator, reducing 4K generation time from over 100 seconds to under 10 seconds without retraining diffusion models.


<details>
  <summary>Details</summary>
Motivation: Current diffusion models have quadratic computational complexity with resolution, making high-resolution generation (like 4K) slow and resource-intensive, taking over 100 seconds for 4K images.

Method: Replaces VAE decoder with a new one-step generator that decodes arbitrary resolution images from fixed-size latent representations generated by diffusion models, maintaining compatibility with existing latent spaces.

Result: InfGen reduces 4K image generation time to under 10 seconds while enabling arbitrary resolution generation without retraining existing diffusion models.

Conclusion: The approach successfully bridges diffusion models to the arbitrary high-resolution era with significantly improved efficiency and can be applied to any model using the same latent space.

Abstract: Arbitrary resolution image generation provides a consistent visual experience
across devices, having extensive applications for producers and consumers.
Current diffusion models increase computational demand quadratically with
resolution, causing 4K image generation delays over 100 seconds. To solve this,
we explore the second generation upon the latent diffusion models, where the
fixed latent generated by diffusion models is regarded as the content
representation and we propose to decode arbitrary resolution images with a
compact generated latent using a one-step generator. Thus, we present the
\textbf{InfGen}, replacing the VAE decoder with the new generator, for
generating images at any resolution from a fixed-size latent without retraining
the diffusion models, which simplifies the process, reducing computational
complexity and can be applied to any model using the same latent space.
Experiments show InfGen is capable of improving many models into the arbitrary
high-resolution era while cutting 4K image generation time to under 10 seconds.

</details>


### [116] [SSL-AD: Spatiotemporal Self-Supervised Learning for Generalizability and Adaptability Across Alzheimer's Prediction Tasks and Datasets](https://arxiv.org/abs/2509.10453)
*Emily Kaczmarek,Justin Szeto,Brennan Nichyporuk,Tal Arbel*

Main category: cs.CV

TL;DR: Self-supervised learning model for Alzheimer's prediction using 3D brain MRI with temporal order prediction and contrastive learning, outperforming supervised methods on most tasks while handling variable-length inputs and time intervals.


<details>
  <summary>Details</summary>
Motivation: Existing deep learning models for Alzheimer's prediction are limited by scarce labeled data, poor generalization across datasets, and inability to handle varying numbers of input scans and time intervals between scans.

Method: Adapted three state-of-the-art temporal SSL approaches for 3D brain MRI analysis with novel extensions for variable-length inputs and robust spatial feature learning. Pre-trained on aggregated dataset of 3,161 patients from four public datasets.

Result: SSL model with temporal order prediction and contrastive learning outperformed supervised learning on 6 out of 7 downstream tasks including diagnosis classification, conversion detection, and future conversion prediction.

Conclusion: The SSL approach demonstrates superior adaptability and generalizability across tasks and varying input conditions, showing strong potential for robust clinical applications in Alzheimer's disease prediction.

Abstract: Alzheimer's disease is a progressive, neurodegenerative disorder that causes
memory loss and cognitive decline. While there has been extensive research in
applying deep learning models to Alzheimer's prediction tasks, these models
remain limited by lack of available labeled data, poor generalization across
datasets, and inflexibility to varying numbers of input scans and time
intervals between scans. In this study, we adapt three state-of-the-art
temporal self-supervised learning (SSL) approaches for 3D brain MRI analysis,
and add novel extensions designed to handle variable-length inputs and learn
robust spatial features. We aggregate four publicly available datasets
comprising 3,161 patients for pre-training, and show the performance of our
model across multiple Alzheimer's prediction tasks including diagnosis
classification, conversion detection, and future conversion prediction.
Importantly, our SSL model implemented with temporal order prediction and
contrastive learning outperforms supervised learning on six out of seven
downstream tasks. It demonstrates adaptability and generalizability across
tasks and number of input images with varying time intervals, highlighting its
capacity for robust performance across clinical applications. We release our
code and model publicly at https://github.com/emilykaczmarek/SSL-AD.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [117] [Clip Your Sequences Fairly: Enforcing Length Fairness for Sequence-Level RL](https://arxiv.org/abs/2509.09177)
*Hanyi Mao,Quanjia Xiao,Lei Pang,Haixiao Liu*

Main category: cs.LG

TL;DR: FSPO is a sequence-level RL method that addresses length bias in LLM training by introducing length-fair clipping in importance-sampling weight space, outperforming existing baselines.


<details>
  <summary>Details</summary>
Motivation: Existing sequence-level RL methods like PPO/GRPO suffer from systematic length bias where fixed clip ranges unfairly reweight short vs long responses, distorting the optimization objective.

Method: FSPO introduces length-fair clipping by using a Gaussian-motivated approach that clips sequence log-IS ratios with a band that applies KL-corrected drift and scales as √L to ensure fairness across different response lengths.

Result: Empirical results show FSPO flattens clip rates across length bins, stabilizes training, and outperforms all baseline methods across multiple evaluation datasets.

Conclusion: FSPO successfully addresses length fairness in sequence-level RL for LLMs through theoretically-grounded clipping that maintains directional alignment between clipped and true updates while improving performance.

Abstract: We propose FSPO (Fair Sequence Policy Optimization), a sequence-level
reinforcement learning method for LLMs that enforces length-fair clipping
directly in the importance-sampling (IS) weight space. We revisit
sequence-level RL methods and identify a mismatch when PPO/GRPO-style clipping
is transplanted to sequences: a fixed clip range systematically reweights short
vs. long responses, distorting the effective objective. Theoretically, we
formalize length fairness via a Length Reweighting Error (LRE) and prove that
small LRE yields a directional cosine guarantee between the clipped and true
updates. FSPO introduces a simple, Gaussian-motivated remedy: we clip the
sequence log-IS ratio with a band that applies a KL-corrected drift term and
scales as $\sqrt{L}$. Empirically, FSPO flattens clip rates across length bins,
stabilizes training, and outperforms all baselines across multiple evaluation
datasets.

</details>


### [118] [Latency and Token-Aware Test-Time Compute](https://arxiv.org/abs/2509.09864)
*Jenny Y. Huang,Mehul Damani,Yousef El-Kurdi,Ramon Astudillo,Wei Sun*

Main category: cs.LG

TL;DR: A framework for dynamic compute allocation in LLM inference that optimizes both accuracy and latency by selecting the best generation strategy (parallel vs incremental) per query.


<details>
  <summary>Details</summary>
Motivation: Existing inference-time scaling methods focus only on parallel generation and ignore latency, which is critical for user experience and agentic workflows requiring multiple efficient queries.

Method: Formulates inference-time scaling as dynamic compute allocation and method selection problem, incorporating both token cost and wall-clock latency. Decides which strategy to apply and how much compute to allocate per query.

Result: Experiments on reasoning benchmarks show the approach consistently outperforms static strategies, achieving favorable accuracy-cost trade-offs while remaining practical for deployment.

Conclusion: Dynamic allocation framework provides superior performance by optimizing both accuracy and latency, making it suitable for real-world deployment where both computational efficiency and user experience matter.

Abstract: Inference-time scaling has emerged as a powerful way to improve large
language model (LLM) performance by generating multiple candidate responses and
selecting among them. However, existing work on dynamic allocation for
test-time compute typically considers only parallel generation methods such as
best-of-N, overlooking incremental decoding methods like beam search, and has
largely ignored latency, focusing only on token usage. We formulate
inference-time scaling as a problem of dynamic compute allocation and method
selection, where the system must decide which strategy to apply and how much
compute to allocate on a per-query basis. Our framework explicitly incorporates
both token cost and wall-clock latency, the latter being critical for user
experience and particularly for agentic workflows where models must issue
multiple queries efficiently. Experiments on reasoning benchmarks show that our
approach consistently outperforms static strategies, achieving favorable
accuracy-cost trade-offs while remaining practical for deployment.

</details>


### [119] [LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios](https://arxiv.org/abs/2509.09926)
*Jiahao Chen,Zhiyuan Huang,Yurou Liu,Bing Su*

Main category: cs.LG

TL;DR: LoFT framework extends long-tailed semi-supervised learning to foundation model fine-tuning, generating more reliable pseudo-labels and handling open-world scenarios with OOD samples.


<details>
  <summary>Details</summary>
Motivation: Existing LTSSL methods train from scratch, leading to overconfidence and low-quality pseudo-labels. Foundation model fine-tuning can address these issues and handle more practical open-world scenarios.

Method: Proposes LoFT (parameter-efficient fine-tuning of foundation models) and LoFT-OW for open-world scenarios with OOD samples. Uses foundation models to generate reliable pseudo-labels for imbalanced learning.

Result: Superior performance on multiple benchmarks, achieving better results even when using only 1% of unlabeled data compared to previous methods.

Conclusion: Fine-tuning foundation models for LTSSL produces more reliable pseudo-labels and effectively handles open-world scenarios, demonstrating significant improvements over traditional approaches.

Abstract: Long-tailed learning has garnered increasing attention due to its wide
applicability in real-world scenarios. Among existing approaches, Long-Tailed
Semi-Supervised Learning (LTSSL) has emerged as an effective solution by
incorporating a large amount of unlabeled data into the imbalanced labeled
dataset. However, most prior LTSSL methods are designed to train models from
scratch, which often leads to issues such as overconfidence and low-quality
pseudo-labels. To address these challenges, we extend LTSSL into the foundation
model fine-tuning paradigm and propose a novel framework: LoFT (Long-tailed
semi-supervised learning via parameter-efficient Fine-Tuning). We demonstrate
that fine-tuned foundation models can generate more reliable pseudolabels,
thereby benefiting imbalanced learning. Furthermore, we explore a more
practical setting by investigating semi-supervised learning under open-world
conditions, where the unlabeled data may include out-of-distribution (OOD)
samples. To handle this problem, we propose LoFT-OW (LoFT under Open-World
scenarios) to improve the discriminative ability. Experimental results on
multiple benchmarks demonstrate that our method achieves superior performance
compared to previous approaches, even when utilizing only 1\% of the unlabeled
data compared with previous works.

</details>


### [120] [Adaptive Token Merging for Efficient Transformer Semantic Communication at the Edge](https://arxiv.org/abs/2509.09955)
*Omar Erak,Omar Alhussein,Hatem Abou-Zeid,Mehdi Bennis,Sami Muhaidat*

Main category: cs.LG

TL;DR: Training-free adaptive token merging framework that compresses transformer representations by merging redundant tokens based on input redundancy, achieving significant efficiency gains while maintaining accuracy.


<details>
  <summary>Details</summary>
Motivation: Large transformers have high computational and communication costs that hinder deployment on resource-constrained edge devices, requiring efficient compression methods.

Method: Adaptive token merging with per-layer similarity thresholds, cast as multi-objective optimization using Bayesian optimization to find Pareto-optimal trade-offs between accuracy, inference cost, and communication cost.

Result: 30% fewer FLOPs and under 20% original communication cost on ImageNet while matching accuracy; competitive performance with LLaVA at <1/3 compute and <1/10 bandwidth for VQA; robust across channel conditions with privacy benefits against model inversion attacks.

Conclusion: Provides practical and versatile solution for deploying transformers in resource-limited edge intelligence scenarios through adaptive, training-free compression.

Abstract: Large-scale transformers are central to modern semantic communication, yet
their high computational and communication costs hinder deployment on
resource-constrained edge devices. This paper introduces a training-free
framework for adaptive token merging, a novel mechanism that compresses
transformer representations at runtime by selectively merging semantically
redundant tokens under per-layer similarity thresholds. Unlike prior
fixed-ratio reduction, our approach couples merging directly to input
redundancy, enabling data-dependent adaptation that balances efficiency and
task relevance without retraining. We cast the discovery of merging strategies
as a multi-objective optimization problem and leverage Bayesian optimization to
obtain Pareto-optimal trade-offs between accuracy, inference cost, and
communication cost. On ImageNet classification, we match the accuracy of the
unmodified transformer with 30\% fewer floating-point operations per second and
under 20\% of the original communication cost, while for visual question
answering our method achieves performance competitive with the full LLaVA model
at less than one-third of the compute and one-tenth of the bandwidth. Finally,
we show that our adaptive merging is robust across varying channel conditions
and provides inherent privacy benefits, substantially degrading the efficacy of
model inversion attacks. Our framework provides a practical and versatile
solution for deploying powerful transformer models in resource-limited edge
intelligence scenarios.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [121] [Differential Robustness in Transformer Language Models: Empirical Evaluation Under Adversarial Text Attacks](https://arxiv.org/abs/2509.09706)
*Taniya Gidatkar,Oluwaseun Ajao,Matthew Shardlow*

Main category: cs.CR

TL;DR: Study evaluates LLM resilience against adversarial attacks, finding RoBERTa-Base and Flan-T5 highly robust (0% attack success) while BERT-Base is vulnerable (93.75% success rate).


<details>
  <summary>Details</summary>
Motivation: To assess the security and robustness of large language models against adversarial attacks and identify vulnerabilities in current safeguarding approaches.

Method: Used TextFooler and BERTAttack tools to systematically test adversarial attacks on Flan-T5, BERT, and RoBERTa-Base models.

Result: RoBERTa-Base and FlanT5 showed remarkable resilience with 0% attack success rates, while BERT-Base was highly vulnerable with TextFooler achieving 93.75% success rate, reducing accuracy from 48% to 3%.

Conclusion: Some LLMs have effective defenses but require substantial computational resources; study identifies security strengths/weaknesses and proposes recommendations for more efficient defensive strategies.

Abstract: This study evaluates the resilience of large language models (LLMs) against
adversarial attacks, specifically focusing on Flan-T5, BERT, and RoBERTa-Base.
Using systematically designed adversarial tests through TextFooler and
BERTAttack, we found significant variations in model robustness. RoBERTa-Base
and FlanT5 demonstrated remarkable resilience, maintaining accuracy even when
subjected to sophisticated attacks, with attack success rates of 0%. In
contrast. BERT-Base showed considerable vulnerability, with TextFooler
achieving a 93.75% success rate in reducing model accuracy from 48% to just 3%.
Our research reveals that while certain LLMs have developed effective defensive
mechanisms, these safeguards often require substantial computational resources.
This study contributes to the understanding of LLM security by identifying
existing strengths and weaknesses in current safeguarding approaches and
proposes practical recommendations for developing more efficient and effective
defensive strategies.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [122] [DB3 Team's Solution For Meta KDD Cup' 25](https://arxiv.org/abs/2509.09681)
*Yikuan Xia,Jiazun Chen,Yirui Zhan,Suifeng Zhao,Weipeng Jiang,Chaorui Zhang,Wei Han,Bo Bai,Jun Gao*

Main category: cs.IR

TL;DR: Winning solution for Meta CRAG-MM Challenge 2025 featuring multi-modal retrieval pipelines and advanced LLM-tuning for hallucination control, achieving top rankings across all tasks.


<details>
  <summary>Details</summary>
Motivation: To address the unique challenges of multi-modal, multi-turn question answering in the CRAG-MM benchmark, particularly handling image-indexed knowledge graphs, web sources, and ego-centric queries.

Method: Developed comprehensive framework with domain-specific retrieval pipelines for different tasks and unified LLM-tuning approach using SFT, DPO, and RL for advanced refusal training and hallucination control.

Result: Achieved 2nd place in Task 1, 2nd place in Task 2, and 1st place in Task 3, securing the grand prize for excellence in ego-centric queries through superior handling of first-person perspective challenges.

Conclusion: The integrated approach combining tailored retrieval pipelines with advanced LLM-tuning techniques proved highly effective for multi-modal, multi-turn QA, particularly excelling in handling ego-centric queries and first-person perspective challenges.

Abstract: This paper presents the db3 team's winning solution for the Meta CRAG-MM
Challenge 2025 at KDD Cup'25. Addressing the challenge's unique multi-modal,
multi-turn question answering benchmark (CRAG-MM), we developed a comprehensive
framework that integrates tailored retrieval pipelines for different tasks with
a unified LLM-tuning approach for hallucination control. Our solution features
(1) domain-specific retrieval pipelines handling image-indexed knowledge
graphs, web sources, and multi-turn conversations; and (2) advanced refusal
training using SFT, DPO, and RL. The system achieved 2nd place in Task 1, 2nd
place in Task 2, and 1st place in Task 3, securing the grand prize for
excellence in ego-centric queries through superior handling of first-person
perspective challenges.

</details>


### [123] [Text-to-SQL Oriented to the Process Mining Domain: A PT-EN Dataset for Query Translation](https://arxiv.org/abs/2509.09684)
*Bruno Yui Yamate,Thais Rodrigues Neubauer,Marcelo Fantinato,Sarajane Marques Peres*

Main category: cs.IR

TL;DR: A bilingual Portuguese-English benchmark dataset for text-to-SQL conversion in process mining domain with 1,655 utterances and 205 SQL statements.


<details>
  <summary>Details</summary>
Motivation: To facilitate natural language querying of databases for process mining, making it accessible to non-SQL experts and improving productivity for experts by addressing domain-specific challenges.

Method: Manual curation by experts, professional translations, detailed annotation process, and baseline study using GPT-3.5 Turbo to demonstrate feasibility.

Result: Created a comprehensive dataset that supports evaluation of text-to-SQL implementations and shows broader applicability for semantic parsing and NLP tasks.

Conclusion: text-2-SQL-4-PM is a valuable benchmark that enables nuanced analysis of task complexity and demonstrates utility for text-to-SQL applications in process mining.

Abstract: This paper introduces text-2-SQL-4-PM, a bilingual (Portuguese-English)
benchmark dataset designed for the text-to-SQL task in the process mining
domain. Text-to-SQL conversion facilitates natural language querying of
databases, increasing accessibility for users without SQL expertise and
productivity for those that are experts. The text-2-SQL-4-PM dataset is
customized to address the unique challenges of process mining, including
specialized vocabularies and single-table relational structures derived from
event logs. The dataset comprises 1,655 natural language utterances, including
human-generated paraphrases, 205 SQL statements, and ten qualifiers. Methods
include manual curation by experts, professional translations, and a detailed
annotation process to enable nuanced analyses of task complexity. Additionally,
a baseline study using GPT-3.5 Turbo demonstrates the feasibility and utility
of the dataset for text-to-SQL applications. The results show that
text-2-SQL-4-PM supports evaluation of text-to-SQL implementations, offering
broader applicability for semantic parsing and other natural language
processing tasks.

</details>


### [124] [AI-Powered Assistant for Long-Term Access to RHIC Knowledge](https://arxiv.org/abs/2509.09688)
*Mohammad Atif,Vincent Garonne,Eric Lancon,Jerome Lauret,Alexandr Prozorov,Michal Vranovsky*

Main category: cs.IR

TL;DR: RHIC develops AI assistant using LLMs with RAG to preserve and provide natural language access to 1EB of heavy ion collision data for reproducibility and future research.


<details>
  <summary>Details</summary>
Motivation: Preserve RHIC's 25 years of scientific data (~1EB) and embedded knowledge to support reproducibility, education, and future discoveries as the collider concludes operations.

Method: Built AI-powered assistant using Large Language Models with Retrieval-Augmented Generation and Model Context Protocol, indexing both structured and unstructured content from RHIC experiments.

Result: Successfully deployed system with good computational performance, ongoing multi-experiment integration, and sustainable/explainable AI architecture for long-term access.

Conclusion: Modern AI/ML tools can transform usability and discoverability of scientific legacy data, demonstrating effective preservation of large-scale experimental knowledge.

Abstract: As the Relativistic Heavy Ion Collider (RHIC) at Brookhaven National
Laboratory concludes 25 years of operation, preserving not only its vast data
holdings ($\sim$1 ExaByte) but also the embedded scientific knowledge becomes a
critical priority. The RHIC Data and Analysis Preservation Plan (DAPP)
introduces an AI-powered assistant system that provides natural language access
to documentation, workflows, and software, with the aim of supporting
reproducibility, education, and future discovery. Built upon Large Language
Models using Retrieval-Augmented Generation and the Model Context Protocol,
this assistant indexes structured and unstructured content from RHIC
experiments and enables domain-adapted interaction. We report on the
deployment, computational performance, ongoing multi-experiment integration,
and architectural features designed for a sustainable and explainable long-term
AI access. Our experience illustrates how modern AI/ML tools can transform the
usability and discoverability of scientific legacy data.

</details>


### [125] [Personas within Parameters: Fine-Tuning Small Language Models with Low-Rank Adapters to Mimic User Behaviors](https://arxiv.org/abs/2509.09689)
*Himanshu Thakur,Eshani Agrawal,Smruthi Mukund*

Main category: cs.IR

TL;DR: Proposes using frozen LLMs to extract textual user representations and fine-tuned small language models (SLMs) with low-rank adapters for persona groups to create efficient user behavior simulation agents for recommender systems.


<details>
  <summary>Details</summary>
Motivation: Traditional methods struggle to simulate complex user behavior due to the stochastic nature of user interactions. Existing LLM approaches face challenges in parsing tabular data, overcoming pre-training biases, and scaling to millions of users.

Method: Uses frozen LLM to extract robust textual user representations, then employs fine-tuned SLMs with multiple low-rank adapters for user persona groups to create cost-effective user simulation agents.

Result: Empirical evidence shows the approach effectively bridges the gap between offline metrics and real-world recommender system performance, achieving optimal balance between scalability and performance.

Conclusion: The proposed method provides a resource-efficient solution for accurate user behavior simulation that outperforms complex prompting or fine-tuning approaches with large LLMs, enabling better recommender system evaluation.

Abstract: A long-standing challenge in developing accurate recommendation models is
simulating user behavior, mainly due to the complex and stochastic nature of
user interactions. Towards this, one promising line of work has been the use of
Large Language Models (LLMs) for simulating user behavior. However, aligning
these general-purpose large pre-trained models with user preferences
necessitates: (i) effectively and continously parsing large-scale tabular
user-item interaction data, (ii) overcoming pre-training-induced inductive
biases to accurately learn user specific knowledge, and (iii) achieving the
former two at scale for millions of users. While most previous works have
focused on complex methods to prompt an LLM or fine-tune it on tabular
interaction datasets, our approach shifts the focus to extracting robust
textual user representations using a frozen LLM and simulating cost-effective,
resource-efficient user agents powered by fine-tuned Small Language Models
(SLMs). Further, we showcase a method for training multiple low-rank adapters
for groups of users or \textit{persona}, striking an optimal balance between
scalability and performance of user behavior agents. Our experiments provide
compelling empirical evidence of the efficacy of our methods, demonstrating
that user agents developed using our approach have the potential to bridge the
gap between offline metrics and real-world performance of recommender systems.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [126] [Vibe Check: Understanding the Effects of LLM-Based Conversational Agents' Personality and Alignment on User Perceptions in Goal-Oriented Tasks](https://arxiv.org/abs/2509.09870)
*Hasibur Rahman,Smit Desai*

Main category: cs.HC

TL;DR: Medium personality expression in conversational agents produces the most positive user perceptions, with an inverted-U relationship where both low and high expression perform worse. Personality alignment, particularly with Extraversion and Emotional Stability, further enhances outcomes.


<details>
  <summary>Details</summary>
Motivation: As LLMs enable conversational agents to express distinctive personalities, there's a need to understand how personality expression levels and user-agent personality alignment influence user perceptions in goal-oriented tasks.

Method: Between-subjects experiment with 150 participants completing travel planning tasks with CAs exhibiting low, medium, or high expression across Big Five traits, controlled via a novel Trait Modulation Keys framework.

Result: Medium expression produced the most positive evaluations across Intelligence, Enjoyment, Anthropomorphism, Intention to Adopt, Trust, and Likeability. Personality alignment enhanced outcomes, with Extraversion and Emotional Stability being most influential. Three distinct compatibility profiles identified.

Conclusion: Personality expression and strategic trait alignment constitute optimal design targets for CA personality, offering design implications for LLM-based conversational agents.

Abstract: Large language models (LLMs) enable conversational agents (CAs) to express
distinctive personalities, raising new questions about how such designs shape
user perceptions. This study investigates how personality expression levels and
user-agent personality alignment influence perceptions in goal-oriented tasks.
In a between-subjects experiment (N=150), participants completed travel
planning with CAs exhibiting low, medium, or high expression across the Big
Five traits, controlled via our novel Trait Modulation Keys framework. Results
revealed an inverted-U relationship: medium expression produced the most
positive evaluations across Intelligence, Enjoyment, Anthropomorphism,
Intention to Adopt, Trust, and Likeability, significantly outperforming both
extremes. Personality alignment further enhanced outcomes, with Extraversion
and Emotional Stability emerging as the most influential traits. Cluster
analysis identified three distinct compatibility profiles, with "Well-Aligned"
users reporting substantially positive perceptions. These findings demonstrate
that personality expression and strategic trait alignment constitute optimal
design targets for CA personality, offering design implications as LLM-based
CAs become increasingly prevalent.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [127] [LLM-Based Instance-Driven Heuristic Bias In the Context of a Biased Random Key Genetic Algorithm](https://arxiv.org/abs/2509.09707)
*Camilo Chacón Sartori,Martín Isla Pino,Pedro Pinacho-Davidson,Christian Blum*

Main category: cs.NE

TL;DR: LLM-BRKGA hybrid framework for Longest Run Subsequence problem that uses human-LLM collaboration to generate instance-specific heuristic biases, achieving significant performance improvements over standard BRKGA.


<details>
  <summary>Details</summary>
Motivation: Existing LLM approaches for optimization often overlook structural properties of individual problem instances, creating a need for instance-driven heuristic biases.

Method: Human-LLM collaborative process to co-design computationally efficient metrics, with LLM analyzing these metrics to generate tailored heuristic bias that steers Biased Random-Key Genetic Algorithm search.

Result: BRKGA+Llama-4-Maverick hybrid achieved statistically significant improvements over baseline BRKGA across 1,050 instances, particularly on complex instances.

Conclusion: Leveraging LLMs to produce a priori, instance-driven heuristic bias is valuable for enhancing metaheuristics in complex optimization domains.

Abstract: Integrating Large Language Models (LLMs) within metaheuristics opens a novel
path for solving complex combinatorial optimization problems. While most
existing approaches leverage LLMs for code generation to create or refine
specific heuristics, they often overlook the structural properties of
individual problem instances. In this work, we introduce a novel framework that
integrates LLMs with a Biased Random-Key Genetic Algorithm (BRKGA) to solve the
NP-hard Longest Run Subsequence problem. Our approach extends the
instance-driven heuristic bias paradigm by introducing a human-LLM
collaborative process to co-design and implement a set of computationally
efficient metrics. The LLM analyzes these instance-specific metrics to generate
a tailored heuristic bias, which steers the BRKGA toward promising areas of the
search space. We conduct a comprehensive experimental evaluation, including
rigorous statistical tests, convergence and behavioral analyses, and targeted
ablation studies, comparing our method against a standard BRKGA baseline across
1,050 generated instances of varying complexity. Results show that our
top-performing hybrid, BRKGA+Llama-4-Maverick, achieves statistically
significant improvements over the baseline, particularly on the most complex
instances. Our findings confirm that leveraging an LLM to produce an a priori,
instance-driven heuristic bias is a valuable approach for enhancing
metaheuristics in complex optimization domains.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [128] [HHI-Assist: A Dataset and Benchmark of Human-Human Interaction in Physical Assistance Scenario](https://arxiv.org/abs/2509.10096)
*Saeed Saadatnejad,Reyhaneh Hosseininejad,Jose Barreiros,Katherine M. Tsui,Alexandre Alahi*

Main category: cs.RO

TL;DR: A new dataset (HHI-Assist) and Transformer-based diffusion model for human motion prediction in assistive care scenarios, improving interaction-aware robotic assistance.


<details>
  <summary>Details</summary>
Motivation: Address labor shortage and aging population needs by developing better assistive robots that require accurate human motion prediction during physical interactions, which is challenging due to variability and complex dynamics.

Method: Created HHI-Assist dataset of human-human interaction motion capture clips, and developed a conditional Transformer-based denoising diffusion model to predict poses of interacting agents.

Result: Model effectively captures coupled dynamics between caregivers and receivers, shows improvements over baselines, and demonstrates strong generalization to unseen scenarios.

Conclusion: The work advances interaction-aware motion prediction and introduces valuable dataset, potentially significantly enhancing robotic assistance policies for care scenarios.

Abstract: The increasing labor shortage and aging population underline the need for
assistive robots to support human care recipients. To enable safe and
responsive assistance, robots require accurate human motion prediction in
physical interaction scenarios. However, this remains a challenging task due to
the variability of assistive settings and the complexity of coupled dynamics in
physical interactions. In this work, we address these challenges through two
key contributions: (1) HHI-Assist, a dataset comprising motion capture clips of
human-human interactions in assistive tasks; and (2) a conditional
Transformer-based denoising diffusion model for predicting the poses of
interacting agents. Our model effectively captures the coupled dynamics between
caregivers and care receivers, demonstrating improvements over baselines and
strong generalization to unseen scenarios. By advancing interaction-aware
motion prediction and introducing a new dataset, our work has the potential to
significantly enhance robotic assistance policies. The dataset and code are
available at: https://sites.google.com/view/hhi-assist/home

</details>


### [129] [GC-VLN: Instruction as Graph Constraints for Training-free Vision-and-Language Navigation](https://arxiv.org/abs/2509.10454)
*Hang Yin,Haoyu Wei,Xiuwei Xu,Wenxuan Guo,Jie Zhou,Jiwen Lu*

Main category: cs.RO

TL;DR: Training-free VLN framework using graph constraint optimization to decompose instructions into spatial constraints, enabling zero-shot navigation in continuous environments without training.


<details>
  <summary>Details</summary>
Motivation: Existing zero-shot VLN methods struggle with generalization to real-world scenarios as they are designed for discrete environments or require unsupervised training in simulators.

Method: Decomposes instructions into explicit spatial constraints using a constraint library, constructs directed acyclic graphs with waypoint/object nodes, and solves graph constraint optimization with backtracking for navigation paths.

Result: Significant improvements in success rate and navigation efficiency on standard benchmarks compared to state-of-the-art zero-shot methods, with effective generalization to new environments.

Conclusion: The constraint-driven paradigm enables robust zero-shot VLN in continuous environments, paving the way for more autonomous and deployable navigation systems.

Abstract: In this paper, we propose a training-free framework for vision-and-language
navigation (VLN). Existing zero-shot VLN methods are mainly designed for
discrete environments or involve unsupervised training in continuous simulator
environments, which makes it challenging to generalize and deploy them in
real-world scenarios. To achieve a training-free framework in continuous
environments, our framework formulates navigation guidance as graph constraint
optimization by decomposing instructions into explicit spatial constraints. The
constraint-driven paradigm decodes spatial semantics through constraint
solving, enabling zero-shot adaptation to unseen environments. Specifically, we
construct a spatial constraint library covering all types of spatial
relationship mentioned in VLN instructions. The human instruction is decomposed
into a directed acyclic graph, with waypoint nodes, object nodes and edges,
which are used as queries to retrieve the library to build the graph
constraints. The graph constraint optimization is solved by the constraint
solver to determine the positions of waypoints, obtaining the robot's
navigation path and final goal. To handle cases of no solution or multiple
solutions, we construct a navigation tree and the backtracking mechanism.
Extensive experiments on standard benchmarks demonstrate significant
improvements in success rate and navigation efficiency compared to
state-of-the-art zero-shot VLN methods. We further conduct real-world
experiments to show that our framework can effectively generalize to new
environments and instruction sets, paving the way for a more robust and
autonomous navigation framework.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [130] [VStyle: A Benchmark for Voice Style Adaptation with Spoken Instructions](https://arxiv.org/abs/2509.09716)
*Jun Zhan,Mingyang Han,Yuxuan Xie,Chen Wang,Dong Zhang,Kexin Huang,Haoxiang Shi,DongXiao Wang,Tengtao Song,Qinyuan Cheng,Shimin Li,Jun Song,Xipeng Qiu,Bo Zheng*

Main category: cs.SD

TL;DR: The paper introduces Voice Style Adaptation (VSA) task to evaluate if spoken language models can modify speaking style based on spoken commands, presents a bilingual benchmark called VStyle, and proposes LALM as a Judge framework for objective evaluation.


<details>
  <summary>Details</summary>
Motivation: Current spoken language models focus on semantic accuracy and instruction following but lack the ability to adapt speaking style based on natural language spoken commands, limiting natural human-machine interaction.

Method: Created VStyle benchmark covering four speech generation categories (acoustic attributes, natural language instruction, role play, implicit empathy) and developed LALM as a Judge framework for progressive evaluation of textual faithfulness, style adherence, and naturalness.

Result: Experiments on commercial systems and open source SLMs show current models have clear limitations in controllable style adaptation, demonstrating the novelty and challenge of the VSA task.

Conclusion: The VStyle benchmark and evaluation toolkit provide a foundation for advancing human-centered spoken interaction, highlighting the need for improved style adaptation capabilities in spoken language models.

Abstract: Spoken language models (SLMs) have emerged as a unified paradigm for speech
understanding and generation, enabling natural human machine interaction.
However, while most progress has focused on semantic accuracy and instruction
following, the ability of SLMs to adapt their speaking style based on spoken
instructions has received limited attention. We introduce Voice Style
Adaptation (VSA), a new task that examines whether SLMs can modify their
speaking style, such as timbre, prosody, or persona following natural language
spoken commands. To study this task, we present VStyle, a bilingual (Chinese &
English) benchmark covering four categories of speech generation: acoustic
attributes, natural language instruction, role play, and implicit empathy. We
also introduce the Large Audio Language Model as a Judge (LALM as a Judge)
framework, which progressively evaluates outputs along textual faithfulness,
style adherence, and naturalness, ensuring reproducible and objective
assessment. Experiments on commercial systems and open source SLMs demonstrate
that current models face clear limitations in controllable style adaptation,
highlighting both the novelty and challenge of this task. By releasing VStyle
and its evaluation toolkit, we aim to provide the community with a foundation
for advancing human centered spoken interaction. The dataset and code are
publicly available at
\href{https://junzhan2000.github.io/VStyle.github.io/}{project's homepage}.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [131] [Whisper Has an Internal Word Aligner](https://arxiv.org/abs/2509.09987)
*Sung-Lin Yeh,Yen Meng,Hao Tang*

Main category: eess.AS

TL;DR: Unsupervised method using Whisper's attention heads with character inputs produces more accurate word-level timestamps than previous approaches without requiring additional training.


<details>
  <summary>Details</summary>
Motivation: There's growing need for precise word-level timestamps from ASR systems like Whisper, but existing methods either need extra training or aren't competitive, with loose evaluation standards (200ms+ tolerance).

Method: Identifies specific attention heads in Whisper that capture accurate word alignments, uses character inputs instead of wordpieces for finer alignment, and filters attention heads while teacher forcing with characters.

Result: Produces word alignments more accurate than prior work under stricter tolerance levels (20-100ms) without requiring any training.

Conclusion: The proposed unsupervised approach leveraging Whisper's inherent attention mechanisms with character inputs achieves superior word alignment accuracy compared to existing methods.

Abstract: There is an increasing interest in obtaining accurate word-level timestamps
from strong automatic speech recognizers, in particular Whisper. Existing
approaches either require additional training or are simply not competitive.
The evaluation in prior work is also relatively loose, typically using a
tolerance of more than 200 ms. In this work, we discover attention heads in
Whisper that capture accurate word alignments and are distinctively different
from those that do not. Moreover, we find that using characters produces finer
and more accurate alignments than using wordpieces. Based on these findings, we
propose an unsupervised approach to extracting word alignments by filtering
attention heads while teacher forcing Whisper with characters. Our approach not
only does not require training but also produces word alignments that are more
accurate than prior work under a stricter tolerance between 20 ms and 100 ms.

</details>


### [132] [Unified Learnable 2D Convolutional Feature Extraction for ASR](https://arxiv.org/abs/2509.10031)
*Peter Vieting,Benedikt Hilmes,Ralf Schlüter,Hermann Ney*

Main category: eess.AS

TL;DR: A generic 2D convolutional neural front-end for ASR that reduces reliance on classical methods while maintaining performance with fewer parameters.


<details>
  <summary>Details</summary>
Motivation: To develop a more generic and unified front-end architecture for speech feature extraction that moves beyond heavily classical-influenced approaches and avoids complex layer compositions from different sources.

Method: A parameter-efficient 2D convolutional neural network front-end designed specifically for limited computational resources, systematically reducing the influence of existing techniques to achieve a generic architecture.

Result: The generic unified approach matches the performance of existing supervised learnable feature extractors while being more parameter-efficient.

Conclusion: A generic 2D convolutional front-end is feasible and effective for ASR, providing comparable performance to specialized feature extractors with better computational efficiency.

Abstract: Neural front-ends represent a promising approach to feature extraction for
automatic speech recognition (ASR) systems as they enable to learn specifically
tailored features for different tasks. Yet, many of the existing techniques
remain heavily influenced by classical methods. While this inductive bias may
ease the system design, our work aims to develop a more generic front-end for
feature extraction. Furthermore, we seek to unify the front-end architecture
contrasting with existing approaches that apply a composition of several layer
topologies originating from different sources. The experiments systematically
show how to reduce the influence of existing techniques to achieve a generic
front-end. The resulting 2D convolutional front-end is parameter-efficient and
suitable for a scenario with limited computational resources unlike large
models pre-trained on unlabeled audio. The results demonstrate that this
generic unified approach is not only feasible but also matches the performance
of existing supervised learnable feature extractors.

</details>


### [133] [Error Analysis in a Modular Meeting Transcription System](https://arxiv.org/abs/2509.10143)
*Peter Vieting,Simon Berger,Thilo von Neumann,Christoph Boeddeker,Ralf Schlüter,Reinhold Haeb-Umbach*

Main category: eess.AS

TL;DR: Analysis of leakage in speech separation for meeting transcription, showing cross-channel leakage occurs but doesn't significantly impact performance due to VAD filtering. Advanced diarization reduces gap to oracle segmentation by one third compared to energy-based VAD.


<details>
  <summary>Details</summary>
Motivation: Meeting transcription has seen significant progress but still faces challenges. The paper aims to analyze leakage issues in speech separation systems with proper sensitivity to temporal locality to understand performance limitations.

Method: Extends a previously proposed framework for analyzing leakage in speech separation. Compares different segmentation approaches including energy-based VAD and advanced diarization methods. Evaluates performance on LibriCSS dataset.

Result: Significant cross-channel leakage occurs in areas where only the primary speaker is active, but this doesn't affect final performance much as leaked parts are largely ignored by VAD. Advanced diarization reduces gap to oracle segmentation by one third compared to simple energy-based VAD.

Conclusion: The study provides state-of-the-art performance on LibriCSS among systems trained only on LibriSpeech data. Reveals factors contributing to remaining performance differences and shows that while leakage exists, current VAD systems effectively mitigate its impact on transcription quality.

Abstract: Meeting transcription is a field of high relevance and remarkable progress in
recent years. Still, challenges remain that limit its performance. In this
work, we extend a previously proposed framework for analyzing leakage in speech
separation with proper sensitivity to temporal locality. We show that there is
significant leakage to the cross channel in areas where only the primary
speaker is active. At the same time, the results demonstrate that this does not
affect the final performance much as these leaked parts are largely ignored by
the voice activity detection (VAD). Furthermore, different segmentations are
compared showing that advanced diarization approaches are able to reduce the
gap to oracle segmentation by a third compared to a simple energy-based VAD. We
additionally reveal what factors contribute to the remaining difference. The
results represent state-of-the-art performance on LibriCSS among systems that
train the recognition module on LibriSpeech data only.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [134] [Automated Tuning for Diffusion Inverse Problem Solvers without Generative Prior Retraining](https://arxiv.org/abs/2509.09880)
*Yaşar Utku Alçalar,Junno Yun,Mehmet Akçakaya*

Main category: eess.IV

TL;DR: ZADS is a zero-shot adaptive diffusion sampling method that optimizes fidelity weights during test-time for MRI reconstruction without requiring diffusion model retraining, outperforming traditional compressed sensing and diffusion-based methods.


<details>
  <summary>Details</summary>
Motivation: Diffusion models for MRI reconstruction depend heavily on carefully tuned data fidelity weights, and existing approaches using fixed weights or heuristics fail to generalize across varying measurement conditions and irregular timestep schedules.

Method: Proposes Zero-shot Adaptive Diffusion Sampling (ZADS) - a test-time optimization method that treats denoising as fixed unrolled sampler and optimizes fidelity weights in self-supervised manner using only undersampled measurements, without requiring diffusion prior retraining.

Result: Experiments on fastMRI knee dataset show ZADS consistently outperforms both traditional compressed sensing and recent diffusion-based methods, delivering high-fidelity reconstructions across varying noise schedules and acquisition settings.

Conclusion: ZADS provides an effective zero-shot approach for adaptive fidelity weight optimization in diffusion-based MRI reconstruction that generalizes well across different measurement conditions and sampling schedules without model retraining.

Abstract: Diffusion/score-based models have recently emerged as powerful generative
priors for solving inverse problems, including accelerated MRI reconstruction.
While their flexibility allows decoupling the measurement model from the
learned prior, their performance heavily depends on carefully tuned data
fidelity weights, especially under fast sampling schedules with few denoising
steps. Existing approaches often rely on heuristics or fixed weights, which
fail to generalize across varying measurement conditions and irregular timestep
schedules. In this work, we propose Zero-shot Adaptive Diffusion Sampling
(ZADS), a test-time optimization method that adaptively tunes fidelity weights
across arbitrary noise schedules without requiring retraining of the diffusion
prior. ZADS treats the denoising process as a fixed unrolled sampler and
optimizes fidelity weights in a self-supervised manner using only undersampled
measurements. Experiments on the fastMRI knee dataset demonstrate that ZADS
consistently outperforms both traditional compressed sensing and recent
diffusion-based methods, showcasing its ability to deliver high-fidelity
reconstructions across varying noise schedules and acquisition settings.

</details>


### [135] [Drone-Based Multispectral Imaging and Deep Learning for Timely Detection of Branched Broomrape in Tomato Farms](https://arxiv.org/abs/2509.09972)
*Mohammadreza Narimani,Alireza Pourreza,Ali Moghimi,Mohsen Mesgaran,Parastoo Farajpoor,Hamid Jafarbiglu*

Main category: eess.IV

TL;DR: Combined drone multispectral imagery with LSTM deep learning and SMOTE to detect parasitic broomrape in tomatoes, achieving 88.37% accuracy and 95.37% recall by integrating multiple growth stages.


<details>
  <summary>Details</summary>
Motivation: Branched broomrape poses a serious threat to California's tomato industry (90% of US processing tomatoes), with difficult early detection due to its underground lifecycle and ineffective conventional chemical controls.

Method: Used drone-based multispectral imagery with LSTM networks and SMOTE for class imbalance, conducted on infested tomato farm across five growth stages determined by growing degree days, processed images to isolate tomato canopy reflectance.

Result: At 897 GDD, achieved 79.09% accuracy and 70.36% recall without later stages. Best performance with all stages and SMOTE: 88.37% overall accuracy and 95.37% recall.

Conclusion: Temporal multispectral analysis with LSTM networks shows strong potential for early broomrape detection. UAV-based sensing with deep learning could provide powerful precision agriculture tool for sustainable tomato production.

Abstract: This study addresses the escalating threat of branched broomrape (Phelipanche
ramosa) to California's tomato industry, which supplies over 90 percent of U.S.
processing tomatoes. The parasite's largely underground life cycle makes early
detection difficult, while conventional chemical controls are costly,
environmentally harmful, and often ineffective. To address this, we combined
drone-based multispectral imagery with Long Short-Term Memory (LSTM) deep
learning networks, using the Synthetic Minority Over-sampling Technique (SMOTE)
to handle class imbalance. Research was conducted on a known broomrape-infested
tomato farm in Woodland, Yolo County, CA, across five key growth stages
determined by growing degree days (GDD). Multispectral images were processed to
isolate tomato canopy reflectance. At 897 GDD, broomrape could be detected with
79.09 percent overall accuracy and 70.36 percent recall without integrating
later stages. Incorporating sequential growth stages with LSTM improved
detection substantially. The best-performing scenario, which integrated all
growth stages with SMOTE augmentation, achieved 88.37 percent overall accuracy
and 95.37 percent recall. These results demonstrate the strong potential of
temporal multispectral analysis and LSTM networks for early broomrape
detection. While further real-world data collection is needed for practical
deployment, this study shows that UAV-based multispectral sensing coupled with
deep learning could provide a powerful precision agriculture tool to reduce
losses and improve sustainability in tomato production.

</details>


### [136] [Polarization Denoising and Demosaicking: Dataset and Baseline Method](https://arxiv.org/abs/2509.10098)
*Muhamad Daniel Ariff Bin Abdul Rahman,Yusuke Monno,Masayuki Tanaka,Masatoshi Okutomi*

Main category: eess.IV

TL;DR: Proposes a dataset and method for joint polarization denoising and demosaicking in division-of-focal-plane polarimeters, addressing the lack of suitable evaluation data and baseline methods.


<details>
  <summary>Details</summary>
Motivation: Division-of-focal-plane polarimeters capture multiple polarization orientations in one shot but require denoising and demosaicking. While polarization demosaicking has been studied for noise-free cases, joint denoising and demosaicking research is scarce due to lack of suitable datasets and baseline methods.

Method: Proposes a denoising-then-demosaicking approach using well-accepted signal processing components. Creates a dataset with 40 real-world scenes and three noise-level conditions, containing pairs of noisy mosaic inputs and noise-free full images.

Result: Experimental results show the proposed method exhibits higher image reconstruction performance than alternative methods, providing a solid baseline for future research.

Conclusion: The proposed dataset and method successfully address the gap in polarization denoising and demosaicking research, offering reproducible components and establishing a strong baseline for this joint task.

Abstract: A division-of-focal-plane (DoFP) polarimeter enables us to acquire images
with multiple polarization orientations in one shot and thus it is valuable for
many applications using polarimetric information. The image processing pipeline
for a DoFP polarimeter entails two crucial tasks: denoising and demosaicking.
While polarization demosaicking for a noise-free case has increasingly been
studied, the research for the joint task of polarization denoising and
demosaicking is scarce due to the lack of a suitable evaluation dataset and a
solid baseline method. In this paper, we propose a novel dataset and method for
polarization denoising and demosaicking. Our dataset contains 40 real-world
scenes and three noise-level conditions, consisting of pairs of noisy mosaic
inputs and noise-free full images. Our method takes a
denoising-then-demosaicking approach based on well-accepted signal processing
components to offer a reproducible method. Experimental results demonstrate
that our method exhibits higher image reconstruction performance than other
alternative methods, offering a solid baseline.

</details>


### [137] [Multi-pathology Chest X-ray Classification with Rejection Mechanisms](https://arxiv.org/abs/2509.10348)
*Yehudit Aperstein,Amit Tzahar,Alon Gottlib,Tal Verber,Ravit Shagan Damti,Alexander Apartsin*

Main category: eess.IV

TL;DR: This paper introduces an uncertainty-aware framework for chest X-ray diagnosis using DenseNet-121 with selective prediction mechanisms to improve reliability by rejecting uncertain predictions.


<details>
  <summary>Details</summary>
Motivation: Overconfidence in deep learning models poses significant risks in high-stakes medical imaging tasks, particularly for multi-label chest X-ray classification where multiple pathologies co-occur and uncertain predictions could lead to diagnostic errors.

Method: Uses DenseNet-121 backbone enhanced with two selective prediction mechanisms: entropy-based rejection and confidence interval-based rejection. Employs quantile-based calibration procedure to tune rejection thresholds using global or class-specific strategies.

Result: Experiments on three large datasets (PadChest, NIH ChestX-ray14, MIMIC-CXR) show selective rejection improves trade-off between diagnostic accuracy and coverage. Entropy-based rejection yields highest average AUC across all pathologies.

Conclusion: The framework supports integration of selective prediction into AI-assisted diagnostic workflows, providing a practical step toward safer, uncertainty-aware deployment of deep learning in clinical settings.

Abstract: Overconfidence in deep learning models poses a significant risk in
high-stakes medical imaging tasks, particularly in multi-label classification
of chest X-rays, where multiple co-occurring pathologies must be detected
simultaneously. This study introduces an uncertainty-aware framework for chest
X-ray diagnosis based on a DenseNet-121 backbone, enhanced with two selective
prediction mechanisms: entropy-based rejection and confidence interval-based
rejection. Both methods enable the model to abstain from uncertain predictions,
improving reliability by deferring ambiguous cases to clinical experts. A
quantile-based calibration procedure is employed to tune rejection thresholds
using either global or class-specific strategies. Experiments conducted on
three large public datasets (PadChest, NIH ChestX-ray14, and MIMIC-CXR)
demonstrate that selective rejection improves the trade-off between diagnostic
accuracy and coverage, with entropy-based rejection yielding the highest
average AUC across all pathologies. These results support the integration of
selective prediction into AI-assisted diagnostic workflows, providing a
practical step toward safer, uncertainty-aware deployment of deep learning in
clinical settings.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [138] [Chord: Chain of Rendering Decomposition for PBR Material Estimation from Generated Texture Images](https://arxiv.org/abs/2509.09952)
*Zhi Ying,Boxiang Rong,Jingyu Wang,Maoyuan Xu*

Main category: cs.GR

TL;DR: A novel two-stage generate-and-estimate framework for PBR material generation that uses fine-tuned diffusion models to create high-quality materials with flexible user control.


<details>
  <summary>Details</summary>
Motivation: Traditional material creation requires significant time and expertise, and existing methods using visual foundation models often lack quality, flexibility, and user control.

Method: Two-stage approach: 1) Generation stage with fine-tuned diffusion model synthesizes shaded, tileable textures from user input; 2) Estimation stage with chained decomposition scheme that sequentially predicts SVBRDF channels using single-step image-conditional diffusion model.

Result: Superior performance compared to existing methods, strong robustness on both generated textures and real photographs, and demonstrated flexibility across text-to-material, image-to-material, structure-guided generation, and material editing applications.

Conclusion: The proposed framework provides an efficient, high-quality solution for PBR material generation with excellent user control and flexibility across diverse applications.

Abstract: Material creation and reconstruction are crucial for appearance modeling but
traditionally require significant time and expertise from artists. While recent
methods leverage visual foundation models to synthesize PBR materials from
user-provided inputs, they often fall short in quality, flexibility, and user
control. We propose a novel two-stage generate-and-estimate framework for PBR
material generation. In the generation stage, a fine-tuned diffusion model
synthesizes shaded, tileable texture images aligned with user input. In the
estimation stage, we introduce a chained decomposition scheme that sequentially
predicts SVBRDF channels by passing previously extracted representation as
input into a single-step image-conditional diffusion model. Our method is
efficient, high quality, and enables flexible user control. We evaluate our
approach against existing material generation and estimation methods,
demonstrating superior performance. Our material estimation method shows strong
robustness on both generated textures and in-the-wild photographs. Furthermore,
we highlight the flexibility of our framework across diverse applications,
including text-to-material, image-to-material, structure-guided generation, and
material editing.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [139] [HypoGeneAgent: A Hypothesis Language Agent for Gene-Set Cluster Resolution Selection Using Perturb-seq Datasets](https://arxiv.org/abs/2509.09740)
*Ying Yuan,Xing-Yue Monica Ge,Aaron Archer Waterman,Tommaso Biancalani,David Richmond,Yogesh Pandit,Avtar Singh,Russell Littman,Jin Liu,Jan-Christian Huetter,Vladimir Ermakov*

Main category: q-bio.QM

TL;DR: HYPOGENEAGENT is an LLM-driven framework that automates and optimizes cluster annotation in single-cell studies by generating GO-based hypotheses with confidence scores and evaluating cluster coherence through intra-cluster agreement and inter-cluster separation metrics.


<details>
  <summary>Details</summary>
Motivation: Current clustering and annotation methods in single-cell studies rely on subjective heuristics and expert curation, lacking quantitative optimization for resolution selection and functional annotation.

Method: Uses an LLM as gene-set analyst to generate ranked GO hypotheses with confidence scores, then employs sentence embeddings to compute intra-cluster agreement and inter-cluster separation, combining them into a resolution score that maximizes cluster coherence and distinctiveness.

Result: When tested on K562 CRISPRi Perturb-seq data, the Resolution Score outperformed traditional metrics (silhouette score, modularity score) in selecting clustering granularities that align with known biological pathways.

Conclusion: LLM agents can serve as objective adjudicators for cluster resolution and functional annotation, enabling fully automated, context-aware interpretation pipelines in single-cell multi-omics studies.

Abstract: Large-scale single-cell and Perturb-seq investigations routinely involve
clustering cells and subsequently annotating each cluster with Gene-Ontology
(GO) terms to elucidate the underlying biological programs. However, both
stages, resolution selection and functional annotation, are inherently
subjective, relying on heuristics and expert curation. We present
HYPOGENEAGENT, a large language model (LLM)-driven framework, transforming
cluster annotation into a quantitatively optimizable task. Initially, an LLM
functioning as a gene-set analyst analyzes the content of each gene program or
perturbation module and generates a ranked list of GO-based hypotheses,
accompanied by calibrated confidence scores. Subsequently, we embed every
predicted description with a sentence-embedding model, compute pair-wise cosine
similarities, and let the agent referee panel score (i) the internal
consistency of the predictions, high average similarity within the same
cluster, termed intra-cluster agreement (ii) their external distinctiveness,
low similarity between clusters, termed inter-cluster separation. These two
quantities are combined to produce an agent-derived resolution score, which is
maximized when clusters exhibit simultaneous coherence and mutual exclusivity.
When applied to a public K562 CRISPRi Perturb-seq dataset as a preliminary
test, our Resolution Score selects clustering granularities that exhibit
alignment with known pathway compared to classical metrics such silhouette
score, modularity score for gene functional enrichment summary. These findings
establish LLM agents as objective adjudicators of cluster resolution and
functional annotation, thereby paving the way for fully automated,
context-aware interpretation pipelines in single-cell multi-omics studies.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [140] [Executable Ontologies: Synthesizing Event Semantics with Dataflow Architecture](https://arxiv.org/abs/2509.09775)
*Aleksandr Boldachev*

Main category: cs.AI

TL;DR: Boldsea is an architecture for modeling complex dynamic systems using executable ontologies that integrate event semantics with dataflow to overcome limitations of traditional BPM systems and object-oriented semantic technologies.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of traditional Business Process Management (BPM) systems and object-oriented semantic technologies by creating a more dynamic and flexible approach to modeling complex systems.

Method: Developed the boldsea architecture with formal BSL (boldsea Semantic Language) including BNF grammar, and created the boldsea-engine that directly interprets semantic models as executable algorithms without compilation.

Result: The approach enables runtime modification of event models, ensures temporal transparency, and seamlessly merges data and business logic within a unified semantic framework.

Conclusion: Boldsea provides an effective architecture for executable ontologies that can directly control process execution while offering flexibility and integration advantages over traditional approaches.

Abstract: This paper presents boldsea, Boldachev's semantic-event approach -- an
architecture for modeling complex dynamic systems using executable ontologies
-- semantic models that act as dynamic structures, directly controlling process
execution. We demonstrate that integrating event semantics with a dataflow
architecture addresses the limitations of traditional Business Process
Management (BPM) systems and object-oriented semantic technologies. The paper
presents the formal BSL (boldsea Semantic Language), including its BNF grammar,
and outlines the boldsea-engine's architecture, which directly interprets
semantic models as executable algorithms without compilation. It enables the
modification of event models at runtime, ensures temporal transparency, and
seamlessly merges data and business logic within a unified semantic framework.

</details>


### [141] [LLMs as Agentic Cooperative Players in Multiplayer UNO](https://arxiv.org/abs/2509.09867)
*Yago Romano Matinez,Jesse Roberts*

Main category: cs.AI

TL;DR: LLMs can play UNO successfully but struggle to effectively help another player win, with performance varying by model size.


<details>
  <summary>Details</summary>
Motivation: To test whether LLMs can actively assist humans in achieving goals, specifically by helping another player win in UNO rather than winning themselves.

Method: Built a tool for decoder-only LLMs to participate in RLCard game environment, providing full game-state information and testing with two prompting strategies across models from 1B to 70B parameters.

Result: All models outperformed random baseline when playing UNO, but few significantly aided another player to win.

Conclusion: While LLMs can perform well in game environments, their ability to provide meaningful assistance to human partners remains limited.

Abstract: LLMs promise to assist humans -- not just by answering questions, but by
offering useful guidance across a wide range of tasks. But how far does that
assistance go? Can a large language model based agent actually help someone
accomplish their goal as an active participant? We test this question by
engaging an LLM in UNO, a turn-based card game, asking it not to win but
instead help another player to do so. We built a tool that allows decoder-only
LLMs to participate as agents within the RLCard game environment. These models
receive full game-state information and respond using simple text prompts under
two distinct prompting strategies. We evaluate models ranging from small (1B
parameters) to large (70B parameters) and explore how model scale impacts
performance. We find that while all models were able to successfully outperform
a random baseline when playing UNO, few were able to significantly aid another
player.

</details>


### [142] [Abduct, Act, Predict: Scaffolding Causal Inference for Automated Failure Attribution in Multi-Agent Systems](https://arxiv.org/abs/2509.10401)
*Alva West,Yixuan Weng,Minjun Zhu,Zhen Lin,Yue Zhang*

Main category: cs.AI

TL;DR: A2P Scaffolding is a novel framework that transforms failure attribution from pattern recognition to structured causal inference, achieving 2.85x improvement in step-level accuracy over baselines.


<details>
  <summary>Details</summary>
Motivation: Current methods for failure attribution in multi-agent systems have critically low step-level accuracy (below 17%) due to inability to perform robust counterfactual reasoning, making them impractical for debugging complex systems.

Method: Abduct-Act-Predict (A2P) Scaffolding - a three-step reasoning process: (1) Abduction to infer hidden root causes, (2) Action to define minimal corrective intervention, (3) Prediction to simulate subsequent trajectory and verify if intervention resolves failure.

Result: On Algorithm-Generated dataset: 47.46% step-level accuracy (2.85x improvement over 16.67% baseline). On Hand-Crafted dataset: 29.31% step accuracy (2.43x improvement over 12.07% baseline).

Conclusion: By reframing failure attribution through a causal lens, A2P Scaffolding provides a robust, verifiable, and significantly more accurate solution for automated failure attribution in multi-agent systems.

Abstract: Failure attribution in multi-agent systems -- pinpointing the exact step
where a decisive error occurs -- is a critical yet unsolved challenge. Current
methods treat this as a pattern recognition task over long conversation logs,
leading to critically low step-level accuracy (below 17\%), which renders them
impractical for debugging complex systems. Their core weakness is a fundamental
inability to perform robust counterfactual reasoning: to determine if
correcting a single action would have actually averted the task failure. To
bridge this counterfactual inference gap, we introduce Abduct-Act-Predict (A2P)
Scaffolding, a novel agent framework that transforms failure attribution from
pattern recognition into a structured causal inference task. A2P explicitly
guides a large language model through a formal three-step reasoning process
within a single inference pass: (1) Abduction, to infer the hidden root causes
behind an agent's actions; (2) Action, to define a minimal corrective
intervention; and (3) Prediction, to simulate the subsequent trajectory and
verify if the intervention resolves the failure. This structured approach
leverages the holistic context of the entire conversation while imposing a
rigorous causal logic on the model's analysis. Our extensive experiments on the
Who\&When benchmark demonstrate its efficacy. On the Algorithm-Generated
dataset, A2P achieves 47.46\% step-level accuracy, a 2.85$\times$ improvement
over the 16.67\% of the baseline. On the more complex Hand-Crafted dataset, it
achieves 29.31\% step accuracy, a 2.43$\times$ improvement over the baseline's
12.07\%. By reframing the problem through a causal lens, A2P Scaffolding
provides a robust, verifiable, and significantly more accurate solution for
automated failure attribution.

</details>
