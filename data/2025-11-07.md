<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 15]
- [cs.CV](#cs.CV) [Total: 11]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Activation-Space Personality Steering: Hybrid Layer Selection for Stable Trait Control in LLMs](https://arxiv.org/abs/2511.03738)
*Pranav Bhandari,Nicolas Fay,Sanjeevan Selvaganapathy,Amitava Datta,Usman Naseem,Mehwish Nasim*

Main category: cs.CL

TL;DR: Proposes a pipeline to extract and control personality traits in LLMs using Big Five personality framework, enabling precise behavioral steering without affecting model capabilities.


<details>
  <summary>Details</summary>
Motivation: Need for reliable mechanisms to control and align implicit personality traits in LLMs to meet specific requirements, as current methods lack effective behavioral manipulation during generation.

Method: Extracts hidden state activations from transformer layers using Big Five Personality Traits, applies low-rank subspace discovery, identifies trait-specific optimal layers, and operationalizes through flexible steering framework with dynamic layer selection.

Result: Personality traits occupy a low-rank shared subspace, and latent structures can be transformed into actionable steering mechanisms through careful perturbations without impacting fluency, variance, or general capabilities.

Conclusion: Bridges the gap between psychological theory and practical model alignment by providing effective personality-aware steering mechanisms for LLMs.

Abstract: Large Language Models exhibit implicit personalities in their generation, but
reliably controlling or aligning these traits to meet specific needs remains an
open challenge. The need for effective mechanisms for behavioural manipulation
of the model during generation is a critical gap in the literature that needs
to be fulfilled. Personality-aware LLMs hold a promising direction towards this
objective. However, the relationship between these psychological constructs and
their representations within LLMs remains underexplored and requires further
investigation. Moreover, it is intriguing to understand and study the use of
these representations to steer the models' behaviour. We propose a novel
pipeline that extracts hidden state activations from transformer layers using
the Big Five Personality Traits (Openness, Conscientiousness, Extraversion,
Agreeableness and Neuroticism), which is a comprehensive and empirically
validated framework to model human personality applies low-rank subspace
discovery methods, and identifies trait-specific optimal layers across
different model architectures for robust injection. The resulting
personality-aligned directions are then operationalised through a flexible
steering framework with dynamic layer selection, enabling precise control of
trait expression in LLM outputs. Our findings reveal that personality traits
occupy a low-rank shared subspace, and that these latent structures can be
transformed into actionable mechanisms for effective steering through careful
perturbations without impacting the fluency, variance and general capabilities,
helping to bridge the gap between psychological theory and practical model
alignment.

</details>


### [2] [TextualVerifier: Verify TextGrad Step-by-Step](https://arxiv.org/abs/2511.03739)
*Eugenius Mario Situmorang,Adila Alfa Krisnadhi,Ari Wibisono*

Main category: cs.CL

TL;DR: TextualVerifier is a self-verification framework that addresses the verification gap in TextGrad's text-based automatic differentiation by using chain-of-thought reasoning and majority voting with LLMs, significantly improving reasoning validity and optimization performance.


<details>
  <summary>Details</summary>
Motivation: TextGrad enables text-based optimization without numerical equations but lacks self-verification mechanisms to ensure reasoning validity in text-based decision making, creating a critical gap in reliable AI systems.

Method: TextualVerifier implements a four-stage workflow: chain-of-thought decomposition, variant generation, majority voting, and consensus aggregation. It integrates non-invasively with TextGrad at both loss function and optimization result verification stages using LLM-based techniques.

Result: Experimental results show statistically significant improvements (p < 0.001): 29% improvement in reasoning step validity, 2.2 percentage point gain (68.2% to 70.4%) in TextGrad integration with moderate overhead, and versioning improvements of 8.08, 10.71, and 3.92 percentage points on GPQA, MMLU-ML, and MMLU-CP benchmarks respectively.

Conclusion: TextualVerifier presents the first self-verification framework for TextGrad through LLM-based techniques without requiring numerical gradients, enabling more reliable reasoning and opening new directions for verification in text-based optimization.

Abstract: TextGrad is a novel approach to text-based automatic differentiation that
enables composite AI systems to perform optimization without explicit numerical
equations. However, it currently lacks self-verification mechanisms that ensure
reasoning validity in text-based decision making. This research introduces
TextualVerifier, a verification framework that leverages chain-of-thought
reasoning and majority voting with large language models to address this
verification gap. TextualVerifier implements a four-stage workflow:
chain-of-thought decomposition, variant generation, majority voting, and
consensus aggregation. It integrates non-invasively with TextGrad at both the
loss function and optimization result verification stages. Experimental
evaluation using the Gemini 1.5 Pro model is conducted in two phases: (1)
standalone evaluation on PRM800K, and (2) integrated evaluation with TextGrad
on GPQA-Diamond, MMLU-ML, and MMLU-CP benchmarks. Results show statistically
significant improvements (p < 0.001). In phase one, TextualVerifier improves
the validity of reasoning steps by 29 percent. In phase two, integration into
TextGrad loss function yields a 2.2 percentage point gain from 68.2 to 70.4
percent with a moderate overhead of 5.9 LLM calls on average. Further
evaluations of TextualVerifier versioning yield 8.08, 10.71, and 3.92
percentage point improvements on GPQA, MMLU-ML, and MMLU-CP respectively.
TextualVerifier thus presents the first self-verification framework for
TextGrad through LLM-based techniques without requiring numerical gradients,
enabling more reliable reasoning and opening new directions for verification in
text-based optimization.

</details>


### [3] [GRDD+: An Extended Greek Dialectal Dataset with Cross-Architecture Fine-tuning Evaluation](https://arxiv.org/abs/2511.03772)
*Stergios Chatzikyriakidis,Dimitris Papadakis,Sevasti-Ioanna Papaioannou,Erofili Psaltaki*

Main category: cs.CL

TL;DR: Extended Greek Dialectal Dataset (GRDD+) with 6.4M words covering 10 Greek varieties, used to fine-tune LLMs and compare with frontier models.


<details>
  <summary>Details</summary>
Motivation: To create the first comprehensive Greek dialectal dataset with significant variation and size, enabling better dialectal language modeling.

Method: Extended existing GRDD dataset with more Cretan, Cypriot, Pontic, Northern Greek data and added six new varieties. Fine-tuned three 8B parameter models (Llama-3-8B, Llama-3.1-8B, Krikri-8B) and compared with frontier models.

Result: Created GRDD+ dataset with 6,374,939 words covering 10 Greek varieties - the largest and most varied Greek dialectal dataset to date.

Conclusion: The study demonstrates the value of high-quality dialectal data for improving language models and provides a benchmark for Greek dialectal NLP tasks.

Abstract: We present an extended Greek Dialectal Dataset (GRDD+) 1that complements the
existing GRDD dataset with more data from Cretan, Cypriot, Pontic and Northern
Greek, while we add six new varieties: Greco-Corsican, Griko (Southern Italian
Greek), Maniot, Heptanesian, Tsakonian, and Katharevusa Greek. The result is a
dataset with total size 6,374,939 words and 10 varieties. This is the first
dataset with such variation and size to date. We conduct a number of
fine-tuning experiments to see the effect of good quality dialectal data on a
number of LLMs. We fine-tune three model architectures (Llama-3-8B,
Llama-3.1-8B, Krikri-8B) and compare the results to frontier models
(Claude-3.7-Sonnet, Gemini-2.5, ChatGPT-5).

</details>


### [4] [PLLuM: A Family of Polish Large Language Models](https://arxiv.org/abs/2511.03823)
*Jan Kocoń,Maciej Piasecki,Arkadiusz Janz,Teddy Ferdinan,Łukasz Radliński,Bartłomiej Koptyra,Marcin Oleksy,Stanisław Woźniak,Paweł Walkowiak,Konrad Wojtasik,Julia Moska,Tomasz Naskręt,Bartosz Walkowiak,Mateusz Gniewkowski,Kamil Szyc,Dawid Motyka,Dawid Banach,Jonatan Dalasiński,Ewa Rudnicka,Bartłomiej Alberski,Tomasz Walkowiak,Aleksander Szczęsny,Maciej Markiewicz,Tomasz Bernaś,Hubert Mazur,Kamil Żyta,Mateusz Tykierko,Grzegorz Chodak,Tomasz Kajdanowicz,Przemysław Kazienko,Agnieszka Karlińska,Karolina Seweryn,Anna Kołos,Maciej Chrabąszcz,Katarzyna Lorenc,Aleksandra Krasnodębska,Artur Wilczek,Katarzyna Dziewulska,Paula Betscher,Zofia Cieślińska,Katarzyna Kowol,Daria Mikoś,Maciej Trzciński,Dawid Krutul,Marek Kozłowski,Sławomir Dadas,Rafał Poświata,Michał Perełkiewicz,Małgorzata Grębowiec,Maciej Kazuła,Marcin Białas,Roman Roszko,Danuta Roszko,Jurgita Vaičenonienė,Andrius Utka,Paweł Levchuk,Paweł Kowalski,Irena Prawdzic-Jankowska,Maciej Ogrodniczuk,Monika Borys,Anna Bulińska,Wiktoria Gumienna,Witold Kieraś,Dorota Komosińska,Katarzyna Krasnowska-Kieraś,Łukasz Kobyliński,Martyna Lewandowska,Marek Łaziński,Mikołaj Łątkowski,Dawid Mastalerz,Beata Milewicz,Agnieszka Anna Mykowiecka,Angelika Peljak-Łapińska,Sandra Penno,Zuzanna Przybysz,Michał Rudolf,Piotr Rybak,Karolina Saputa,Aleksandra Tomaszewska,Aleksander Wawer,Marcin Woliński,Joanna Wołoszyn,Alina Wróblewska,Bartosz Żuk,Filip Żarnecki,Konrad Kaczyński,Anna Cichosz,Zuzanna Deckert,Monika Garnys,Izabela Grabarczyk,Wojciech Janowski,Sylwia Karasińska,Aleksandra Kujawiak,Piotr Misztela,Maria Szymańska,Karolina Walkusz,Igor Siek,Jakub Kwiatkowski,Piotr Pęzik*

Main category: cs.CL

TL;DR: PLLuM is the largest open-source family of Polish language foundation models developed to address the English-centric bias in LLMs, featuring extensive Polish corpora and responsible AI framework.


<details>
  <summary>Details</summary>
Motivation: To overcome the limited support for non-English languages in LLMs and provide high-quality, culturally relevant language models for Polish, addressing the gap in the English-dominated commercial landscape.

Method: Developed through consortium collaboration, constructed a 140B-token Polish corpus, 77k custom instructions dataset, and 100k preference optimization dataset. Implemented Responsible AI framework with strict data governance and hybrid safety filtering.

Result: Created the largest open-source Polish LLM family with both base and instruction-tuned variants, demonstrated utility in public administration downstream tasks.

Conclusion: PLLuM successfully addresses Polish language AI needs, fosters open research, and strengthens sovereign AI technologies in Poland through transparent, culturally relevant models.

Abstract: Large Language Models (LLMs) play a central role in modern artificial
intelligence, yet their development has been primarily focused on English,
resulting in limited support for other languages. We present PLLuM (Polish
Large Language Model), the largest open-source family of foundation models
tailored specifically for the Polish language. Developed by a consortium of
major Polish research institutions, PLLuM addresses the need for high-quality,
transparent, and culturally relevant language models beyond the English-centric
commercial landscape. We describe the development process, including the
construction of a new 140-billion-token Polish text corpus for pre-training, a
77k custom instructions dataset, and a 100k preference optimization dataset. A
key component is a Responsible AI framework that incorporates strict data
governance and a hybrid module for output correction and safety filtering. We
detail the models' architecture, training procedures, and alignment techniques
for both base and instruction-tuned variants, and demonstrate their utility in
a downstream task within public administration. By releasing these models
publicly, PLLuM aims to foster open research and strengthen sovereign AI
technologies in Poland.

</details>


### [5] [STARS: Segment-level Token Alignment with Rejection Sampling in Large Language Models](https://arxiv.org/abs/2511.03827)
*Mohammad Atif Quamar,Mohammad Areeb,Mikhail Kuznetsov,Muslum Ozgur Ozmen,Z. Berkay Celik*

Main category: cs.CL

TL;DR: STARS is a decoding-time algorithm that improves LLM alignment by iteratively sampling, scoring, and rejecting/accepting short token segments, achieving better performance than fine-tuning methods with higher computational efficiency.


<details>
  <summary>Details</summary>
Motivation: Existing methods for aligning LLMs with human values (fine-tuning, Best-of-N sampling) are computationally expensive and suboptimal, creating a need for more efficient and effective alignment approaches.

Method: STARS uses segment-level token alignment with rejection sampling - iteratively sampling, scoring, and rejecting/accepting short, fixed-size token segments during decoding to enable early correction of generation paths.

Result: STARS outperforms Supervised Fine-Tuning by up to 14.9 percentage points and Direct Preference Optimization by up to 4.3 percentage points on win-rates across six LLMs, while remaining competitive with Best-of-N baselines.

Conclusion: Granular, reward-guided sampling provides a generalizable, robust, and efficient alternative to traditional fine-tuning and full-sequence ranking methods for aligning LLMs.

Abstract: Aligning large language models with human values is crucial for their safe
deployment; however, existing methods, such as fine-tuning, are computationally
expensive and suboptimal. In contrast, inference-time approaches like Best-of-N
sampling require practically infeasible computation to achieve optimal
alignment. We propose STARS: Segment-level Token Alignment with Rejection
Sampling, a decoding-time algorithm that steers model generation by iteratively
sampling, scoring, and rejecting/accepting short, fixed-size token segments.
This allows for early correction of the generation path, significantly
improving computational efficiency and boosting alignment quality. Across a
suite of six LLMs, we show that STARS outperforms Supervised Fine-Tuning (SFT)
by up to 14.9 percentage points and Direct Preference Optimization (DPO) by up
to 4.3 percentage points on win-rates, while remaining highly competitive with
strong Best-of-N baselines. Our work establishes granular, reward-guided
sampling as a generalizable, robust, and efficient alternative to traditional
fine-tuning and full-sequence ranking methods for aligning LLMs.

</details>


### [6] [Divide, Cache, Conquer: Dichotomic Prompting for Efficient Multi-Label LLM-Based Classification](https://arxiv.org/abs/2511.03830)
*Mikołaj Langner,Jan Eliasz,Ewa Rudnicka,Jan Kocoń*

Main category: cs.CL

TL;DR: Efficient multi-label text classification using LLMs by reformulating tasks as sequences of yes/no decisions for each label dimension, with prefix caching for efficiency gains.


<details>
  <summary>Details</summary>
Motivation: To address the inefficiency of traditional multi-label classification with LLMs that generate all labels in a single response, which is computationally expensive for short-text inference.

Method: Decompose multi-label classification into independent dichotomic queries for each target dimension, use LLM-to-SLM distillation with DeepSeek-V3 as annotator, fine-tune smaller models (HerBERT-Large, CLARIN-1B, PLLuM-8B, Gemma3-1B), and implement prefix caching mechanism.

Result: Fine-tuned models show significant improvements over zero-shot baselines, especially on trained dimensions, with substantial efficiency gains for short-text inference without accuracy loss.

Conclusion: Dichotomic query decomposition combined with distillation and cache-aware inference provides a scalable and effective framework for LLM-based multi-label classification, applicable across domains beyond affective text analysis.

Abstract: We introduce a method for efficient multi-label text classification with
large language models (LLMs), built on reformulating classification tasks as
sequences of dichotomic (yes/no) decisions. Instead of generating all labels in
a single structured response, each target dimension is queried independently,
which, combined with a prefix caching mechanism, yields substantial efficiency
gains for short-text inference without loss of accuracy. To demonstrate the
approach, we focus on affective text analysis, covering 24 dimensions including
emotions and sentiment. Using LLM-to-SLM distillation, a powerful annotator
model (DeepSeek-V3) provides multiple annotations per text, which are
aggregated to fine-tune smaller models (HerBERT-Large, CLARIN-1B, PLLuM-8B,
Gemma3-1B). The fine-tuned models show significant improvements over zero-shot
baselines, particularly on the dimensions seen during training. Our findings
suggest that decomposing multi-label classification into dichotomic queries,
combined with distillation and cache-aware inference, offers a scalable and
effective framework for LLM-based classification. While we validate the method
on affective states, the approach is general and applicable across domains.

</details>


### [7] [Evaluating Machine Translation Datasets for Low-Web Data Languages: A Gendered Lens](https://arxiv.org/abs/2511.03880)
*Hellina Hailu Nigatu,Bethelhem Yemane Mamo,Bontu Fufa Balcha,Debora Taye Tesfaye,Elbethel Daniel Zewdie,Ikram Behiru Nesiru,Jitu Ewnetu Hailu,Senait Mengesha Yayo*

Main category: cs.CL

TL;DR: Analysis of Machine Translation datasets for three low-resourced languages (Afan Oromo, Amharic, Tigrinya) reveals significant gender biases, domain imbalances, and harmful content, with larger datasets showing worse quality issues.


<details>
  <summary>Details</summary>
Motivation: To investigate the quality of MT datasets for low-resourced languages, focusing on gender representation and potential harms, as current approaches prioritize quantity over quality.

Method: Analyzed MT datasets for three low-resourced languages, examining gender representation through names, grammatical gender of verbs, stereotypical depictions, and harmful/toxic content.

Result: Found large gender skew towards males, domain imbalances (training data focused on political/religious domains vs benchmarks on news/health/sports), and harmful depictions against women that were worse in languages with more data.

Conclusion: Quantity does not guarantee quality in low-resourced language datasets; work highlights need for early mitigation of harmful content and further inquiry into dataset quality.

Abstract: As low-resourced languages are increasingly incorporated into NLP research,
there is an emphasis on collecting large-scale datasets. But in prioritizing
quantity over quality, we risk 1) building language technologies that perform
poorly for these languages and 2) producing harmful content that perpetuates
societal biases. In this paper, we investigate the quality of Machine
Translation (MT) datasets for three low-resourced languages--Afan Oromo,
Amharic, and Tigrinya, with a focus on the gender representation in the
datasets. Our findings demonstrate that while training data has a large
representation of political and religious domain text, benchmark datasets are
focused on news, health, and sports. We also found a large skew towards the
male gender--in names of persons, the grammatical gender of verbs, and in
stereotypical depictions in the datasets. Further, we found harmful and toxic
depictions against women, which were more prominent for the language with the
largest amount of data, underscoring that quantity does not guarantee quality.
We hope that our work inspires further inquiry into the datasets collected for
low-resourced languages and prompts early mitigation of harmful content.
WARNING: This paper contains discussion of NSFW content that some may find
disturbing.

</details>


### [8] [GRAD: Graph-Retrieved Adaptive Decoding for Hallucination Mitigation](https://arxiv.org/abs/2511.03900)
*Manh Nguyen,Sunil Gupta,Dai Do,Hung Le*

Main category: cs.CL

TL;DR: GRAD is a decoding-time method that mitigates LLM hallucinations by constructing token transition graphs from retrieved corpus evidence and adaptively fusing them with model logits during generation.


<details>
  <summary>Details</summary>
Motivation: Existing hallucination mitigation approaches rely on external knowledge sources through prompting or retrieval, but prompt-based grounding is fragile and symbolic knowledge integration is costly. GRAD aims to provide lightweight corpus-derived evidence without retraining.

Method: Constructs sparse token transition graphs by accumulating next-token logits across a small retrieved corpus in a single forward pass, then max-normalizes and adaptively fuses graph-retrieved logits with model logits during decoding to favor high-evidence continuations.

Result: Across three models and multiple QA benchmarks, GRAD achieved up to 9.7% higher intrinsic accuracy, 8.6% lower hallucination rates, and 6.9% greater correctness compared to greedy decoding, with the highest truth-informativeness product score.

Conclusion: GRAD offers a lightweight, plug-and-play alternative to contrastive decoding and knowledge graph augmentation, demonstrating that statistical evidence from corpus-level token transitions can effectively steer generation toward more truthful and verifiable outputs.

Abstract: Hallucination mitigation remains a persistent challenge for large language
models (LLMs), even as model scales grow. Existing approaches often rely on
external knowledge sources, such as structured databases or knowledge graphs,
accessed through prompting or retrieval. However, prompt-based grounding is
fragile and domain-sensitive, while symbolic knowledge integration incurs heavy
retrieval and formatting costs. Motivated by knowledge graphs, we introduce
Graph-Retrieved Adaptive Decoding (GRAD), a decoding-time method that grounds
generation in corpus-derived evidence without retraining. GRAD constructs a
sparse token transition graph by accumulating next-token logits across a small
retrieved corpus in a single forward pass. During decoding, graph-retrieved
logits are max-normalized and adaptively fused with model logits to favor
high-evidence continuations while preserving fluency. Across three models and a
range of question-answering benchmarks spanning intrinsic, extrinsic
hallucination, and factuality tasks, GRAD consistently surpasses baselines,
achieving up to 9.7$\%$ higher intrinsic accuracy, 8.6$\%$ lower hallucination
rates, and 6.9$\%$ greater correctness compared to greedy decoding, while
attaining the highest truth--informativeness product score among all methods.
GRAD offers a lightweight, plug-and-play alternative to contrastive decoding
and knowledge graph augmentation, demonstrating that statistical evidence from
corpus-level token transitions can effectively steer generation toward more
truthful and verifiable outputs.

</details>


### [9] [Context informs pragmatic interpretation in vision-language models](https://arxiv.org/abs/2511.03908)
*Alvin Wei Ming Tan,Ben Prystawski,Veronica Boyce,Michael C. Frank*

Main category: cs.CL

TL;DR: Iterated reference games test pragmatic reasoning in multi-turn language environments. Models perform poorly without context but improve dramatically with relevant context, though still lag behind humans.


<details>
  <summary>Details</summary>
Motivation: To test agents' ability to perform context-sensitive pragmatic reasoning in multi-turn linguistic environments through iterated reference games.

Method: Tested humans and vision-language models on iterated reference games with varying context (amount, order, relevance) using abstract referents.

Result: Models performed above chance but substantially worse than humans without relevant context. With relevant context, model performance increased dramatically over trials. Few-shot reference games remain difficult for models.

Conclusion: Iterated reference games with abstract referents present a challenging test case for machine learning models' pragmatic reasoning abilities, though relevant context significantly improves performance.

Abstract: Iterated reference games - in which players repeatedly pick out novel
referents using language - present a test case for agents' ability to perform
context-sensitive pragmatic reasoning in multi-turn linguistic environments. We
tested humans and vision-language models on trials from iterated reference
games, varying the given context in terms of amount, order, and relevance.
Without relevant context, models were above chance but substantially worse than
humans. However, with relevant context, model performance increased
dramatically over trials. Few-shot reference games with abstract referents
remain a difficult task for machine learning models.

</details>


### [10] [The Human Flourishing Geographic Index: A County-Level Dataset for the United States, 2013--2023](https://arxiv.org/abs/2511.03915)
*Stefano M. Iacus,Devika Jain,Andrea Nasuto,Giuseppe Porro,Marcello Carammia,Andrea Vezzulli*

Main category: cs.CL

TL;DR: The paper introduces the Human Flourishing Geographic Index (HFGI), a high-resolution measure of human flourishing derived from 2.6 billion geolocated tweets using fine-tuned LLMs to analyze 48 indicators aligned with established flourishing frameworks.


<details>
  <summary>Details</summary>
Motivation: Existing measures of human flourishing lack fine spatial and temporal resolution, limiting understanding of societal well-being beyond economic indicators.

Method: Analyzed 2.6 billion geolocated U.S. tweets (2013-2023) using fine-tuned large language models to classify expressions across 48 indicators aligned with Harvard's Global Flourishing Study framework, plus attitudes towards migration and perception of corruption.

Result: Created monthly and yearly county- and state-level indicators of flourishing-related discourse, validated to accurately represent underlying constructs and show expected correlations with established indicators.

Conclusion: The HFGI enables multidisciplinary analyses of well-being, inequality, and social change at unprecedented resolution, offering insights into human flourishing dynamics across the United States over the past decade.

Abstract: Quantifying human flourishing, a multidimensional construct including
happiness, health, purpose, virtue, relationships, and financial stability, is
critical for understanding societal well-being beyond economic indicators.
Existing measures often lack fine spatial and temporal resolution. Here we
introduce the Human Flourishing Geographic Index (HFGI), derived from analyzing
approximately 2.6 billion geolocated U.S. tweets (2013-2023) using fine-tuned
large language models to classify expressions across 48 indicators aligned with
Harvard's Global Flourishing Study framework plus attitudes towards migration
and perception of corruption. The dataset offers monthly and yearly county- and
state-level indicators of flourishing-related discourse, validated to confirm
that the measures accurately represent the underlying constructs and show
expected correlations with established indicators. This resource enables
multidisciplinary analyses of well-being, inequality, and social change at
unprecedented resolution, offering insights into the dynamics of human
flourishing as reflected in social media discourse across the United States
over the past decade.

</details>


### [11] [Direct Semantic Communication Between Large Language Models via Vector Translation](https://arxiv.org/abs/2511.03945)
*Fu-Chun Yang,Jason Eshraghian*

Main category: cs.CL

TL;DR: The paper proposes using vector translations as a latent bridge for direct semantic exchange between LLMs, enabling more efficient cross-model communication without token-based overhead.


<details>
  <summary>Details</summary>
Motivation: Current multi-agent LLM systems use token-based messaging which discards latent semantics, constraining information transfer and adding computational overhead.

Method: Developed a dual-encoder translator trained between Llama-2-7B and Mistral-7B-Instruct models to enable direct semantic exchange via vector translations with conservative injection at 30% blending strength.

Result: Achieved average cosine alignment of 0.538, demonstrated stable generation without destabilizing logits, and found 2.01:1 transfer asymmetry showing general-purpose models yield more transferable representations than instruction-tuned variants.

Conclusion: Cross-model latent communication is feasible and enables collaborative AI systems that share meaning rather than tokens, while preserving computational stability.

Abstract: In multi-agent settings, such as debate, reflection, or tool-calling, large
language models (LLMs) pass messages as plain tokens, discarding most latent
semantics. This constrains information transfer and adds unnecessary
computational overhead. We form a latent bridge via vector translations, which
use learned mappings that enable direct semantic exchange between
representation spaces. A dual-encoder translator trained between Llama-2-7B and
Mistral-7B-Instruct attains an average cosine alignment of 0.538. Injecting the
translated vectors at 30 percent blending strength steers the target model's
generation without destabilizing logits. Bidirectional evaluation shows a
2.01:1 transfer asymmetry, indicating that general-purpose models yield more
transferable representations than instruction-tuned variants. This conservative
injection preserves computational stability while demonstrating that
cross-model latent communication is feasible, enabling collaborative AI systems
that share meaning rather than tokens.

</details>


### [12] [Abductive Inference in Retrieval-Augmented Language Models: Generating and Validating Missing Premises](https://arxiv.org/abs/2511.04020)
*Shiyin Lin*

Main category: cs.CL

TL;DR: A framework that integrates abductive inference into RAG systems to handle incomplete evidence by generating and validating missing premises, improving accuracy and faithfulness.


<details>
  <summary>Details</summary>
Motivation: RAG pipelines often fail when retrieved evidence is incomplete, leaving gaps in reasoning that need to be bridged through abductive inference.

Method: Detects insufficient evidence, generates candidate missing premises, and validates them through consistency and plausibility checks.

Result: Experimental results on abductive reasoning and multi-hop QA benchmarks show improved answer accuracy and reasoning faithfulness.

Conclusion: Abductive inference is a promising direction for enhancing the robustness and explainability of RAG systems.

Abstract: Large Language Models (LLMs) enhanced with retrieval -- commonly referred to
as Retrieval-Augmented Generation (RAG) -- have demonstrated strong performance
in knowledge-intensive tasks. However, RAG pipelines often fail when retrieved
evidence is incomplete, leaving gaps in the reasoning process. In such cases,
\emph{abductive inference} -- the process of generating plausible missing
premises to explain observations -- offers a principled approach to bridge
these gaps. In this paper, we propose a framework that integrates abductive
inference into retrieval-augmented LLMs. Our method detects insufficient
evidence, generates candidate missing premises, and validates them through
consistency and plausibility checks. Experimental results on abductive
reasoning and multi-hop QA benchmarks show that our approach improves both
answer accuracy and reasoning faithfulness. This work highlights abductive
inference as a promising direction for enhancing the robustness and
explainability of RAG systems.

</details>


### [13] [WST: Weakly Supervised Transducer for Automatic Speech Recognition](https://arxiv.org/abs/2511.04035)
*Dongji Gao,Chenda Liao,Changliang Liu,Matthew Wiesner,Leibny Paola Garcia,Daniel Povey,Sanjeev Khudanpur,Jian Wu*

Main category: cs.CL

TL;DR: Proposes Weakly Supervised Transducer (WST) for ASR that handles noisy transcripts without needing confidence scores or pre-trained models, maintaining performance with up to 70% transcription errors.


<details>
  <summary>Details</summary>
Motivation: RNN-T models require large-scale, high-quality annotated data which is costly and difficult to obtain, creating a need for methods that can work with noisy or imperfect transcripts.

Method: Integrates a flexible training graph designed to robustly handle errors in transcripts without requiring additional confidence estimation or auxiliary pre-trained models.

Result: WST maintains performance even with transcription error rates up to 70%, consistently outperforming existing CTC-based weakly supervised approaches like BTC and OTC on synthetic and industrial datasets.

Conclusion: WST demonstrates practical utility and robustness in realistic ASR settings, offering an effective solution for training with imperfect transcripts.

Abstract: The Recurrent Neural Network-Transducer (RNN-T) is widely adopted in
end-to-end (E2E) automatic speech recognition (ASR) tasks but depends heavily
on large-scale, high-quality annotated data, which are often costly and
difficult to obtain. To mitigate this reliance, we propose a Weakly Supervised
Transducer (WST), which integrates a flexible training graph designed to
robustly handle errors in the transcripts without requiring additional
confidence estimation or auxiliary pre-trained models. Empirical evaluations on
synthetic and industrial datasets reveal that WST effectively maintains
performance even with transcription error rates of up to 70%, consistently
outperforming existing Connectionist Temporal Classification (CTC)-based weakly
supervised approaches, such as Bypass Temporal Classification (BTC) and
Omni-Temporal Classification (OTC). These results demonstrate the practical
utility and robustness of WST in realistic ASR settings. The implementation
will be publicly available.

</details>


### [14] [T-FIX: Text-Based Explanations with Features Interpretable to eXperts](https://arxiv.org/abs/2511.04070)
*Shreya Havaldar,Helen Jin,Chaehyeon Kim,Anton Xue,Weiqiu You,Marco Gatti,Bhuvnesh Jain,Helen Qu,Daniel A Hashimoto,Amin Madani,Rajat Deo,Sameed Ahmed M. Khatana,Gary E. Weissman,Lyle Ungar,Eric Wong*

Main category: cs.CL

TL;DR: The paper introduces T-FIX, a benchmark for evaluating LLM explanations in knowledge-intensive domains, focusing on expert alignment rather than just plausibility or faithfulness.


<details>
  <summary>Details</summary>
Motivation: Current evaluation schemes for LLM explanations focus on plausibility and faithfulness but fail to assess whether explanations align with expert reasoning in knowledge-intensive domains like surgery, astronomy, and therapy.

Method: Developed T-FIX benchmark spanning seven knowledge-intensive domains in collaboration with domain experts, and created novel metrics to measure alignment of LLM explanations with expert judgment.

Result: The paper formalizes expert alignment as a key criterion for evaluating explanations, providing a framework to assess whether LLM-generated explanations reflect expert-level reasoning.

Conclusion: T-FIX addresses the gap in current evaluation methods by focusing on expert alignment, enabling better assessment of LLM explanations in professional domains where users are domain experts.

Abstract: As LLMs are deployed in knowledge-intensive settings (e.g., surgery,
astronomy, therapy), users expect not just answers, but also meaningful
explanations for those answers. In these settings, users are often domain
experts (e.g., doctors, astrophysicists, psychologists) who require
explanations that reflect expert-level reasoning. However, current evaluation
schemes primarily emphasize plausibility or internal faithfulness of the
explanation, which fail to capture whether the content of the explanation truly
aligns with expert intuition. We formalize expert alignment as a criterion for
evaluating explanations with T-FIX, a benchmark spanning seven
knowledge-intensive domains. In collaboration with domain experts, we develop
novel metrics to measure the alignment of LLM explanations with expert
judgment.

</details>


### [15] [Plan of Knowledge: Retrieval-Augmented Large Language Models for Temporal Knowledge Graph Question Answering](https://arxiv.org/abs/2511.04072)
*Xinying Qian,Ying Zhang,Yu Zhao,Baohang Zhou,Xuhui Sui,Xiaojie Yuan*

Main category: cs.CL

TL;DR: PoK framework enhances LLMs for temporal reasoning by decomposing questions into sub-objectives and using contrastive temporal retrieval from TKGs.


<details>
  <summary>Details</summary>
Motivation: Existing TKGQA methods fail to fully understand complex temporal semantics, while LLMs have strong semantic understanding but limited temporal reasoning abilities and suffer from hallucination.

Method: Proposes Plan of Knowledge (PoK) framework with: 1) Question decomposition into sub-objectives using pre-defined tools, 2) Temporal Knowledge Store with contrastive retrieval for semantically and temporally aligned facts.

Result: Significant improvements on four TKGQA benchmarks, surpassing state-of-the-art methods by up to 56.0% in reasoning accuracy and retrieval precision.

Conclusion: PoK effectively combines structured planning with temporal knowledge retrieval to enhance interpretability and factual consistency in temporal reasoning for LLMs.

Abstract: Temporal Knowledge Graph Question Answering (TKGQA) aims to answer
time-sensitive questions by leveraging factual information from Temporal
Knowledge Graphs (TKGs). While previous studies have employed pre-trained TKG
embeddings or graph neural networks to inject temporal knowledge, they fail to
fully understand the complex semantic information of time constraints.
Recently, Large Language Models (LLMs) have shown remarkable progress,
benefiting from their strong semantic understanding and reasoning
generalization capabilities. However, their temporal reasoning ability remains
limited. LLMs frequently suffer from hallucination and a lack of knowledge. To
address these limitations, we propose the Plan of Knowledge framework with a
contrastive temporal retriever, which is named PoK. Specifically, the proposed
Plan of Knowledge module decomposes a complex temporal question into a sequence
of sub-objectives from the pre-defined tools, serving as intermediate guidance
for reasoning exploration. In parallel, we construct a Temporal Knowledge Store
(TKS) with a contrastive retrieval framework, enabling the model to selectively
retrieve semantically and temporally aligned facts from TKGs. By combining
structured planning with temporal knowledge retrieval, PoK effectively enhances
the interpretability and factual consistency of temporal reasoning. Extensive
experiments on four benchmark TKGQA datasets demonstrate that PoK significantly
improves the retrieval precision and reasoning accuracy of LLMs, surpassing the
performance of the state-of-the-art TKGQA methods by 56.0% at most.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [16] [LoRA-Edge: Tensor-Train-Assisted LoRA for Practical CNN Fine-Tuning on Edge Devices](https://arxiv.org/abs/2511.03765)
*Hyunseok Kwak,Kyeongwon Lee,Jae-Jin Lee,Woojoo Lee*

Main category: cs.CV

TL;DR: LoRA-Edge enables efficient on-device CNN fine-tuning using tensor-train assisted LoRA, reducing trainable parameters by up to 100x while maintaining near-full fine-tuning accuracy.


<details>
  <summary>Details</summary>
Motivation: Full fine-tuning of CNNs is infeasible for edge devices due to strict memory, compute, and energy constraints, especially for applications like Human Activity Recognition that face domain shift issues.

Method: Applies Tensor-Train SVD to pre-trained convolutional layers, selectively updates only the output-side core with zero-initialization, and fuses updates back into dense kernels without changing inference cost.

Result: Achieves accuracy within 4.7% of full fine-tuning while updating at most 1.49% of parameters, with 1.4-3.8x faster convergence on Jetson Orin Nano, outperforming prior parameter-efficient methods.

Conclusion: LoRA-Edge makes structure-aligned, parameter-efficient on-device CNN adaptation practical for edge platforms by preserving convolutional structure and significantly reducing training overhead.

Abstract: On-device fine-tuning of CNNs is essential to withstand domain shift in edge
applications such as Human Activity Recognition (HAR), yet full fine-tuning is
infeasible under strict memory, compute, and energy budgets. We present
LoRA-Edge, a parameter-efficient fine-tuning (PEFT) method that builds on
Low-Rank Adaptation (LoRA) with tensor-train assistance. LoRA-Edge (i) applies
Tensor-Train Singular Value Decomposition (TT-SVD) to pre-trained convolutional
layers, (ii) selectively updates only the output-side core with
zero-initialization to keep the auxiliary path inactive at the start, and (iii)
fuses the update back into dense kernels, leaving inference cost unchanged.
This design preserves convolutional structure and reduces the number of
trainable parameters by up to two orders of magnitude compared to full
fine-tuning. Across diverse HAR datasets and CNN backbones, LoRA-Edge achieves
accuracy within 4.7% of full fine-tuning while updating at most 1.49% of
parameters, consistently outperforming prior parameter-efficient baselines
under similar budgets. On a Jetson Orin Nano, TT-SVD initialization and
selective-core training yield 1.4-3.8x faster convergence to target F1.
LoRA-Edge thus makes structure-aligned, parameter-efficient on-device CNN
adaptation practical for edge platforms.

</details>


### [17] [SILVI: Simple Interface for Labeling Video Interactions](https://arxiv.org/abs/2511.03819)
*Ozan Kanbertay,Richard Vogg,Elif Karakoc,Peter M. Kappeler,Claudia Fichtel,Alexander S. Ecker*

Main category: cs.CV

TL;DR: SILVI is an open-source video annotation tool that enables researchers to label both behaviors and interactions in animal videos, bridging the gap between behavioral labeling and individual localization for computer vision model training.


<details>
  <summary>Details</summary>
Motivation: Existing annotation tools either support behavioral labeling without localization or localization without interaction detection, creating a gap for analyzing social and individualized animal behavior through computer vision.

Method: Developed SILVI - an open-source labeling software that integrates both behavioral annotation and interaction detection functionalities directly within video data.

Result: SILVI generates structured outputs suitable for training and validating computer vision models, facilitating automated approaches for fine-grained behavioral analyses.

Conclusion: SILVI bridges behavioral ecology with computer vision and could be broadly useful for annotating human interactions in videos requiring dynamic scene graph extraction.

Abstract: Computer vision methods are increasingly used for the automated analysis of
large volumes of video data collected through camera traps, drones, or direct
observations of animals in the wild. While recent advances have focused
primarily on detecting individual actions, much less work has addressed the
detection and annotation of interactions -- a crucial aspect for understanding
social and individualized animal behavior. Existing open-source annotation
tools support either behavioral labeling without localization of individuals,
or localization without the capacity to capture interactions. To bridge this
gap, we present SILVI, an open-source labeling software that integrates both
functionalities. SILVI enables researchers to annotate behaviors and
interactions directly within video data, generating structured outputs suitable
for training and validating computer vision models. By linking behavioral
ecology with computer vision, SILVI facilitates the development of automated
approaches for fine-grained behavioral analyses. Although developed primarily
in the context of animal behavior, SILVI could be useful more broadly to
annotate human interactions in other videos that require extracting dynamic
scene graphs. The software, along with documentation and download instructions,
is available at: https://gitlab.gwdg.de/kanbertay/interaction-labelling-app.

</details>


### [18] [Noise Injection: Improving Out-of-Distribution Generalization for Limited Size Datasets](https://arxiv.org/abs/2511.03855)
*Duong Mai,Lawrence Hall*

Main category: cs.CV

TL;DR: Noise injection during training improves COVID-19 detection from chest X-rays by reducing performance gap between in-distribution and out-of-distribution data from 0.10-0.20 to 0.01-0.06.


<details>
  <summary>Details</summary>
Motivation: Deep learning models for COVID-19 detection fail to generalize to new clinical sources due to learning source-specific shortcuts rather than meaningful biomarkers.

Method: Applied fundamental noise injection techniques (Gaussian, Speckle, Poisson, and Salt and Pepper) during model training to improve robustness to distribution shifts.

Result: Significantly reduced performance gap between in-distribution and out-of-distribution evaluation from 0.10-0.20 to 0.01-0.06 across AUC, F1, accuracy, recall and specificity metrics.

Conclusion: Noise injection is an effective technique to enhance model robustness and generalization for COVID-19 detection from chest X-rays across different clinical sources.

Abstract: Deep learned (DL) models for image recognition have been shown to fail to
generalize to data from different devices, populations, etc. COVID-19 detection
from Chest X-rays (CXRs), in particular, has been shown to fail to generalize
to out-of-distribution (OOD) data from new clinical sources not covered in the
training set. This occurs because models learn to exploit shortcuts -
source-specific artifacts that do not translate to new distributions - rather
than reasonable biomarkers to maximize performance on in-distribution (ID)
data. Rendering the models more robust to distribution shifts, our study
investigates the use of fundamental noise injection techniques (Gaussian,
Speckle, Poisson, and Salt and Pepper) during training. Our empirical results
demonstrate that this technique can significantly reduce the performance gap
between ID and OOD evaluation from 0.10-0.20 to 0.01-0.06, based on results
averaged over ten random seeds across key metrics such as AUC, F1, accuracy,
recall and specificity. Our source code is publicly available at
https://github.com/Duongmai127/Noisy-ood

</details>


### [19] [Investigating Robot Control Policy Learning for Autonomous X-ray-guided Spine Procedures](https://arxiv.org/abs/2511.03882)
*Florence Klitzner,Blanca Inigo,Benjamin D. Killeen,Lalithkumar Seenivasan,Michelle Song,Axel Krieger,Mathias Unberath*

Main category: cs.CV

TL;DR: Imitation learning policies for X-ray-guided spine cannula insertion were developed and tested in simulation, achieving 68.5% first-attempt success with safe trajectories and generalization to complex anatomy.


<details>
  <summary>Details</summary>
Motivation: To explore whether imitation learning applies to X-ray-guided spine procedures, specifically bi-plane-guided cannula insertion, given the complexity of interpreting multi-view X-rays.

Method: Created an in silico sandbox for realistic simulation of X-ray-guided spine procedures, curated dataset of correct trajectories with bi-planar X-ray sequences, trained imitation learning policies for planning and open-loop control using visual information only.

Result: Policy succeeded on first attempt in 68.5% of cases, maintained safe intra-pedicular trajectories across diverse vertebral levels, generalized to complex anatomy including fractures, remained robust to varied initializations, and produced plausible trajectories on real bi-planar X-rays despite simulation-only training.

Conclusion: While promising with good generalization and robustness, limitations exist in entry point precision. Full closed-loop control requires more frequent feedback, but with improved priors and domain knowledge, these models could enable lightweight CT-free robotic spinal navigation.

Abstract: Imitation learning-based robot control policies are enjoying renewed interest
in video-based robotics. However, it remains unclear whether this approach
applies to X-ray-guided procedures, such as spine instrumentation. This is
because interpretation of multi-view X-rays is complex. We examine
opportunities and challenges for imitation policy learning in bi-plane-guided
cannula insertion. We develop an in silico sandbox for scalable, automated
simulation of X-ray-guided spine procedures with a high degree of realism. We
curate a dataset of correct trajectories and corresponding bi-planar X-ray
sequences that emulate the stepwise alignment of providers. We then train
imitation learning policies for planning and open-loop control that iteratively
align a cannula solely based on visual information. This precisely controlled
setup offers insights into limitations and capabilities of this method. Our
policy succeeded on the first attempt in 68.5% of cases, maintaining safe
intra-pedicular trajectories across diverse vertebral levels. The policy
generalized to complex anatomy, including fractures, and remained robust to
varied initializations. Rollouts on real bi-planar X-rays further suggest that
the model can produce plausible trajectories, despite training exclusively in
simulation. While these preliminary results are promising, we also identify
limitations, especially in entry point precision. Full closed-look control will
require additional considerations around how to provide sufficiently frequent
feedback. With more robust priors and domain knowledge, such models may provide
a foundation for future efforts toward lightweight and CT-free robotic
intra-operative spinal navigation.

</details>


### [20] [Desert Waste Detection and Classification Using Data-Based and Model-Based Enhanced YOLOv12 DL Model](https://arxiv.org/abs/2511.03888)
*Abdulmumin Sa'ad,Sulaimon Oyeniyi Adebayo,Abdul Jabbar Siddiqui*

Main category: cs.CV

TL;DR: Proposes an enhanced real-time object detection framework using pruned YOLOv12 with Self-Adversarial Training and specialized data augmentation for automated waste detection in desert environments, achieving optimal accuracy-efficiency balance for drone deployment.


<details>
  <summary>Details</summary>
Motivation: Addresses the global waste crisis and limitations of traditional waste collection methods in remote/harsh environments like deserts, where current computer vision research focuses mainly on urban areas and recyclables while overlooking organic/hazardous waste in underexplored terrains.

Method: Developed a pruned, lightweight YOLOv12 framework integrated with Self-Adversarial Training (SAT) and specialized data augmentation strategies, using the DroneTrashNet dataset for training and evaluation.

Result: Achieved significant improvements in precision, recall, and mean average precision (mAP) with low latency and compact model size suitable for resource-constrained aerial drones, outperforming state-of-the-art lightweight YOLO variants.

Conclusion: Validates the effectiveness of combining data-centric and model-centric enhancements for robust, real-time waste detection in desert environments, providing an optimal solution for automated waste management in challenging terrains.

Abstract: The global waste crisis is escalating, with solid waste generation expected
to increase by 70% by 2050. Traditional waste collection methods, particularly
in remote or harsh environments like deserts, are labor-intensive, inefficient,
and often hazardous. Recent advances in computer vision and deep learning have
opened the door to automated waste detection systems, yet most research focuses
on urban environments and recyclable materials, overlooking organic and
hazardous waste and underexplored terrains such as deserts. In this work, we
propose an enhanced real-time object detection framework based on a pruned,
lightweight version of YOLOv12 integrated with Self-Adversarial Training (SAT)
and specialized data augmentation strategies. Using the DroneTrashNet dataset,
we demonstrate significant improvements in precision, recall, and mean average
precision (mAP), while achieving low latency and compact model size suitable
for deployment on resource-constrained aerial drones. Benchmarking our model
against state-of-the-art lightweight YOLO variants further highlights its
optimal balance of accuracy and efficiency. Our results validate the
effectiveness of combining data-centric and model-centric enhancements for
robust, real-time waste detection in desert environments.

</details>


### [21] [Improving Diagnostic Performance on Small and Imbalanced Datasets Using Class-Based Input Image Composition](https://arxiv.org/abs/2511.03891)
*Hlali Azzeddine,Majid Ben Yakhlef,Soulaiman El Hazzat*

Main category: cs.CV

TL;DR: Class-Based Image Composition creates composite images from multiple same-class images to address small, imbalanced datasets and poor image quality, significantly improving diagnostic accuracy in OCT retinal scans.


<details>
  <summary>Details</summary>
Motivation: To overcome challenges of small imbalanced datasets and poor image quality that cause high false prediction rates in deep learning models for medical imaging.

Method: Fusion of multiple images from the same class into Composite Input Images (CoImg) arranged in 3x1 layouts, creating a balanced dataset (Co-OCTDL) from the original imbalanced OCTDL dataset.

Result: Achieved near-perfect accuracy (99.6%), F1-score (0.995), and AUC (0.9996) with significantly lower false prediction rates compared to baseline model trained on raw dataset.

Conclusion: The method effectively enhances intra-class variance and information density, enabling high-quality predictions even with weak datasets affected by class imbalance or small sample sizes.

Abstract: Small, imbalanced datasets and poor input image quality can lead to high
false predictions rates with deep learning models. This paper introduces
Class-Based Image Composition, an approach that allows us to reformulate
training inputs through a fusion of multiple images of the same class into
combined visual composites, named Composite Input Images (CoImg). That enhances
the intra-class variance and improves the valuable information density per
training sample and increases the ability of the model to distinguish between
subtle disease patterns. Our method was evaluated on the Optical Coherence
Tomography Dataset for Image-Based Deep Learning Methods (OCTDL) (Kulyabin et
al., 2024), which contains 2,064 high-resolution optical coherence tomography
(OCT) scans of the human retina, representing seven distinct diseases with a
significant class imbalance. We constructed a perfectly class-balanced version
of this dataset, named Co-OCTDL, where each scan is resented as a 3x1 layout
composite image. To assess the effectiveness of this new representation, we
conducted a comparative analysis between the original dataset and its variant
using a VGG16 model. A fair comparison was ensured by utilizing the identical
model architecture and hyperparameters for all experiments. The proposed
approach markedly improved diagnostic results.The enhanced Dataset achieved
near-perfect accuracy (99.6%) with F1-score (0.995) and AUC (0.9996), compared
to a baseline model trained on raw dataset. The false prediction rate was also
significantly lower, this demonstrates that the method can producehigh-quality
predictions even for weak datasets affected by class imbalance or small sample
size.

</details>


### [22] [I Detect What I Don't Know: Incremental Anomaly Learning with Stochastic Weight Averaging-Gaussian for Oracle-Free Medical Imaging](https://arxiv.org/abs/2511.03912)
*Nand Kumar Yadav,Rodrigue Rizk,William CW Chen,KC Santosh*

Main category: cs.CV

TL;DR: Unsupervised anomaly detection framework for medical imaging that incrementally expands normal samples without anomaly labels using lightweight adapters and uncertainty-gated admission.


<details>
  <summary>Details</summary>
Motivation: Addresses the challenge of unknown anomaly detection in medical imaging where labeled anomalies are scarce and expert supervision is costly.

Method: Uses frozen pretrained vision backbone with tiny convolutional adapters for domain adaptation, k-NN anomaly scoring with coreset storage, and dual probabilistic gates (z-score threshold and SWAG-based epistemic uncertainty) for safe sample admission.

Result: Substantial performance improvements: COVID-CXR ROC-AUC from 0.9489 to 0.9982, Pneumonia CXR ROC-AUC from 0.6834 to 0.8968, Brain MRI ND-5 ROC-AUC from 0.6041 to 0.7269.

Conclusion: The framework is effective and efficient for real-world, label-scarce medical imaging applications, steadily refining normality as unlabeled data arrive.

Abstract: Unknown anomaly detection in medical imaging remains a fundamental challenge
due to the scarcity of labeled anomalies and the high cost of expert
supervision. We introduce an unsupervised, oracle-free framework that
incrementally expands a trusted set of normal samples without any anomaly
labels. Starting from a small, verified seed of normal images, our method
alternates between lightweight adapter updates and uncertainty-gated sample
admission. A frozen pretrained vision backbone is augmented with tiny
convolutional adapters, ensuring rapid domain adaptation with negligible
computational overhead. Extracted embeddings are stored in a compact coreset
enabling efficient k-nearest neighbor anomaly (k-NN) scoring. Safety during
incremental expansion is enforced by dual probabilistic gates, a sample is
admitted into the normal memory only if its distance to the existing coreset
lies within a calibrated z-score threshold, and its SWAG-based epistemic
uncertainty remains below a seed-calibrated bound. This mechanism prevents
drift and false inclusions without relying on generative reconstruction or
replay buffers. Empirically, our system steadily refines the notion of
normality as unlabeled data arrive, producing substantial gains over baselines.
On COVID-CXR, ROC-AUC improves from 0.9489 to 0.9982 (F1: 0.8048 to 0.9746); on
Pneumonia CXR, ROC-AUC rises from 0.6834 to 0.8968; and on Brain MRI ND-5,
ROC-AUC increases from 0.6041 to 0.7269 and PR-AUC from 0.7539 to 0.8211. These
results highlight the effectiveness and efficiency of the proposed framework
for real-world, label-scarce medical imaging applications.

</details>


### [23] [Adaptive Temporal Refinement: Continuous Depth Allocation and Distance Regression for Efficient Action Localization](https://arxiv.org/abs/2511.03943)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.CV

TL;DR: BDR improves temporal action localization through signed-distance regression for sharper boundary detection, while ATR enables adaptive computation allocation via continuous depth selection, achieving better performance with less computation.


<details>
  <summary>Details</summary>
Motivation: Current temporal action localization methods apply uniform computation despite significant variations in boundary detection difficulty, leading to inefficient resource allocation.

Method: Two complementary approaches: Boundary Distance Regression (BDR) using signed-distance regression instead of classification, and Adaptive Temporal Refinement (ATR) with continuous depth selection for computation allocation.

Result: BDR achieves 43% sharper boundary peaks and 1.8-3.1% mAP@0.7 improvements across architectures. ATR achieves 56.5% mAP@0.7 at 162G FLOPs vs 53.6% at 198G for uniform processing, with 4.2% improvement on short actions.

Conclusion: The methods provide significant performance gains with reduced computation, validated across four benchmarks, with gains scaling according to boundary heterogeneity.

Abstract: Temporal action localization requires precise boundary detection; however,
current methods apply uniform computation despite significant variations in
difficulty across boundaries. We present two complementary contributions.
First, Boundary Distance Regression (BDR) provides information-theoretically
optimal localization through signed-distance regression rather than
classification, achieving 43\% sharper boundary peaks. BDR retrofits to
existing methods with approximately 50 lines of code, yielding consistent 1.8
to 3.1\% mAP@0.7 improvements across diverse architectures. Second, Adaptive
Temporal Refinement (ATR) allocates computation via continuous depth selection
$\tau \in [0,1]$, enabling end-to-end differentiable optimization without
reinforcement learning. On THUMOS14, ATR achieves 56.5\% mAP@0.7 at 162G FLOPs,
compared to 53.6\% at 198G for uniform processing, providing a 2.9\%
improvement with 18\% less compute. Gains scale with boundary heterogeneity,
showing 4.2\% improvement on short actions. Training cost is mitigated via
knowledge distillation, with lightweight students retaining 99\% performance at
baseline cost. Results are validated across four benchmarks with rigorous
statistical testing.

</details>


### [24] [Improving Multi-View Reconstruction via Texture-Guided Gaussian-Mesh Joint Optimization](https://arxiv.org/abs/2511.03950)
*Zhejia Cai,Puhua Jiang,Shiwei Mao,Hongkun Cao,Ruqi Huang*

Main category: cs.CV

TL;DR: Proposes a unified framework for joint optimization of mesh geometry and appearance using Gaussian-guided differentiable rendering, enabling high-quality 3D reconstruction suitable for downstream editing tasks.


<details>
  <summary>Details</summary>
Motivation: Existing methods either prioritize geometric accuracy or photorealistic rendering, decoupling geometry and appearance optimization, which hinders downstream editing applications like 3D editing, AR/VR, and digital content creation.

Method: Simultaneously optimizes mesh geometry (vertex positions and faces) and vertex colors via Gaussian-guided mesh differentiable rendering, leveraging photometric consistency from input images and geometric regularization from normal and depth maps.

Result: Obtains high-quality 3D reconstruction that can be exploited in downstream editing tasks such as relighting and shape deformation.

Conclusion: Advocates for unified treatment of geometry and appearance optimization through seamless Gaussian-mesh joint optimization to enable better downstream editing capabilities.

Abstract: Reconstructing real-world objects from multi-view images is essential for
applications in 3D editing, AR/VR, and digital content creation. Existing
methods typically prioritize either geometric accuracy (Multi-View Stereo) or
photorealistic rendering (Novel View Synthesis), often decoupling geometry and
appearance optimization, which hinders downstream editing tasks. This paper
advocates an unified treatment on geometry and appearance optimization for
seamless Gaussian-mesh joint optimization. More specifically, we propose a
novel framework that simultaneously optimizes mesh geometry (vertex positions
and faces) and vertex colors via Gaussian-guided mesh differentiable rendering,
leveraging photometric consistency from input images and geometric
regularization from normal and depth maps. The obtained high-quality 3D
reconstruction can be further exploit in down-stream editing tasks, such as
relighting and shape deformation. The code will be publicly available upon
acceptance.

</details>


### [25] [A Linear Fractional Transformation Model and Calibration Method for Light Field Camera](https://arxiv.org/abs/2511.03962)
*Zhong Chen,Changfeng Chen*

Main category: cs.CV

TL;DR: Proposes a linear fractional transformation parameter to decouple main lens and micro lens array for light field camera calibration, with analytical solution and nonlinear refinement.


<details>
  <summary>Details</summary>
Motivation: Accurate calibration of internal parameters is crucial but challenging for 3D reconstruction using light field cameras.

Method: Uses linear fractional transformation parameter α to decouple main lens and micro lens array, with analytical solution based on least squares followed by nonlinear refinement, plus feature detection from raw images.

Result: Experimental results on both physical and simulated data verify the method's performance, and the model enables faster simulation of raw light field images.

Conclusion: The proposed calibration method is effective and enables faster light field image simulation, which benefits data-driven deep learning approaches.

Abstract: Accurate calibration of internal parameters is a crucial yet challenging
prerequisite for 3D reconstruction using light field cameras. In this paper, we
propose a linear fractional transformation(LFT) parameter $\alpha$ to decoupled
the main lens and micro lens array (MLA). The proposed method includes an
analytical solution based on least squares, followed by nonlinear refinement.
The method for detecting features from the raw images is also introduced.
Experimental results on both physical and simulated data have verified the
performance of proposed method. Based on proposed model, the simulation of raw
light field images becomes faster, which is crucial for data-driven deep
learning methods. The corresponding code can be obtained from the author's
website.

</details>


### [26] [Room Envelopes: A Synthetic Dataset for Indoor Layout Reconstruction from Images](https://arxiv.org/abs/2511.03970)
*Sam Bahrami,Dylan Campbell*

Main category: cs.CV

TL;DR: A synthetic dataset called Room Envelopes is introduced to help predict structural scene elements like walls, floors, and ceilings that are typically occluded in standard scene reconstructions.


<details>
  <summary>Details</summary>
Motivation: Standard scene reconstruction methods only recover visible surfaces, leaving occluded structural elements missing. Structural elements are easier to predict due to their planar, repetitive nature, suggesting simpler approaches could be effective.

Method: Created a synthetic dataset with RGB images and two pointmaps per image: one for visible surfaces and one for structural layout surfaces (after removing fixtures). This enables direct supervision for monocular geometry estimators.

Result: The dataset facilitates training of feed-forward monocular geometry estimators that can predict both visible surfaces and structural layout surfaces.

Conclusion: This approach enables understanding of scene extent and object shapes/locations by predicting both visible and structural surfaces, addressing the limitation of incomplete reconstructions in current methods.

Abstract: Modern scene reconstruction methods are able to accurately recover 3D
surfaces that are visible in one or more images. However, this leads to
incomplete reconstructions, missing all occluded surfaces. While much progress
has been made on reconstructing entire objects given partial observations using
generative models, the structural elements of a scene, like the walls, floors
and ceilings, have received less attention. We argue that these scene elements
should be relatively easy to predict, since they are typically planar,
repetitive and simple, and so less costly approaches may be suitable. In this
work, we present a synthetic dataset -- Room Envelopes -- that facilitates
progress on this task by providing a set of RGB images and two associated
pointmaps for each image: one capturing the visible surface and one capturing
the first surface once fittings and fixtures are removed, that is, the
structural layout. As we show, this enables direct supervision for feed-forward
monocular geometry estimators that predict both the first visible surface and
the first layout surface. This confers an understanding of the scene's extent,
as well as the shape and location of its objects.

</details>
