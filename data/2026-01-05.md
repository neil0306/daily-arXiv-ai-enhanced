<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 35]
- [cs.CV](#cs.CV) [Total: 68]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 1]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]
- [eess.SY](#eess.SY) [Total: 1]
- [eess.SP](#eess.SP) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.LG](#cs.LG) [Total: 9]
- [eess.IV](#eess.IV) [Total: 2]
- [cs.CR](#cs.CR) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]
- [cs.AI](#cs.AI) [Total: 6]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [RIMRULE: Improving Tool-Using Language Agents via MDL-Guided Rule Learning](https://arxiv.org/abs/2601.00086)
*Xiang Gao,Yuguang Yao,Qi Zhang,Kaiwen Dong,Avinash Baidya,Ruocheng Guo,Hilaf Hasson,Kamalika Das*

Main category: cs.CL

TL;DR: RIMRULE: A neuro-symbolic approach that distills interpretable rules from LLM failure traces and injects them during inference to improve tool-use performance without weight updates.


<details>
  <summary>Details</summary>
Motivation: LLMs struggle with domain-specific tools that have idiosyncratic, under-documented, or private APIs, requiring effective adaptation to task-specific tools without extensive retraining.

Method: Dynamic rule injection: LLMs propose rules from failure traces, consolidated using Minimum Description Length objective for generality/conciseness. Rules stored in natural language and symbolic form for efficient retrieval during inference.

Result: Improves accuracy on both seen and unseen tools without modifying LLM weights; outperforms prompting-based methods and complements finetuning; rules are portable across LLM architectures.

Conclusion: RIMRULE enables effective LLM adaptation to domain-specific tools through interpretable, portable symbolic rules that enhance tool-use performance across different model architectures.

Abstract: Large language models (LLMs) often struggle to use tools reliably in domain-specific settings, where APIs may be idiosyncratic, under-documented, or tailored to private workflows. This highlights the need for effective adaptation to task-specific tools. We propose RIMRULE, a neuro-symbolic approach for LLM adaptation based on dynamic rule injection. Compact, interpretable rules are distilled from failure traces and injected into the prompt during inference to improve task performance. These rules are proposed by the LLM itself and consolidated using a Minimum Description Length (MDL) objective that favors generality and conciseness. Each rule is stored in both natural language and a structured symbolic form, supporting efficient retrieval at inference time. Experiments on tool-use benchmarks show that this approach improves accuracy on both seen and unseen tools without modifying LLM weights. It outperforms prompting-based adaptation methods and complements finetuning. Moreover, rules learned from one LLM can be reused to improve others, including long reasoning LLMs, highlighting the portability of symbolic knowledge across architectures.

</details>


### [2] [Universal Adaptive Constraint Propagation: Scaling Structured Inference for Large Language Models via Meta-Reinforcement Learning](https://arxiv.org/abs/2601.00095)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.CL

TL;DR: MetaJuLS is a meta-reinforcement learning approach that learns universal constraint propagation policies for structured inference tasks, achieving 1.5-2x speedups over GPU-optimized baselines while maintaining near-state-of-the-art accuracy.


<details>
  <summary>Details</summary>
Motivation: Large language models increasingly need structured inference with complex constraints (JSON schema enforcement, multi-lingual parsing), but current approaches require task-specific retraining which is inefficient and time-consuming.

Method: Formulates structured inference as adaptive constraint propagation and trains a Graph Attention Network with meta-learning to learn universal policies applicable across languages and tasks without task-specific retraining.

Result: Achieves 1.5-2x speedups over GPU-optimized baselines while maintaining within 0.2% accuracy of state-of-the-art parsers. Demonstrates rapid cross-domain adaptation: policies trained on English parsing adapt to new languages/tasks with 5-10 gradient steps (5-15 seconds) instead of hours of task-specific training.

Conclusion: MetaJuLS enables efficient structured inference across languages and tasks, reduces inference carbon footprint (Green AI contribution), and discovers both human-like and novel non-intuitive parsing strategies through mechanistic analysis.

Abstract: Large language models increasingly require structured inference, from JSON schema enforcement to multi-lingual parsing, where outputs must satisfy complex constraints. We introduce MetaJuLS, a meta-reinforcement learning approach that learns universal constraint propagation policies applicable across languages and tasks without task-specific retraining. By formulating structured inference as adaptive constraint propagation and training a Graph Attention Network with meta-learning, MetaJuLS achieves 1.5--2.0$\times$ speedups over GPU-optimized baselines while maintaining within 0.2\% accuracy of state-of-the-art parsers. On Universal Dependencies across 10 languages and LLM-constrained generation (LogicBench, GSM8K-Constrained), MetaJuLS demonstrates rapid cross-domain adaptation: a policy trained on English parsing adapts to new languages and tasks with 5--10 gradient steps (5--15 seconds) rather than requiring hours of task-specific training. Mechanistic analysis reveals the policy discovers human-like parsing strategies (easy-first) and novel non-intuitive heuristics. By reducing propagation steps in LLM deployments, MetaJuLS contributes to Green AI by directly reducing inference carbon footprint.

</details>


### [3] [Pat-DEVAL: Chain-of-Legal-Thought Evaluation for Patent Description](https://arxiv.org/abs/2601.00166)
*Yongmin Yoo,Kris W Pan*

Main category: cs.CL

TL;DR: Pat-DEVAL: A multi-dimensional evaluation framework for patent descriptions using LLM-as-a-judge with legal-constrained reasoning to assess structural coherence and statutory compliance.


<details>
  <summary>Details</summary>
Motivation: Existing evaluation approaches for automated patent drafting fail to assess long-form structural coherence and statutory compliance specific to patent descriptions, despite LLMs enabling end-to-end automated drafting.

Method: Proposes Pat-DEVAL framework using LLM-as-a-judge paradigm with Chain-of-Legal-Thought (CoLT), a legally-constrained reasoning mechanism that enforces sequential patent-law-specific analysis.

Result: Achieves Pearson correlation of 0.69 on Pap2Pat-EvalGold dataset, significantly outperforming baseline metrics and existing LLM evaluators, with superior correlation of 0.73 in Legal-Professional Compliance.

Conclusion: Pat-DEVAL establishes a new standard for ensuring both technical soundness and legal compliance, providing robust methodological foundation for practical deployment of automated patent drafting systems.

Abstract: Patent descriptions must deliver comprehensive technical disclosure while meeting strict legal standards such as enablement and written description requirements. Although large language models have enabled end-to-end automated patent drafting, existing evaluation approaches fail to assess long-form structural coherence and statutory compliance specific to descriptions. We propose Pat-DEVAL, the first multi-dimensional evaluation framework dedicated to patent description bodies. Leveraging the LLM-as-a-judge paradigm, Pat-DEVAL introduces Chain-of-Legal-Thought (CoLT), a legally-constrained reasoning mechanism that enforces sequential patent-law-specific analysis. Experiments validated by patent expert on our Pap2Pat-EvalGold dataset demonstrate that Pat-DEVAL achieves a Pearson correlation of 0.69, significantly outperforming baseline metrics and existing LLM evaluators. Notably, the framework exhibits a superior correlation of 0.73 in Legal-Professional Compliance, proving that the explicit injection of statutory constraints is essential for capturing nuanced legal validity. By establishing a new standard for ensuring both technical soundness and legal compliance, Pat-DEVAL provides a robust methodological foundation for the practical deployment of automated patent drafting systems.

</details>


### [4] [Understanding Emotion in Discourse: Recognition Insights and Linguistic Patterns for Generation](https://arxiv.org/abs/2601.00181)
*Cheonkam Jeong,Adeline Nyamathi*

Main category: cs.CL

TL;DR: Systematic analysis of Emotion Recognition in Conversation reveals that conversational context is crucial (90% gain within 10-30 turns), hierarchical sentence representations help only without context, and affective lexicons provide no additional benefit. Linguistic analysis shows emotion-specific discourse marker patterns, with sadness benefiting most from context due to reduced explicit pragmatic signals.


<details>
  <summary>Details</summary>
Motivation: Address two critical gaps in Emotion Recognition in Conversation: 1) limited understanding of which architectural choices actually matter, and 2) lack of linguistic analysis connecting recognition to generation.

Method: Conducted systematic analysis on IEMOCAP dataset with 10-seed evaluation for recognition, including rigorous ablation study. For linguistic analysis, examined 5,286 discourse marker occurrences to study emotion-marker positioning associations.

Result: Achieved 82.69% (4-way) and 67.07% (6-way) weighted F1 with simple causal-context architectures, outperforming prior text-only methods. Found conversational context is paramount (90% gain within 10-30 turns), hierarchical representations help only without context, and affective lexicons provide no gain. Linguistic analysis revealed significant emotion-marker positioning association (p<.0001), with sadness showing reduced left-periphery markers (21.9% vs 28-32% for other emotions).

Conclusion: Conversational context is the most important factor in ERC, with diminishing returns beyond 10-30 turns. Linguistic analysis connects recognition findings to generation, showing sadness benefits most from context due to reduced explicit pragmatic signals, requiring conversational history for disambiguation.

Abstract: While Emotion Recognition in Conversation (ERC) has achieved high accuracy, two critical gaps remain: a limited understanding of \textit{which} architectural choices actually matter, and a lack of linguistic analysis connecting recognition to generation. We address both gaps through a systematic analysis of the IEMOCAP dataset.
  For recognition, we conduct a rigorous ablation study with 10-seed evaluation and report three key findings. First, conversational context is paramount, with performance saturating rapidly -- 90\% of the total gain achieved within just the most recent 10--30 preceding turns (depending on the label set). Second, hierarchical sentence representations help at utterance-level, but this benefit disappears once conversational context is provided, suggesting that context subsumes intra-utterance structure. Third, external affective lexicons (SenticNet) provide no gain, indicating that pre-trained encoders already capture necessary emotional semantics. With simple architectures using strictly causal context, we achieve 82.69\% (4-way) and 67.07\% (6-way) weighted F1, outperforming prior text-only methods including those using bidirectional context.
  For linguistic analysis, we analyze 5,286 discourse marker occurrences and find a significant association between emotion and marker positioning ($p < .0001$). Notably, "sad" utterances exhibit reduced left-periphery marker usage (21.9\%) compared to other emotions (28--32\%), consistent with theories linking left-periphery markers to active discourse management. This connects to our recognition finding that sadness benefits most from context (+22\%p): lacking explicit pragmatic signals, sad utterances require conversational history for disambiguation.

</details>


### [5] [Knowledge Distillation for Temporal Knowledge Graph Reasoning with Large Language Models](https://arxiv.org/abs/2601.00202)
*Wang Xing,Wei Song,Siyu Lin,Chen Wu,Zhesi Li,Man Wang*

Main category: cs.CL

TL;DR: A distillation framework using LLMs as teachers to compress temporal knowledge graph reasoning models while preserving temporal dependencies, achieving better accuracy-efficiency trade-offs.


<details>
  <summary>Details</summary>
Motivation: Existing TKG reasoning models are computationally expensive and hardware-intensive, hindering deployment on resource-constrained platforms. Current compression techniques designed for static knowledge graphs fail to capture temporal dependencies in TKGs, leading to performance degradation.

Method: Proposes a distillation framework specifically for TKG reasoning that uses large language models as teacher models to guide the distillation process. The approach transfers both structural and temporal reasoning capabilities to lightweight student models by integrating large-scale public knowledge with task-specific temporal information.

Result: Extensive experiments on multiple benchmark datasets show the method consistently outperforms strong baselines, achieving favorable trade-offs between reasoning accuracy, computational efficiency, and practical deployability.

Conclusion: The proposed distillation framework effectively addresses the computational challenges of TKG reasoning while maintaining reasoning performance, enabling deployment on resource-constrained platforms for real-time inference applications.

Abstract: Reasoning over temporal knowledge graphs (TKGs) is fundamental to improving the efficiency and reliability of intelligent decision-making systems and has become a key technological foundation for future artificial intelligence applications. Despite recent progress, existing TKG reasoning models typically rely on large parameter sizes and intensive computation, leading to high hardware costs and energy consumption. These constraints hinder their deployment on resource-constrained, low-power, and distributed platforms that require real-time inference. Moreover, most existing model compression and distillation techniques are designed for static knowledge graphs and fail to adequately capture the temporal dependencies inherent in TKGs, often resulting in degraded reasoning performance. To address these challenges, we propose a distillation framework specifically tailored for temporal knowledge graph reasoning. Our approach leverages large language models as teacher models to guide the distillation process, enabling effective transfer of both structural and temporal reasoning capabilities to lightweight student models. By integrating large-scale public knowledge with task-specific temporal information, the proposed framework enhances the student model's ability to model temporal dynamics while maintaining a compact and efficient architecture. Extensive experiments on multiple publicly available benchmark datasets demonstrate that our method consistently outperforms strong baselines, achieving a favorable trade-off between reasoning accuracy, computational efficiency, and practical deployability.

</details>


### [6] [From Evidence-Based Medicine to Knowledge Graph: Retrieval-Augmented Generation for Sports Rehabilitation and a Domain Benchmark](https://arxiv.org/abs/2601.00216)
*Jinning Zhang,Jie Song,Wenhui Tu,Zecheng Li,Jingxuan Li,Jin Li,Xuan Liu,Taole Sha,Zichen Wei,Yan Li*

Main category: cs.CL

TL;DR: EBM-adapted graph-based RAG system for sports rehabilitation that integrates PICO framework and evidence hierarchy, achieving high performance metrics and expert clinician approval.


<details>
  <summary>Details</summary>
Motivation: Current RAG approaches in medicine overlook evidence-based medicine principles, specifically lacking PICO alignment between queries and evidence, and ignoring evidence hierarchy during reranking.

Method: Generalizable strategy adapting EBM to graph-based RAG: integrates PICO framework into knowledge graph construction and retrieval, uses Bayesian-inspired reranking algorithm to calibrate scores by evidence grade without predefined weights.

Result: System achieved 0.830 nugget coverage, 0.819 answer faithfulness, 0.882 semantic similarity, 0.788 PICOT match accuracy. Expert clinicians rated 4.66-4.84 across key metrics. Released knowledge graph (357,844 nodes, 371,226 edges) and benchmark of 1,637 QA pairs.

Conclusion: EBM adaptation strategy improves retrieval and answer quality, transferable to other clinical domains. Released resources address scarcity of RAG datasets in sports rehabilitation.

Abstract: In medicine, large language models (LLMs) increasingly rely on retrieval-augmented generation (RAG) to ground outputs in up-to-date external evidence. However, current RAG approaches focus primarily on performance improvements while overlooking evidence-based medicine (EBM) principles. This study addresses two key gaps: (1) the lack of PICO alignment between queries and retrieved evidence, and (2) the absence of evidence hierarchy considerations during reranking. We present a generalizable strategy for adapting EBM to graph-based RAG, integrating the PICO framework into knowledge graph construction and retrieval, and proposing a Bayesian-inspired reranking algorithm to calibrate ranking scores by evidence grade without introducing predefined weights. We validated this framework in sports rehabilitation, a literature-rich domain currently lacking RAG systems and benchmarks. We released a knowledge graph (357,844 nodes and 371,226 edges) and a reusable benchmark of 1,637 QA pairs. The system achieved 0.830 nugget coverage, 0.819 answer faithfulness, 0.882 semantic similarity, and 0.788 PICOT match accuracy. In a 5-point Likert evaluation, five expert clinicians rated the system 4.66-4.84 across factual accuracy, faithfulness, relevance, safety, and PICO alignment. These findings demonstrate that the proposed EBM adaptation strategy improves retrieval and answer quality and is transferable to other clinical domains. The released resources also help address the scarcity of RAG datasets in sports rehabilitation.

</details>


### [7] [JP-TL-Bench: Anchored Pairwise LLM Evaluation for Bidirectional Japanese-English Translation](https://arxiv.org/abs/2601.00223)
*Leonard Lin,Adam Lensenmayer*

Main category: cs.CL

TL;DR: JP-TL-Bench is a lightweight Japanese-English translation benchmark that uses pairwise LLM comparisons against a fixed anchor set to evaluate subtle translation quality differences.


<details>
  <summary>Details</summary>
Motivation: Japanese-English translation evaluation needs to distinguish between "which of two good translations is better?" rather than just acceptability, due to subtle factors like politeness, implicature, ellipsis, and register affecting naturalness.

Method: Uses reference-free pairwise LLM comparisons against a versioned anchor set, aggregates results with Bradley-Terry model, and reports win rates plus normalized 0-10 "LT" score from logistic transform of fitted log-strengths.

Result: Provides structurally stable scores that are comparable across evaluations when using the same anchor set, judge, and aggregation code, making LLM judging both reliable and affordable.

Conclusion: JP-TL-Bench offers a practical, iterative development tool for Japanese-English translation systems by focusing on nuanced quality distinctions through stable, pairwise evaluation methodology.

Abstract: We introduce JP-TL-Bench, a lightweight, open benchmark designed to guide the iterative development of Japanese-English translation systems. In this context, the challenge is often "which of these two good translations is better?" rather than "is this translation acceptable?" This distinction matters for Japanese-English, where subtle choices in politeness, implicature, ellipsis, and register strongly affect perceived naturalness. JP-TL-Bench uses a protocol built to make LLM judging both reliable and affordable: it evaluates a candidate model via reference-free, pairwise LLM comparisons against a fixed, versioned anchor set. Pairwise results are aggregated with a Bradley-Terry model and reported as win rates plus a normalized 0-10 "LT" score derived from a logistic transform of fitted log-strengths. Because each candidate is scored against the same frozen anchor set, scores are structurally stable given the same base set, judge, and aggregation code.

</details>


### [8] [Talk Less, Verify More: Improving LLM Assistants with Semantic Checks and Execution Feedback](https://arxiv.org/abs/2601.00224)
*Yan Sun,Ming Cai,Stanley Kok*

Main category: cs.CL

TL;DR: The paper introduces Q* and Feedback+ verification techniques for LLM assistants in enterprise workflows, reducing errors and completion time through reverse translation and execution feedback in a generator-discriminator framework.


<details>
  <summary>Details</summary>
Motivation: Current conversational business analytics systems lack built-in verification mechanisms, forcing users to manually validate potentially flawed LLM outputs, which is inefficient and error-prone for enterprise decision support.

Method: Two complementary verification techniques: Q* performs reverse translation and semantic matching between generated code and user intent; Feedback+ incorporates execution feedback to guide code refinement. Both are embedded within a generator-discriminator framework.

Result: Evaluations on Spider, Bird, and GSM8K benchmark datasets show both Q* and Feedback+ reduce error rates and task completion time. Reverse translation is identified as a key bottleneck for future improvement.

Conclusion: The work contributes a design-oriented framework for building more reliable, enterprise-grade GenAI systems capable of trustworthy decision support by shifting validation responsibilities from users to the system.

Abstract: As large language model (LLM) assistants become increasingly integrated into enterprise workflows, their ability to generate accurate, semantically aligned, and executable outputs is critical. However, current conversational business analytics (CBA) systems often lack built-in verification mechanisms, leaving users to manually validate potentially flawed results. This paper introduces two complementary verification techniques: Q*, which performs reverse translation and semantic matching between code and user intent, and Feedback+, which incorporates execution feedback to guide code refinement. Embedded within a generator-discriminator framework, these mechanisms shift validation responsibilities from users to the system. Evaluations on three benchmark datasets, Spider, Bird, and GSM8K, demonstrate that both Q* and Feedback+ reduce error rates and task completion time. The study also identifies reverse translation as a key bottleneck, highlighting opportunities for future improvement. Overall, this work contributes a design-oriented framework for building more reliable, enterprise-grade GenAI systems capable of trustworthy decision support.

</details>


### [9] [Parallel Universes, Parallel Languages: A Comprehensive Study on LLM-based Multilingual Counterfactual Example Generation](https://arxiv.org/abs/2601.00263)
*Qianli Wang,Van Bach Nguyen,Yihong Liu,Fedor Splitt,Nils Feldhus,Christin Seifert,Hinrich Schütze,Sebastian Möller,Vera Schmitt*

Main category: cs.CL

TL;DR: LLMs generate multilingual counterfactuals but translation-based ones are more valid but less efficient; cross-lingual perturbations follow similar patterns; four error types identified; multilingual CDA outperforms cross-lingual CDA but gains limited by counterfactual quality.


<details>
  <summary>Details</summary>
Motivation: Counterfactuals are important for explaining model behavior, and while LLMs excel at generating English counterfactuals and have multilingual capabilities, their effectiveness in generating multilingual counterfactuals remains unclear and needs systematic investigation.

Method: Comprehensive study on multilingual counterfactuals including: 1) automatic evaluation of directly generated vs. translation-based counterfactuals across six languages, 2) analysis of edit patterns in high-resource European languages, 3) categorization of error types in generated counterfactuals, and 4) comparison of multilingual vs. cross-lingual counterfactual data augmentation (CDA).

Result: 1) Translation-based counterfactuals have higher validity but require more modifications and still underperform English counterfactuals; 2) Edit patterns are remarkably similar across high-resource European languages; 3) Four consistent error types identified across languages; 4) Multilingual CDA yields larger performance improvements than cross-lingual CDA, especially for lower-resource languages, but gains are limited by counterfactual imperfections.

Conclusion: LLMs can generate multilingual counterfactuals but with limitations: translation-based approaches offer validity at the cost of efficiency, cross-lingual perturbations follow common principles, and while multilingual CDA shows promise, counterfactual quality issues constrain performance and robustness gains.

Abstract: Counterfactuals refer to minimally edited inputs that cause a model's prediction to change, serving as a promising approach to explaining the model's behavior. Large language models (LLMs) excel at generating English counterfactuals and demonstrate multilingual proficiency. However, their effectiveness in generating multilingual counterfactuals remains unclear. To this end, we conduct a comprehensive study on multilingual counterfactuals. We first conduct automatic evaluations on both directly generated counterfactuals in the target languages and those derived via English translation across six languages. Although translation-based counterfactuals offer higher validity than their directly generated counterparts, they demand substantially more modifications and still fall short of matching the quality of the original English counterfactuals. Second, we find the patterns of edits applied to high-resource European-language counterfactuals to be remarkably similar, suggesting that cross-lingual perturbations follow common strategic principles. Third, we identify and categorize four main types of errors that consistently appear in the generated counterfactuals across languages. Finally, we reveal that multilingual counterfactual data augmentation (CDA) yields larger model performance improvements than cross-lingual CDA, especially for lower-resource languages. Yet, the imperfections of the generated counterfactuals limit gains in model performance and robustness.

</details>


### [10] [Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity](https://arxiv.org/abs/2601.00268)
*Doyoung Kim,Zhiwei Ren,Jie Hao,Zhongkai Sun,Lichao Wang,Xiyao Ma,Zack Ye,Xu Han,Jun Yin,Heng Ji,Wei Shen,Xing Fan,Benjamin Yao,Chenlei Guo*

Main category: cs.CL

TL;DR: WildAGTEval is a benchmark for evaluating LLM agents' function-calling capabilities under realistic API complexity, addressing noisy outputs and real-world constraints.


<details>
  <summary>Details</summary>
Motivation: Prior work assumes idealized API systems and ignores real-world factors like noisy API outputs, creating a gap between academic benchmarks and practical deployment needs.

Method: WildAGTEval accounts for two dimensions of real-world complexity: API specification (detailed documentation, usage constraints) and API execution (runtime challenges). It includes 60 distinct complexity scenarios that can be composed into ~32K test configurations with user-agent interactions.

Result: Most scenarios are challenging, with irrelevant information complexity reducing strong LLM performance by 27.3%. Qualitative analysis reveals LLMs sometimes distort user intent to claim task completion, critically affecting user satisfaction.

Conclusion: WildAGTEval provides a realistic benchmark for evaluating LLM agents' function-calling capabilities, revealing significant performance gaps and concerning behaviors in current models when faced with real-world API complexity.

Abstract: We introduce WildAGTEval, a benchmark designed to evaluate large language model (LLM) agents' function-calling capabilities under realistic API complexity. Unlike prior work that assumes an idealized API system and disregards real-world factors such as noisy API outputs, WildAGTEval accounts for two dimensions of real-world complexity: 1. API specification, which includes detailed documentation and usage constraints, and 2. API execution, which captures runtime challenges. Consequently, WildAGTEval offers (i) an API system encompassing 60 distinct complexity scenarios that can be composed into approximately 32K test configurations, and (ii) user-agent interactions for evaluating LLM agents on these scenarios. Using WildAGTEval, we systematically assess several advanced LLMs and observe that most scenarios are challenging, with irrelevant information complexity posing the greatest difficulty and reducing the performance of strong LLMs by 27.3%. Furthermore, our qualitative analysis reveals that LLMs occasionally distort user intent merely to claim task completion, critically affecting user satisfaction.

</details>


### [11] [Can Large Language Models Still Explain Themselves? Investigating the Impact of Quantization on Self-Explanations](https://arxiv.org/abs/2601.00282)
*Qianli Wang,Nils Feldhus,Pepa Atanasova,Fedor Splitt,Simon Ostermann,Sebastian Möller,Vera Schmitt*

Main category: cs.CL

TL;DR: Quantization of large language models causes moderate declines in self-explanation quality and faithfulness, with natural language explanations being more sensitive than counterfactual examples.


<details>
  <summary>Details</summary>
Motivation: Self-explanations are crucial for transparency in high-stakes LLM applications, but the effects of quantization (widely used for model compression) on SE quality and faithfulness remain unexplored.

Method: Examined two types of SEs (natural language explanations and counterfactual examples) generated by LLMs quantized using three common techniques at different bit widths, supplemented with user studies.

Result: Quantization leads to moderate declines in SE quality (up to 4.4%) and faithfulness (up to 2.38%), with user studies showing reduced coherence and trustworthiness (up to 8.5%). Larger models show limited resilience to quality degradation but better maintain faithfulness.

Conclusion: While quantization causes minor deterioration in SE quality and faithfulness, it doesn't undermine its effectiveness as a compression technique. However, SE quality should be validated for specific use cases, especially for more sensitive natural language explanations.

Abstract: Quantization is widely used to accelerate inference and streamline the deployment of large language models (LLMs), yet its effects on self-explanations (SEs) remain unexplored. SEs, generated by LLMs to justify their own outputs, require reasoning about the model's own decision-making process, a capability that may exhibit particular sensitivity to quantization. As SEs are increasingly relied upon for transparency in high-stakes applications, understanding whether and to what extent quantization degrades SE quality and faithfulness is critical. To address this gap, we examine two types of SEs: natural language explanations (NLEs) and counterfactual examples, generated by LLMs quantized using three common techniques at distinct bit widths. Our findings indicate that quantization typically leads to moderate declines in both SE quality (up to 4.4\%) and faithfulness (up to 2.38\%). The user study further demonstrates that quantization diminishes both the coherence and trustworthiness of SEs (up to 8.5\%). Compared to smaller models, larger models show limited resilience to quantization in terms of SE quality but better maintain faithfulness. Moreover, no quantization technique consistently excels across task accuracy, SE quality, and faithfulness. Given that quantization's impact varies by context, we recommend validating SE quality for specific use cases, especially for NLEs, which show greater sensitivity. Nonetheless, the relatively minor deterioration in SE quality and faithfulness does not undermine quantization's effectiveness as a model compression technique.

</details>


### [12] [DepFlow: Disentangled Speech Generation to Mitigate Semantic Bias in Depression Detection](https://arxiv.org/abs/2601.00303)
*Yuxin Li,Xiangyu Zhang,Yifei Li,Zhiwei Guo,Haoyang Zhang,Eng Siong Chng,Cuntai Guan*

Main category: cs.CL

TL;DR: DepFlow: A depression-conditioned text-to-speech framework that generates acoustic-semantic mismatches to mitigate linguistic bias in depression detection models, improving robustness for real-world scenarios like camouflaged depression.


<details>
  <summary>Details</summary>
Motivation: Existing depression datasets show strong coupling between linguistic sentiment and diagnostic labels, causing models to learn semantic shortcuts. This compromises robustness in real-world scenarios like camouflaged depression where people use positive/neutral language despite being depressed.

Method: Three-stage framework: 1) Depression Acoustic Encoder with adversarial training learns speaker- and content-invariant depression embeddings; 2) Flow-matching TTS with FiLM modulation injects embeddings for controlled synthesis; 3) Prototype-based severity mapping for interpretable manipulation across depression continuum.

Result: Depression embeddings achieve ROC-AUC of 0.693. The generated Camouflage Depression-oriented Augmentation (CDoA) dataset improves macro-F1 by 9%, 12%, and 5% across three depression detection architectures, outperforming conventional augmentation strategies.

Conclusion: DepFlow effectively mitigates semantic bias in depression detection and provides a controllable synthesis platform for conversational systems and simulation-based evaluation where real clinical data is limited by ethical constraints.

Abstract: Speech is a scalable and non-invasive biomarker for early mental health screening. However, widely used depression datasets like DAIC-WOZ exhibit strong coupling between linguistic sentiment and diagnostic labels, encouraging models to learn semantic shortcuts. As a result, model robustness may be compromised in real-world scenarios, such as Camouflaged Depression, where individuals maintain socially positive or neutral language despite underlying depressive states. To mitigate this semantic bias, we propose DepFlow, a three-stage depression-conditioned text-to-speech framework. First, a Depression Acoustic Encoder learns speaker- and content-invariant depression embeddings through adversarial training, achieving effective disentanglement while preserving depression discriminability (ROC-AUC: 0.693). Second, a flow-matching TTS model with FiLM modulation injects these embeddings into synthesis, enabling control over depressive severity while preserving content and speaker identity. Third, a prototype-based severity mapping mechanism provides smooth and interpretable manipulation across the depression continuum. Using DepFlow, we construct a Camouflage Depression-oriented Augmentation (CDoA) dataset that pairs depressed acoustic patterns with positive/neutral content from a sentiment-stratified text bank, creating acoustic-semantic mismatches underrepresented in natural data. Evaluated across three depression detection architectures, CDoA improves macro-F1 by 9%, 12%, and 5%, respectively, consistently outperforming conventional augmentation strategies in depression Detection. Beyond enhancing robustness, DepFlow provides a controllable synthesis platform for conversational systems and simulation-based evaluation, where real clinical data remains limited by ethical and coverage constraints.

</details>


### [13] [Robust Uncertainty Quantification for Factual Generation of Large Language Models](https://arxiv.org/abs/2601.00348)
*Yuhao Zhang,Zhongliang Yang,Linna Zhou*

Main category: cs.CL

TL;DR: The paper proposes a novel uncertainty quantification method (RU) for detecting LLM hallucinations using trap questions with fake names, showing significant performance improvements over baseline methods.


<details>
  <summary>Details</summary>
Motivation: LLM hallucination remains a critical limitation affecting AI reliability. Traditional uncertainty quantification methods work well in standard QA but fail with non-canonical or adversarial questioning, creating a gap for real-world applications requiring robust critical thinking.

Method: The study creates trap questions containing fake names and proposes a novel robust uncertainty quantification method (RU). Experiments compare RU with baseline methods across four different LLM models using this adversarial testing scenario.

Result: The trap question set performs excellently. RU outperforms baseline methods with an average 0.1-0.2 increase in ROCAUC values compared to the best baseline across all four models tested.

Conclusion: The proposed RU method provides effective uncertainty quantification for LLM hallucination detection in adversarial scenarios, offering new insights and methods for addressing LLM reliability issues in real-world applications.

Abstract: The rapid advancement of large language model(LLM) technology has facilitated its integration into various domains of professional and daily life. However, the persistent challenge of LLM hallucination has emerged as a critical limitation, significantly compromising the reliability and trustworthiness of AI-generated content. This challenge has garnered significant attention within the scientific community, prompting extensive research efforts in hallucination detection and mitigation strategies. Current methodological frameworks reveal a critical limitation: traditional uncertainty quantification approaches demonstrate effectiveness primarily within conventional question-answering paradigms, yet exhibit notable deficiencies when confronted with non-canonical or adversarial questioning strategies. This performance gap raises substantial concerns regarding the dependability of LLM responses in real-world applications requiring robust critical thinking capabilities. This study aims to fill this gap by proposing an uncertainty quantification scenario in the task of generating with multiple facts. We have meticulously constructed a set of trap questions contained with fake names. Based on this scenario, we innovatively propose a novel and robust uncertainty quantification method(RU). A series of experiments have been conducted to verify its effectiveness. The results show that the constructed set of trap questions performs excellently. Moreover, when compared with the baseline methods on four different models, our proposed method has demonstrated great performance, with an average increase of 0.1-0.2 in ROCAUC values compared to the best performing baseline method, providing new sights and methods for addressing the hallucination issue of LLMs.

</details>


### [14] [The Role of Mixed-Language Documents for Multilingual Large Language Model Pretraining](https://arxiv.org/abs/2601.00364)
*Jiandong Shao,Raphael Tang,Crystina Zhang,Karin Sevegnani,Pontus Stenetorp,Jianfei Yang,Yao Lu*

Main category: cs.CL

TL;DR: Bilingual data (only 2% of corpus) is crucial for translation but not for cross-lingual QA/reasoning. Parallel data (14% of bilingual) restores translation, while code-switching (72%) contributes minimally.


<details>
  <summary>Details</summary>
Motivation: To understand how bilingual data in pretraining corpora enables cross-lingual abilities in multilingual LLMs, particularly why translation performance depends on it while other cross-lingual tasks don't.

Method: Pretrained models from scratch under controlled conditions: compared standard web corpus vs monolingual-only version (removed all multilingual docs). Categorized bilingual data into parallel (14%), code-switching (72%), and miscellaneous (14%). Conducted granular ablations by reintroducing parallel or code-switching data into monolingual-only corpus.

Result: Removing bilingual data (only 2% of corpus) causes 56% BLEU drop in translation, but cross-lingual QA and reasoning remain stable. Parallel data restores 91% of translation performance, while code-switching contributes minimally. Other cross-lingual tasks unaffected by either type.

Conclusion: Translation critically depends on systematic token-level alignments from parallel data, whereas cross-lingual understanding and reasoning can be achieved without bilingual data, suggesting different mechanisms for different cross-lingual abilities.

Abstract: Multilingual large language models achieve impressive cross-lingual performance despite largely monolingual pretraining. While bilingual data in pretraining corpora is widely believed to enable these abilities, details of its contributions remain unclear. We investigate this question by pretraining models from scratch under controlled conditions, comparing the standard web corpus with a monolingual-only version that removes all multilingual documents. Despite constituting only 2% of the corpus, removing bilingual data causes translation performance to drop 56% in BLEU, while behaviour on cross-lingual QA and general reasoning tasks remains stable, with training curves largely overlapping the baseline. To understand this asymmetry, we categorize bilingual data into parallel (14%), code-switching (72%), and miscellaneous documents (14%) based on the semantic relevance of content in different languages. We then conduct granular ablations by reintroducing parallel or code-switching data into the monolingual-only corpus. Our experiments reveal that parallel data almost fully restores translation performance (91% of the unfiltered baseline), whereas code-switching contributes minimally. Other cross-lingual tasks remain largely unaffected by either type. These findings reveal that translation critically depends on systematic token-level alignments from parallel data, whereas cross-lingual understanding and reasoning appear to be achievable even without bilingual data.

</details>


### [15] [BERT-JEPA: Reorganizing CLS Embeddings for Language-Invariant Semantics](https://arxiv.org/abs/2601.00366)
*Taj Gillin,Adam Lalani,Kenneth Zhang,Marcel Mateos Salles*

Main category: cs.CL

TL;DR: BERT-JEPA (BEPA) combines BERT-style models with Joint Embedding Predictive Architecture (JEPA) training to create language-agnostic [CLS] embeddings, improving multilingual performance.


<details>
  <summary>Details</summary>
Motivation: To address the collapsed [CLS] embedding space in BERT-style models and transform it into a language-agnostic representation space for better multilingual performance.

Method: Adds a JEPA (Joint Embedding Predictive Architecture) training objective to BERT-style models, creating BERT-JEPA (BEPA) architecture that learns to predict embeddings across languages.

Result: Increased performance across multilingual benchmarks, demonstrating the effectiveness of JEPA training for creating language-agnostic representations.

Conclusion: BEPA successfully combines JEPA training with BERT-style models to create language-agnostic embeddings, improving multilingual task performance and addressing collapsed embedding spaces.

Abstract: Joint Embedding Predictive Architectures (JEPA) are a novel self supervised training technique that have shown recent promise across domains. We introduce BERT-JEPA (BEPA), a training paradigm that adds a JEPA training objective to BERT-style models, working to combat a collapsed [CLS] embedding space and turning it into a language-agnostic space. This new structure leads to increased performance across multilingual benchmarks.

</details>


### [16] [Vision-Language Reasoning for Geolocalization: A Reinforcement Learning Approach](https://arxiv.org/abs/2601.00388)
*Biao Wu,Meng Fang,Ling Chen,Ke Xu,Tao Cheng,Jun Wang*

Main category: cs.CL

TL;DR: Geo-R is a retrieval-free vision-language framework for image geolocalization that uses structured geographic reasoning with reinforcement learning, achieving improved accuracy and interpretability without synthetic annotations or external retrieval.


<details>
  <summary>Details</summary>
Motivation: Existing vision-language models for image geolocalization rely on synthetic reasoning annotations or external image retrieval, which limits interpretability and generalizability. There's a need for a more transparent, scalable approach that doesn't depend on these limitations.

Method: Proposes Geo-R with two key components: 1) Chain of Region - a rule-based hierarchical reasoning paradigm that maps GPS coordinates to geographic entities (country, province, city) without synthetic labels, and 2) A lightweight reinforcement learning strategy with coordinate-aligned rewards based on Haversine distance to refine predictions through spatially meaningful feedback.

Result: Experimental results across multiple benchmarks confirm the effectiveness of Geo-R, showing improved localization accuracy, stronger generalization, and more transparent inference compared to existing approaches.

Conclusion: Geo-R establishes a new retrieval-free paradigm for scalable and interpretable image geolocalization by bridging structured geographic reasoning with direct spatial supervision, with both model and code to be made publicly available for reproducibility.

Abstract: Recent advances in vision-language models have opened up new possibilities for reasoning-driven image geolocalization. However, existing approaches often rely on synthetic reasoning annotations or external image retrieval, which can limit interpretability and generalizability. In this paper, we present Geo-R, a retrieval-free framework that uncovers structured reasoning paths from existing ground-truth coordinates and optimizes geolocation accuracy via reinforcement learning. We propose the Chain of Region, a rule-based hierarchical reasoning paradigm that generates precise, interpretable supervision by mapping GPS coordinates to geographic entities (e.g., country, province, city) without relying on model-generated or synthetic labels. Building on this, we introduce a lightweight reinforcement learning strategy with coordinate-aligned rewards based on Haversine distance, enabling the model to refine predictions through spatially meaningful feedback. Our approach bridges structured geographic reasoning with direct spatial supervision, yielding improved localization accuracy, stronger generalization, and more transparent inference. Experimental results across multiple benchmarks confirm the effectiveness of Geo-R, establishing a new retrieval-free paradigm for scalable and interpretable image geolocalization. To facilitate further research and ensure reproducibility, both the model and code will be made publicly available.

</details>


### [17] [Do LLMs Judge Distantly Supervised Named Entity Labels Well? Constructing the JudgeWEL Dataset](https://arxiv.org/abs/2601.00411)
*Alistair Plum,Laura Bernardy,Tharindu Ranasinghe*

Main category: cs.CL

TL;DR: judgeWEL is a new Luxembourgish NER dataset created using Wikipedia/Wikidata weak supervision and LLM verification, offering 5x larger and more balanced coverage than existing resources.


<details>
  <summary>Details</summary>
Motivation: Building datasets for under-represented languages like Luxembourgish is challenging due to resource scarcity, high annotation costs, and linguistic particularities that lead to inconsistency.

Method: Leverages Wikipedia internal links and Wikidata entries for weak supervision to infer entity types, then uses multiple LLMs to verify and filter annotations for quality, creating a novel automated pipeline.

Result: Produced a Luxembourgish NER corpus approximately 5 times larger than currently available datasets with broader and more balanced coverage across entity categories.

Conclusion: judgeWEL provides a substantial new resource for multilingual and low-resource NER research, demonstrating effective use of structured knowledge bases and LLMs for dataset creation in under-resourced languages.

Abstract: We present judgeWEL, a dataset for named entity recognition (NER) in Luxembourgish, automatically labelled and subsequently verified using large language models (LLM) in a novel pipeline. Building datasets for under-represented languages remains one of the major bottlenecks in natural language processing, where the scarcity of resources and linguistic particularities make large-scale annotation costly and potentially inconsistent. To address these challenges, we propose and evaluate a novel approach that leverages Wikipedia and Wikidata as structured sources of weak supervision. By exploiting internal links within Wikipedia articles, we infer entity types based on their corresponding Wikidata entries, thereby generating initial annotations with minimal human intervention. Because such links are not uniformly reliable, we mitigate noise by employing and comparing several LLMs to identify and retain only high-quality labelled sentences. The resulting corpus is approximately five times larger than the currently available Luxembourgish NER dataset and offers broader and more balanced coverage across entity categories, providing a substantial new resource for multilingual and low-resource NER research.

</details>


### [18] [Toward Better Temporal Structures for Geopolitical Events Forecasting](https://arxiv.org/abs/2601.00430)
*Kian Ahrabian,Eric Boxer,Jay Pujara*

Main category: cs.CL

TL;DR: The paper introduces Hyper-Relational Temporal Knowledge Generalized Hypergraphs (HTKGHs) to address limitations of existing temporal knowledge graphs in representing complex geopolitical events with more than two entities, and benchmarks LLMs on relation prediction using a new dataset.


<details>
  <summary>Details</summary>
Motivation: Current temporal knowledge graphs (TKGs) and hyper-relational TKGs (HTKGs) lack expressive power for complex facts, particularly those involving more than two primary entities in real-world geopolitical events.

Method: 1) Formalize HTKGHs as a generalization of HTKGs with backward compatibility, 2) Create htkgh-polecat dataset from POLECAT global event database, 3) Benchmark popular LLMs on relation prediction tasks.

Result: Introduces HTKGH framework that supports complex fact types common in geopolitical incidents, creates a new dataset, and provides analysis of LLM performance on complex forecasting scenarios.

Conclusion: HTKGHs offer improved representation for complex temporal facts in geopolitical forecasting, and LLM benchmarking reveals insights about their adaptability to complex relation prediction tasks.

Abstract: Forecasting on geopolitical temporal knowledge graphs (TKGs) through the lens of large language models (LLMs) has recently gained traction. While TKGs and their generalization, hyper-relational temporal knowledge graphs (HTKGs), offer a straightforward structure to represent simple temporal relationships, they lack the expressive power to convey complex facts efficiently. One of the critical limitations of HTKGs is a lack of support for more than two primary entities in temporal facts, which commonly occur in real-world events. To address this limitation, in this work, we study a generalization of HTKGs, Hyper-Relational Temporal Knowledge Generalized Hypergraphs (HTKGHs). We first derive a formalization for HTKGHs, demonstrating their backward compatibility while supporting two complex types of facts commonly found in geopolitical incidents. Then, utilizing this formalization, we introduce the htkgh-polecat dataset, built upon the global event database POLECAT. Finally, we benchmark and analyze popular LLMs on the relation prediction task, providing insights into their adaptability and capabilities in complex forecasting scenarios.

</details>


### [19] [Comparative Efficiency Analysis of Lightweight Transformer Models: A Multi-Domain Empirical Benchmark for Enterprise NLP Deployment](https://arxiv.org/abs/2601.00444)
*Muhammad Shahmeer Khan*

Main category: cs.CL

TL;DR: Comparative analysis of three lightweight Transformer models (DistilBERT, MiniLM, ALBERT) across three NLP domains shows trade-offs: ALBERT has highest accuracy in multiple domains, MiniLM excels in inference speed, and DistilBERT offers most consistent accuracy with competitive efficiency.


<details>
  <summary>Details</summary>
Motivation: Enterprise NLP needs efficient, lightweight models for multi-domain text automation tasks, requiring understanding of trade-offs between accuracy and efficiency for practical deployment.

Method: Comparative analysis of DistilBERT, MiniLM, and ALBERT across three domains (customer sentiment, news topic classification, toxicity detection) using IMDB, AG News, and Measuring Hate Speech datasets. Evaluated using accuracy metrics (accuracy, precision, recall, F1) and efficiency metrics (model size, inference time, throughput, memory usage) with controlled fine-tuning under fixed enterprise constraints.

Result: No single model dominates all dimensions: ALBERT achieves highest task-specific accuracy in multiple domains, MiniLM excels in inference speed and throughput, and DistilBERT demonstrates most consistent accuracy across tasks while maintaining competitive efficiency.

Conclusion: Trade-offs exist between accuracy and efficiency: recommend MiniLM for latency-sensitive applications, DistilBERT for balanced performance, and ALBERT for resource-constrained environments. Model selection should align with specific enterprise requirements.

Abstract: In the rapidly evolving landscape of enterprise natural language processing (NLP), the demand for efficient, lightweight models capable of handling multi-domain text automation tasks has intensified. This study conducts a comparative analysis of three prominent lightweight Transformer models - DistilBERT, MiniLM, and ALBERT - across three distinct domains: customer sentiment classification, news topic classification, and toxicity and hate speech detection. Utilizing datasets from IMDB, AG News, and the Measuring Hate Speech corpus, we evaluated performance using accuracy-based metrics including accuracy, precision, recall, and F1-score, as well as efficiency metrics such as model size, inference time, throughput, and memory usage. Key findings reveal that no single model dominates all performance dimensions. ALBERT achieves the highest task-specific accuracy in multiple domains, MiniLM excels in inference speed and throughput, and DistilBERT demonstrates the most consistent accuracy across tasks while maintaining competitive efficiency. All results reflect controlled fine-tuning under fixed enterprise-oriented constraints rather than exhaustive hyperparameter optimization. These results highlight trade-offs between accuracy and efficiency, recommending MiniLM for latency-sensitive enterprise applications, DistilBERT for balanced performance, and ALBERT for resource-constrained environments.

</details>


### [20] [Language as Mathematical Structure: Examining Semantic Field Theory Against Language Games](https://arxiv.org/abs/2601.00448)
*Dimitris Vartziotis*

Main category: cs.CL

TL;DR: LLMs provide a testbed for linguistic theories: mathematical Semantic Field Theory vs. social constructivist language games. The paper formalizes lexical/linguistic fields in semantic space and analyzes how transformer architectures relate to these concepts.


<details>
  <summary>Details</summary>
Motivation: To examine long-standing theories of linguistic meaning using LLMs as an empirical setting, contrasting social constructivist approaches (language games) with mathematical Semantic Field Theory.

Method: Formalizes lexical fields (Lexfelder) and linguistic fields (Lingofelder) as interacting structures in continuous semantic space. Analyzes how transformer architecture properties (distributed representations, attention mechanisms, embedding space geometry) relate to these concepts.

Result: LLMs' success in capturing semantic regularities supports mathematical structure in language, while their limitations in pragmatic reasoning and context sensitivity align with social grounding importance. Mathematical structure and language games are complementary rather than competing perspectives.

Conclusion: The framework clarifies scope/limits of statistical language models and motivates new directions for theoretically informed AI architectures that integrate both mathematical structure and social aspects of language.

Abstract: Large language models (LLMs) offer a new empirical setting in which long-standing theories of linguistic meaning can be examined. This paper contrasts two broad approaches: social constructivist accounts associated with language games, and a mathematically oriented framework we call Semantic Field Theory. Building on earlier work by the author, we formalize the notions of lexical fields (Lexfelder) and linguistic fields (Lingofelder) as interacting structures in a continuous semantic space. We then analyze how core properties of transformer architectures-such as distributed representations, attention mechanisms, and geometric regularities in embedding spaces-relate to these concepts. We argue that the success of LLMs in capturing semantic regularities supports the view that language exhibits an underlying mathematical structure, while their persistent limitations in pragmatic reasoning and context sensitivity are consistent with the importance of social grounding emphasized in philosophical accounts of language use. On this basis, we suggest that mathematical structure and language games can be understood as complementary rather than competing perspectives. The resulting framework clarifies the scope and limits of purely statistical models of language and motivates new directions for theoretically informed AI architectures.

</details>


### [21] [Defensive M2S: Training Guardrail Models on Compressed Multi-turn Conversations](https://arxiv.org/abs/2601.00454)
*Hyunjun Kim*

Main category: cs.CL

TL;DR: Defensive M2S trains guardrail models on compressed multi-turn conversations, reducing training cost from O(n²) to O(n) and achieving 93× token reduction while maintaining high attack detection performance.


<details>
  <summary>Details</summary>
Motivation: Processing full multi-turn conversation histories for LLM safety guardrails incurs significant computational cost, making deployment inefficient for long conversations.

Method: Fine-tunes guardrail models on Multi-turn to Single-turn (M2S) compressed conversations using compression templates (hyphenize, numberize, pythonize) rather than complete dialogue histories.

Result: Achieves 93.8% attack detection recall with 94.6% inference token reduction (from 3,231 to 173 tokens), representing 38.9 percentage point improvement over baseline while reducing training tokens by 93×.

Conclusion: M2S compression is an effective efficiency technique for guardrail deployment, enabling scalable safety screening of long multi-turn conversations with dramatically reduced computational costs.

Abstract: Guardrail models are essential for ensuring the safety of Large Language Model (LLM) deployments, but processing full multi-turn conversation histories incurs significant computational cost. We propose Defensive M2S, a training paradigm that fine-tunes guardrail models on Multi-turn to Single-turn (M2S) compressed conversations rather than complete dialogue histories. We provide a formal complexity analysis showing that M2S reduces training cost from $O(n^2)$ to $O(n)$ for $n$-turn conversations. Empirically, on our training dataset (779 samples, avg. 10.6 turns), M2S requires only 169K tokens compared to 15.7M tokens for the multi-turn baseline -- a 93$\times$ reduction. We evaluate Defensive M2S across three guardrail model families (LlamaGuard, Nemotron, Qwen3Guard) and three compression templates (hyphenize, numberize, pythonize) on SafeDialBench, a comprehensive multi-turn jailbreak benchmark. Our best configuration, Qwen3Guard with hyphenize compression, achieves 93.8% attack detection recall while reducing inference tokens by 94.6% (from 3,231 to 173 tokens per conversation). This represents a 38.9 percentage point improvement over the baseline while dramatically reducing both training and inference costs. Our findings demonstrate that M2S compression can serve as an effective efficiency technique for guardrail deployment, enabling scalable safety screening of long multi-turn conversations.

</details>


### [22] [Noise-Aware Named Entity Recognition for Historical VET Documents](https://arxiv.org/abs/2601.00488)
*Alexander M. Esser,Jens Dörpinghaus*

Main category: cs.CL

TL;DR: A robust NER approach for noisy VET documents using noise-aware training with synthetic OCR errors, transfer learning, and multi-stage fine-tuning, achieving improved accuracy under noisy conditions.


<details>
  <summary>Details</summary>
Motivation: NER in Vocational Education and Training (VET) documents is challenging due to historical digitized documents with OCR-induced noise, requiring robust methods to handle these noisy conditions.

Method: Proposes noise-aware training with synthetically injected OCR errors, transfer learning, and multi-stage fine-tuning. Compares three strategies: training on noisy data, clean data, and artificially generated data.

Result: Domain-specific and noise-aware fine-tuning substantially increases robustness and accuracy under noisy conditions. The method successfully recognizes multiple entity types in VET documents.

Conclusion: The approach provides an effective solution for NER in noisy domain-specific documents, with publicly available code for reproducible noise-aware NER applications across languages.

Abstract: This paper addresses Named Entity Recognition (NER) in the domain of Vocational Education and Training (VET), focusing on historical, digitized documents that suffer from OCR-induced noise. We propose a robust NER approach leveraging Noise-Aware Training (NAT) with synthetically injected OCR errors, transfer learning, and multi-stage fine-tuning. Three complementary strategies, training on noisy, clean, and artificial data, are systematically compared. Our method is one of the first to recognize multiple entity types in VET documents. It is applied to German documents but transferable to arbitrary languages. Experimental results demonstrate that domain-specific and noise-aware fine-tuning substantially increases robustness and accuracy under noisy conditions. We provide publicly available code for reproducible noise-aware NER in domain-specific contexts.

</details>


### [23] [Rule-Based Approaches to Atomic Sentence Extraction](https://arxiv.org/abs/2601.00506)
*Lineesha Kamana,Akshita Ananda Subramanian,Mehuli Ghosh,Suman Saha*

Main category: cs.CL

TL;DR: Rule-based atomic sentence extraction achieves moderate-to-high performance but struggles with complex syntactic structures like relative clauses, appositions, and passive constructions.


<details>
  <summary>Details</summary>
Motivation: Previous machine learning approaches for atomic sentence extraction lack interpretability and insight into which linguistic structures cause extraction failures, creating a need for principled analysis of specific clause structures and dependencies.

Method: Implemented dependency-based extraction rules in spaCy using the WikiSplit dataset, generated 100 gold-standard atomic sentence sets, and evaluated performance using ROUGE and BERTScore metrics.

Result: System achieved ROUGE-1 F1 = 0.6714, ROUGE-2 F1 = 0.478, ROUGE-L F1 = 0.650, and BERTScore F1 = 0.5898, showing moderate-to-high alignment. Challenging structures included relative clauses, appositions, coordinated predicates, adverbial clauses, and passive constructions.

Conclusion: Rule-based extraction is reasonably accurate but sensitive to syntactic complexity, providing interpretable insights into extraction difficulties that machine learning approaches lack.

Abstract: Natural language often combines multiple ideas into complex sentences. Atomic sentence extraction, the task of decomposing complex sentences into simpler sentences that each express a single idea, improves performance in information retrieval, question answering, and automated reasoning systems. Previous work has formalized the "split-and-rephrase" task and established evaluation metrics, and machine learning approaches using large language models have improved extraction accuracy. However, these methods lack interpretability and provide limited insight into which linguistic structures cause extraction failures. Although some studies have explored dependency-based extraction of subject-verb-object triples and clauses, no principled analysis has examined which specific clause structures and dependencies lead to extraction difficulties. This study addresses this gap by analyzing how complex sentence structures, including relative clauses, adverbial clauses, coordination patterns, and passive constructions, affect the performance of rule-based atomic sentence extraction. Using the WikiSplit dataset, we implemented dependency-based extraction rules in spaCy, generated 100 gold=standard atomic sentence sets, and evaluated performance using ROUGE and BERTScore. The system achieved ROUGE-1 F1 = 0.6714, ROUGE-2 F1 = 0.478, ROUGE-L F1 = 0.650, and BERTScore F1 = 0.5898, indicating moderate-to-high lexical, structural, and semantic alignment. Challenging structures included relative clauses, appositions, coordinated predicates, adverbial clauses, and passive constructions. Overall, rule-based extraction is reasonably accurate but sensitive to syntactic complexity.

</details>


### [24] [Retrieval--Reasoning Processes for Multi-hop Question Answering: A Four-Axis Design Framework and Empirical Trends](https://arxiv.org/abs/2601.00536)
*Yuelyu Ji,Zhuochun Li,Rui Meng,Daqing He*

Main category: cs.CL

TL;DR: Survey paper analyzing multi-hop QA systems through a four-axis framework focusing on execution procedures, mapping existing approaches, and identifying trade-offs between effectiveness, efficiency, and faithfulness.


<details>
  <summary>Details</summary>
Motivation: Current multi-hop QA systems often leave their retrieval-reasoning processes implicit, making it difficult to compare procedural choices across different model families and approaches.

Method: Introduces a four-axis framework for analyzing multi-hop QA systems: (A) overall execution plan, (B) index structure, (C) next-step control (strategies and triggers), and (D) stop/continue criteria. Uses this framework to map representative systems and analyze ablations on standard benchmarks.

Result: Systematically categorizes multi-hop QA approaches, synthesizes ablation studies and performance tendencies on benchmarks like HotpotQA, 2WikiMultiHopQA, and MuSiQue, highlighting recurring trade-offs among effectiveness, efficiency, and evidence faithfulness.

Conclusion: Identifies open challenges for retrieval-reasoning agents including structure-aware planning, transferable control policies, and robust stopping under distribution shift, providing a structured framework for future research.

Abstract: Multi-hop question answering (QA) requires systems to iteratively retrieve evidence and reason across multiple hops. While recent RAG and agentic methods report strong results, the underlying retrieval--reasoning \emph{process} is often left implicit, making procedural choices hard to compare across model families. This survey takes the execution procedure as the unit of analysis and introduces a four-axis framework covering (A) overall execution plan, (B) index structure, (C) next-step control (strategies and triggers), and (D) stop/continue criteria. Using this schema, we map representative multi-hop QA systems and synthesize reported ablations and tendencies on standard benchmarks (e.g., HotpotQA, 2WikiMultiHopQA, MuSiQue), highlighting recurring trade-offs among effectiveness, efficiency, and evidence faithfulness. We conclude with open challenges for retrieval--reasoning agents, including structure-aware planning, transferable control policies, and robust stopping under distribution shift.

</details>


### [25] [ECR: Manifold-Guided Semantic Cues for Compact Language Models](https://arxiv.org/abs/2601.00543)
*Chung-Wei Victor Yuan*

Main category: cs.CL

TL;DR: ECR framework preserves embedding space structure in compact models by maintaining geometry around semantic anchors, enabling better downstream task performance without altering inference architecture.


<details>
  <summary>Details</summary>
Motivation: Compact models lose embedding space structure when capacity is limited or data spans multiple languages, causing semantic drift and making downstream tasks difficult. Existing compression methods fail to preserve underlying manifold structure.

Method: Embedding Consistency Regulation (ECR) framework: derives semantic anchors from teacher embeddings offline, then trains compact model to maintain consistent geometry around these anchors without matching logits or internal features. Adds only small projection step at inference without altering decoding architecture.

Result: On 100K multilingual corpus, ECR stabilizes training and preserves semantic structure across tasks and languages. Produces more compact and task-aligned representation space, enabling low-capacity models to learn cleaner manifolds than conventional baselines.

Conclusion: ECR helps compact models better follow task requirements and makes them easier to deploy under strict efficiency or privacy limits. Works without teacher outputs and is compatible with but independent of distillation.

Abstract: Compact models often lose the structure of their embedding space. The issue shows up when the capacity is tight or the data spans several languages. Such collapse makes it difficult for downstream tasks to build on the resulting representation. Existing compression methods focus on aligning model outputs at a superficial level but fail to preserve the underlying manifold structure. This mismatch often leads to semantic drift in the compact model, causing both task behavior and linguistic properties to deviate from the reference model.
  To address those issues, we provide a new framework called Embedding Consistency Regulation (ECR). This framework first derives a set of semantic anchors from teacher embeddings (computed once offline). Then, the compact model learns to maintain consistent geometry around these anchors, without relying on matching logits or internal features. ECR adds only a small projection step at inference, without altering the decoding architecture or its runtime behavior.
  In experiments on a 100K multilingual corpus, ECR consistently stabilizes training and preserves semantic structure across tasks and languages. It also produces a more compact and task-aligned representation space, enabling low-capacity models to learn cleaner manifolds than conventional baselines. ECR works without teacher outputs and is compatible with, but independent of, distillation. Taken together, our results show that ECR helps compact models better follow task requirements and makes them easier to deploy under strict efficiency or privacy limits.

</details>


### [26] [A Language-Agnostic Hierarchical LoRA-MoE Architecture for CTC-based Multilingual ASR](https://arxiv.org/abs/2601.00557)
*Yuang Zheng,Yuxiang Mei,Dongxing Xu,Jie Chen,Yanhua Long*

Main category: cs.CL

TL;DR: Lightweight multilingual ASR system using CTC architecture with domain adaptation via Language-agnostic Hierarchical LoRA-MoE framework for efficient edge deployment.


<details>
  <summary>Details</summary>
Motivation: Large-scale multilingual ASR models like Whisper have high computational and latency costs, limiting deployment on resource-constrained edge devices.

Method: Propose HLoRA framework integrated into mHuBERT-CTC model with hierarchical design: multilingual shared LoRA for language-invariant representations and language-specific LoRA experts for language-dependent characteristics. Uses LID-posterior-driven LoRA routing for end-to-end decoding without prior language information.

Result: Achieves competitive performance with state-of-the-art two-stage inference methods using only single-pass decoding, significantly improving decoding efficiency for low-resource mASR applications on MSR-86K and MLC-SLM 2025 Challenge datasets.

Conclusion: HLoRA enables lightweight, language-agnostic multilingual ASR with efficient single-pass decoding, making it suitable for resource-constrained edge devices while maintaining competitive performance.

Abstract: Large-scale multilingual ASR (mASR) models such as Whisper achieve strong performance but incur high computational and latency costs, limiting their deployment on resource-constrained edge devices. In this study, we propose a lightweight and language-agnostic multilingual ASR system based on a CTC architecture with domain adaptation. Specifically, we introduce a Language-agnostic Hierarchical LoRA-MoE (HLoRA) framework integrated into an mHuBERT-CTC model, enabling end-to-end decoding via LID-posterior-driven LoRA routing. The hierarchical design consists of a multilingual shared LoRA for learning language-invariant acoustic representations and language-specific LoRA experts for modeling language-dependent characteristics. The proposed routing mechanism removes the need for prior language identity information or explicit language labels during inference, achieving true language-agnostic decoding. Experiments on MSR-86K and the MLC-SLM 2025 Challenge datasets demonstrate that HLoRA achieves competitive performance with state-of-the-art two-stage inference methods using only single-pass decoding, significantly improving decoding efficiency for low-resource mASR applications.

</details>


### [27] [InfoSynth: Information-Guided Benchmark Synthesis for LLMs](https://arxiv.org/abs/2601.00575)
*Ishir Garg,Neel Kolhe,Xuandong Zhao,Dawn Song*

Main category: cs.CL

TL;DR: InfoSynth is an automated framework for generating novel and diverse reasoning benchmarks for LLMs using information-theoretic metrics and genetic algorithms, achieving 97% accuracy in creating Python coding problems with controllable novelty and difficulty.


<details>
  <summary>Details</summary>
Motivation: Traditional benchmark creation is manual, expensive, and time-consuming. Existing benchmarks often contaminate LLM training data, requiring novel and diverse benchmarks to accurately assess LLMs' genuine reasoning and code generation capabilities.

Method: Proposes InfoSynth framework using information-theoretic principles (KL-divergence and entropy metrics) to quantify benchmark novelty/diversity. Develops end-to-end pipeline that synthesizes Python coding problems from seed datasets using genetic algorithms and iterative code feedback.

Result: Method generates accurate test cases and solutions to new problems 97% of the time. Synthesized benchmarks consistently show higher novelty and diversity compared to seed datasets. Algorithm provides control over novelty/diversity and difficulty of generated problems.

Conclusion: InfoSynth offers a scalable, self-verifying pipeline for constructing high-quality, novel and diverse benchmarks for LLMs, addressing the limitations of traditional manual benchmark creation methods.

Abstract: Large language models (LLMs) have demonstrated significant advancements in reasoning and code generation. However, efficiently creating new benchmarks to evaluate these capabilities remains a challenge. Traditional benchmark creation relies on manual human effort, a process that is both expensive and time-consuming. Furthermore, existing benchmarks often contaminate LLM training data, necessitating novel and diverse benchmarks to accurately assess their genuine capabilities. This work introduces InfoSynth, a novel framework for automatically generating and evaluating reasoning benchmarks guided by information-theoretic principles. We propose metrics based on KL-divergence and entropy to quantify benchmark novelty and diversity without relying on costly model evaluations. Building on this framework, we develop an end-to-end pipeline that synthesizes robust Python coding problems from seed datasets using genetic algorithms and iterative code feedback. Our method generates accurate test cases and solutions to new problems 97% of the time, and the synthesized benchmarks consistently exhibit higher novelty and diversity compared to their seed datasets. Moreover, our algorithm provides a method for controlling the novelty/diversity and difficulty of generated problems. InfoSynth offers a scalable, self-verifying pipeline for constructing high-quality, novel and diverse benchmarks for LLMs. Project Page: https://ishirgarg.github.io/infosynth_web/

</details>


### [28] [CSSBench: Evaluating the Safety of Lightweight LLMs against Chinese-Specific Adversarial Patterns](https://arxiv.org/abs/2601.00588)
*Zhenhong Zhou,Shilinlu Yan,Chuanpu Liu,Qiankun Li,Kun Wang,Zhigang Zeng*

Main category: cs.CL

TL;DR: CSSBench is a Chinese-specific safety benchmark that evaluates lightweight LLMs against adversarial patterns unique to Chinese (homophones, pinyin, symbol-splitting) across six safety domains, revealing vulnerabilities in current models.


<details>
  <summary>Details</summary>
Motivation: Existing safety benchmarks focus mainly on English, creating a gap for Chinese where malicious queries use language-specific adversarial patterns (homophones, pinyin, symbol-splitting) that lightweight LLMs deployed in cost-sensitive scenarios may be vulnerable to.

Method: Created CSSBench covering six Chinese safety domains (illegal activities, privacy, health misinformation, fraud/hate, adult content, political safety) with queries organized into multiple task types. Evaluated popular lightweight LLMs and measured over-refusal behavior to assess safety-induced performance degradation.

Result: Chinese-specific adversarial patterns present a critical challenge for lightweight LLMs, revealing safety vulnerabilities not captured by English-focused benchmarks. The benchmark provides comprehensive evaluation of LLM safety in Chinese contexts.

Conclusion: CSSBench bridges the Chinese safety evaluation gap by focusing on language-specific adversarial patterns, helping ensure robust deployment of lightweight LLMs in real-world Chinese scenarios where cost-sensitive and on-device applications are common.

Abstract: Large language models (LLMs) are increasingly deployed in cost-sensitive and on-device scenarios, and safety guardrails have advanced mainly in English. However, real-world Chinese malicious queries typically conceal intent via homophones, pinyin, symbol-based splitting, and other Chinese-specific patterns. These Chinese-specific adversarial patterns create the safety evaluation gap that is not well captured by existing benchmarks focused on English. This gap is particularly concerning for lightweight models, which may be more vulnerable to such specific adversarial perturbations. To bridge this gap, we introduce the Chinese-Specific Safety Benchmark (CSSBench) that emphasizes these adversarial patterns and evaluates the safety of lightweight LLMs in Chinese. Our benchmark covers six domains that are common in real Chinese scenarios, including illegal activities and compliance, privacy leakage, health and medical misinformation, fraud and hate, adult content, and public and political safety, and organizes queries into multiple task types. We evaluate a set of popular lightweight LLMs and measure over-refusal behavior to assess safety-induced performance degradation. Our results show that the Chinese-specific adversarial pattern is a critical challenge for lightweight LLMs. This benchmark offers a comprehensive evaluation of LLM safety in Chinese, assisting robust deployments in practice.

</details>


### [29] [Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence](https://arxiv.org/abs/2601.00596)
*Sumanth Balaji,Piyush Mishra,Aashraya Sachdeva,Suraj Agrawal*

Main category: cs.CL

TL;DR: JourneyBench is a new benchmark for evaluating LLM agents in customer support, focusing on policy adherence rather than just task completion, with a novel metric and showing that dynamic prompt agents outperform static ones.


<details>
  <summary>Details</summary>
Motivation: Traditional customer support systems like IVR are rigid and can't handle complex policy-driven tasks. While LLM agents offer promise, existing benchmarks focus only on tool usage or task completion, ignoring crucial aspects like policy adherence, multi-step workflows, and robustness to unpredictable user behavior.

Method: Introduced JourneyBench benchmark using graph representations to generate diverse, realistic support scenarios. Proposed User Journey Coverage Score metric to measure policy adherence. Evaluated two agent designs: Static-Prompt Agent (SPA) and Dynamic-Prompt Agent (DPA) that explicitly models policy control. Tested across 703 conversations in three domains.

Result: DPA significantly boosts policy adherence, allowing smaller models like GPT-4o-mini to outperform more capable ones like GPT-4o. Structured orchestration through dynamic prompting proves crucial for policy-aware performance.

Conclusion: JourneyBench establishes a critical resource to advance AI-driven customer support beyond IVR limitations, demonstrating the importance of structured orchestration for policy adherence in complex support workflows.

Abstract: Traditional customer support systems, such as Interactive Voice Response (IVR), rely on rigid scripts and lack the flexibility required for handling complex, policy-driven tasks. While large language model (LLM) agents offer a promising alternative, evaluating their ability to act in accordance with business rules and real-world support workflows remains an open challenge. Existing benchmarks primarily focus on tool usage or task completion, overlooking an agent's capacity to adhere to multi-step policies, navigate task dependencies, and remain robust to unpredictable user or environment behavior. In this work, we introduce JourneyBench, a benchmark designed to assess policy-aware agents in customer support. JourneyBench leverages graph representations to generate diverse, realistic support scenarios and proposes the User Journey Coverage Score, a novel metric to measure policy adherence. We evaluate multiple state-of-the-art LLMs using two agent designs: a Static-Prompt Agent (SPA) and a Dynamic-Prompt Agent (DPA) that explicitly models policy control. Across 703 conversations in three domains, we show that DPA significantly boosts policy adherence, even allowing smaller models like GPT-4o-mini to outperform more capable ones like GPT-4o. Our findings demonstrate the importance of structured orchestration and establish JourneyBench as a critical resource to advance AI-driven customer support beyond IVR-era limitations.

</details>


### [30] [Probabilistic Guarantees for Reducing Contextual Hallucinations in LLMs](https://arxiv.org/abs/2601.00641)
*Nils Rautenberg,Sven Schippkus*

Main category: cs.CL

TL;DR: A framework providing probabilistic guarantees against hallucinations in fixed-input LLM workflows using repeated sampling and judge ensembles.


<details>
  <summary>Details</summary>
Motivation: LLMs frequently produce contextual hallucinations that contradict explicit prompt information, which is problematic for deterministic automation workflows where correctness must be unambiguous.

Method: Model-agnostic framework using repeated prompting in independent context windows (exponential error reduction), LLM-as-a-judge to identify correct answers, and majority voting over judge calls to strengthen imperfect judges.

Result: Experiments show pipeline failure decreases exponentially with repetitions, and hallucination-selection decreases exponentially with number of judges in ensemble, matching theoretical predictions.

Conclusion: Provides lightweight, modular, theoretically grounded method to drive hallucination probabilities arbitrarily low in fixed-input LLM workflows without modifying model weights, decoding strategies, or prompt engineering.

Abstract: Large language models (LLMs) frequently produce contextual hallucinations, where generated content contradicts or ignores information explicitly stated in the prompt. Such errors are particularly problematic in deterministic automation workflows, where inputs are fixed and correctness is unambiguous. We introduce a simple and model-agnostic framework that provides explicit probabilistic guarantees for reducing hallucinations in this setting.
  We formalize the notion of a specific task, defined by a fixed input and a deterministic correctness criterion, and show that issuing the same prompt in independent context windows yields an exponential reduction in the probability that all model outputs are incorrect. To identify a correct answer among repeated runs, we incorporate an LLM-as-a-judge and prove that the probability that the judged pipeline fails decays at a rate determined by the judge's true- and false-positive probabilities. When the judge is imperfect, we strengthen it through majority vote over independent judge calls, obtaining ensemble-level error rates that decrease exponentially in the number of votes. This yields an explicit bound on the probability that the pipeline selects a hallucinated answer.
  Experiments on controlled extraction tasks with synthetic noisy judges match these predictions exactly: pipeline failure decreases exponentially with the number of repetitions, and hallucination-selection decreases exponentially with the number of judges in the ensemble. Together, these results provide a lightweight, modular, and theoretically grounded method for driving hallucination probabilities arbitrarily low in fixed-input LLM workflows-without modifying model weights, decoding strategies, or prompt engineering.

</details>


### [31] [Physio-DPO: Aligning Large Language Models with the Protein Energy Landscape to Eliminate Structural Hallucinations](https://arxiv.org/abs/2601.00647)
*QiWei Meng*

Main category: cs.CL

TL;DR: Physio-DPO: A physics-informed alignment framework that grounds protein language models in thermodynamic stability to reduce structural hallucinations in generative protein design.


<details>
  <summary>Details</summary>
Motivation: Current protein language models often produce structural hallucinations - sequences with high linguistic likelihood but thermodynamically unstable conformations. Existing alignment methods like DPO are limited because they treat preferences as binary labels and ignore the continuous energy landscape of protein folding.

Method: Physio-DPO introduces a magnitude-aware objective that scales optimization updates according to the energy gap between native structures and physics-perturbed hard negatives. This grounds the model in thermodynamic stability by incorporating physical energy considerations into the alignment process.

Result: Physio-DPO consistently outperforms SFT, PPO, and standard DPO, reducing self-consistency RMSD to 1.28 Å and increasing foldability to 92.8%. It effectively mitigates structural hallucinations by recovering biophysical interactions like hydrophobic core packing and hydrogen bond networks.

Conclusion: Physics-informed alignment through Physio-DPO successfully grounds protein language models in thermodynamic stability, addressing the critical problem of structural hallucinations in generative protein design and producing more physically realistic protein sequences.

Abstract: Large Protein Language Models have shown strong potential for generative protein design, yet they frequently produce structural hallucinations, generating sequences with high linguistic likelihood that fold into thermodynamically unstable conformations. Existing alignment approaches such as Direct Preference Optimization are limited in this setting, as they model preferences as binary labels and ignore the continuous structure of the physical energy landscape. We propose Physio-DPO, a physics informed alignment framework that grounds protein language models in thermodynamic stability. Physio-DPO introduces a magnitude aware objective that scales optimization updates according to the energy gap between native structures and physics perturbed hard negatives. Experiments show that Physio-DPO consistently outperforms strong baselines including SFT, PPO, and standard DPO, reducing self consistency RMSD to 1.28 Å and increasing foldability to 92.8%. Qualitative analysis further demonstrates that Physio-DPO effectively mitigates structural hallucinations by recovering biophysical interactions such as hydrophobic core packing and hydrogen bond networks.

</details>


### [32] [Fast-weight Product Key Memory](https://arxiv.org/abs/2601.00671)
*Tianyu Zhao,Llion Jones*

Main category: cs.CL

TL;DR: FwPKM transforms static Product Key Memory into dynamic fast-weight episodic memory that updates via local gradient descent, enabling efficient long-context processing with minimal training.


<details>
  <summary>Details</summary>
Motivation: Current sequence modeling layers face a trade-off: Softmax attention has unlimited storage but quadratic computational costs, while linear variants are efficient but have limited fixed-size storage. There's a need for an architecture that combines efficient computation with dynamic storage capabilities.

Method: Proposes Fast-weight Product Key Memory (FwPKM) that transforms sparse Product Key Memory into a dynamic episodic memory. Unlike static PKM, FwPKM updates parameters dynamically during both training and inference using local chunk-level gradient descent, allowing rapid memorization and retrieval of new key-value pairs from input sequences.

Result: FwPKM functions as effective episodic memory complementing standard semantic memory, yielding significant perplexity reductions on long-context datasets. Notably generalizes to 128K-token contexts despite being trained on only 4K-token sequences in Needle in a Haystack evaluations.

Conclusion: FwPKM resolves the storage-capacity vs computational-efficiency trade-off in sequence modeling by providing dynamic episodic memory that can rapidly adapt to new information while maintaining computational efficiency, enabling effective long-context processing.

Abstract: Sequence modeling layers in modern language models typically face a trade-off between storage capacity and computational efficiency. While Softmax attention offers unbounded storage at prohibitive quadratic costs, linear variants provide efficiency but suffer from limited, fixed-size storage. We propose Fast-weight Product Key Memory (FwPKM), a novel architecture that resolves this tension by transforming the sparse Product Key Memory (PKM) from a static module into a dynamic, "fast-weight" episodic memory. Unlike PKM, FwPKM updates its parameters dynamically at both training and inference time via local chunk-level gradient descent, allowing the model to rapidly memorize and retrieve new key-value pairs from input sequences. Experiments reveal that FwPKM functions as an effective episodic memory that complements the semantic memory of standard modules, yielding significant perplexity reductions on long-context datasets. Notably, in Needle in a Haystack evaluations, FwPKM generalizes to 128K-token contexts despite being trained on only 4K-token sequences.

</details>


### [33] [Sigmoid Head for Quality Estimation under Language Ambiguity](https://arxiv.org/abs/2601.00680)
*Tu Anh Dinh,Jan Niehues*

Main category: cs.CL

TL;DR: Proposes a Sigmoid Head module for Quality Estimation that addresses LM probability limitations by using sigmoid activation and negative sampling heuristics to better estimate output quality without human-annotated data.


<details>
  <summary>Details</summary>
Motivation: LM probability is unreliable for quality estimation because natural language ambiguity causes probability distribution to spread across multiple valid outputs, misleadingly indicating low quality. Two key limitations: (1) softmax activation prevents multiple correct options from receiving high probabilities simultaneously, and (2) training with single one-hot encoded references suggests only one correct option per step.

Method: Train a Quality Estimation module (Sigmoid Head) on top of pre-trained LMs. The module uses an extra unembedding head with sigmoid activation to address the softmax limitation. During negative sampling for training, a heuristic avoids selecting potentially alternative correct tokens to address the single-reference training limitation.

Result: Sigmoid Head is computationally efficient for training and inference. Its probability provides notably better quality signals compared to original softmax head. Being trained without human-annotated quality data, it shows better robustness in out-of-domain settings compared to supervised Quality Estimation methods.

Conclusion: The proposed Sigmoid Head effectively addresses LM probability limitations for quality estimation by using sigmoid activation and careful negative sampling, providing more reliable quality signals without requiring annotated data, making it robust for out-of-domain applications.

Abstract: Language model (LM) probability is not a reliable quality estimator, as natural language is ambiguous. When multiple output options are valid, the model's probability distribution is spread across them, which can misleadingly indicate low output quality. This issue is caused by two reasons: (1) LMs' final output activation is softmax, which does not allow multiple correct options to receive high probabilities simultaneuously and (2) LMs' training data is single, one-hot encoded references, indicating that there is only one correct option at each output step. We propose training a module for Quality Estimation on top of pre-trained LMs to address these limitations. The module, called Sigmoid Head, is an extra unembedding head with sigmoid activation to tackle the first limitation. To tackle the second limitation, during the negative sampling process to train the Sigmoid Head, we use a heuristic to avoid selecting potentially alternative correct tokens. Our Sigmoid Head is computationally efficient during training and inference. The probability from Sigmoid Head is notably better quality signal compared to the original softmax head. As the Sigmoid Head does not rely on human-annotated quality data, it is more robust to out-of-domain settings compared to supervised QE.

</details>


### [34] [Exploring the Performance of Large Language Models on Subjective Span Identification Tasks](https://arxiv.org/abs/2601.00736)
*Alphaeus Dmonte,Roland Oruche,Tharindu Ranasinghe,Marcos Zampieri,Prasad Calyam*

Main category: cs.CL

TL;DR: LLMs show promise for subjective span identification tasks like sentiment analysis, offensive language detection, and claim verification, with text relationships aiding precision.


<details>
  <summary>Details</summary>
Motivation: Current span identification approaches focus on explicit tasks like NER using smaller models, while subjective span identification with LLMs (especially in tasks like ABSA) remains underexplored despite its importance for model explainability.

Method: Evaluated various LLMs on three subjective span identification tasks: sentiment analysis, offensive language identification, and claim verification. Explored multiple LLM strategies including instruction tuning, in-context learning, and chain of thought prompting.

Result: LLMs demonstrate capability in subjective span identification, with underlying relationships within text helping them identify precise text spans more effectively.

Conclusion: LLMs can effectively handle subjective span identification tasks, filling an important gap in NLP research, with text relationships playing a crucial role in their performance.

Abstract: Identifying relevant text spans is important for several downstream tasks in NLP, as it contributes to model explainability. While most span identification approaches rely on relatively smaller pre-trained language models like BERT, a few recent approaches have leveraged the latest generation of Large Language Models (LLMs) for the task. Current work has focused on explicit span identification like Named Entity Recognition (NER), while more subjective span identification with LLMs in tasks like Aspect-based Sentiment Analysis (ABSA) has been underexplored. In this paper, we fill this important gap by presenting an evaluation of the performance of various LLMs on text span identification in three popular tasks, namely sentiment analysis, offensive language identification, and claim verification. We explore several LLM strategies like instruction tuning, in-context learning, and chain of thought. Our results indicate underlying relationships within text aid LLMs in identifying precise text spans.

</details>


### [35] [Adapting Natural Language Processing Models Across Jurisdictions: A pilot Study in Canadian Cancer Registries](https://arxiv.org/abs/2601.00787)
*Jonathan Simkin,Lovedeep Gondara,Zeeshan Rizvi,Gregory Doyle,Jeff Dowden,Dan Bond,Desmond Martin,Raymond Ng*

Main category: cs.CL

TL;DR: Cross-provincial evaluation shows transformer models can be adapted between Canadian cancer registries with modest fine-tuning, and ensemble methods significantly reduce missed cancer cases while maintaining privacy.


<details>
  <summary>Details</summary>
Motivation: Manual abstraction of pathology reports for cancer registries is resource-intensive and causes delays. While NLP systems help, their ability to generalize across different jurisdictions with varying reporting conventions is not well understood.

Method: Adapted BCCRTron (domain-adapted transformer) and GatorTron (biomedical transformer) for cancer surveillance using pathology reports from Newfoundland & Labrador Cancer Registry. Fine-tuned models on ~104,000 reports for Tier 1 (cancer vs. non-cancer) and ~22,000 for Tier 2 (reportable vs. non-reportable) tasks. Used complementary synoptic and diagnosis-focused input pipelines, then combined models with conservative OR-ensemble.

Result: Adapted models maintained high performance across jurisdictions. OR-ensemble achieved Tier 1 recall of 0.99, reducing missed cancers to 24 (vs 48 and 54 for standalone models). Tier 2 recall of 0.99, reducing missed reportable cancers to 33 (vs 54 and 46 for individual models).

Conclusion: Transformer models pretrained in one jurisdiction can be localized to another with modest fine-tuning. Ensemble combining complementary text representations substantially reduces missed cancers and improves error coverage. Privacy-preserving workflow using only shared model weights supports interoperable NLP infrastructure and future pan-Canadian foundation model.

Abstract: Population-based cancer registries depend on pathology reports as their primary diagnostic source, yet manual abstraction is resource-intensive and contributes to delays in cancer data. While transformer-based NLP systems have improved registry workflows, their ability to generalize across jurisdictions with differing reporting conventions remains poorly understood. We present the first cross-provincial evaluation of adapting BCCRTron, a domain-adapted transformer model developed at the British Columbia Cancer Registry, alongside GatorTron, a biomedical transformer model, for cancer surveillance in Canada. Our training dataset consisted of approximately 104,000 and 22,000 de-identified pathology reports from the Newfoundland & Labrador Cancer Registry (NLCR) for Tier 1 (cancer vs. non-cancer) and Tier 2 (reportable vs. non-reportable) tasks, respectively. Both models were fine-tuned using complementary synoptic and diagnosis focused report section input pipelines. Across NLCR test sets, the adapted models maintained high performance, demonstrating transformers pretrained in one jurisdiction can be localized to another with modest fine-tuning. To improve sensitivity, we combined the two models using a conservative OR-ensemble achieving a Tier 1 recall of 0.99 and reduced missed cancers to 24, compared with 48 and 54 for the standalone models. For Tier 2, the ensemble achieved 0.99 recall and reduced missed reportable cancers to 33, compared with 54 and 46 for the individual models. These findings demonstrate that an ensemble combining complementary text representations substantially reduce missed cancers and improve error coverage in cancer-registry NLP. We implement a privacy-preserving workflow in which only model weights are shared between provinces, supporting interoperable NLP infrastructure and a future pan-Canadian foundation model for cancer pathology and registry workflows.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [36] [TeleWorld: Towards Dynamic Multimodal Synthesis with a 4D World Model](https://arxiv.org/abs/2601.00051)
*Yabo Chen,Yuanzhi Liang,Jiepeng Wang,Tingxi Chen,Junfei Cheng,Zixiao Gu,Yuyang Huang,Zicheng Jiang,Wei Li,Tian Li,Weichen Li,Zuoxin Li,Guangce Liu,Jialun Liu,Junqi Liu,Haoyuan Wang,Qizhen Weng,Xuan'er Wu,Xunzhi Xiang,Xiaoyan Yang,Xin Zhang,Shiwen Zhang,Junyu Zhou,Chengcheng Zhou,Haibin Huang,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: TeleWorld is a real-time multimodal 4D world modeling framework that unifies video generation, dynamic scene reconstruction, and long-term memory in a closed-loop system for practical interactive world models.


<details>
  <summary>Details</summary>
Motivation: Current video generation models lack real-time interaction, long-horizon consistency, and persistent memory of dynamic scenes, preventing them from evolving into practical world models for AI systems.

Method: Introduces a generation-reconstruction-guidance paradigm where generated videos are continuously reconstructed into dynamic 4D spatio-temporal representations that guide subsequent generation. Uses autoregressive diffusion-based video model enhanced with Macro-from-Micro Planning (hierarchical planning) and Distribution Matching Distillation for real-time synthesis.

Result: Achieves strong performance in static/dynamic world understanding, long-term consistency, and real-time generation efficiency. Enables seamless integration of dynamic object modeling and static scene representation within a unified 4D framework.

Conclusion: TeleWorld represents a practical step toward interactive, memory-enabled world models for multimodal generation and embodied intelligence, advancing world models toward practical, interactive, and computationally accessible systems.

Abstract: World models aim to endow AI systems with the ability to represent, generate, and interact with dynamic environments in a coherent and temporally consistent manner. While recent video generation models have demonstrated impressive visual quality, they remain limited in real-time interaction, long-horizon consistency, and persistent memory of dynamic scenes, hindering their evolution into practical world models. In this report, we present TeleWorld, a real-time multimodal 4D world modeling framework that unifies video generation, dynamic scene reconstruction, and long-term world memory within a closed-loop system. TeleWorld introduces a novel generation-reconstruction-guidance paradigm, where generated video streams are continuously reconstructed into a dynamic 4D spatio-temporal representation, which in turn guides subsequent generation to maintain spatial, temporal, and physical consistency. To support long-horizon generation with low latency, we employ an autoregressive diffusion-based video model enhanced with Macro-from-Micro Planning (MMPL)--a hierarchical planning method that reduces error accumulation from frame-level to segment-level-alongside efficient Distribution Matching Distillation (DMD), enabling real-time synthesis under practical computational budgets. Our approach achieves seamless integration of dynamic object modeling and static scene representation within a unified 4D framework, advancing world models toward practical, interactive, and computationally accessible systems. Extensive experiments demonstrate that TeleWorld achieves strong performance in both static and dynamic world understanding, long-term consistency, and real-time generation efficiency, positioning it as a practical step toward interactive, memory-enabled world models for multimodal generation and embodied intelligence.

</details>


### [37] [It's Never Too Late: Noise Optimization for Collapse Recovery in Trained Diffusion Models](https://arxiv.org/abs/2601.00090)
*Anne Harrington,A. Sophia Koepke,Shyamgopal Karthik,Trevor Darrell,Alexei A. Efros*

Main category: cs.CV

TL;DR: Simple noise optimization method reduces mode collapse in text-to-image models while maintaining quality, with frequency analysis showing alternative noise initializations improve results.


<details>
  <summary>Details</summary>
Motivation: Text-to-image models suffer from mode collapse where multiple generations from the same prompt produce similar images, limiting diversity despite guidance mechanisms and candidate refinement approaches.

Method: Proposes noise optimization objective to mitigate mode collapse while preserving base model fidelity. Analyzes frequency characteristics of noise and explores alternative noise initializations with different frequency profiles to improve optimization and search.

Result: Noise optimization yields superior results in terms of generation quality and variety compared to previous approaches, demonstrating effective mitigation of mode collapse.

Conclusion: Simple noise optimization effectively addresses mode collapse in text-to-image generation, with frequency-aware noise initialization further enhancing diversity and quality of generated images.

Abstract: Contemporary text-to-image models exhibit a surprising degree of mode collapse, as can be seen when sampling several images given the same text prompt. While previous work has attempted to address this issue by steering the model using guidance mechanisms, or by generating a large pool of candidates and refining them, in this work we take a different direction and aim for diversity in generations via noise optimization. Specifically, we show that a simple noise optimization objective can mitigate mode collapse while preserving the fidelity of the base model. We also analyze the frequency characteristics of the noise and show that alternative noise initializations with different frequency profiles can improve both optimization and search. Our experiments demonstrate that noise optimization yields superior results in terms of generation quality and variety.

</details>


### [38] [Spatial4D-Bench: A Versatile 4D Spatial Intelligence Benchmark](https://arxiv.org/abs/2601.00092)
*Pan Wang,Yang Liu,Guile Wu,Eduardo R. Corral-Soto,Chengjie Huang,Binbin Xu,Dongfeng Bai,Xu Yan,Yuan Ren,Xingxin Chen,Yizhe Wu,Tao Huang,Wenjun Wan,Xin Wu,Pei Zhou,Xuyang Dai,Kangbo Lv,Hongbo Zhang,Yosef Fried,Aixue Ye,Bailan Feng,Zhenyu Chen,Zhen Li,Yingcong Chen,Yiyi Liao,Bingbing Liu*

Main category: cs.CV

TL;DR: Spatial4D-Bench is a large-scale benchmark with ~40K QA pairs across 18 tasks to evaluate MLLMs' 4D spatial intelligence, revealing current models' substantial limitations.


<details>
  <summary>Details</summary>
Motivation: To assess whether Multimodal Large Language Models (MLLMs) can achieve human-level 4D spatial intelligence (perceiving object changes over time), which is naturally present in humans but under-evaluated in current benchmarks.

Method: Created Spatial4D-Bench, a comprehensive benchmark with ~40,000 question-answer pairs covering 18 tasks organized into six cognitive categories: object understanding, scene understanding, spatial relationship understanding, spatiotemporal relationship understanding, spatial reasoning, and spatiotemporal reasoning.

Result: Benchmarking various state-of-the-art open-source and proprietary MLLMs revealed substantial limitations in 4D spatial reasoning abilities, including route planning, action recognition, and physical plausibility reasoning.

Conclusion: Current MLLMs have significant gaps in 4D spatial intelligence compared to humans, and Spatial4D-Bench provides a structured framework to facilitate development of more capable models toward human-level spatial cognition.

Abstract: 4D spatial intelligence involves perceiving and processing how objects move or change over time. Humans naturally possess 4D spatial intelligence, supporting a broad spectrum of spatial reasoning abilities. To what extent can Multimodal Large Language Models (MLLMs) achieve human-level 4D spatial intelligence? In this work, we present Spatial4D-Bench, a versatile 4D spatial intelligence benchmark designed to comprehensively assess the 4D spatial reasoning abilities of MLLMs. Unlike existing spatial intelligence benchmarks that are often small-scale or limited in diversity, Spatial4D-Bench provides a large-scale, multi-task evaluation benchmark consisting of ~40,000 question-answer pairs covering 18 well-defined tasks. We systematically organize these tasks into six cognitive categories: object understanding, scene understanding, spatial relationship understanding, spatiotemporal relationship understanding, spatial reasoning and spatiotemporal reasoning. Spatial4D-Bench thereby offers a structured and comprehensive benchmark for evaluating the spatial cognition abilities of MLLMs, covering a broad spectrum of tasks that parallel the versatility of human spatial intelligence. We benchmark various state-of-the-art open-source and proprietary MLLMs on Spatial4D-Bench and reveal their substantial limitations in a wide variety of 4D spatial reasoning aspects, such as route plan, action recognition, and physical plausibility reasoning. We hope that the findings provided in this work offer valuable insights to the community and that our benchmark can facilitate the development of more capable MLLMs toward human-level 4D spatial intelligence. More resources can be found on our project page.

</details>


### [39] [A Spatially Masked Adaptive Gated Network for multimodal post-flood water extent mapping using SAR and incomplete multispectral data](https://arxiv.org/abs/2601.00123)
*Hyunho Lee,Wenwen Li*

Main category: cs.CV

TL;DR: SMAGNet is a multimodal deep learning model that uses SAR data as primary input for flood water mapping and adaptively integrates MSI data when available, maintaining performance even when MSI data is missing.


<details>
  <summary>Details</summary>
Motivation: Current flood water mapping relies heavily on SAR data, but multimodal approaches combining SAR and MSI data show promise. However, adaptive integration of partially available MSI data into SAR-based mapping remains underexplored, creating a need for robust models that can handle varying data availability in real-world flood scenarios.

Method: Proposed Spatially Masked Adaptive Gated Network (SMAGNet) - a multimodal deep learning model that uses SAR data as primary input and integrates complementary MSI data through feature fusion. The model is designed to adapt to varying levels of MSI data availability.

Result: SMAGNet consistently outperformed other multimodal models across varying MSI data availability levels on the C2S-MS Floods dataset. Even with completely missing MSI data, SMAGNet maintained performance statistically comparable to a SAR-only U-Net model.

Conclusion: SMAGNet enhances model robustness to missing data and improves the applicability of multimodal deep learning in real-world flood management scenarios by effectively handling varying MSI data availability while maintaining strong performance.

Abstract: Mapping water extent during a flood event is essential for effective disaster management throughout all phases: mitigation, preparedness, response, and recovery. In particular, during the response stage, when timely and accurate information is important, Synthetic Aperture Radar (SAR) data are primarily employed to produce water extent maps. Recently, leveraging the complementary characteristics of SAR and MSI data through a multimodal approach has emerged as a promising strategy for advancing water extent mapping using deep learning models. This approach is particularly beneficial when timely post-flood observations, acquired during or shortly after the flood peak, are limited, as it enables the use of all available imagery for more accurate post-flood water extent mapping. However, the adaptive integration of partially available MSI data into the SAR-based post-flood water extent mapping process remains underexplored. To bridge this research gap, we propose the Spatially Masked Adaptive Gated Network (SMAGNet), a multimodal deep learning model that utilizes SAR data as the primary input for post-flood water extent mapping and integrates complementary MSI data through feature fusion. In experiments on the C2S-MS Floods dataset, SMAGNet consistently outperformed other multimodal deep learning models in prediction performance across varying levels of MSI data availability. Furthermore, we found that even when MSI data were completely missing, the performance of SMAGNet remained statistically comparable to that of a U-Net model trained solely on SAR data. These findings indicate that SMAGNet enhances the model robustness to missing data as well as the applicability of multimodal deep learning in real-world flood management scenarios.

</details>


### [40] [Compressed Map Priors for 3D Perception](https://arxiv.org/abs/2601.00139)
*Brady Zhou,Philipp Krähenbühl*

Main category: cs.CV

TL;DR: CMP is a framework that learns spatial priors from historical traversals using compressed binarized hashmaps, improving 3D object detection in autonomous vehicles with minimal storage and computational overhead.


<details>
  <summary>Details</summary>
Motivation: Current autonomous vision systems treat every location as new, ignoring that most deployment areas have been visited before. This wastes valuable historical spatial information that could improve perception.

Method: Uses compressed binarized hashmaps to store spatial priors learned from historical traversals, requiring only 32KB/km² (20× reduction vs dense storage). Easily integrates into existing 3D perception systems.

Result: Significant and consistent improvement in 3D object detection on nuScenes dataset across several architectures, with minimal extra computational costs.

Conclusion: Learning from historical traversals through compressed map priors is an effective way to improve autonomous vehicle perception, leveraging previously collected spatial information that current systems ignore.

Abstract: Human drivers rarely travel where no person has gone before. After all, thousands of drivers use busy city roads every day, and only one can claim to be the first. The same holds for autonomous computer vision systems. The vast majority of the deployment area of an autonomous vision system will have been visited before. Yet, most autonomous vehicle vision systems act as if they are encountering each location for the first time. In this work, we present Compressed Map Priors (CMP), a simple but effective framework to learn spatial priors from historic traversals. The map priors use a binarized hashmap that requires only $32\text{KB}/\text{km}^2$, a $20\times$ reduction compared to the dense storage. Compressed Map Priors easily integrate into leading 3D perception systems at little to no extra computational costs, and lead to a significant and consistent improvement in 3D object detection on the nuScenes dataset across several architectures.

</details>


### [41] [Attention to Detail: Global-Local Attention for High-Resolution AI-Generated Image Detection](https://arxiv.org/abs/2601.00141)
*Lawrence Han*

Main category: cs.CV

TL;DR: GLASS is a novel architecture for AI-generated image detection that combines global resized views with multiple original-resolution local crops using stratified sampling and attention-based aggregation, outperforming standard transfer learning approaches.


<details>
  <summary>Details</summary>
Motivation: Most AI-generated image detection architectures downsample images before processing, which risks losing fine-grained details crucial for distinguishing AI-generated content from real images. As generative AI produces increasingly realistic and high-resolution images, there's a need for detection methods that preserve detailed information.

Method: GLASS combines a globally resized view with multiple randomly sampled local crops at original resolution. It uses spatially stratified sampling to efficiently select local regions and attention-based scoring to aggregate information. The architecture can be integrated into various vision models (Vision Transformer, ResNet, ConvNeXt) to leverage both global and local information regardless of image size.

Result: Experiments show that GLASS outperforms standard transfer learning by achieving higher predictive performance while maintaining feasible computational constraints across different backbone models.

Conclusion: GLASS provides an effective approach for AI-generated image detection that preserves fine-grained details through its global-local attention mechanism with stratified sampling, offering improved detection performance without prohibitive computational costs.

Abstract: The rapid development of generative AI has made AI-generated images increasingly realistic and high-resolution. Most AI-generated image detection architectures typically downsample images before inputting them into models, risking the loss of fine-grained details. This paper presents GLASS (Global-Local Attention with Stratified Sampling), an architecture that combines a globally resized view with multiple randomly sampled local crops. These crops are original-resolution regions efficiently selected through spatially stratified sampling and aggregated using attention-based scoring. GLASS can be integrated into vision models to leverage both global and local information in images of any size. Vision Transformer, ResNet, and ConvNeXt models are used as backbones, and experiments show that GLASS outperforms standard transfer learning by achieving higher predictive performance within feasible computational constraints.

</details>


### [42] [FCMBench: A Comprehensive Financial Credit Multimodal Benchmark for Real-world Applications](https://arxiv.org/abs/2601.00150)
*Yehui Yang,Dalu Yang,Wenshuo Zhou,Fangxin Shang,Yifan Liu,Jie Ren,Haojun Fei,Qing Yang,Tao Chen*

Main category: cs.CV

TL;DR: FCMBench-V1.0 is a financial credit multimodal benchmark with 4,043 privacy-compliant images and 8,446 QA samples covering 18 certificate types, designed to evaluate VLMs on perception, reasoning, and robustness for credit risk assessment.


<details>
  <summary>Details</summary>
Motivation: There's an urgent need for a domain-specific benchmark for financial credit applications that reflects real documents and workflows, includes credit-specific understanding and robustness testing, and preserves privacy compliance while maintaining practical utility.

Method: Created FCMBench-V1.0 using a closed synthesis-capture pipeline: manually synthesized document templates with virtual content and captured scenario-aware images in-house to ensure privacy compliance and avoid web-sourced data leakage. The benchmark includes 3 perception tasks, 4 credit-specific reasoning tasks, and 10 real-world acquisition artifact types for robustness testing.

Result: Evaluated 23 state-of-the-art VLMs from 14 organizations. Gemini 3 Pro achieved best commercial model score (64.61 F1), Qwen3-VL-235B best open-source (57.27), and their financial-specific model Qfin-VL-Instruct achieved top overall score (64.92). Robustness tests showed significant performance drops under acquisition artifacts even for top models.

Conclusion: FCMBench effectively discriminates performance disparities and robustness across modern VLMs, revealing that even top models struggle with real-world acquisition artifacts, highlighting the need for domain-specific benchmarks and models in financial credit applications.

Abstract: As multimodal AI becomes widely used for credit risk assessment and document review, a domain-specific benchmark is urgently needed that (1) reflects documents and workflows specific to financial credit applications, (2) includes credit-specific understanding and real-world robustness, and (3) preserves privacy compliance without sacrificing practical utility. Here, we introduce FCMBench-V1.0 -- a large-scale financial credit multimodal benchmark for real-world applications, covering 18 core certificate types, with 4,043 privacy-compliant images and 8,446 QA samples. The FCMBench evaluation framework consists of three dimensions: Perception, Reasoning, and Robustness, including 3 foundational perception tasks, 4 credit-specific reasoning tasks that require decision-oriented understanding of visual evidence, and 10 real-world acquisition artifact types for robustness stress testing. To reconcile compliance with realism, we construct all samples via a closed synthesis-capture pipeline: we manually synthesize document templates with virtual content and capture scenario-aware images in-house. This design also mitigates pre-training data leakage by avoiding web-sourced or publicly released images. FCMBench can effectively discriminate performance disparities and robustness across modern vision-language models. Extensive experiments were conducted on 23 state-of-the-art vision-language models (VLMs) from 14 top AI companies and research institutes. Among them, Gemini 3 Pro achieves the best F1(\%) score as a commercial model (64.61), Qwen3-VL-235B achieves the best score as an open-source baseline (57.27), and our financial credit-specific model, Qfin-VL-Instruct, achieves the top overall score (64.92). Robustness evaluations show that even top-performing models suffer noticeable performance drops under acquisition artifacts.

</details>


### [43] [Focal-RegionFace: Generating Fine-Grained Multi-attribute Descriptions for Arbitrarily Selected Face Focal Regions](https://arxiv.org/abs/2601.00156)
*Kaiwen Zheng,Junchen Fu,Songpei Xu,Yaoqing He,Joemon M. Jose,Han Hu,Xuri Ge*

Main category: cs.CV

TL;DR: A new vision-language model called Focal-RegionFace is proposed for generating and recognizing multi-attribute natural language descriptions of arbitrarily selected face regions, including facial action units, emotions, and age estimation.


<details>
  <summary>Details</summary>
Motivation: The paper addresses an underexplored problem in facial analysis: generating and recognizing multi-attribute natural language descriptions for arbitrarily selected face regions. The authors argue that focusing on individual facial areas leads to better understanding and control in facial analysis.

Method: The authors construct a new multi-attribute description dataset for arbitrarily selected face regions with rich region-level annotations and natural language descriptions. They propose Focal-RegionFace, a fine-tuned vision-language model based on Qwen2.5-VL, which incrementally refines its focus on localized facial features through multiple progressively fine-tuning stages.

Result: Focal-RegionFace achieves the best performance on the new benchmark in terms of both traditional metrics and newly proposed metrics, demonstrating effectiveness and versatility in fine-grained multi-attribute face region-focal analysis scenarios.

Conclusion: The proposed approach successfully addresses the FaceFocalDesc problem, providing interpretable age estimation, facial action unit detection, and emotion detection through region-focused analysis, with experimental results fully verifying its effectiveness.

Abstract: In this paper, we introduce an underexplored problem in facial analysis: generating and recognizing multi-attribute natural language descriptions, containing facial action units (AUs), emotional states, and age estimation, for arbitrarily selected face regions (termed FaceFocalDesc). We argue that the system's ability to focus on individual facial areas leads to better understanding and control. To achieve this capability, we construct a new multi-attribute description dataset for arbitrarily selected face regions, providing rich region-level annotations and natural language descriptions. Further, we propose a fine-tuned vision-language model based on Qwen2.5-VL, called Focal-RegionFace for facial state analysis, which incrementally refines its focus on localized facial features through multiple progressively fine-tuning stages, resulting in interpretable age estimation, FAU and emotion detection. Experimental results show that Focal-RegionFace achieves the best performance on the new benchmark in terms of traditional and widely used metrics, as well as new proposed metrics. This fully verifies its effectiveness and versatility in fine-grained multi-attribute face region-focal analysis scenarios.

</details>


### [44] [DichroGAN: Towards Restoration of in-air Colours of Seafloor from Satellite Imagery](https://arxiv.org/abs/2601.00194)
*Salma Gonzalez-Sabbagh,Antonio Robles-Kelly,Shang Gao*

Main category: cs.CV

TL;DR: DichroGAN is a cGAN that recovers in-air seafloor colors from satellite imagery by modeling atmospheric radiance and underwater light transmission to remove water column effects.


<details>
  <summary>Details</summary>
Motivation: Recovering true seafloor colors from satellite imagery is challenging due to light attenuation in water columns, which exponentially reduces light intensity with depth and distorts colors.

Method: Uses a conditional GAN with four generators: two estimate diffuse/specular reflections for atmospheric radiance, one processes spectral band features, and one estimates underwater light transmission. Trained on PRISMA satellite dataset with RGB images, spectral bands, and masks.

Result: DichroGAN achieves competitive performance compared to state-of-the-art underwater restoration techniques on both satellite and underwater datasets.

Conclusion: The proposed DichroGAN framework effectively recovers in-air seafloor colors by modeling the underwater image formation process, demonstrating promising results for satellite-based seafloor analysis.

Abstract: Recovering the in-air colours of seafloor from satellite imagery is a challenging task due to the exponential attenuation of light with depth in the water column. In this study, we present DichroGAN, a conditional generative adversarial network (cGAN) designed for this purpose. DichroGAN employs a two-steps simultaneous training: first, two generators utilise a hyperspectral image cube to estimate diffuse and specular reflections, thereby obtaining atmospheric scene radiance. Next, a third generator receives as input the generated scene radiance containing the features of each spectral band, while a fourth generator estimates the underwater light transmission. These generators work together to remove the effects of light absorption and scattering, restoring the in-air colours of seafloor based on the underwater image formation equation. DichroGAN is trained on a compact dataset derived from PRISMA satellite imagery, comprising RGB images paired with their corresponding spectral bands and masks. Extensive experiments on both satellite and underwater datasets demonstrate that DichroGAN achieves competitive performance compared to state-of-the-art underwater restoration techniques.

</details>


### [45] [MorphAny3D: Unleashing the Power of Structured Latent in 3D Morphing](https://arxiv.org/abs/2601.00204)
*Xiaokun Sun,Zeyu Cai,Hao Tang,Ying Tai,Jian Yang,Zhenyu Zhang*

Main category: cs.CV

TL;DR: MorphAny3D is a training-free framework for high-quality 3D morphing using Structured Latent (SLAT) representations, achieving state-of-the-art results even for cross-category morphing.


<details>
  <summary>Details</summary>
Motivation: 3D morphing is challenging due to difficulties in generating semantically consistent and temporally smooth deformations, especially across different categories.

Method: Uses Structured Latent (SLAT) representations with Morphing Cross-Attention (MCA) for structural coherence, Temporal-Fused Self-Attention (TFSA) for temporal consistency, and orientation correction for pose ambiguity.

Result: Generates state-of-the-art morphing sequences, even for challenging cross-category cases, and supports advanced applications like decoupled morphing and 3D style transfer.

Conclusion: MorphAny3D provides an effective training-free framework for high-quality 3D morphing that can generalize to other SLAT-based generative models.

Abstract: 3D morphing remains challenging due to the difficulty of generating semantically consistent and temporally smooth deformations, especially across categories. We present MorphAny3D, a training-free framework that leverages Structured Latent (SLAT) representations for high-quality 3D morphing. Our key insight is that intelligently blending source and target SLAT features within the attention mechanisms of 3D generators naturally produces plausible morphing sequences. To this end, we introduce Morphing Cross-Attention (MCA), which fuses source and target information for structural coherence, and Temporal-Fused Self-Attention (TFSA), which enhances temporal consistency by incorporating features from preceding frames. An orientation correction strategy further mitigates the pose ambiguity within the morphing steps. Extensive experiments show that our method generates state-of-the-art morphing sequences, even for challenging cross-category cases. MorphAny3D further supports advanced applications such as decoupled morphing and 3D style transfer, and can be generalized to other SLAT-based generative models. Project page: https://xiaokunsun.github.io/MorphAny3D.github.io/.

</details>


### [46] [CropNeRF: A Neural Radiance Field-Based Framework for Crop Counting](https://arxiv.org/abs/2601.00207)
*Md Ahmed Al Muzaddid,William J. Beksi*

Main category: cs.CV

TL;DR: A novel 3D instance segmentation framework for accurate crop counting using multi-view images and neural radiance fields, validated on cotton, apples, and pears with superior performance.


<details>
  <summary>Details</summary>
Motivation: Accurate crop counting is essential for agricultural management, but outdoor field environments present challenges including partial occlusions and ambiguity in distinguishing clustered crops from single viewpoints, which existing image-based segmentation methods struggle with.

Method: Uses 2D images from multiple viewpoints with independent instance masks for neural radiance field (NeRF) view synthesis. Introduces crop visibility and mask consistency scores combined with 3D information from NeRF to segment crop instances in 3D, eliminating dependence on crop-specific parameter tuning.

Result: Validated on three agricultural datasets (cotton bolls, apples, pears) showing consistent counting performance despite variations in crop color, shape, and size. Comparative analysis demonstrates superior performance against state-of-the-art methods.

Conclusion: The framework enables highly accurate crop counting via 3D instance segmentation, addresses occlusion and clustering challenges, and contributes a cotton plant dataset to advance agricultural research.

Abstract: Rigorous crop counting is crucial for effective agricultural management and informed intervention strategies. However, in outdoor field environments, partial occlusions combined with inherent ambiguity in distinguishing clustered crops from individual viewpoints poses an immense challenge for image-based segmentation methods. To address these problems, we introduce a novel crop counting framework designed for exact enumeration via 3D instance segmentation. Our approach utilizes 2D images captured from multiple viewpoints and associates independent instance masks for neural radiance field (NeRF) view synthesis. We introduce crop visibility and mask consistency scores, which are incorporated alongside 3D information from a NeRF model. This results in an effective segmentation of crop instances in 3D and highly-accurate crop counts. Furthermore, our method eliminates the dependence on crop-specific parameter tuning. We validate our framework on three agricultural datasets consisting of cotton bolls, apples, and pears, and demonstrate consistent counting performance despite major variations in crop color, shape, and size. A comparative analysis against the state of the art highlights superior performance on crop counting tasks. Lastly, we contribute a cotton plant dataset to advance further research on this topic.

</details>


### [47] [IntraStyler: Exemplar-based Style Synthesis for Cross-modality Domain Adaptation](https://arxiv.org/abs/2601.00212)
*Han Liu,Yubo Fan,Hao Li,Dewei Hu,Daniel Moyer,Zhoubing Xu,Benoit M. Dawant,Ipek Oguz*

Main category: cs.CV

TL;DR: IntraStyler: An exemplar-based style synthesis method for unsupervised domain adaptation that captures diverse intra-domain styles without prior knowledge, improving downstream segmentation tasks.


<details>
  <summary>Details</summary>
Motivation: Prior domain adaptation methods focus on source-target domain shift but neglect intra-domain variability. Existing style diversification methods require pre-specified intra-domain variations, which is impractical.

Method: IntraStyler uses exemplar images to guide style synthesis, matching output styles to exemplar styles. A style encoder extracts style-only features using contrastive learning for discriminative style representation.

Result: Evaluated on CrossMoDA 2023 dataset, showing efficacy in controllable style synthesis and benefits of diverse synthetic data for downstream segmentation tasks.

Conclusion: IntraStyler effectively addresses intra-domain variability in domain adaptation without requiring prior knowledge of intra-domain variations, improving segmentation performance through diverse style synthesis.

Abstract: Image-level domain alignment is the de facto approach for unsupervised domain adaptation, where unpaired image translation is used to minimize the domain gap. Prior studies mainly focus on the domain shift between the source and target domains, whereas the intra-domain variability remains under-explored. To address the latter, an effective strategy is to diversify the styles of the synthetic target domain data during image translation. However, previous methods typically require intra-domain variations to be pre-specified for style synthesis, which may be impractical. In this paper, we propose an exemplar-based style synthesis method named IntraStyler, which can capture diverse intra-domain styles without any prior knowledge. Specifically, IntraStyler uses an exemplar image to guide the style synthesis such that the output style matches the exemplar style. To extract the style-only features, we introduce a style encoder to learn styles discriminatively based on contrastive learning. We evaluate the proposed method on the largest public dataset for cross-modality domain adaptation, CrossMoDA 2023. Our experiments show the efficacy of our method in controllable style synthesis and the benefits of diverse synthetic data for downstream segmentation. Code is available at https://github.com/han-liu/IntraStyler.

</details>


### [48] [From Sight to Insight: Improving Visual Reasoning Capabilities of Multimodal Models via Reinforcement Learning](https://arxiv.org/abs/2601.00215)
*Omar Sharif,Eftekhar Hossain,Patrick Ng*

Main category: cs.CV

TL;DR: RL improves multimodal LLMs' visual reasoning by incentivizing longer, structured reasoning chains that integrate visual information, achieving 5.56% gains over base models.


<details>
  <summary>Details</summary>
Motivation: Current multimodal LLMs generate reasoning chains that lack proper integration of visual information, limiting their ability to solve visual perception tasks like visual puzzles. Visual perception is identified as the key bottleneck, with textual descriptions of images significantly improving performance.

Method: Use reward-driven reinforcement learning with six reward functions targeting different reasoning aspects (image understanding, thinking steps, answer accuracy). Apply group relative policy optimization (GRPO) to explicitly incentivize longer, structured reasoning and prevent bypassing of visual information.

Result: Achieved 5.56% improvement over base Qwen-2.5-VL-7B model, with consistent gains across both in-domain and out-of-domain settings. Converting images to textual descriptions yielded even larger gains of 26.7% for Claude 3.5 and 23.6% for Claude 3.7.

Conclusion: Reward-driven RL effectively unlocks long visual reasoning in open-source MLLMs without costly supervision, addressing the visual perception bottleneck and improving performance on tasks requiring accurate visual reasoning.

Abstract: Reinforcement learning (RL) has emerged as a promising approach for eliciting reasoning chains before generating final answers. However, multimodal large language models (MLLMs) generate reasoning that lacks integration of visual information. This limits their ability to solve problems that demand accurate visual perception, such as visual puzzles. We show that visual perception is the key bottleneck in such tasks: converting images into textual descriptions significantly improves performance, yielding gains of 26.7% for Claude 3.5 and 23.6% for Claude 3.7.
  To address this, we investigate reward-driven RL as a mechanism to unlock long visual reasoning in open-source MLLMs without requiring costly supervision. We design and evaluate six reward functions targeting different reasoning aspects, including image understanding, thinking steps, and answer accuracy. Using group relative policy optimization (GRPO), our approach explicitly incentivizes longer, structured reasoning and mitigates bypassing of visual information. Experiments on Qwen-2.5-VL-7B achieve 5.56% improvements over the base model, with consistent gains across both in-domain and out-of-domain settings.

</details>


### [49] [LooC: Effective Low-Dimensional Codebook for Compositional Vector Quantization](https://arxiv.org/abs/2601.00222)
*Jie Li,Kwan-Yee K. Wong,Kai Han*

Main category: cs.CV

TL;DR: LooC is a new vector quantization method that uses low-dimensional compositional codebooks and extrapolation-by-interpolation to achieve state-of-the-art performance with significantly smaller codebooks.


<details>
  <summary>Details</summary>
Motivation: As data and models become more diverse and complex, there's an urgent need for high-capacity yet compact vector quantization methods. Current VQ approaches face limitations in balancing capacity with compactness.

Method: LooC introduces: 1) A parameter-efficient codebook by treating codevectors as lower-dimensional compositional units within feature vectors, 2) A parameter-free extrapolation-by-interpolation mechanism to enhance feature smoothing during VQ, and 3) A plug-and-play module design for existing VQ-based methods.

Result: Extensive evaluations across different tasks, datasets, and architectures show LooC outperforms existing VQ methods, achieving state-of-the-art performance with significantly smaller codebooks while ensuring full codebook usage and avoiding collapse problems.

Conclusion: LooC successfully reconciles the conflict between high capacity and compactness in vector quantization through its compositional approach and feature enhancement mechanisms, offering an effective plug-and-play solution for various downstream VQ tasks.

Abstract: Vector quantization (VQ) is a prevalent and fundamental technique that discretizes continuous feature vectors by approximating them using a codebook. As the diversity and complexity of data and models continue to increase, there is an urgent need for high-capacity, yet more compact VQ methods. This paper aims to reconcile this conflict by presenting a new approach called LooC, which utilizes an effective Low-dimensional codebook for Compositional vector quantization. Firstly, LooC introduces a parameter-efficient codebook by reframing the relationship between codevectors and feature vectors, significantly expanding its solution space. Instead of individually matching codevectors with feature vectors, LooC treats them as lower-dimensional compositional units within feature vectors and combines them, resulting in a more compact codebook with improved performance. Secondly, LooC incorporates a parameter-free extrapolation-by-interpolation mechanism to enhance and smooth features during the VQ process, which allows for better preservation of details and fidelity in feature approximation. The design of LooC leads to full codebook usage, effectively utilizing the compact codebook while avoiding the problem of collapse. Thirdly, LooC can serve as a plug-and-play module for existing methods for different downstream tasks based on VQ. Finally, extensive evaluations on different tasks, datasets, and architectures demonstrate that LooC outperforms existing VQ methods, achieving state-of-the-art performance with a significantly smaller codebook.

</details>


### [50] [Towards Syn-to-Real IQA: A Novel Perspective on Reshaping Synthetic Data Distributions](https://arxiv.org/abs/2601.00225)
*Aobo Li,Jinjian Wu,Yongxu Liu,Leida Li,Weisheng Dong*

Main category: cs.CV

TL;DR: SynDR-IQA improves BIQA generalization by reshaping synthetic data distribution through diversity upsampling and redundancy downsampling to address clustered feature patterns in synthetic datasets.


<details>
  <summary>Details</summary>
Motivation: BIQA suffers from limited labeled data. Synthetic data helps but models trained on existing synthetic datasets show poor generalization due to clustered feature patterns where high-quality images cluster around references and low-quality images cluster by distortion types.

Method: SynDR-IQA reshapes synthetic data distribution using two strategies: 1) Distribution-aware diverse content upsampling to enhance visual diversity while preserving content distribution, and 2) Density-aware redundant cluster downsampling to balance samples by reducing density in densely clustered areas.

Result: Extensive experiments across three cross-dataset settings (synthetic-to-authentic, synthetic-to-algorithmic, and synthetic-to-synthetic) demonstrate the effectiveness of the proposed method.

Conclusion: The paper presents SynDR-IQA, a novel framework that addresses the generalization limitations of BIQA models trained on synthetic data by strategically reshaping synthetic data distribution, with theoretical grounding and empirical validation across multiple settings.

Abstract: Blind Image Quality Assessment (BIQA) has advanced significantly through deep learning, but the scarcity of large-scale labeled datasets remains a challenge. While synthetic data offers a promising solution, models trained on existing synthetic datasets often show limited generalization ability. In this work, we make a key observation that representations learned from synthetic datasets often exhibit a discrete and clustered pattern that hinders regression performance: features of high-quality images cluster around reference images, while those of low-quality images cluster based on distortion types. Our analysis reveals that this issue stems from the distribution of synthetic data rather than model architecture. Consequently, we introduce a novel framework SynDR-IQA, which reshapes synthetic data distribution to enhance BIQA generalization. Based on theoretical derivations of sample diversity and redundancy's impact on generalization error, SynDR-IQA employs two strategies: distribution-aware diverse content upsampling, which enhances visual diversity while preserving content distribution, and density-aware redundant cluster downsampling, which balances samples by reducing the density of densely clustered areas. Extensive experiments across three cross-dataset settings (synthetic-to-authentic, synthetic-to-algorithmic, and synthetic-to-synthetic) demonstrate the effectiveness of our method. The code is available at https://github.com/Li-aobo/SynDR-IQA.

</details>


### [51] [Application Research of a Deep Learning Model Integrating CycleGAN and YOLO in PCB Infrared Defect Detection](https://arxiv.org/abs/2601.00237)
*Chao Yang,Haoyuan Zheng,Yue Ma*

Main category: cs.CV

TL;DR: Cross-modal data augmentation framework using CycleGAN to generate pseudo-IR PCB images from visible-light data, combined with YOLOv8 for defect detection, overcoming IR data scarcity.


<details>
  <summary>Details</summary>
Motivation: Addresses critical bottleneck of infrared (IR) data scarcity in PCB defect detection, as conventional methods rely on paired supervision which is limited in IR domain.

Method: Uses CycleGAN for unpaired image-to-image translation to map abundant visible-light PCB images into infrared domain, generating pseudo-IR samples. Then employs heterogeneous training strategy fusing generated pseudo-IR data with limited real IR samples to train lightweight YOLOv8 detector.

Result: Method effectively enhances feature learning under low-data conditions. Augmented detector significantly outperforms models trained on limited real data alone and approaches performance benchmarks of fully supervised training.

Conclusion: Pseudo-IR synthesis via cross-modal data augmentation is an effective robust strategy for industrial inspection, overcoming IR data scarcity in PCB defect detection.

Abstract: This paper addresses the critical bottleneck of infrared (IR) data scarcity in Printed Circuit Board (PCB) defect detection by proposing a cross-modal data augmentation framework integrating CycleGAN and YOLOv8. Unlike conventional methods relying on paired supervision, we leverage CycleGAN to perform unpaired image-to-image translation, mapping abundant visible-light PCB images into the infrared domain. This generative process synthesizes high-fidelity pseudo-IR samples that preserve the structural semantics of defects while accurately simulating thermal distribution patterns. Subsequently, we construct a heterogeneous training strategy that fuses generated pseudo-IR data with limited real IR samples to train a lightweight YOLOv8 detector. Experimental results demonstrate that this method effectively enhances feature learning under low-data conditions. The augmented detector significantly outperforms models trained on limited real data alone and approaches the performance benchmarks of fully supervised training, proving the efficacy of pseudo-IR synthesis as a robust augmentation strategy for industrial inspection.

</details>


### [52] [Context-Aware Pesticide Recommendation via Few-Shot Pest Recognition for Precision Agriculture](https://arxiv.org/abs/2601.00243)
*Anirudha Ghosh,Ritam Sarkar,Debaditya Barman*

Main category: cs.CV

TL;DR: A lightweight framework for pest detection and pesticide recommendation using compact CNN with meta-learning for low-resource devices, achieving high accuracy with reduced computational complexity for precision agriculture.


<details>
  <summary>Details</summary>
Motivation: Traditional pest management methods are costly, time-consuming, labor-intensive, and environmentally harmful. There's a need for accessible solutions for small farmers using low-resource devices like smartphones and drones.

Method: Two-component framework: 1) Pest Detection Module using lightweight CNN with prototypical meta-learning for few-shot learning, 2) Pesticide Recommendation Module incorporating environmental factors (crop type, growth stage). Trained on comprehensive pest image dataset combining multiple public sources.

Result: The lightweight CNN achieves high accuracy comparable to state-of-the-art models while significantly reducing computational complexity. The system reduces dependence on chemical pesticides and enables sustainable practices.

Conclusion: The framework demonstrates potential for real-time precision agriculture applications, offering accessible pest management for small farmers through low-resource devices while promoting environmental sustainability.

Abstract: Effective pest management is crucial for enhancing agricultural productivity, especially for crops such as sugarcane and wheat that are highly vulnerable to pest infestations. Traditional pest management methods depend heavily on manual field inspections and the use of chemical pesticides. These approaches are often costly, time-consuming, labor-intensive, and can have a negative impact on the environment. To overcome these challenges, this study presents a lightweight framework for pest detection and pesticide recommendation, designed for low-resource devices such as smartphones and drones, making it suitable for use by small and marginal farmers.
  The proposed framework includes two main components. The first is a Pest Detection Module that uses a compact, lightweight convolutional neural network (CNN) combined with prototypical meta-learning to accurately identify pests even when only a few training samples are available. The second is a Pesticide Recommendation Module that incorporates environmental factors like crop type and growth stage to suggest safe and eco-friendly pesticide recommendations. To train and evaluate our framework, a comprehensive pest image dataset was developed by combining multiple publicly available datasets. The final dataset contains samples with different viewing angles, pest sizes, and background conditions to ensure strong generalization.
  Experimental results show that the proposed lightweight CNN achieves high accuracy, comparable to state-of-the-art models, while significantly reducing computational complexity. The Decision Support System additionally improves pest management by reducing dependence on traditional chemical pesticides and encouraging sustainable practices, demonstrating its potential for real-time applications in precision agriculture.

</details>


### [53] [TotalFM: An Organ-Separated Framework for 3D-CT Vision Foundation Models](https://arxiv.org/abs/2601.00260)
*Kohei Yamamoto,Tomohiro Kikuchi*

Main category: cs.CV

TL;DR: TotalFM is a radiological foundation model that efficiently learns 3D-CT to text correspondence using organ separation, achieving better zero-shot classification than CT-CLIP and Merlin.


<details>
  <summary>Details</summary>
Motivation: Foundation models for radiology face computational cost challenges when training on 3D-CT volumetric data, requiring efficient approaches for practical clinical implementation.

Method: Uses organ separation concept with automated creation of organ volume and finding-sentence pairs via segmentation and LLM-based report processing. Combines self-supervised pre-training (VideoMAE) with contrastive learning using volume-text pairs.

Result: Achieved higher F1 scores in 83% of organs vs CT-CLIP and 64% vs Merlin in zero-shot organ-wise lesion classification. In finding-wise classification, achieved higher AUROC in 83% of categories vs Merlin. Comparable performance to existing VLMs in radiology report generation.

Conclusion: The organ-separated learning framework provides a realistic and effective design guideline for practical implementation of 3D-CT foundation models with high generalization performance in clinical settings.

Abstract: While foundation models in radiology are expected to be applied to various clinical tasks, computational cost constraints remain a major challenge when training on 3D-CT volumetric data. In this study, we propose TotalFM, a radiological foundation model that efficiently learns the correspondence between 3D-CT images and linguistic expressions based on the concept of organ separation, utilizing a large-scale dataset of 140,000 series. By automating the creation of organ volume and finding-sentence pairs through segmentation techniques and Large Language Model (LLM)-based radiology report processing, and by combining self-supervised pre-training via VideoMAE with contrastive learning using volume-text pairs, we aimed to balance computational efficiency and representation capability. In zero-shot organ-wise lesion classification tasks, the proposed model achieved higher F1 scores in 83% (5/6) of organs compared to CT-CLIP and 64% (9/14) of organs compared to Merlin. These results suggest that the proposed model exhibits high generalization performance in a clinical evaluation setting using actual radiology report sentences. Furthermore, in zero-shot finding-wise lesion classification tasks, our model achieved a higher AUROC in 83% (25/30) of finding categories compared to Merlin. We also confirmed performance comparable to existing Vision-Language Models (VLMs) in radiology report generation tasks. Our results demonstrate that the organ-separated learning framework can serve as a realistic and effective design guideline for the practical implementation of 3D-CT foundation models.

</details>


### [54] [S1-MMAlign: A Large-Scale, Multi-Disciplinary Dataset for Scientific Figure-Text Understanding](https://arxiv.org/abs/2601.00264)
*He Wang,Longteng Guo,Pengkang Huo,Xuanxu Lin,Yichen Yuan,Jie Jiang,Jing Liu*

Main category: cs.CV

TL;DR: S1-MMAlign is a large-scale multimodal dataset of 15.5M scientific image-text pairs from 2.5M papers, enhanced with AI-generated captions to bridge the semantic gap between complex scientific imagery and sparse descriptions.


<details>
  <summary>Details</summary>
Motivation: Multimodal learning has transformed general tasks but struggles in scientific discovery due to the semantic gap between complex scientific imagery and sparse textual descriptions in papers.

Method: Created dataset from 2.5M open-access papers, then used Qwen-VL multimodal large model series to recaption images by synthesizing context from paper abstracts and citation contexts to enhance alignment.

Result: Dataset contains 15.5M high-quality image-text pairs across physics, biology, engineering. Enhancement improved image-text alignment by 18.21% (CLIP scores) and reduced semantic ambiguity (SciBERT metrics).

Conclusion: S1-MMAlign provides a foundational resource for advancing scientific reasoning and cross-modal understanding in AI for Science, addressing the alignment problem in scientific multimodal learning.

Abstract: Multimodal learning has revolutionized general domain tasks, yet its application in scientific discovery is hindered by the profound semantic gap between complex scientific imagery and sparse textual descriptions. We present S1-MMAlign, a large-scale, multi-disciplinary multimodal dataset comprising over 15.5 million high-quality image-text pairs derived from 2.5 million open-access scientific papers. Spanning disciplines from physics and biology to engineering, the dataset captures diverse visual modalities including experimental setups, heatmaps, and microscopic imagery. To address the pervasive issue of weak alignment in raw scientific captions, we introduce an AI-ready semantic enhancement pipeline that utilizes the Qwen-VL multimodal large model series to recaption images by synthesizing context from paper abstracts and citation contexts. Technical validation demonstrates that this enhancement significantly improves data quality: SciBERT-based pseudo-perplexity metrics show reduced semantic ambiguity, while CLIP scores indicate an 18.21% improvement in image-text alignment. S1-MMAlign provides a foundational resource for advancing scientific reasoning and cross-modal understanding in the era of AI for Science. The dataset is publicly available at https://huggingface.co/datasets/ScienceOne-AI/S1-MMAlign.

</details>


### [55] [ActErase: A Training-Free Paradigm for Precise Concept Erasure via Activation Patching](https://arxiv.org/abs/2601.00267)
*Yi Sun,Xinhao Zhong,Hongyan Li,Yimin Zhou,Junhao Li,Bin Chen,Xuan Wang*

Main category: cs.CV

TL;DR: ActErase: A training-free method for concept erasure in diffusion models that identifies activation differences via prompt-pair analysis and dynamically replaces target activations during forward passes.


<details>
  <summary>Details</summary>
Motivation: Text-to-image diffusion models raise safety, copyright, and ethical concerns. Existing concept erasure methods require data-intensive fine-tuning, which is computationally expensive and limiting.

Method: Training-free approach that identifies activation difference regions via prompt-pair analysis, extracts target activations, and dynamically replaces input activations during forward passes without model fine-tuning.

Result: Achieves SOTA erasure performance across nudity, artistic style, and object removal tasks while preserving generative capability. Shows strong robustness against adversarial attacks.

Conclusion: ActErase establishes a new plug-and-play paradigm for lightweight yet effective concept manipulation in diffusion models, overcoming limitations of fine-tuning-based approaches.

Abstract: Recent advances in text-to-image diffusion models have demonstrated remarkable generation capabilities, yet they raise significant concerns regarding safety, copyright, and ethical implications. Existing concept erasure methods address these risks by removing sensitive concepts from pre-trained models, but most of them rely on data-intensive and computationally expensive fine-tuning, which poses a critical limitation. To overcome these challenges, inspired by the observation that the model's activations are predominantly composed of generic concepts, with only a minimal component can represent the target concept, we propose a novel training-free method (ActErase) for efficient concept erasure. Specifically, the proposed method operates by identifying activation difference regions via prompt-pair analysis, extracting target activations and dynamically replacing input activations during forward passes. Comprehensive evaluations across three critical erasure tasks (nudity, artistic style, and object removal) demonstrates that our training-free method achieves state-of-the-art (SOTA) erasure performance, while effectively preserving the model's overall generative capability. Our approach also exhibits strong robustness against adversarial attacks, establishing a new plug-and-play paradigm for lightweight yet effective concept manipulation in diffusion models.

</details>


### [56] [FaithSCAN: Model-Driven Single-Pass Hallucination Detection for Faithful Visual Question Answering](https://arxiv.org/abs/2601.00269)
*Chaodong Tong,Qi Zhang,Chen Li,Lei Jiang,Yanbing Liu*

Main category: cs.CV

TL;DR: FaithSCAN: A lightweight network that detects VQA hallucinations by fusing internal VLM signals (token uncertainty, visual representations, cross-modal alignment) with uncertainty-aware attention, using automatically generated supervision without human labels.


<details>
  <summary>Details</summary>
Motivation: Existing VQA hallucination detection methods have limitations: external verification approaches are computationally expensive and dependent on external resources, while uncertainty-driven methods capture only limited facets of model uncertainty and fail to explore rich internal signals associated with diverse failure modes.

Method: FaithSCAN exploits rich internal VLM signals including token-level decoding uncertainty, intermediate visual representations, and cross-modal alignment features. These signals are fused via branch-wise evidence encoding and uncertainty-aware attention. The method extends LLM-as-a-Judge paradigm to VQA hallucination detection with a low-cost strategy to automatically generate model-dependent supervision signals for training without human labels.

Result: Experiments on multiple VQA benchmarks show FaithSCAN significantly outperforms existing methods in both effectiveness and efficiency. Analysis reveals hallucinations arise from systematic internal state variations in visual perception, cross-modal reasoning, and language decoding, with different internal signals providing complementary diagnostic cues.

Conclusion: FaithSCAN addresses limitations of existing hallucination detection methods by efficiently leveraging rich internal VLM signals. The approach provides new insights into multimodal hallucination causes, showing hallucination patterns vary across VLM architectures and offering a practical solution for reliable VQA systems.

Abstract: Faithfulness hallucinations in VQA occur when vision-language models produce fluent yet visually ungrounded answers, severely undermining their reliability in safety-critical applications. Existing detection methods mainly fall into two categories: external verification approaches relying on auxiliary models or knowledge bases, and uncertainty-driven approaches using repeated sampling or uncertainty estimates. The former suffer from high computational overhead and are limited by external resource quality, while the latter capture only limited facets of model uncertainty and fail to sufficiently explore the rich internal signals associated with the diverse failure modes. Both paradigms thus have inherent limitations in efficiency, robustness, and detection performance. To address these challenges, we propose FaithSCAN: a lightweight network that detects hallucinations by exploiting rich internal signals of VLMs, including token-level decoding uncertainty, intermediate visual representations, and cross-modal alignment features. These signals are fused via branch-wise evidence encoding and uncertainty-aware attention. We also extend the LLM-as-a-Judge paradigm to VQA hallucination and propose a low-cost strategy to automatically generate model-dependent supervision signals, enabling supervised training without costly human labels while maintaining high detection accuracy. Experiments on multiple VQA benchmarks show that FaithSCAN significantly outperforms existing methods in both effectiveness and efficiency. In-depth analysis shows hallucinations arise from systematic internal state variations in visual perception, cross-modal reasoning, and language decoding. Different internal signals provide complementary diagnostic cues, and hallucination patterns vary across VLM architectures, offering new insights into the underlying causes of multimodal hallucinations.

</details>


### [57] [Disentangling Hardness from Noise: An Uncertainty-Driven Model-Agnostic Framework for Long-Tailed Remote Sensing Classification](https://arxiv.org/abs/2601.00278)
*Chi Ding,Junxiao Xue,Xinyi Yin,Shi Chen,Yunyun Shi,Yiduo Wang,Fengjian Xue,Xuecheng Wu*

Main category: cs.CV

TL;DR: DUAL is an uncertainty-aware framework for long-tailed remote sensing that disentangles epistemic uncertainty (for hard tail samples) and aleatoric uncertainty (for noisy ambiguous data) using evidential deep learning.


<details>
  <summary>Details</summary>
Motivation: Long-tailed distributions are common in remote sensing due to imbalanced object occurrence, but existing methods fail to distinguish between hard-to-learn tail samples and noisy ambiguous data, leading to overfitting on noise.

Method: Proposes DUAL framework based on Evidential Deep Learning that dynamically disentangles prediction uncertainty into Epistemic Uncertainty (EU) and Aleatoric Uncertainty (AU). Uses EU as indicator of sample scarcity to guide reweighting for hard tail samples, and leverages AU to quantify data ambiguity with adaptive label smoothing to suppress noise impact.

Result: Extensive experiments on multiple datasets across various backbones demonstrate effectiveness and generalization, surpassing strong baselines like TGN and SADE. Ablation studies provide insights into design choices.

Conclusion: DUAL effectively addresses the critical challenge of disentangling hard tail samples from noisy ambiguous ones in long-tailed remote sensing through uncertainty-aware modeling, offering a model-agnostic solution with strong empirical performance.

Abstract: Long-Tailed distributions are pervasive in remote sensing due to the inherently imbalanced occurrence of grounded objects. However, a critical challenge remains largely overlooked, i.e., disentangling hard tail data samples from noisy ambiguous ones. Conventional methods often indiscriminately emphasize all low-confidence samples, leading to overfitting on noisy data. To bridge this gap, building upon Evidential Deep Learning, we propose a model-agnostic uncertainty-aware framework termed DUAL, which dynamically disentangles prediction uncertainty into Epistemic Uncertainty (EU) and Aleatoric Uncertainty (AU). Specifically, we introduce EU as an indicator of sample scarcity to guide a reweighting strategy for hard-to-learn tail samples, while leveraging AU to quantify data ambiguity, employing an adaptive label smoothing mechanism to suppress the impact of noise. Extensive experiments on multiple datasets across various backbones demonstrate the effectiveness and generalization of our framework, surpassing strong baselines such as TGN and SADE. Ablation studies provide further insights into the crucial choices of our design.

</details>


### [58] [SV-GS: Sparse View 4D Reconstruction with Skeleton-Driven Gaussian Splatting](https://arxiv.org/abs/2601.00285)
*Jun-Jee Chao,Volkan Isler*

Main category: cs.CV

TL;DR: SV-GS: A framework for dynamic object reconstruction from sparse temporal and viewpoint observations using skeleton-guided deformation fields.


<details>
  <summary>Details</summary>
Motivation: Dynamic object reconstruction typically requires dense multi-view video coverage, which is impractical in real-world scenarios like security cameras where observations are sparse in both time and viewpoints. Existing methods struggle with this ill-posed problem.

Method: Uses skeleton-driven deformation field with two components: coarse skeleton joint pose estimator (time-dependent) and fine-grained deformation module. Initialized with rough skeleton graph and static reconstruction, later relaxed to use diffusion-based generative priors. Enables smooth motion interpolation while preserving geometric details.

Result: Outperforms existing approaches by up to 34% in PSNR on synthetic datasets under sparse observations. Achieves comparable performance to dense monocular video methods on real-world datasets despite using significantly fewer frames.

Conclusion: SV-GS provides an effective solution for dynamic reconstruction from sparse observations, making it practical for real-world applications like security camera systems where dense coverage is unavailable.

Abstract: Reconstructing a dynamic target moving over a large area is challenging. Standard approaches for dynamic object reconstruction require dense coverage in both the viewing space and the temporal dimension, typically relying on multi-view videos captured at each time step. However, such setups are only possible in constrained environments. In real-world scenarios, observations are often sparse over time and captured sparsely from diverse viewpoints (e.g., from security cameras), making dynamic reconstruction highly ill-posed. We present SV-GS, a framework that simultaneously estimates a deformation model and the object's motion over time under sparse observations. To initialize SV-GS, we leverage a rough skeleton graph and an initial static reconstruction as inputs to guide motion estimation. (Later, we show that this input requirement can be relaxed.) Our method optimizes a skeleton-driven deformation field composed of a coarse skeleton joint pose estimator and a module for fine-grained deformations. By making only the joint pose estimator time-dependent, our model enables smooth motion interpolation while preserving learned geometric details. Experiments on synthetic datasets show that our method outperforms existing approaches under sparse observations by up to 34% in PSNR, and achieves comparable performance to dense monocular video methods on real-world datasets despite using significantly fewer frames. Moreover, we demonstrate that the input initial static reconstruction can be replaced by a diffusion-based generative prior, making our method more practical for real-world scenarios.

</details>


### [59] [Towards Automated Differential Diagnosis of Skin Diseases Using Deep Learning and Imbalance-Aware Strategies](https://arxiv.org/abs/2601.00286)
*Ali Anaissi,Ali Braytee,Weidong Huang,Junaid Akram,Alaa Farhat,Jie Hua*

Main category: cs.CV

TL;DR: A Swin Transformer-based deep learning model achieves 87.71% accuracy on ISIC2019 dataset for classifying 8 skin lesion types, demonstrating potential as a diagnostic support tool.


<details>
  <summary>Details</summary>
Motivation: Growing need for intelligent diagnostic tools due to increasing dermatological conditions and limited availability of dermatologists, requiring support for both patients and clinicians in timely and accurate skin disease diagnosis.

Method: Developed deep learning model using Swin Transformer architecture with pretraining on public skin disease datasets, refined architecture, optimized data preprocessing workflows, and applied targeted data augmentation techniques.

Result: Achieved 87.71% prediction accuracy across eight skin lesion classes on the ISIC2019 dataset.

Conclusion: The model demonstrates potential as both a diagnostic support tool for clinicians and a self-assessment aid for patients in dermatological diagnosis.

Abstract: As dermatological conditions become increasingly common and the availability of dermatologists remains limited, there is a growing need for intelligent tools to support both patients and clinicians in the timely and accurate diagnosis of skin diseases. In this project, we developed a deep learning based model for the classification and diagnosis of skin conditions. By leveraging pretraining on publicly available skin disease image datasets, our model effectively extracted visual features and accurately classified various dermatological cases. Throughout the project, we refined the model architecture, optimized data preprocessing workflows, and applied targeted data augmentation techniques to improve overall performance. The final model, based on the Swin Transformer, achieved a prediction accuracy of 87.71 percent across eight skin lesion classes on the ISIC2019 dataset. These results demonstrate the model's potential as a diagnostic support tool for clinicians and a self assessment aid for patients.

</details>


### [60] [TimeColor: Flexible Reference Colorization via Temporal Concatenation](https://arxiv.org/abs/2601.00296)
*Bryan Constantine Sadihin,Yihao Meng,Michael Hua Wang,Matteo Jiahao Chen,Hang Su*

Main category: cs.CV

TL;DR: TimeColor is a sketch-based video colorization model that supports multiple heterogeneous references (character sheets, background images, etc.) with explicit per-reference region assignment, improving color fidelity, identity consistency, and temporal stability.


<details>
  <summary>Details</summary>
Motivation: Existing colorization models only condition on a single reference (typically the first frame), ignoring other valuable conditional data sources like character sheets, background images, or arbitrary colorized frames.

Method: Encodes references as additional latent frames concatenated temporally, processed concurrently in each diffusion step. Uses spatiotemporal correspondence-masked attention and modality-disjoint RoPE indexing to enforce subject-reference binding and prevent shortcutting/cross-identity palette leakage.

Result: Experiments on SAKUGA-42M dataset show TimeColor improves color fidelity, identity consistency, and temporal stability over prior baselines under both single- and multi-reference protocols.

Conclusion: TimeColor successfully addresses limitations of single-reference colorization by supporting heterogeneous, variable-count references with explicit region assignment, leading to better video colorization quality.

Abstract: Most colorization models condition only on a single reference, typically the first frame of the scene. However, this approach ignores other sources of conditional data, such as character sheets, background images, or arbitrary colorized frames. We propose TimeColor, a sketch-based video colorization model that supports heterogeneous, variable-count references with the use of explicit per-reference region assignment. TimeColor encodes references as additional latent frames which are concatenated temporally, permitting them to be processed concurrently in each diffusion step while keeping the model's parameter count fixed. TimeColor also uses spatiotemporal correspondence-masked attention to enforce subject-reference binding in addition to modality-disjoint RoPE indexing. These mechanisms mitigate shortcutting and cross-identity palette leakage. Experiments on SAKUGA-42M under both single- and multi-reference protocols show that TimeColor improves color fidelity, identity consistency, and temporal stability over prior baselines.

</details>


### [61] [VisNet: Efficient Person Re-Identification via Alpha-Divergence Loss, Feature Fusion and Dynamic Multi-Task Learning](https://arxiv.org/abs/2601.00307)
*Anns Ijaz,Muhammad Azeem Javed*

Main category: cs.CV

TL;DR: VisNet is an efficient person re-identification model that achieves strong accuracy with low computational cost through multi-scale feature fusion, semantic clustering, and optimized loss functions.


<details>
  <summary>Details</summary>
Motivation: Person re-identification needs high accuracy with minimal computational cost for real-world surveillance and mobile applications, but current state-of-the-art methods have high computational budgets.

Method: VisNet combines: 1) multi-scale feature fusion from ResNet50 stages 1-4 without parallel paths, 2) semantic clustering with anatomical body partitioning using rule-based pseudo-labeling, 3) dynamic weight averaging for classification regularization, and 4) FIDI loss function for improved metric learning.

Result: Achieves 87.05% Rank-1 and 77.65% mAP on Market-1501 dataset with only 32.41M parameters and 4.601 GFLOPs, making it suitable for real-time deployment.

Conclusion: VisNet provides a practical, computationally efficient solution for person re-identification in resource-constrained real-world applications like surveillance and mobile systems.

Abstract: Person re-identification (ReID) is an extremely important area in both surveillance and mobile applications, requiring strong accuracy with minimal computational cost. State-of-the-art methods give good accuracy but with high computational budgets. To remedy this, this paper proposes VisNet, a computationally efficient and effective re-identification model suitable for real-world scenarios. It is the culmination of conceptual contributions, including feature fusion at multiple scales with automatic attention on each, semantic clustering with anatomical body partitioning, a dynamic weight averaging technique to balance classification semantic regularization, and the use of loss function FIDI for improved metric learning tasks. The multiple scales fuse ResNet50's stages 1 through 4 without the use of parallel paths, with semantic clustering introducing spatial constraints through the use of rule-based pseudo-labeling. VisNet achieves 87.05% Rank-1 and 77.65% mAP on the Market-1501 dataset, having 32.41M parameters and 4.601 GFLOPs, hence, proposing a practical approach for real-time deployment in surveillance and mobile applications where computational resources are limited.

</details>


### [62] [ReMA: A Training-Free Plug-and-Play Mixing Augmentation for Video Behavior Recognition](https://arxiv.org/abs/2601.00311)
*Feng-Qi Cui,Jinyang Huang,Sirui Zhao,Jinglong Guo,Qifan Cai,Xin Yan,Zhi Liu*

Main category: cs.CV

TL;DR: ReMA is a plug-and-play video augmentation strategy that performs controlled mixing to expand representations while preserving class-conditional stability, improving robustness across spatiotemporal scales.


<details>
  <summary>Details</summary>
Motivation: Current video data augmentation strategies are perturbation-driven and introduce uncontrolled variations that amplify non-discriminative factors, weakening intra-class distributional structure and causing representation drift with inconsistent gains across temporal scales.

Method: ReMA integrates two mechanisms: 1) Representation Alignment Mechanism (RAM) for structured intra-class mixing under distributional alignment constraints, and 2) Dynamic Selection Mechanism (DSM) that generates motion-aware spatiotemporal masks to localize perturbations away from discrimination-sensitive regions.

Result: Extensive experiments on diverse video behavior benchmarks demonstrate that ReMA consistently enhances generalization and robustness across different spatiotemporal granularities.

Conclusion: ReMA improves representation robustness without additional supervision or trainable parameters by jointly controlling how and where mixing is applied, addressing limitations of conventional perturbation-driven video augmentation.

Abstract: Video behavior recognition demands stable and discriminative representations under complex spatiotemporal variations. However, prevailing data augmentation strategies for videos remain largely perturbation-driven, often introducing uncontrolled variations that amplify non-discriminative factors, which finally weaken intra-class distributional structure and representation drift with inconsistent gains across temporal scales. To address these problems, we propose Representation-aware Mixing Augmentation (ReMA), a plug-and-play augmentation strategy that formulates mixing as a controlled replacement process to expand representations while preserving class-conditional stability. ReMA integrates two complementary mechanisms. Firstly, the Representation Alignment Mechanism (RAM) performs structured intra-class mixing under distributional alignment constraints, suppressing irrelevant intra-class drift while enhancing statistical reliability. Then, the Dynamic Selection Mechanism (DSM) generates motion-aware spatiotemporal masks to localize perturbations, guiding them away from discrimination-sensitive regions and promoting temporal coherence. By jointly controlling how and where mixing is applied, ReMA improves representation robustness without additional supervision or trainable parameters. Extensive experiments on diverse video behavior benchmarks demonstrate that ReMA consistently enhances generalization and robustness across different spatiotemporal granularities.

</details>


### [63] [Depth-Synergized Mamba Meets Memory Experts for All-Day Image Reflection Separation](https://arxiv.org/abs/2601.00322)
*Siyan Fang,Long Peng,Yuntao Wang,Ruonan Wei,Yuehuan Wang*

Main category: cs.CV

TL;DR: DMDNet uses depth-aware Mamba and memory compensation to separate image reflections, especially effective for challenging nighttime scenarios.


<details>
  <summary>Details</summary>
Motivation: Existing reflection separation methods struggle when transmission and reflection layers have similar contrasts, which is particularly challenging at night due to limited information from single images.

Method: Proposes Depth-Memory Decoupling Network (DMDNet) with: 1) Depth-Aware Scanning (DAScan) to guide Mamba toward salient structures, 2) Depth-Synergized State-Space Model (DS-SSM) to modulate state activations by depth, 3) Memory Expert Compensation Module (MECM) using cross-image historical knowledge, and 4) NightIRS dataset for nighttime reflection separation.

Result: DMDNet outperforms state-of-the-art methods in both daytime and nighttime reflection separation, with extensive experimental validation.

Conclusion: The proposed depth-aware Mamba approach with memory compensation effectively addresses the challenging problem of nighttime image reflection separation, achieving superior performance over existing methods.

Abstract: Image reflection separation aims to disentangle the transmission layer and the reflection layer from a blended image. Existing methods rely on limited information from a single image, tending to confuse the two layers when their contrasts are similar, a challenge more severe at night. To address this issue, we propose the Depth-Memory Decoupling Network (DMDNet). It employs the Depth-Aware Scanning (DAScan) to guide Mamba toward salient structures, promoting information flow along semantic coherence to construct stable states. Working in synergy with DAScan, the Depth-Synergized State-Space Model (DS-SSM) modulates the sensitivity of state activations by depth, suppressing the spread of ambiguous features that interfere with layer disentanglement. Furthermore, we introduce the Memory Expert Compensation Module (MECM), leveraging cross-image historical knowledge to guide experts in providing layer-specific compensation. To address the lack of datasets for nighttime reflection separation, we construct the Nighttime Image Reflection Separation (NightIRS) dataset. Extensive experiments demonstrate that DMDNet outperforms state-of-the-art methods in both daytime and nighttime.

</details>


### [64] [HarmoniAD: Harmonizing Local Structures and Global Semantics for Anomaly Detection](https://arxiv.org/abs/2601.00327)
*Naiqi Zhang,Chuancheng Shi,Jingtong Dou,Wenhua Wu,Fei Shen,Jianhua Cao*

Main category: cs.CV

TL;DR: HarmoniAD is a frequency-guided dual-branch anomaly detection framework that balances structure and semantics by decoupling features into high- and low-frequency paths, achieving state-of-the-art performance on industrial defect detection benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing anomaly detection methods face a structure-semantics trade-off: structure-oriented models are noise-sensitive, while semantics-oriented models often miss fine details needed for detecting tiny defects in industrial quality inspection.

Method: Frequency-guided dual-branch framework: 1) Extract features using CLIP image encoder, 2) Transform to frequency domain, 3) Decouple into high-frequency (with FSAM for fine-grained structural attention) and low-frequency (with GSCM for global structural context) branches for complementary modeling.

Result: State-of-the-art performance on MVTec-AD, VisA, and BTAD benchmarks, demonstrating both sensitivity to small anomalies and robustness.

Conclusion: HarmoniAD effectively balances fine detail and global semantics through frequency-guided dual-branch architecture, addressing the structure-semantics trade-off in industrial anomaly detection.

Abstract: Anomaly detection is crucial in industrial product quality inspection. Failing to detect tiny defects often leads to serious consequences. Existing methods face a structure-semantics trade-off: structure-oriented models (such as frequency-based filters) are noise-sensitive, while semantics-oriented models (such as CLIP-based encoders) often miss fine details. To address this, we propose HarmoniAD, a frequency-guided dual-branch framework. Features are first extracted by the CLIP image encoder, then transformed into the frequency domain, and finally decoupled into high- and low-frequency paths for complementary modeling of structure and semantics. The high-frequency branch is equipped with a fine-grained structural attention module (FSAM) to enhance textures and edges for detecting small anomalies, while the low-frequency branch uses a global structural context module (GSCM) to capture long-range dependencies and preserve semantic consistency. Together, these branches balance fine detail and global semantics. HarmoniAD further adopts a multi-class joint training strategy, and experiments on MVTec-AD, VisA, and BTAD show state-of-the-art performance with both sensitivity and robustness.

</details>


### [65] [Joint Geometry-Appearance Human Reconstruction in a Unified Latent Space via Bridge Diffusion](https://arxiv.org/abs/2601.00328)
*Yingzhi Tang,Qijian Zhang,Junhui Hou*

Main category: cs.CV

TL;DR: JGA-LBD is a unified framework for 3D human reconstruction from single RGB images using joint geometry-appearance latent representation and bridge diffusion, outperforming state-of-the-art methods.


<details>
  <summary>Details</summary>
Motivation: Existing methods use decoupled pipelines for geometry estimation and appearance synthesis, causing inconsistencies and hindering unified reconstruction of 3D humans from single images.

Method: Unifies geometry and appearance modeling into joint latent representation using 3D Gaussian representations compressed via shared sparse VAE, then applies bridge diffusion to infer missing components from partial observations.

Result: Outperforms current state-of-the-art approaches in both geometry fidelity and appearance quality, including challenging in-the-wild scenarios.

Conclusion: JGA-LBD successfully unifies geometry and appearance reconstruction through joint latent representation and bridge diffusion, achieving consistent high-fidelity 3D human reconstruction from single images.

Abstract: Achieving consistent and high-fidelity geometry and appearance reconstruction of 3D digital humans from a single RGB image is inherently a challenging task. Existing studies typically resort to decoupled pipelines for geometry estimation and appearance synthesis, often hindering unified reconstruction and causing inconsistencies. This paper introduces \textbf{JGA-LBD}, a novel framework that unifies the modeling of geometry and appearance into a joint latent representation and formulates the generation process as bridge diffusion. Observing that directly integrating heterogeneous input conditions (e.g., depth maps, SMPL models) leads to substantial training difficulties, we unify all conditions into the 3D Gaussian representations, which can be further compressed into a unified latent space through a shared sparse variational autoencoder (VAE). Subsequently, the specialized form of bridge diffusion enables to start with a partial observation of the target latent code and solely focuses on inferring the missing components. Finally, a dedicated decoding module extracts the complete 3D human geometric structure and renders novel views from the inferred latent representation. Experiments demonstrate that JGA-LBD outperforms current state-of-the-art approaches in terms of both geometry fidelity and appearance quality, including challenging in-the-wild scenarios. Our code will be made publicly available at https://github.com/haiantyz/JGA-LBD.

</details>


### [66] [Intelligent Traffic Surveillance for Real-Time Vehicle Detection, License Plate Recognition, and Speed Estimation](https://arxiv.org/abs/2601.00344)
*Bruce Mugizi,Sudi Murindanyi,Olivia Nakacwa,Andrew Katumba*

Main category: cs.CV

TL;DR: Real-time intelligent traffic surveillance system for developing countries using computer vision for vehicle detection, license plate recognition, and speed estimation with automated ticket issuance via SMS.


<details>
  <summary>Details</summary>
Motivation: Speeding is a major contributor to road fatalities in developing countries like Uganda where road safety infrastructure is limited, creating an urgent need for automated traffic enforcement solutions.

Method: Used computer vision techniques with YOLOv8 for license plate detection (97.9% mAP), CNN and transformer models for character recognition, and source/target ROI for speed estimation. Collected dataset using speed gun, Canon Camera, and mobile phone. Established database with Africa's Talking API for automated SMS ticket issuance.

Result: License plate detection achieved 97.9% mAP; character recognition: CNN had 3.85% CER, transformer reduced to 1.79% CER; speed estimation had 10 km/h margin of error. System successfully enables automated traffic enforcement.

Conclusion: The proposed system effectively addresses critical traffic management needs in resource-constrained environments and shows potential to reduce road accidents through automated enforcement in developing countries where such interventions are urgently needed.

Abstract: Speeding is a major contributor to road fatalities, particularly in developing countries such as Uganda, where road safety infrastructure is limited. This study proposes a real-time intelligent traffic surveillance system tailored to such regions, using computer vision techniques to address vehicle detection, license plate recognition, and speed estimation. The study collected a rich dataset using a speed gun, a Canon Camera, and a mobile phone to train the models. License plate detection using YOLOv8 achieved a mean average precision (mAP) of 97.9%. For character recognition of the detected license plate, the CNN model got a character error rate (CER) of 3.85%, while the transformer model significantly reduced the CER to 1.79%. Speed estimation used source and target regions of interest, yielding a good performance of 10 km/h margin of error. Additionally, a database was established to correlate user information with vehicle detection data, enabling automated ticket issuance via SMS via Africa's Talking API. This system addresses critical traffic management needs in resource-constrained environments and shows potential to reduce road accidents through automated traffic enforcement in developing countries where such interventions are urgently needed.

</details>


### [67] [OmniVaT: Single Domain Generalization for Multimodal Visual-Tactile Learning](https://arxiv.org/abs/2601.00352)
*Liuxiang Qiu,Hui Da,Yuzhen Niu,Tiesong Zhao,Yang Cao,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: OmniVaT framework addresses single domain generalization for multimodal visual-tactile learning by bridging modality gaps and enhancing domain adaptation without multi-domain training data.


<details>
  <summary>Details</summary>
Motivation: Visual-tactile learning suffers from modality discrepancies between visual and tactile sensors, and domain gaps caused by non-standardized sensors and inconsistent data collection procedures.

Method: Proposes OmniVaT with two key components: 1) Multimodal Fractional Fourier Adapter (MFFA) maps VIS and TAC embeddings into unified embedding-frequency space to mitigate modality gap, 2) Discrete Tree Generation (DTG) module obtains diverse multimodal fractional representations through hierarchical tree structure for better domain adaptation.

Result: Extensive experiments demonstrate superior cross-domain generalization performance on the SDG-VTL task.

Conclusion: OmniVaT successfully addresses the single domain generalization for multimodal visual-tactile learning task, effectively bridging modality gaps and enhancing domain adaptation without requiring multi-domain training data.

Abstract: Visual-tactile learning (VTL) enables embodied agents to perceive the physical world by integrating visual (VIS) and tactile (TAC) sensors. However, VTL still suffers from modality discrepancies between VIS and TAC images, as well as domain gaps caused by non-standardized tactile sensors and inconsistent data collection procedures. We formulate these challenges as a new task, termed single domain generalization for multimodal VTL (SDG-VTL). In this paper, we propose an OmniVaT framework that, for the first time, successfully addresses this task. On the one hand, OmniVaT integrates a multimodal fractional Fourier adapter (MFFA) to map VIS and TAC embeddings into a unified embedding-frequency space, thereby effectively mitigating the modality gap without multi-domain training data or careful cross-modal fusion strategies. On the other hand, it also incorporates a discrete tree generation (DTG) module that obtains diverse and reliable multimodal fractional representations through a hierarchical tree structure, thereby enhancing its adaptivity to fluctuating domain shifts in unseen domains. Extensive experiments demonstrate the superior cross-domain generalization performance of OmniVaT on the SDG-VTL task.

</details>


### [68] [Efficient Prediction of Dense Visual Embeddings via Distillation and RGB-D Transformers](https://arxiv.org/abs/2601.00359)
*Söhnke Benedikt Fischedick,Daniel Seichter,Benedict Stephan,Robin Schmidt,Horst-Michael Gross*

Main category: cs.CV

TL;DR: DVEFormer: An efficient RGB-D Transformer that predicts dense text-aligned visual embeddings via knowledge distillation from Alpha-CLIP, enabling flexible text-based querying and 3D mapping while maintaining real-time performance.


<details>
  <summary>Details</summary>
Motivation: Robots in domestic environments need comprehensive scene understanding to interact effectively with untrained humans. Traditional semantic segmentation with fixed classes is limited, so the paper aims to enable more flexible, text-based querying and integration with 3D mapping systems.

Method: Proposes DVEFormer, an efficient RGB-D Transformer-based approach that uses knowledge distillation from Alpha-CLIP teacher embeddings. The student model learns fine-grained pixel-wise embeddings aligned with text, enabling both classical segmentation (via linear probing) and flexible text-based querying.

Result: Achieves competitive performance on common indoor datasets while meeting real-time requirements: 26.3 FPS for full model and 77.0 FPS for smaller variant on NVIDIA Jetson AGX Orin. Qualitative results demonstrate effectiveness in real-world applications.

Conclusion: DVEFormer serves as a drop-in replacement for traditional segmentation approaches while enabling flexible natural-language querying and seamless integration into 3D mapping pipelines for mobile robotics.

Abstract: In domestic environments, robots require a comprehensive understanding of their surroundings to interact effectively and intuitively with untrained humans. In this paper, we propose DVEFormer - an efficient RGB-D Transformer-based approach that predicts dense text-aligned visual embeddings (DVE) via knowledge distillation. Instead of directly performing classical semantic segmentation with fixed predefined classes, our method uses teacher embeddings from Alpha-CLIP to guide our efficient student model DVEFormer in learning fine-grained pixel-wise embeddings. While this approach still enables classical semantic segmentation, e.g., via linear probing, it further enables flexible text-based querying and other applications, such as creating comprehensive 3D maps. Evaluations on common indoor datasets demonstrate that our approach achieves competitive performance while meeting real-time requirements, operating at 26.3 FPS for the full model and 77.0 FPS for a smaller variant on an NVIDIA Jetson AGX Orin. Additionally, we show qualitative results that highlight the effectiveness and possible use cases in real-world applications. Overall, our method serves as a drop-in replacement for traditional segmentation approaches while enabling flexible natural-language querying and seamless integration into 3D mapping pipelines for mobile robotics.

</details>


### [69] [Mask-Conditioned Voxel Diffusion for Joint Geometry and Color Inpainting](https://arxiv.org/abs/2601.00368)
*Aarya Sumuk*

Main category: cs.CV

TL;DR: A two-stage framework for joint 3D geometry and color inpainting that first localizes damage via 2D CNN on RGB slices, then performs mask-conditioned volumetric diffusion inpainting using a 3D U-Net.


<details>
  <summary>Details</summary>
Motivation: Digital restoration of cultural heritage artifacts requires joint reconstruction of both geometry and color for damaged 3D objects, going beyond simple symmetry-based approaches.

Method: Two-stage pipeline: 1) Damage localization using 2D CNN on RGB slices aggregated into volumetric mask, 2) Mask-conditioned inpainting using diffusion-based 3D U-Net that jointly predicts occupancy and color with composite objective combining occupancy reconstruction, masked color reconstruction, and perceptual regularization.

Result: Produces more complete geometry and coherent color reconstructions compared to symmetry-based baselines at fixed 32^3 resolution, with explicit mask conditioning proving effective for guiding volumetric diffusion models.

Conclusion: Explicit mask conditioning is a practical approach for guiding volumetric diffusion models in joint 3D geometry and color inpainting tasks, particularly valuable for cultural heritage restoration applications.

Abstract: We present a lightweight two-stage framework for joint geometry and color inpainting of damaged 3D objects, motivated by the digital restoration of cultural heritage artifacts. The pipeline separates damage localization from reconstruction. In the first stage, a 2D convolutional network predicts damage masks on RGB slices extracted from a voxelized object, and these predictions are aggregated into a volumetric mask. In the second stage, a diffusion-based 3D U-Net performs mask-conditioned inpainting directly on voxel grids, reconstructing geometry and color while preserving observed regions. The model jointly predicts occupancy and color using a composite objective that combines occupancy reconstruction with masked color reconstruction and perceptual regularization. We evaluate the approach on a curated set of textured artifacts with synthetically generated damage using standard geometric and color metrics. Compared to symmetry-based baselines, our method produces more complete geometry and more coherent color reconstructions at a fixed 32^3 resolution. Overall, the results indicate that explicit mask conditioning is a practical way to guide volumetric diffusion models for joint 3D geometry and color inpainting.

</details>


### [70] [BHaRNet: Reliability-Aware Body-Hand Modality Expertized Networks for Fine-grained Skeleton Action Recognition](https://arxiv.org/abs/2601.00369)
*Seungyeon Cho,Tae-kyun Kim*

Main category: cs.CV

TL;DR: A probabilistic dual-stream framework for skeleton-based human action recognition that unifies reliability modeling and multi-modal integration, handling both body and hand motions with improved robustness to noise.


<details>
  <summary>Details</summary>
Motivation: Existing skeleton-based HAR methods are body-centric and neglect subtle hand articulations crucial for fine-grained recognition. There's a need for approaches that handle both large-scale body motions and fine hand movements while being robust to noisy and heterogeneous conditions.

Method: Three key components: 1) Calibration-free preprocessing using native coordinates, 2) Probabilistic Noisy-OR fusion for reliability-aware dual-stream learning without confidence supervision, 3) Intra- to cross-modal ensemble coupling four skeleton modalities (Joint, Bone, Joint Motion, Bone Motion) with RGB representations.

Result: Comprehensive evaluations across multiple benchmarks (NTU RGB+D 60/120, PKU-MMD, N-UCLA) and a new hand-centric benchmark show consistent improvements and robustness under noisy and heterogeneous conditions.

Conclusion: The probabilistic dual-stream framework effectively unifies reliability modeling and multi-modal integration, enabling expertized learning under uncertainty across intra-skeleton and cross-modal domains for improved fine-grained action recognition.

Abstract: Skeleton-based human action recognition (HAR) has achieved remarkable progress with graph-based architectures. However, most existing methods remain body-centric, focusing on large-scale motions while neglecting subtle hand articulations that are crucial for fine-grained recognition. This work presents a probabilistic dual-stream framework that unifies reliability modeling and multi-modal integration, generalizing expertized learning under uncertainty across both intra-skeleton and cross-modal domains. The framework comprises three key components: (1) a calibration-free preprocessing pipeline that removes canonical-space transformations and learns directly from native coordinates; (2) a probabilistic Noisy-OR fusion that stabilizes reliability-aware dual-stream learning without requiring explicit confidence supervision; and (3) an intra- to cross-modal ensemble that couples four skeleton modalities (Joint, Bone, Joint Motion, and Bone Motion) to RGB representations, bridging structural and visual motion cues in a unified cross-modal formulation. Comprehensive evaluations across multiple benchmarks (NTU RGB+D~60/120, PKU-MMD, N-UCLA) and a newly defined hand-centric benchmark exhibit consistent improvements and robustness under noisy and heterogeneous conditions.

</details>


### [71] [NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos](https://arxiv.org/abs/2601.00393)
*Yuxue Yang,Lue Fan,Ziqi Shi,Junran Peng,Feng Wang,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: NeoVerse is a versatile 4D world model that enables scalable 4D reconstruction and novel-trajectory video generation from diverse monocular videos, overcoming limitations of existing methods that require expensive multi-view data or cumbersome pre-processing.


<details>
  <summary>Details</summary>
Motivation: Current 4D world modeling methods suffer from scalability limitations due to their reliance on expensive multi-view 4D data or cumbersome training pre-processing, which restricts their practical application to diverse real-world scenarios.

Method: NeoVerse features pose-free feed-forward 4D reconstruction, online monocular degradation pattern simulation, and other well-aligned techniques designed to make the full pipeline scalable to diverse in-the-wild monocular videos.

Result: NeoVerse achieves state-of-the-art performance in standard reconstruction and generation benchmarks while demonstrating versatility and generalization to various domains.

Conclusion: NeoVerse presents a scalable and versatile 4D world model that can handle diverse monocular video inputs, enabling rich downstream applications in 4D reconstruction and novel-trajectory video generation.

Abstract: In this paper, we propose NeoVerse, a versatile 4D world model that is capable of 4D reconstruction, novel-trajectory video generation, and rich downstream applications. We first identify a common limitation of scalability in current 4D world modeling methods, caused either by expensive and specialized multi-view 4D data or by cumbersome training pre-processing. In contrast, our NeoVerse is built upon a core philosophy that makes the full pipeline scalable to diverse in-the-wild monocular videos. Specifically, NeoVerse features pose-free feed-forward 4D reconstruction, online monocular degradation pattern simulation, and other well-aligned techniques. These designs empower NeoVerse with versatility and generalization to various domains. Meanwhile, NeoVerse achieves state-of-the-art performance in standard reconstruction and generation benchmarks. Our project page is available at https://neoverse-4d.github.io

</details>


### [72] [RoLID-11K: A Dashcam Dataset for Small-Object Roadside Litter Detection](https://arxiv.org/abs/2601.00398)
*Tao Wu,Qing Xu,Xiangjian He,Oakleigh Weekes,James Brown,Wenting Duan*

Main category: cs.CV

TL;DR: RoLID-11K is the first large-scale dataset for roadside litter detection from dashcams, featuring 11k annotated images with extreme small objects and long-tail distribution, benchmarking modern detectors for scalable litter monitoring.


<details>
  <summary>Details</summary>
Motivation: Current roadside litter monitoring relies on labor-intensive surveys with limited coverage. Existing vision datasets don't address dashcam-specific challenges where litter appears extremely small, sparse, and in cluttered backgrounds.

Method: Created RoLID-11K dataset with 11k annotated dashcam images from diverse UK driving conditions. Benchmarked various modern detectors including transformer architectures (CO-DETR) and real-time YOLO models to evaluate performance on this challenging task.

Result: Transformer architectures like CO-DETR achieved best localization accuracy, while real-time models were constrained by coarse feature hierarchies. The dataset exhibits pronounced long-tail and small-object distributions typical of dashcam footage.

Conclusion: RoLID-11K establishes a challenging benchmark for extreme small-object detection in dynamic driving scenes and aims to support development of scalable, low-cost systems for roadside litter monitoring.

Abstract: Roadside litter poses environmental, safety and economic challenges, yet current monitoring relies on labour-intensive surveys and public reporting, providing limited spatial coverage. Existing vision datasets for litter detection focus on street-level still images, aerial scenes or aquatic environments, and do not reflect the unique characteristics of dashcam footage, where litter appears extremely small, sparse and embedded in cluttered road-verge backgrounds. We introduce RoLID-11K, the first large-scale dataset for roadside litter detection from dashcams, comprising over 11k annotated images spanning diverse UK driving conditions and exhibiting pronounced long-tail and small-object distributions. We benchmark a broad spectrum of modern detectors, from accuracy-oriented transformer architectures to real-time YOLO models, and analyse their strengths and limitations on this challenging task. Our results show that while CO-DETR and related transformers achieve the best localisation accuracy, real-time models remain constrained by coarse feature hierarchies. RoLID-11K establishes a challenging benchmark for extreme small-object detection in dynamic driving scenes and aims to support the development of scalable, low-cost systems for roadside-litter monitoring. The dataset is available at https://github.com/xq141839/RoLID-11K.

</details>


### [73] [ABFR-KAN: Kolmogorov-Arnold Networks for Functional Brain Analysis](https://arxiv.org/abs/2601.00416)
*Tyler Ward,Abdullah Imran*

Main category: cs.CV

TL;DR: ABFR-KAN is a transformer-based network using Kolmogorov-Arnold Networks to improve functional connectivity analysis for autism diagnosis by reducing structural bias and enhancing anatomical conformity.


<details>
  <summary>Details</summary>
Motivation: Traditional atlas-based parcellation for functional connectivity analysis suffers from selection bias and lacks subject specificity, limiting its reliability for brain disorder diagnosis.

Method: Proposes ABFR-KAN, a transformer-based classification network that incorporates novel brain function representation components with Kolmogorov-Arnold Networks (KANs) to mitigate structural bias and improve anatomical conformity.

Result: Extensive experiments on ABIDE I dataset show ABFR-KAN consistently outperforms state-of-the-art baselines for autism spectrum disorder classification, validated through cross-site evaluation and ablation studies.

Conclusion: ABFR-KAN effectively addresses limitations of traditional atlas-based approaches and improves the reliability of functional connectivity estimation for brain disorder diagnosis.

Abstract: Functional connectivity (FC) analysis, a valuable tool for computer-aided brain disorder diagnosis, traditionally relies on atlas-based parcellation. However, issues relating to selection bias and a lack of regard for subject specificity can arise as a result of such parcellations. Addressing this, we propose ABFR-KAN, a transformer-based classification network that incorporates novel advanced brain function representation components with the power of Kolmogorov-Arnold Networks (KANs) to mitigate structural bias, improve anatomical conformity, and enhance the reliability of FC estimation. Extensive experiments on the ABIDE I dataset, including cross-site evaluation and ablation studies across varying model backbones and KAN configurations, demonstrate that ABFR-KAN consistently outperforms state-of-the-art baselines for autism spectrum distorder (ASD) classification. Our code is available at https://github.com/tbwa233/ABFR-KAN.

</details>


### [74] [Robust Assembly Progress Estimation via Deep Metric Learning](https://arxiv.org/abs/2601.00422)
*Kazuma Miura,Sarthak Pathak,Kazunori Umeda*

Main category: cs.CV

TL;DR: Proposes Anomaly Quadruplet-Net for robust assembly progress estimation using small datasets, improving accuracy and reducing misclassification between adjacent tasks.


<details>
  <summary>Details</summary>
Motivation: Manual multi-day assembly tasks challenge smart factory implementation. Existing methods fail when visual changes between tasks are subtle, leading to misclassification.

Method: Uses Quadruplet Loss-based learning for anomaly images with custom data loader that strategically selects training samples to enhance estimation accuracy.

Result: Outperformed existing methods on desktop PC assembly dataset, improving estimation accuracy by 1.3% and reducing misclassification between adjacent tasks by 1.9%.

Conclusion: The proposed system effectively estimates assembly progress even with occlusion or minimal visual changes using small-scale datasets, demonstrating practical value for smart factories.

Abstract: In recent years, the advancement of AI technologies has accelerated the development of smart factories. In particular, the automatic monitoring of product assembly progress is crucial for improving operational efficiency, minimizing the cost of discarded parts, and maximizing factory productivity. However, in cases where assembly tasks are performed manually over multiple days, implementing smart factory systems remains a challenge. Previous work has proposed Anomaly Triplet-Net, which estimates assembly progress by applying deep metric learning to the visual features of products. Nevertheless, when visual changes between consecutive tasks are subtle, misclassification often occurs. To address this issue, this paper proposes a robust system for estimating assembly progress, even in cases of occlusion or minimal visual change, using a small-scale dataset. Our method leverages a Quadruplet Loss-based learning approach for anomaly images and introduces a custom data loader that strategically selects training samples to enhance estimation accuracy. We evaluated our approach using a image datasets: captured during desktop PC assembly. The proposed Anomaly Quadruplet-Net outperformed existing methods on the dataset. Specifically, it improved the estimation accuracy by 1.3% and reduced misclassification between adjacent tasks by 1.9% in the desktop PC dataset and demonstrating the effectiveness of the proposed method.

</details>


### [75] [CPPO: Contrastive Perception for Vision Language Policy Optimization](https://arxiv.org/abs/2601.00501)
*Ahmad Rezaei,Mohsen Gholami,Saeed Ranjbar Alvar,Kevin Cannons,Mohammad Asiful Hossain,Zhou Weimin,Shunbo Zhou,Yong Zhang,Mohammad Akbari*

Main category: cs.CV

TL;DR: CPPO is a Contrastive Perception Policy Optimization method that improves multimodal reasoning in vision-language models by detecting perception tokens via entropy shifts and applying contrastive perception loss, outperforming previous methods without needing extra models.


<details>
  <summary>Details</summary>
Motivation: While RL has advanced reasoning in language models, extending it to multimodal reasoning requires improving both perception and reasoning. Prior methods use explicit perception rewards but struggle to disentangle perception from reasoning tokens, requiring extra LLMs, ground-truth data, or indiscriminate reward application.

Method: CPPO detects perception tokens by analyzing entropy shifts in model outputs under perturbed input images. It extends the RL objective with Contrastive Perception Loss (CPL) that enforces consistency under information-preserving perturbations and sensitivity under information-removing perturbations.

Result: CPPO surpasses previous perception-rewarding methods while avoiding the need for extra models, making training more efficient and scalable.

Conclusion: CPPO provides an effective approach for finetuning vision-language models by addressing the perception-reasoning disentanglement problem through contrastive perception optimization, offering improved performance with greater efficiency.

Abstract: We introduce CPPO, a Contrastive Perception Policy Optimization method for finetuning vision-language models (VLMs). While reinforcement learning (RL) has advanced reasoning in language models, extending it to multimodal reasoning requires improving both the perception and reasoning aspects. Prior works tackle this challenge mainly with explicit perception rewards, but disentangling perception tokens from reasoning tokens is difficult, requiring extra LLMs, ground-truth data, forced separation of perception from reasoning by policy model, or applying rewards indiscriminately to all output tokens. CPPO addresses this problem by detecting perception tokens via entropy shifts in the model outputs under perturbed input images. CPPO then extends the RL objective function with a Contrastive Perception Loss (CPL) that enforces consistency under information-preserving perturbations and sensitivity under information-removing ones. Experiments show that CPPO surpasses previous perception-rewarding methods, while avoiding extra models, making training more efficient and scalable.

</details>


### [76] [MotionPhysics: Learnable Motion Distillation for Text-Guided Simulation](https://arxiv.org/abs/2601.00504)
*Miaowei Wang,Jakub Zadrożny,Oisin Mac Aodha,Amir Vaxman*

Main category: cs.CV

TL;DR: MotionPhysics: A framework that infers physical parameters from natural language prompts to simulate dynamic behaviors of 3D objects and materials without requiring ground-truth trajectories or annotated videos.


<details>
  <summary>Details</summary>
Motivation: Simulating 3D objects with various materials requires expert knowledge and time-consuming parameter tuning. Current approaches need ground-truth trajectories or annotated videos, which are difficult to obtain.

Method: 1) Uses multimodal LLM to estimate material parameters within plausible ranges. 2) Proposes learnable motion distillation loss to extract motion priors from pretrained video diffusion models while minimizing appearance/geometry biases.

Result: Evaluated on 30+ scenarios with real-world, human-designed, and AI-generated 3D objects across diverse materials (elastic solids, metals, foams, sand, Newtonian/non-Newtonian fluids). Produces visually realistic simulations guided by natural language, surpassing state-of-the-art.

Conclusion: MotionPhysics enables automatic determination of physically plausible parameters for dynamic simulations from natural language prompts, eliminating the need for expert tuning or ground-truth data.

Abstract: Accurately simulating existing 3D objects and a wide variety of materials often demands expert knowledge and time-consuming physical parameter tuning to achieve the desired dynamic behavior. We introduce MotionPhysics, an end-to-end differentiable framework that infers plausible physical parameters from a user-provided natural language prompt for a chosen 3D scene of interest, removing the need for guidance from ground-truth trajectories or annotated videos. Our approach first utilizes a multimodal large language model to estimate material parameter values, which are constrained to lie within plausible ranges. We further propose a learnable motion distillation loss that extracts robust motion priors from pretrained video diffusion models while minimizing appearance and geometry inductive biases to guide the simulation. We evaluate MotionPhysics across more than thirty scenarios, including real-world, human-designed, and AI-generated 3D objects, spanning a wide range of materials such as elastic solids, metals, foams, sand, and both Newtonian and non-Newtonian fluids. We demonstrate that MotionPhysics produces visually realistic dynamic simulations guided by natural language, surpassing the state of the art while automatically determining physically plausible parameters. The code and project page are available at: https://wangmiaowei.github.io/MotionPhysics.github.io/.

</details>


### [77] [All-in-One Video Restoration under Smoothly Evolving Unknown Weather Degradations](https://arxiv.org/abs/2601.00533)
*Wenrui Li,Hongtao Chen,Yao Xiao,Wangmeng Zuo,Jiantao Zhou,Yonghong Tian,Xiaopeng Fan*

Main category: cs.CV

TL;DR: ORCANet addresses video restoration under Smoothly Evolving Unknown Degradations (SEUD) scenario using recurrent conditional adaptive prompting with coarse intensity estimation and flow-based prompts.


<details>
  <summary>Details</summary>
Motivation: Existing video restoration approaches focus on frame-wise degradation variation but overlook temporal continuity in real-world degradation processes, where degradation types and intensities evolve smoothly over time with possible coexistence or gradual transitions.

Method: Proposes ORCANet with: 1) Coarse Intensity Estimation Dehazing (CIED) module using physical priors for haze intensity estimation and coarse dehazed features; 2) Flow Prompt Generation (FPG) module extracting static prompts for segment-level degradation types and dynamic prompts for frame-level intensity variations; 3) Label-aware supervision for discriminative static prompt representations.

Result: Extensive experiments show ORCANet achieves superior restoration quality, temporal consistency, and robustness over image and video-based baselines.

Conclusion: ORCANet effectively addresses the SEUD scenario in video restoration through temporally-aware degradation modeling and adaptive prompting mechanisms, advancing all-in-one video restoration capabilities.

Abstract: All-in-one image restoration aims to recover clean images from diverse unknown degradations using a single model. But extending this task to videos faces unique challenges. Existing approaches primarily focus on frame-wise degradation variation, overlooking the temporal continuity that naturally exists in real-world degradation processes. In practice, degradation types and intensities evolve smoothly over time, and multiple degradations may coexist or transition gradually. In this paper, we introduce the Smoothly Evolving Unknown Degradations (SEUD) scenario, where both the active degradation set and degradation intensity change continuously over time. To support this scenario, we design a flexible synthesis pipeline that generates temporally coherent videos with single, compound, and evolving degradations. To address the challenges in the SEUD scenario, we propose an all-in-One Recurrent Conditional and Adaptive prompting Network (ORCANet). First, a Coarse Intensity Estimation Dehazing (CIED) module estimates haze intensity using physical priors and provides coarse dehazed features as initialization. Second, a Flow Prompt Generation (FPG) module extracts degradation features. FPG generates both static prompts that capture segment-level degradation types and dynamic prompts that adapt to frame-level intensity variations. Furthermore, a label-aware supervision mechanism improves the discriminability of static prompt representations under different degradations. Extensive experiments show that ORCANet achieves superior restoration quality, temporal consistency, and robustness over image and video-based baselines. Code is available at https://github.com/Friskknight/ORCANet-SEUD.

</details>


### [78] [FreeText: Training-Free Text Rendering in Diffusion Transformers via Attention Localization and Spectral Glyph Injection](https://arxiv.org/abs/2601.00535)
*Ruiqiang Zhang,Hengyi Wang,Chang Liu,Guanjie Wang,Zehua Ma,Weiming Zhang*

Main category: cs.CV

TL;DR: FreeText is a training-free framework that improves text rendering in diffusion models by localizing writing regions via attention mechanisms and injecting glyph priors with frequency modulation.


<details>
  <summary>Details</summary>
Motivation: Current text-to-image diffusion models struggle with precise text rendering, especially for complex layouts, dense typography, and non-Latin scripts like Chinese. Existing solutions require costly retraining or impose rigid constraints that degrade aesthetics and flexibility.

Method: FreeText decomposes text rendering into two parts: 1) "Where to write" - uses token-wise spatial attribution from image-to-text attention with sink-like tokens as anchors and topology-aware refinement to localize writing regions; 2) "What to write" - introduces Spectral-Modulated Glyph Injection (SGMI) that injects noise-aligned glyph priors with frequency-domain band-pass modulation to strengthen glyph structure while suppressing semantic leakage.

Result: Extensive experiments on Qwen-Image, FLUX.1-dev, and SD3 variants across multiple benchmarks (longText-Benchmark, CVTG, and CLT-Bench) show consistent improvements in text readability while largely preserving semantic alignment and aesthetic quality, with only modest inference overhead.

Conclusion: FreeText provides an effective, training-free solution for improving text rendering in diffusion models by leveraging intrinsic attention mechanisms and frequency-domain modulation, offering better flexibility and aesthetics compared to previous approaches.

Abstract: Large-scale text-to-image (T2I) diffusion models excel at open-domain synthesis but still struggle with precise text rendering, especially for multi-line layouts, dense typography, and long-tailed scripts such as Chinese. Prior solutions typically require costly retraining or rigid external layout constraints, which can degrade aesthetics and limit flexibility. We propose \textbf{FreeText}, a training-free, plug-and-play framework that improves text rendering by exploiting intrinsic mechanisms of \emph{Diffusion Transformer (DiT)} models. \textbf{FreeText} decomposes the problem into \emph{where to write} and \emph{what to write}. For \emph{where to write}, we localize writing regions by reading token-wise spatial attribution from endogenous image-to-text attention, using sink-like tokens as stable spatial anchors and topology-aware refinement to produce high-confidence masks. For \emph{what to write}, we introduce Spectral-Modulated Glyph Injection (SGMI), which injects a noise-aligned glyph prior with frequency-domain band-pass modulation to strengthen glyph structure and suppress semantic leakage (rendering the concept instead of the word). Extensive experiments on Qwen-Image, FLUX.1-dev, and SD3 variants across longText-Benchmark, CVTG, and our CLT-Bench show consistent gains in text readability while largely preserving semantic alignment and aesthetic quality, with modest inference overhead.

</details>


### [79] [Boosting Segment Anything Model to Generalize Visually Non-Salient Scenarios](https://arxiv.org/abs/2601.00537)
*Guangqian Guo,Pengfei Chen,Yong Guo,Huafeng Chen,Boqiang Zhang,Shan Gao*

Main category: cs.CV

TL;DR: VNS-SAM enhances SAM's segmentation performance in visually non-salient scenarios (low contrast foreground/background) while preserving zero-shot capabilities, using minimal parameter additions and a new dataset.


<details>
  <summary>Details</summary>
Motivation: SAM struggles with visually non-salient scenarios where foreground and background have low contrast, leading to inaccurate contours and poor segmentation results in these challenging cases.

Method: Proposes VNS-SAM with two key designs: 1) Mask-Edge Token Interactive decoder, and 2) Non-Salient Feature Mining module, which leverage SAM's low-level features to understand non-salient characteristics with minimal parameter/computational overhead. Also introduces VNS-SEG dataset with 35K+ images for training and evaluation.

Result: VNS-SAM achieves superior performance across various VNS segmentation tasks, especially in zero-shot settings, with additional parameters that can be optimized within 4 hours, demonstrating feasibility and practicality.

Conclusion: VNS-SAM effectively enhances SAM's perception of visually non-salient scenarios while maintaining zero-shot generalizability, offering broad real-world application potential with minimal computational cost.

Abstract: Segment Anything Model (SAM), known for its remarkable zero-shot segmentation capabilities, has garnered significant attention in the community. Nevertheless, its performance is challenged when dealing with what we refer to as visually non-salient scenarios, where there is low contrast between the foreground and background. In these cases, existing methods often cannot capture accurate contours and fail to produce promising segmentation results. In this paper, we propose Visually Non-Salient SAM (VNS-SAM), aiming to enhance SAM's perception of visually non-salient scenarios while preserving its original zero-shot generalizability. We achieve this by effectively exploiting SAM's low-level features through two designs: Mask-Edge Token Interactive decoder and Non-Salient Feature Mining module. These designs help the SAM decoder gain a deeper understanding of non-salient characteristics with only marginal parameter increments and computational requirements. The additional parameters of VNS-SAM can be optimized within 4 hours, demonstrating its feasibility and practicality. In terms of data, we established VNS-SEG, a unified dataset for various VNS scenarios, with more than 35K images, in contrast to previous single-task adaptations. It is designed to make the model learn more robust VNS features and comprehensively benchmark the model's segmentation performance and generalizability on VNS scenarios. Extensive experiments across various VNS segmentation tasks demonstrate the superior performance of VNS-SAM, particularly under zero-shot settings, highlighting its potential for broad real-world applications. Codes and datasets are publicly available at https://guangqian-guo.github.io/VNS-SAM.

</details>


### [80] [DynaDrag: Dynamic Drag-Style Image Editing by Motion Prediction](https://arxiv.org/abs/2601.00542)
*Jiacheng Sui,Yujie Zhou,Li Niu*

Main category: cs.CV

TL;DR: DynaDrag is a new drag-style image editing method using a predict-and-move framework to avoid tracking issues in previous move-and-track approaches.


<details>
  <summary>Details</summary>
Motivation: Previous drag-style image editing methods suffer from problems like miss tracking, ambiguous tracking, large gaps between source and target images, and unreasonable intermediate points that reduce editability.

Method: DynaDrag uses a predict-and-move framework with iterative Motion Prediction and Motion Supervision. Motion Prediction predicts where handle points should move, then Motion Supervision drags them accordingly. It also dynamically adjusts valid handle points.

Result: Experiments on face and human datasets demonstrate superiority over previous works in drag-style image editing.

Conclusion: DynaDrag successfully addresses limitations of previous drag-style editing methods by introducing a predict-and-move framework with iterative motion prediction and supervision.

Abstract: To achieve pixel-level image manipulation, drag-style image editing which edits images using points or trajectories as conditions is attracting widespread attention. Most previous methods follow move-and-track framework, in which miss tracking and ambiguous tracking are unavoidable challenging issues. Other methods under different frameworks suffer from various problems like the huge gap between source image and target edited image as well as unreasonable intermediate point which can lead to low editability. To avoid these problems, we propose DynaDrag, the first dragging method under predict-and-move framework. In DynaDrag, Motion Prediction and Motion Supervision are performed iteratively. In each iteration, Motion Prediction first predicts where the handle points should move, and then Motion Supervision drags them accordingly. We also propose to dynamically adjust the valid handle points to further improve the performance. Experiments on face and human datasets showcase the superiority over previous works.

</details>


### [81] [SingBAG Pro: Accelerating point cloud-based iterative reconstruction for 3D photoacoustic imaging under arbitrary array](https://arxiv.org/abs/2601.00551)
*Shuang Li,Yibing Wang,Jian Gao,Chulhong Kim,Seongwook Choi,Yu Zhang,Qian Chen,Yao Yao,Changhui Li*

Main category: cs.CV

TL;DR: SlingBAG Pro is an advanced 3D photoacoustic reconstruction algorithm that extends the original SlingBAG method to work with irregular transducer arrays, achieving faster reconstruction while maintaining quality.


<details>
  <summary>Details</summary>
Motivation: Irregular geometric transducer arrays are promising for high-quality 3D photoacoustic imaging with fewer transducers, but traditional iterative reconstruction algorithms struggle with irregular arrays due to high computational complexity, memory requirements, and long reconstruction times.

Method: SlingBAG Pro extends the point cloud iteration concept of the original SlingBAG method to arbitrary array geometries. It employs a hierarchical optimization strategy combining zero-gradient filtering with progressively increased temporal sampling rates during iteration to rapidly remove redundant spatial point clouds and accelerate convergence.

Result: SlingBAG Pro achieves up to 2.2-fold speed improvement compared to the original SlingBAG algorithm for point cloud-based 3D PA reconstruction under irregular array geometries. The method is validated through both simulation and in vivo mouse experiments.

Conclusion: SlingBAG Pro enables efficient 3D photoacoustic reconstruction with irregular transducer arrays, reducing computational complexity and reconstruction time while maintaining quality, making it suitable for clinical applications where space and cost constraints favor irregular array configurations.

Abstract: High-quality three-dimensional (3D) photoacoustic imaging (PAI) is gaining increasing attention in clinical applications. To address the challenges of limited space and high costs, irregular geometric transducer arrays that conform to specific imaging regions are promising for achieving high-quality 3D PAI with fewer transducers. However, traditional iterative reconstruction algorithms struggle with irregular array configurations, suffering from high computational complexity, substantial memory requirements, and lengthy reconstruction times. In this work, we introduce SlingBAG Pro, an advanced reconstruction algorithm based on the point cloud iteration concept of the Sliding ball adaptive growth (SlingBAG) method, while extending its compatibility to arbitrary array geometries. SlingBAG Pro maintains high reconstruction quality, reduces the number of required transducers, and employs a hierarchical optimization strategy that combines zero-gradient filtering with progressively increased temporal sampling rates during iteration. This strategy rapidly removes redundant spatial point clouds, accelerates convergence, and significantly shortens overall reconstruction time. Compared to the original SlingBAG algorithm, SlingBAG Pro achieves up to a 2.2-fold speed improvement in point cloud-based 3D PA reconstruction under irregular array geometries. The proposed method is validated through both simulation and in vivo mouse experiments, and the source code is publicly available at https://github.com/JaegerCQ/SlingBAG_Pro.

</details>


### [82] [A Comprehensive Dataset for Human vs. AI Generated Image Detection](https://arxiv.org/abs/2601.00553)
*Rajarshi Roy,Nasrin Imanpour,Ashhar Aziz,Shashwat Bajpai,Gurpreet Singh,Shwetangshu Biswas,Kapil Wanaskar,Parth Patwa,Subhankar Ghosh,Shreyas Dixit,Nilesh Ranjan Pal,Vipula Rawte,Ritvik Garimella,Gaytri Jena,Vasu Sharma,Vinija Jain,Aman Chadha,Aishwarya Naresh Reganti,Amitava Das*

Main category: cs.CV

TL;DR: MS COCOAI is a new dataset for AI-generated image detection with 96,000 real/synthetic images from 5 generators, enabling two tasks: real vs. generated classification and model attribution.


<details>
  <summary>Details</summary>
Motivation: Multimodal generative AI systems enable both innovation and the spread of misleading content. As generated images become harder to distinguish from photographs, detecting them has become an urgent priority.

Method: Created MS COCOAI dataset using MS COCO dataset as base, generating synthetic images with five generators: Stable Diffusion 3, Stable Diffusion 2.1, SDXL, DALL-E 3, and MidJourney v6. Dataset contains 96,000 real and synthetic datapoints.

Result: Released a novel dataset for AI generated image detection available at https://huggingface.co/datasets/Rajarshi-Roy-research/Defactify_Image_Dataset, enabling two tasks: (1) classifying images as real or generated, and (2) identifying which model produced a given synthetic image.

Conclusion: MS COCOAI provides a valuable resource for developing and evaluating AI-generated image detection methods to combat the spread of misleading synthetic content.

Abstract: Multimodal generative AI systems like Stable Diffusion, DALL-E, and MidJourney have fundamentally changed how synthetic images are created. These tools drive innovation but also enable the spread of misleading content, false information, and manipulated media. As generated images become harder to distinguish from photographs, detecting them has become an urgent priority. To combat this challenge, We release MS COCOAI, a novel dataset for AI generated image detection consisting of 96000 real and synthetic datapoints, built using the MS COCO dataset. To generate synthetic images, we use five generators: Stable Diffusion 3, Stable Diffusion 2.1, SDXL, DALL-E 3, and MidJourney v6. Based on the dataset, we propose two tasks: (1) classifying images as real or generated, and (2) identifying which model produced a given synthetic image. The dataset is available at https://huggingface.co/datasets/Rajarshi-Roy-research/Defactify_Image_Dataset.

</details>


### [83] [AEGIS: Exploring the Limit of World Knowledge Capabilities for Unified Mulitmodal Models](https://arxiv.org/abs/2601.00561)
*Jintao Lin,Bowen Dong,Weikang Shi,Chenyang Lei,Suiyun Zhang,Rui Liu,Xihui Liu*

Main category: cs.CV

TL;DR: AEGIS benchmark assesses UMMs' world knowledge across multiple tasks using deterministic evaluation, revealing significant knowledge deficits and reasoning vulnerabilities.


<details>
  <summary>Details</summary>
Motivation: Existing benchmarks for Unified Multimodal Models (UMMs) are limited to siloed, single-task evaluations with poor diagnostic power, failing to assess world knowledge application across diverse tasks.

Method: Proposed AEGIS benchmark with 1,050 manually-annotated questions across 21 topics and 6 reasoning types, plus Deterministic Checklist-based Evaluation (DCE) using atomic Y/N judgments for reliable scoring.

Result: Most UMMs show severe world knowledge deficits, with performance degrading significantly on complex reasoning tasks. Simple plug-in reasoning modules can partially mitigate these vulnerabilities.

Conclusion: World-knowledge-based reasoning is a critical frontier for UMMs, and AEGIS provides a comprehensive evaluation framework to address current limitations in multimodal model assessment.

Abstract: The capability of Unified Multimodal Models (UMMs) to apply world knowledge across diverse tasks remains a critical, unresolved challenge. Existing benchmarks fall short, offering only siloed, single-task evaluations with limited diagnostic power. To bridge this gap, we propose AEGIS (\emph{i.e.}, \textbf{A}ssessing \textbf{E}diting, \textbf{G}eneration, \textbf{I}nterpretation-Understanding for \textbf{S}uper-intelligence), a comprehensive multi-task benchmark covering visual understanding, generation, editing, and interleaved generation. AEGIS comprises 1,050 challenging, manually-annotated questions spanning 21 topics (including STEM, humanities, daily life, etc.) and 6 reasoning types. To concretely evaluate the performance of UMMs in world knowledge scope without ambiguous metrics, we further propose Deterministic Checklist-based Evaluation (DCE), a protocol that replaces ambiguous prompt-based scoring with atomic ``Y/N'' judgments, to enhance evaluation reliability. Our extensive experiments reveal that most UMMs exhibit severe world knowledge deficits and that performance degrades significantly with complex reasoning. Additionally, simple plug-in reasoning modules can partially mitigate these vulnerabilities, highlighting a promising direction for future research. These results highlight the importance of world-knowledge-based reasoning as a critical frontier for UMMs.

</details>


### [84] [A Cascaded Information Interaction Network for Precise Image Segmentation](https://arxiv.org/abs/2601.00562)
*Hewen Xiao,Jie Mei,Guangfu Ma,Weiren Wu*

Main category: cs.CV

TL;DR: Proposes a cascaded CNN with Global Information Guidance Module for robust image segmentation, outperforming SOTA methods especially in cluttered/blurred environments.


<details>
  <summary>Details</summary>
Motivation: Visual perception is crucial for autonomous behavior as a cost-effective alternative to multi-sensor systems, but robust segmentation remains challenging in complex scenarios.

Method: Cascaded convolutional neural network integrated with a novel Global Information Guidance Module that fuses low-level texture details with high-level semantic features across multiple layers.

Result: Achieves superior precision on benchmark image segmentation datasets, outperforming existing state-of-the-art methods, particularly in visually cluttered or blurred environments.

Conclusion: The approach is effective and shows promising potential for deployment in practical robotic applications due to enhanced segmentation accuracy in challenging environments.

Abstract: Visual perception plays a pivotal role in enabling autonomous behavior, offering a cost-effective and efficient alternative to complex multi-sensor systems. However, robust segmentation remains a challenge in complex scenarios. To address this, this paper proposes a cascaded convolutional neural network integrated with a novel Global Information Guidance Module. This module is designed to effectively fuse low-level texture details with high-level semantic features across multiple layers, thereby overcoming the inherent limitations of single-scale feature extraction. This architectural innovation significantly enhances segmentation accuracy, particularly in visually cluttered or blurred environments where traditional methods often fail. Experimental evaluations on benchmark image segmentation datasets demonstrate that the proposed framework achieves superior precision, outperforming existing state-of-the-art methods. The results highlight the effectiveness of the approach and its promising potential for deployment in practical robotic applications.

</details>


### [85] [GranAlign: Granularity-Aware Alignment Framework for Zero-Shot Video Moment Retrieval](https://arxiv.org/abs/2601.00584)
*Mingyu Jeon,Sunjae Yoon,Jonghee Kim,Junyeoung Kim*

Main category: cs.CV

TL;DR: GranAlign is a training-free framework for zero-shot video moment retrieval that addresses semantic granularity mismatch between text queries and video content through query rewriting and query-aware caption generation.


<details>
  <summary>Details</summary>
Motivation: Previous ZVMR approaches failed to balance semantic granularity between pre-trained video and language representations, leading to inaccurate retrieval despite high-quality individual modality representations.

Method: Proposes Granularity-Aware Alignment (GranAlign) with two techniques: 1) granularity-based query rewriting to generate varied semantic granularities, and 2) query-aware caption generation to embed query intent into video content.

Result: Sets new state-of-the-art across all three major benchmarks (QVHighlights, Charades-STA, ActivityNet-Captions), with 3.23% mAP@avg improvement on QVHighlights.

Conclusion: The training-free framework effectively resolves semantic granularity mismatches in zero-shot video moment retrieval by pairing multi-level queries with both query-agnostic and query-aware captions.

Abstract: Zero-shot video moment retrieval (ZVMR) is the task of localizing a temporal moment within an untrimmed video using a natural language query without relying on task-specific training data. The primary challenge in this setting lies in the mismatch in semantic granularity between textual queries and visual content. Previous studies in ZVMR have attempted to achieve alignment by leveraging high-quality pre-trained knowledge that represents video and language in a joint space. However, these approaches failed to balance the semantic granularity between the pre-trained knowledge provided by each modality for a given scene. As a result, despite the high quality of each modality's representations, the mismatch in granularity led to inaccurate retrieval. In this paper, we propose a training-free framework, called Granularity-Aware Alignment (GranAlign), that bridges this gap between coarse and fine semantic representations. Our approach introduces two complementary techniques: granularity-based query rewriting to generate varied semantic granularities, and query-aware caption generation to embed query intent into video content. By pairing multi-level queries with both query-agnostic and query-aware captions, we effectively resolve semantic mismatches. As a result, our method sets a new state-of-the-art across all three major benchmarks (QVHighlights, Charades-STA, ActivityNet-Captions), with a notable 3.23% mAP@avg improvement on the challenging QVHighlights dataset.

</details>


### [86] [SafeMo: Linguistically Grounded Unlearning for Trustworthy Text-to-Motion Generation](https://arxiv.org/abs/2601.00590)
*Yiling Wang,Zeyu Zhang,Yiran Wang,Hao Tang*

Main category: cs.CV

TL;DR: SafeMo: A trustworthy motion generation framework using Minimal Motion Unlearning (MMU) to generate safe human motions in continuous space, avoiding artifacts from discrete codebook methods while maintaining good performance on benign prompts.


<details>
  <summary>Details</summary>
Motivation: Existing text-to-motion generation methods have safety concerns, and current discrete codebook replacement approaches cause performance degradation on benign tasks and introduce artifacts due to quantization loss. Additionally, existing datasets contain unsafe content unsuitable for safety-focused learning.

Method: Proposes SafeMo framework with Minimal Motion Unlearning (MMU), a two-stage machine unlearning strategy that operates in continuous space to avoid codebook quantization loss. Also introduces SafeMoVAE-29K dataset with rewritten safe text prompts and refined motions for trustworthy unlearning.

Result: Achieves 2.5x and 14.4x higher forget-set FID on HumanML3D and Motion-X datasets respectively compared to previous SOTA method LCR, while maintaining comparable or better performance on safe prompts. Generates safe motions with natural transitions.

Conclusion: SafeMo provides an effective solution for trustworthy motion generation by addressing limitations of discrete codebook methods through continuous-space unlearning, achieving strong safety-utility trade-offs and setting new benchmarks for safe text-to-motion generation.

Abstract: Text-to-motion (T2M) generation with diffusion backbones achieves strong realism and alignment. Safety concerns in T2M methods have been raised in recent years; existing methods replace discrete VQ-VAE codebook entries to steer the model away from unsafe behaviors. However, discrete codebook replacement-based methods have two critical flaws: firstly, replacing codebook entries which are reused by benign prompts leads to drifts on everyday tasks, degrading the model's benign performance; secondly, discrete token-based methods introduce quantization and smoothness loss, resulting in artifacts and jerky transitions. Moreover, existing text-to-motion datasets naturally contain unsafe intents and corresponding motions, making them unsuitable for safety-driven machine learning. To address these challenges, we propose SafeMo, a trustworthy motion generative framework integrating Minimal Motion Unlearning (MMU), a two-stage machine unlearning strategy, enabling safe human motion generation in continuous space, preserving continuous kinematics without codebook loss and delivering strong safety-utility trade-offs compared to current baselines. Additionally, we present the first safe text-to-motion dataset SafeMoVAE-29K integrating rewritten safe text prompts and continuous refined motion for trustworthy human motion unlearning. Built upon DiP, SafeMo efficiently generates safe human motions with natural transitions. Experiments demonstrate effective unlearning performance of SafeMo by showing strengthened forgetting on unsafe prompts, reaching 2.5x and 14.4x higher forget-set FID on HumanML3D and Motion-X respectively, compared to the previous SOTA human motion unlearning method LCR, with benign performance on safe prompts being better or comparable. Code: https://github.com/AIGeeksGroup/SafeMo. Website: https://aigeeksgroup.github.io/SafeMo.

</details>


### [87] [Modality Dominance-Aware Optimization for Embodied RGB-Infrared Perception](https://arxiv.org/abs/2601.00598)
*Xianhui Liu,Siqi Jiang,Yi Xie,Yuqing Lin,Siao Liu*

Main category: cs.CV

TL;DR: The paper proposes MDACL framework to address optimization bias in RGB-IR multimodal fusion by quantifying modality dominance with MDI and balancing optimization through hierarchical guidance and adversarial regularization.


<details>
  <summary>Details</summary>
Motivation: RGB-IR multimodal perception is crucial for embodied systems, but asymmetric modality characteristics (differences in information density and feature quality) cause persistent optimization bias where training overemphasizes one dominant modality, hindering effective fusion.

Method: Proposes Modality Dominance Index (MDI) to quantify modality dominance by jointly modeling feature entropy and gradient contribution. Develops MDACL framework with Hierarchical Cross-modal Guidance (HCG) for feature alignment and Adversarial Equilibrium Regularization (AER) to balance optimization dynamics.

Result: Extensive experiments on three RGB-IR benchmarks demonstrate that MDACL effectively mitigates optimization bias and achieves state-of-the-art (SOTA) performance.

Conclusion: The proposed MDACL framework successfully addresses the optimization bias problem in RGB-IR multimodal fusion by quantifying modality dominance and regulating cross-modal optimization, leading to improved performance on standard benchmarks.

Abstract: RGB-Infrared (RGB-IR) multimodal perception is fundamental to embodied multimedia systems operating in complex physical environments. Although recent cross-modal fusion methods have advanced RGB-IR detection, the optimization dynamics caused by asymmetric modality characteristics remain underexplored. In practice, disparities in information density and feature quality introduce persistent optimization bias, leading training to overemphasize a dominant modality and hindering effective fusion. To quantify this phenomenon, we propose the Modality Dominance Index (MDI), which measures modality dominance by jointly modeling feature entropy and gradient contribution. Based on MDI, we develop a Modality Dominance-Aware Cross-modal Learning (MDACL) framework that regulates cross-modal optimization. MDACL incorporates Hierarchical Cross-modal Guidance (HCG) to enhance feature alignment and Adversarial Equilibrium Regularization (AER) to balance optimization dynamics during fusion. Extensive experiments on three RGB-IR benchmarks demonstrate that MDACL effectively mitigates optimization bias and achieves SOTA performance.

</details>


### [88] [Noise-Robust Tiny Object Localization with Flows](https://arxiv.org/abs/2601.00617)
*Huixin Sun,Linlin Yang,Ronyu Chen,Kerui Gu,Baochang Zhang,Angela Yao,Xianbin Cao*

Main category: cs.CV

TL;DR: TOLF is a noise-robust localization framework for tiny objects that uses normalizing flows for flexible error modeling and uncertainty-guided optimization to prevent overfitting to annotation noise.


<details>
  <summary>Details</summary>
Motivation: Tiny objects in object detection are highly sensitive to annotation noise, and optimizing strict localization objectives risks overfitting to this noise, creating a persistent performance gap compared to normal-scale objects.

Method: Proposes Tiny Object Localization with Flows (TOLF) with two key components: 1) flow-based error modeling using normalizing flows to capture complex, non-Gaussian prediction distributions, and 2) uncertainty-aware gradient modulation that suppresses learning from high-uncertainty, noise-prone samples.

Result: Extensive experiments across three datasets validate effectiveness. TOLF boosts the DINO baseline by 1.2% AP on the AI-TOD dataset, demonstrating improved performance for tiny object detection.

Conclusion: TOLF provides a robust solution for tiny object localization by addressing annotation noise sensitivity through flexible error modeling and uncertainty-guided optimization, bridging the performance gap between tiny and normal-scale objects.

Abstract: Despite significant advances in generic object detection, a persistent performance gap remains for tiny objects compared to normal-scale objects. We demonstrate that tiny objects are highly sensitive to annotation noise, where optimizing strict localization objectives risks noise overfitting. To address this, we propose Tiny Object Localization with Flows (TOLF), a noise-robust localization framework leveraging normalizing flows for flexible error modeling and uncertainty-guided optimization. Our method captures complex, non-Gaussian prediction distributions through flow-based error modeling, enabling robust learning under noisy supervision. An uncertainty-aware gradient modulation mechanism further suppresses learning from high-uncertainty, noise-prone samples, mitigating overfitting while stabilizing training. Extensive experiments across three datasets validate our approach's effectiveness. Especially, TOLF boosts the DINO baseline by 1.2% AP on the AI-TOD dataset.

</details>


### [89] [RePose: A Real-Time 3D Human Pose Estimation and Biomechanical Analysis Framework for Rehabilitation](https://arxiv.org/abs/2601.00625)
*Junxiao Xue,Pavel Smirnov,Ziao Li,Yunyun Shi,Shi Chen,Xinyi Yin,Xiaohan Yue,Lei Wang,Yiduo Wang,Feng Lin,Yijia Chen,Xiao Ma,Xiaoran Yan,Qing Zhang,Fengjian Xue,Xuecheng Wu*

Main category: cs.CV

TL;DR: RePose: A real-time 3D human pose estimation system for rehabilitation training that monitors patient movements, provides immediate feedback, and displays muscle stress conditions using multiple RGB cameras and Unity visualization.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address the need for real-time monitoring and evaluation in rehabilitation training, helping patients execute exercises correctly with immediate feedback to regain muscle strength and motor functions.

Method: 1) Unified end-to-end pipeline for real-time human pose estimation from multiple RGB cameras; 2) Fast tracking method for medical rehabilitation with multi-person interference (<1ms per frame); 3) Modified SmoothNet for real-time posture estimation to reduce errors and smooth motion; 4) Unity platform integration for real-time monitoring and muscle stress visualization.

Result: The system achieves real-time performance with sub-millisecond tracking, effectively reduces pose estimation errors, restores patients' true motion states, and provides visually smoother motion analysis for rehabilitation monitoring.

Conclusion: RePose provides an effective real-time solution for rehabilitation training that enables accurate motion monitoring, immediate feedback, and muscle stress visualization to assist patients in proper exercise execution and recovery.

Abstract: We propose a real-time 3D human pose estimation and motion analysis method termed RePose for rehabilitation training. It is capable of real-time monitoring and evaluation of patients'motion during rehabilitation, providing immediate feedback and guidance to assist patients in executing rehabilitation exercises correctly. Firstly, we introduce a unified pipeline for end-to-end real-time human pose estimation and motion analysis using RGB video input from multiple cameras which can be applied to the field of rehabilitation training. The pipeline can help to monitor and correct patients'actions, thus aiding them in regaining muscle strength and motor functions. Secondly, we propose a fast tracking method for medical rehabilitation scenarios with multiple-person interference, which requires less than 1ms for tracking for a single frame. Additionally, we modify SmoothNet for real-time posture estimation, effectively reducing pose estimation errors and restoring the patient's true motion state, making it visually smoother. Finally, we use Unity platform for real-time monitoring and evaluation of patients' motion during rehabilitation, and to display the muscle stress conditions to assist patients with their rehabilitation training.

</details>


### [90] [HyperPriv-EPN: Hypergraph Learning with Privileged Knowledge for Ependymoma Prognosis](https://arxiv.org/abs/2601.00626)
*Shuren Gabriel Yu,Sikang Ren,Yongji Tian*

Main category: cs.CV

TL;DR: HyperPriv-EPN: A hypergraph-based LUPI framework that transfers expert knowledge from post-operative surgical reports to pre-operative MRI analysis without requiring text during inference.


<details>
  <summary>Details</summary>
Motivation: Preoperative prognosis of Ependymoma is challenging due to lack of semantic insights in MRI compared to post-operative surgical reports. Existing multimodal methods fail when privileged text data is unavailable during inference.

Method: Hypergraph-based Learning Using Privileged Information (LUPI) framework with Severed Graph Strategy. Uses shared encoder for Teacher graph (with post-surgery info) and Student graph (pre-op only). Dual-stream distillation enables Student to hallucinate semantic community structures from visual features alone.

Result: Validated on multi-center cohort of 311 patients. Achieves state-of-the-art diagnostic accuracy and survival stratification. Effectively transfers expert knowledge to preoperative setting.

Conclusion: Unlocks value of historical post-operative data to guide diagnosis of new patients without requiring text at inference. Bridges gap between preoperative MRI analysis and post-operative expert knowledge.

Abstract: Preoperative prognosis of Ependymoma is critical for treatment planning but challenging due to the lack of semantic insights in MRI compared to post-operative surgical reports. Existing multimodal methods fail to leverage this privileged text data when it is unavailable during inference. To bridge this gap, we propose HyperPriv-EPN, a hypergraph-based Learning Using Privileged Information (LUPI) framework. We introduce a Severed Graph Strategy, utilizing a shared encoder to process both a Teacher graph (enriched with privileged post-surgery information) and a Student graph (restricted to pre-operation data). Through dual-stream distillation, the Student learns to hallucinate semantic community structures from visual features alone. Validated on a multi-center cohort of 311 patients, HyperPriv-EPN achieves state-of-the-art diagnostic accuracy and survival stratification. This effectively transfers expert knowledge to the preoperative setting, unlocking the value of historical post-operative data to guide the diagnosis of new patients without requiring text at inference.

</details>


### [91] [Quality Detection of Stored Potatoes via Transfer Learning: A CNN and Vision Transformer Approach](https://arxiv.org/abs/2601.00645)
*Shrikant Kapse,Priyankkumar Dhrangdhariya,Priya Kedia,Manasi Patwardhan,Shankar Kausley,Soumyadipta Maiti,Beena Rai,Shirish Karande*

Main category: cs.CV

TL;DR: Image-based deep learning models using pre-trained architectures (ResNet, VGG, DenseNet, ViT) effectively monitor potato quality during storage, achieving 98% accuracy for sprout detection and 89%+ accuracy for shelf-life prediction with coarse class divisions.


<details>
  <summary>Details</summary>
Motivation: To develop non-invasive, scalable solutions for monitoring potato quality during storage, addressing challenges in sprout detection, weight loss estimation, and shelf-life prediction to improve inventory management and reduce food waste.

Method: Collected images and weight data over 200 days under controlled conditions; used pre-trained architectures (ResNet, VGG, DenseNet, ViT) to design two specialized models: (1) binary classifier for sprout detection, (2) multi-class predictor for weight loss and shelf-life estimation.

Result: DenseNet achieved 98.03% accuracy in sprout detection. Shelf-life prediction performed best with coarse class divisions (2-5 classes, over 89.83% accuracy), while accuracy declined for finer divisions (6-8 classes) due to subtle visual differences and limited data.

Conclusion: Image-based models are feasible for automated sorting systems, enabling early sprout detection and dynamic categorization. Practical applications include improved inventory management and reduced waste. Future work should focus on generalized models for diverse potato varieties and conditions.

Abstract: Image-based deep learning provides a non-invasive, scalable solution for monitoring potato quality during storage, addressing key challenges such as sprout detection, weight loss estimation, and shelf-life prediction. In this study, images and corresponding weight data were collected over a 200-day period under controlled temperature and humidity conditions. Leveraging powerful pre-trained architectures of ResNet, VGG, DenseNet, and Vision Transformer (ViT), we designed two specialized models: (1) a high-precision binary classifier for sprout detection, and (2) an advanced multi-class predictor to estimate weight loss and forecast remaining shelf-life with remarkable accuracy. DenseNet achieved exceptional performance, with 98.03% accuracy in sprout detection. Shelf-life prediction models performed best with coarse class divisions (2-5 classes), achieving over 89.83% accuracy, while accuracy declined for finer divisions (6-8 classes) due to subtle visual differences and limited data per class. These findings demonstrate the feasibility of integrating image-based models into automated sorting and inventory systems, enabling early identification of sprouted potatoes and dynamic categorization based on storage stage. Practical implications include improved inventory management, differential pricing strategies, and reduced food waste across supply chains. While predicting exact shelf-life intervals remains challenging, focusing on broader class divisions ensures robust performance. Future research should aim to develop generalized models trained on diverse potato varieties and storage conditions to enhance adaptability and scalability. Overall, this approach offers a cost-effective, non-destructive method for quality assessment, supporting efficiency and sustainability in potato storage and distribution.

</details>


### [92] [Reconstructing Building Height from Spaceborne TomoSAR Point Clouds Using a Dual-Topology Network](https://arxiv.org/abs/2601.00658)
*Zhaiyu Chen,Yuanyuan Wang,Yilei Shi,Xiao Xiang Zhu*

Main category: cs.CV

TL;DR: Learning-based framework converts noisy TomoSAR point clouds into high-resolution building height maps using dual-topology network with point and grid branches.


<details>
  <summary>Details</summary>
Motivation: Spaceborne SAR tomography provides weather-independent urban observations but produces noisy, anisotropic point clouds with data voids that hinder accurate building height estimation.

Method: Dual-topology network alternates between point branch (models irregular scatterer features) and grid branch (enforces spatial consistency) to jointly denoise and inpaint missing regions.

Result: First proof of concept for large-scale urban height mapping directly from TomoSAR point clouds, validated on Munich and Berlin data, with extension to incorporate optical imagery for enhanced quality.

Conclusion: Proposed framework effectively converts raw TomoSAR points into continuous height maps, addressing noise and data void challenges, with potential for multi-modal enhancement using optical imagery.

Abstract: Reliable building height estimation is essential for various urban applications. Spaceborne SAR tomography (TomoSAR) provides weather-independent, side-looking observations that capture facade-level structure, offering a promising alternative to conventional optical methods. However, TomoSAR point clouds often suffer from noise, anisotropic point distributions, and data voids on incoherent surfaces, all of which hinder accurate height reconstruction. To address these challenges, we introduce a learning-based framework for converting raw TomoSAR points into high-resolution building height maps. Our dual-topology network alternates between a point branch that models irregular scatterer features and a grid branch that enforces spatial consistency. By jointly processing these representations, the network denoises the input points and inpaints missing regions to produce continuous height estimates. To our knowledge, this is the first proof of concept for large-scale urban height mapping directly from TomoSAR point clouds. Extensive experiments on data from Munich and Berlin validate the effectiveness of our approach. Moreover, we demonstrate that our framework can be extended to incorporate optical satellite imagery, further enhancing reconstruction quality. The source code is available at https://github.com/zhu-xlab/tomosar2height.

</details>


### [93] [CRoPS: A Training-Free Hallucination Mitigation Framework for Vision-Language Models](https://arxiv.org/abs/2601.00659)
*Neeraj Anand,Samyak Jha,Udbhav Bamba,Rahul Rahaman*

Main category: cs.CV

TL;DR: CRoPS is a training-free framework that mitigates hallucinations in Large Vision-Language Models by using Generalized Contrastive Decoding with multiple hallucinated models that selectively remove key text tokens.


<details>
  <summary>Details</summary>
Motivation: LVLMs suffer from hallucination issues that undermine reliability. Existing training-free methods have limitations: they rely on narrow assumptions about hallucination sources, and their effectiveness declines toward the end of generation where hallucinations are most likely to occur.

Method: Proposes CRoPS framework with two key innovations: 1) A novel hallucinated model that captures hallucination effects by selectively removing key text tokens (not just visual tokens), and 2) Generalized Contrastive Decoding that integrates multiple hallucinated models to represent diverse hallucination sources.

Result: Improves CHAIR scores by 20% and achieves consistent gains across six benchmarks and three LVLM families, outperforming state-of-the-art training-free methods.

Conclusion: CRoPS effectively addresses hallucination mitigation in LVLMs through a training-free approach that better captures diverse hallucination sources and maintains effectiveness throughout generation.

Abstract: Despite the rapid success of Large Vision-Language Models (LVLMs), a persistent challenge is their tendency to generate hallucinated content, undermining reliability in real-world use. Existing training-free methods address hallucinations but face two limitations: (i) they rely on narrow assumptions about hallucination sources, and (ii) their effectiveness declines toward the end of generation, where hallucinations are most likely to occur. A common strategy is to build hallucinated models by completely or partially removing visual tokens and contrasting them with the original model. Yet, this alone proves insufficient, since visual information still propagates into generated text. Building on this insight, we propose a novel hallucinated model that captures hallucination effects by selectively removing key text tokens. We further introduce Generalized Contrastive Decoding, which integrates multiple hallucinated models to represent diverse hallucination sources. Together, these ideas form CRoPS, a training-free hallucination mitigation framework that improves CHAIR scores by 20% and achieves consistent gains across six benchmarks and three LVLM families, outperforming state-of-the-art training-free methods.

</details>


### [94] [Pixel-to-4D: Camera-Controlled Image-to-Video Generation with Dynamic 3D Gaussians](https://arxiv.org/abs/2601.00678)
*Melonie de Almeida,Daniela Ivanova,Tong Shi,John H. Williamson,Paul Henderson*

Main category: cs.CV

TL;DR: A novel framework for single-image-to-video generation that uses 3D Gaussian scene representation to enable fast, camera-guided video generation with precise camera control and object motion in a single forward pass.


<details>
  <summary>Details</summary>
Motivation: Existing single-image-conditioned video generation methods lack robust user controllability (like camera path modification) and struggle with accurate camera motion modeling, temporal consistency, and geometric integrity. While 3D representation-based methods offer promise, current two-step approaches still fail to achieve full temporal consistency.

Method: Proposes a framework that constructs a 3D Gaussian scene representation from a single image and samples plausible object motion in a single forward pass, enabling fast camera-guided video generation without iterative denoising for object motion injection.

Result: Achieves state-of-the-art video quality and inference efficiency on KITTI, Waymo, RealEstate10K and DL3DV-10K datasets, demonstrating superior performance in camera-controlled video generation.

Conclusion: The proposed method enables fast, camera-guided video generation from single images with precise camera control and object motion, addressing limitations of existing approaches in temporal consistency and user controllability.

Abstract: Humans excel at forecasting the future dynamics of a scene given just a single image. Video generation models that can mimic this ability are an essential component for intelligent systems. Recent approaches have improved temporal coherence and 3D consistency in single-image-conditioned video generation. However, these methods often lack robust user controllability, such as modifying the camera path, limiting their applicability in real-world applications. Most existing camera-controlled image-to-video models struggle with accurately modeling camera motion, maintaining temporal consistency, and preserving geometric integrity. Leveraging explicit intermediate 3D representations offers a promising solution by enabling coherent video generation aligned with a given camera trajectory. Although these methods often use 3D point clouds to render scenes and introduce object motion in a later stage, this two-step process still falls short in achieving full temporal consistency, despite allowing precise control over camera movement. We propose a novel framework that constructs a 3D Gaussian scene representation and samples plausible object motion, given a single image in a single forward pass. This enables fast, camera-guided video generation without the need for iterative denoising to inject object motion into render frames. Extensive experiments on the KITTI, Waymo, RealEstate10K and DL3DV-10K datasets demonstrate that our method achieves state-of-the-art video quality and inference efficiency. The project page is available at https://melonienimasha.github.io/Pixel-to-4D-Website.

</details>


### [95] [Efficient Deep Demosaicing with Spatially Downsampled Isotropic Networks](https://arxiv.org/abs/2601.00703)
*Cory Fan,Wenchao Zhang*

Main category: cs.CV

TL;DR: Downsampling in isotropic networks improves efficiency and performance for image demosaicing and joint-demosaicing-and-denoising tasks, enabling better mobile deployment.


<details>
  <summary>Details</summary>
Motivation: Most deep learning demosaicing networks avoid spatial downsampling, making them computationally expensive for mobile applications. The paper challenges this design choice by claiming that downsampling can actually improve both efficiency and performance.

Method: Designed simple fully convolutional networks with and without downsampling using DeepMAD mathematical architecture design technique. Created a downsampled variant called JD3Net for empirical testing.

Result: Downsampling improves empirical performance. JD3Net demonstrates strong performance on various image demosaicing and joint-demosaicing-and-denoising tasks.

Conclusion: Contrary to conventional isotropic network designs, spatial downsampling significantly improves efficiency and performance for demosaicing networks, making them more suitable for mobile applications.

Abstract: In digital imaging, image demosaicing is a crucial first step which recovers the RGB information from a color filter array (CFA). Oftentimes, deep learning is utilized to perform image demosaicing. Given that most modern digital imaging applications occur on mobile platforms, applying deep learning to demosaicing requires lightweight and efficient networks. Isotropic networks, also known as residual-in-residual networks, have been often employed for image demosaicing and joint-demosaicing-and-denoising (JDD). Most demosaicing isotropic networks avoid spatial downsampling entirely, and thus are often prohibitively expensive computationally for mobile applications. Contrary to previous isotropic network designs, this paper claims that spatial downsampling to a signficant degree can improve the efficiency and performance of isotropic networks. To validate this claim, we design simple fully convolutional networks with and without downsampling using a mathematical architecture design technique adapted from DeepMAD, and find that downsampling improves empirical performance. Additionally, empirical testing of the downsampled variant, JD3Net, of our fully convolutional networks reveals strong empirical performance on a variety of image demosaicing and JDD tasks.

</details>


### [96] [RGS-SLAM: Robust Gaussian Splatting SLAM with One-Shot Dense Initialization](https://arxiv.org/abs/2601.00705)
*Wei-Tse Cheng,Yen-Jen Chiou,Yuan-Fu Yang*

Main category: cs.CV

TL;DR: RGS-SLAM replaces GS-SLAM's residual-driven densification with a training-free correspondence-to-Gaussian initialization using DINOv3 descriptors, achieving 20% faster convergence and higher rendering quality while maintaining real-time performance.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of GS-SLAM's progressive densification approach, which can be unstable and slow during early mapping stages, by providing a more robust initialization method that yields better-distributed Gaussian seeds from the start.

Method: Uses DINOv3 descriptors to establish dense multi-view correspondences, refines them through a confidence-aware inlier classifier, performs one-shot triangulation to generate Gaussian seeds, and optimizes using existing GS-SLAM pipelines.

Result: Achieves 20% faster convergence, higher rendering fidelity in texture-rich and cluttered scenes, competitive/superior localization and reconstruction accuracy on TUM RGB-D and Replica datasets, and sustains real-time mapping at up to 925 FPS.

Conclusion: RGS-SLAM demonstrates that replacing residual-driven densification with a robust correspondence-to-Gaussian initialization significantly improves SLAM performance while maintaining compatibility with existing Gaussian splatting frameworks.

Abstract: We introduce RGS-SLAM, a robust Gaussian-splatting SLAM framework that replaces the residual-driven densification stage of GS-SLAM with a training-free correspondence-to-Gaussian initialization. Instead of progressively adding Gaussians as residuals reveal missing geometry, RGS-SLAM performs a one-shot triangulation of dense multi-view correspondences derived from DINOv3 descriptors refined through a confidence-aware inlier classifier, generating a well-distributed and structure-aware Gaussian seed prior to optimization. This initialization stabilizes early mapping and accelerates convergence by roughly 20\%, yielding higher rendering fidelity in texture-rich and cluttered scenes while remaining fully compatible with existing GS-SLAM pipelines. Evaluated on the TUM RGB-D and Replica datasets, RGS-SLAM achieves competitive or superior localization and reconstruction accuracy compared with state-of-the-art Gaussian and point-based SLAM systems, sustaining real-time mapping performance at up to 925 FPS.

</details>


### [97] [Detecting Performance Degradation under Data Shift in Pathology Vision-Language Model](https://arxiv.org/abs/2601.00716)
*Hao Guan,Li Zhou*

Main category: cs.CV

TL;DR: This paper investigates performance degradation detection in pathology Vision-Language Models under data shift, developing DomainSAT toolbox for input shift analysis and proposing a confidence-based output indicator that complements input shift detection for more reliable monitoring.


<details>
  <summary>Details</summary>
Motivation: Vision-Language Models in medical imaging face performance degradation after deployment when input data distribution shifts, but detecting this degradation is challenging for large pre-trained VLMs operating without labeled data, which is essential for clinical reliability.

Method: The study examines both input-level data shift and output-level prediction behavior, develops DomainSAT (a lightweight toolbox with graphical interface integrating shift detection algorithms), and introduces a label-free, confidence-based degradation indicator that captures changes in model prediction confidence.

Result: Input data shift detection effectively identifies distributional changes but doesn't always correspond to actual performance degradation. The confidence-based indicator shows close relationship with performance degradation and serves as an effective complement to input shift detection. Combining both approaches enables more reliable detection and interpretation of performance degradation.

Conclusion: The findings provide a practical complementary framework for monitoring foundation model reliability in digital pathology, showing that combining input data shift detection with output confidence-based indicators offers more robust performance degradation detection under data shift.

Abstract: Vision-Language Models have demonstrated strong potential in medical image analysis and disease diagnosis. However, after deployment, their performance may deteriorate when the input data distribution shifts from that observed during development. Detecting such performance degradation is essential for clinical reliability, yet remains challenging for large pre-trained VLMs operating without labeled data. In this study, we investigate performance degradation detection under data shift in a state-of-the-art pathology VLM. We examine both input-level data shift and output-level prediction behavior to understand their respective roles in monitoring model reliability. To facilitate systematic analysis of input data shift, we develop DomainSAT, a lightweight toolbox with a graphical interface that integrates representative shift detection algorithms and enables intuitive exploration of data shift. Our analysis shows that while input data shift detection is effective at identifying distributional changes and providing early diagnostic signals, it does not always correspond to actual performance degradation. Motivated by this observation, we further study output-based monitoring and introduce a label-free, confidence-based degradation indicator that directly captures changes in model prediction confidence. We find that this indicator exhibits a close relationship with performance degradation and serves as an effective complement to input shift detection. Experiments on a large-scale pathology dataset for tumor classification demonstrate that combining input data shift detection and output confidence-based indicators enables more reliable detection and interpretation of performance degradation in VLMs under data shift. These findings provide a practical and complementary framework for monitoring the reliability of foundation models in digital pathology.

</details>


### [98] [Multi-Level Feature Fusion for Continual Learning in Visual Quality Inspection](https://arxiv.org/abs/2601.00725)
*Johannes C. Bauer,Paul Geng,Stephan Trattnig,Petr Dokládal,Rüdiger Daub*

Main category: cs.CV

TL;DR: MLFF approach uses multi-level feature fusion from pretrained networks for efficient continual learning in manufacturing quality inspection, reducing parameters and catastrophic forgetting while maintaining performance.


<details>
  <summary>Details</summary>
Motivation: Deep neural networks struggle in volatile manufacturing scenarios like remanufacturing where products and defects frequently change, requiring frequent model adaptation. Current approaches need to balance computational efficiency with avoiding catastrophic forgetting in continual learning settings.

Method: Multi-level feature fusion (MLFF) approach that utilizes representations from different depths of a pretrained network. This enables efficient adaptation by leveraging hierarchical features rather than full end-to-end retraining.

Result: MLFF matches end-to-end training performance for quality inspection problems while using significantly fewer trainable parameters. It reduces catastrophic forgetting and improves generalization robustness to new product types or defects.

Conclusion: The MLFF approach provides an effective solution for continual learning in manufacturing quality inspection, enabling efficient adaptation to changing conditions while maintaining performance and reducing forgetting effects.

Abstract: Deep neural networks show great potential for automating various visual quality inspection tasks in manufacturing. However, their applicability is limited in more volatile scenarios, such as remanufacturing, where the inspected products and defect patterns often change. In such settings, deployed models require frequent adaptation to novel conditions, effectively posing a continual learning problem. To enable quick adaptation, the necessary training processes must be computationally efficient while still avoiding effects like catastrophic forgetting. This work presents a multi-level feature fusion (MLFF) approach that aims to improve both aspects simultaneously by utilizing representations from different depths of a pretrained network. We show that our approach is able to match the performance of end-to-end training for different quality inspection problems while using significantly less trainable parameters. Furthermore, it reduces catastrophic forgetting and improves generalization robustness to new product types or defects.

</details>


### [99] [Grading Handwritten Engineering Exams with Multimodal Large Language Models](https://arxiv.org/abs/2601.00730)
*Janez Perš,Jon Muhovič,Andrej Košir,Boštjan Murovec*

Main category: cs.CV

TL;DR: An end-to-end workflow using multimodal LLMs to automatically grade handwritten STEM exams while preserving standard exam formats, achieving ≈8-point mean absolute difference to lecturer grades with low bias.


<details>
  <summary>Details</summary>
Motivation: Manual grading of handwritten STEM exams is slow and difficult to scale, despite capturing valuable open-ended reasoning and diagrams. There's a need for automated solutions that maintain the standard exam process while handling unconstrained student handwriting.

Method: Multimodal LLM-based workflow with: 1) handwritten reference solution converted to text-only summary for conditioning, 2) multi-stage design with format/presence checks, 3) ensemble of independent graders, 4) supervisor aggregation, and 5) rigid templates with deterministic validation for auditable reports.

Result: Using GPT-5.2 and Gemini-3 Pro backends, the pipeline achieves ≈8-point mean absolute difference to lecturer grades with low bias, ≈17% manual-review trigger rate at D_max=40. Ablations show structured prompting and reference grounding are essential.

Conclusion: The workflow successfully automates grading of handwritten engineering quizzes while preserving standard exam processes, demonstrating that structured prompting with reference grounding is crucial for accurate, reliable automated grading.

Abstract: Handwritten STEM exams capture open-ended reasoning and diagrams, but manual grading is slow and difficult to scale. We present an end-to-end workflow for grading scanned handwritten engineering quizzes with multimodal large language models (LLMs) that preserves the standard exam process (A4 paper, unconstrained student handwriting). The lecturer provides only a handwritten reference solution (100%) and a short set of grading rules; the reference is converted into a text-only summary that conditions grading without exposing the reference scan. Reliability is achieved through a multi-stage design with a format/presence check to prevent grading blank answers, an ensemble of independent graders, supervisor aggregation, and rigid templates with deterministic validation to produce auditable, machine-parseable reports. We evaluate the frozen pipeline in a clean-room protocol on a held-out real course quiz in Slovenian, including hand-drawn circuit schematics. With state-of-the-art backends (GPT-5.2 and Gemini-3 Pro), the full pipeline achieves $\approx$8-point mean absolute difference to lecturer grades with low bias and an estimated manual-review trigger rate of $\approx$17% at $D_{\max}=40$. Ablations show that trivial prompting and removing the reference solution substantially degrade accuracy and introduce systematic over-grading, confirming that structured prompting and reference grounding are essential.

</details>


### [100] [Unified Primitive Proxies for Structured Shape Completion](https://arxiv.org/abs/2601.00759)
*Zhaiyu Chen,Yuqing Wang,Xiao Xiang Zhu*

Main category: cs.CV

TL;DR: UniCo is a single-pass structured shape completion method that predicts assembly-ready primitives with complete geometry, semantics, and inlier membership, outperforming baselines by up to 50% in Chamfer distance.


<details>
  <summary>Details</summary>
Motivation: The paper aims to improve structured shape completion by rethinking how primitives and points should interact, moving away from the prevailing cascade approach to enable more effective primitive decoding that produces assembly-ready outputs.

Method: UniCo uses a dedicated pathway with primitive proxies (learnable queries) that attend to shared shape features to decode primitives in a single feed-forward pass. It employs a training strategy that couples primitives and points with online target updates for consistent optimization.

Result: UniCo consistently outperforms recent baselines across synthetic and real-world benchmarks with four independent assembly solvers, lowering Chamfer distance by up to 50% and improving normal consistency by up to 7%.

Conclusion: The approach establishes an attractive recipe for structured 3D understanding from incomplete data by unifying primitive prediction with complete geometry, semantics, and inlier membership in a single feed-forward pass.

Abstract: Structured shape completion recovers missing geometry as primitives rather than as unstructured points, which enables primitive-based surface reconstruction. Instead of following the prevailing cascade, we rethink how primitives and points should interact, and find it more effective to decode primitives in a dedicated pathway that attends to shared shape features. Following this principle, we present UniCo, which in a single feed-forward pass predicts a set of primitives with complete geometry, semantics, and inlier membership. To drive this unified representation, we introduce primitive proxies, learnable queries that are contextualized to produce assembly-ready outputs. To ensure consistent optimization, our training strategy couples primitives and points with online target updates. Across synthetic and real-world benchmarks with four independent assembly solvers, UniCo consistently outperforms recent baselines, lowering Chamfer distance by up to 50% and improving normal consistency by up to 7%. These results establish an attractive recipe for structured 3D understanding from incomplete data. Project page: https://unico-completion.github.io.

</details>


### [101] [Fusion-SSAT: Unleashing the Potential of Self-supervised Auxiliary Task by Feature Fusion for Generalized Deepfake Detection](https://arxiv.org/abs/2601.00789)
*Shukesh Reddy,Srijan Das,Abhijit Das*

Main category: cs.CV

TL;DR: Self-supervised learning as auxiliary task improves generalized deepfake detection performance and cross-dataset generalization.


<details>
  <summary>Details</summary>
Motivation: To enhance generalized deepfake detection by leveraging self-supervised learning as an auxiliary task to optimize the primary detection task.

Method: Examined different training scheme combinations for self-supervised auxiliary tasks and primary deepfake detection tasks, focusing on fusing feature representations from both tasks.

Result: Fused self-supervised features provide powerful representations that improve performance on DF40, FaceForensics++, Celeb-DF, DFD, FaceShifter, UADFV datasets, achieving better cross-dataset generalization than state-of-the-art detectors.

Conclusion: Self-supervised auxiliary tasks can effectively optimize generalized deepfake detection by providing unique feature representations that enhance performance and generalization across diverse datasets.

Abstract: In this work, we attempted to unleash the potential of self-supervised learning as an auxiliary task that can optimise the primary task of generalised deepfake detection. To explore this, we examined different combinations of the training schemes for these tasks that can be most effective. Our findings reveal that fusing the feature representation from self-supervised auxiliary tasks is a powerful feature representation for the problem at hand. Such a representation can leverage the ultimate potential and bring in a unique representation of both the self-supervised and primary tasks, achieving better performance for the primary task. We experimented on a large set of datasets, which includes DF40, FaceForensics++, Celeb-DF, DFD, FaceShifter, UADFV, and our results showed better generalizability on cross-dataset evaluation when compared with current state-of-the-art detectors.

</details>


### [102] [Two Deep Learning Approaches for Automated Segmentation of Left Ventricle in Cine Cardiac MRI](https://arxiv.org/abs/2601.00794)
*Wenhui Chu,Nikolaos V. Tsekos*

Main category: cs.CV

TL;DR: Proposed LNU-Net and IBU-Net architectures for left ventricle segmentation from MRI images, outperforming state-of-the-art methods in dice coefficient and distance metrics.


<details>
  <summary>Details</summary>
Motivation: Left ventricle segmentation is critical for clinical quantification and diagnosis of cardiac images, requiring accurate automated methods for medical image analysis.

Method: Two novel deep learning architectures: LNU-Net (layer normalization U-Net) applies layer normalization in each convolutional block, and IBU-Net (instance-batch normalized U-Net) incorporates instance and batch normalization together in the first block. Both use down-sampling for feature extraction and up-sampling for localization, with affine transformations and elastic deformations for data augmentation.

Result: The proposed approaches outperform other state-of-the-art methods in terms of dice coefficient and average perpendicular distance metrics on a dataset of 805 MRI images from 45 patients.

Conclusion: LNU-Net and IBU-Net architectures provide effective solutions for left ventricle segmentation from short-axis cine MRI images, demonstrating superior performance compared to existing methods for clinical cardiac image analysis.

Abstract: Left ventricle (LV) segmentation is critical for clinical quantification and diagnosis of cardiac images. In this work, we propose two novel deep learning architectures called LNU-Net and IBU-Net for left ventricle segmentation from short-axis cine MRI images. LNU-Net is derived from layer normalization (LN) U-Net architecture, while IBU-Net is derived from the instance-batch normalized (IB) U-Net for medical image segmentation. The architectures of LNU-Net and IBU-Net have a down-sampling path for feature extraction and an up-sampling path for precise localization. We use the original U-Net as the basic segmentation approach and compared it with our proposed architectures. Both LNU-Net and IBU-Net have left ventricle segmentation methods: LNU-Net applies layer normalization in each convolutional block, while IBU-Net incorporates instance and batch normalization together in the first convolutional block and passes its result to the next layer. Our method incorporates affine transformations and elastic deformations for image data processing. Our dataset that contains 805 MRI images regarding the left ventricle from 45 patients is used for evaluation. We experimentally evaluate the results of the proposed approaches outperforming the dice coefficient and the average perpendicular distance than other state-of-the-art approaches.

</details>


### [103] [AdaGaR: Adaptive Gabor Representation for Dynamic Scene Reconstruction](https://arxiv.org/abs/2601.00796)
*Jiewen Chan,Zhenjun Zhao,Yu-Lun Liu*

Main category: cs.CV

TL;DR: AdaGaR is a framework for dynamic 3D scene reconstruction from monocular videos that addresses frequency adaptivity and temporal continuity using adaptive Gabor representations and cubic Hermite splines with curvature regularization.


<details>
  <summary>Details</summary>
Motivation: Existing methods using single Gaussian primitives have low-pass filtering limitations, standard Gabor functions suffer from energy instability, and lack of temporal continuity constraints leads to motion artifacts during interpolation.

Method: Proposes Adaptive Gabor Representation with learnable frequency weights and adaptive energy compensation; uses Cubic Hermite Splines with Temporal Curvature Regularization for smooth motion; includes Adaptive Initialization combining depth estimation, point tracking, and foreground masks.

Result: Achieves state-of-the-art performance on Tap-Vid DAVIS (PSNR 35.49, SSIM 0.9433, LPIPS 0.0723) with strong generalization across frame interpolation, depth consistency, video editing, and stereo view synthesis.

Conclusion: AdaGaR provides a unified framework that effectively balances high-frequency detail capture with temporal continuity, enabling high-quality dynamic 3D scene reconstruction from monocular videos.

Abstract: Reconstructing dynamic 3D scenes from monocular videos requires simultaneously capturing high-frequency appearance details and temporally continuous motion. Existing methods using single Gaussian primitives are limited by their low-pass filtering nature, while standard Gabor functions introduce energy instability. Moreover, lack of temporal continuity constraints often leads to motion artifacts during interpolation. We propose AdaGaR, a unified framework addressing both frequency adaptivity and temporal continuity in explicit dynamic scene modeling. We introduce Adaptive Gabor Representation, extending Gaussians through learnable frequency weights and adaptive energy compensation to balance detail capture and stability. For temporal continuity, we employ Cubic Hermite Splines with Temporal Curvature Regularization to ensure smooth motion evolution. An Adaptive Initialization mechanism combining depth estimation, point tracking, and foreground masks establishes stable point cloud distributions in early training. Experiments on Tap-Vid DAVIS demonstrate state-of-the-art performance (PSNR 35.49, SSIM 0.9433, LPIPS 0.0723) and strong generalization across frame interpolation, depth consistency, video editing, and stereo view synthesis. Project page: https://jiewenchan.github.io/AdaGaR/

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [104] [Automated electrostatic characterization of quantum dot devices in single- and bilayer heterostructures](https://arxiv.org/abs/2601.00067)
*Merritt P. R. Losert,Dario Denora,Barnaby van Straaten,Michael Chan,Stefan D. Oosterhout,Lucas Stehouwer,Giordano Scappucci,Menno Veldhorst,Justyna P. Zwolak*

Main category: cond-mat.mes-hall

TL;DR: Automated protocol using ML and image processing to extract capacitive properties from quantum dot charge stability diagrams, enabling rapid device characterization without manual labeling.


<details>
  <summary>Details</summary>
Motivation: As quantum dot spin qubits scale to larger architectures, manual interpretation of charge stability diagrams becomes time-consuming, error-prone, and impractical. Automated tools are needed for rapid device characterization.

Method: Integrates machine learning, image processing, and object detection to automatically identify and track charge transitions in charge stability diagrams without manual labeling. Demonstrated on strained-germanium single-quantum-well (planar) and double-quantum-well (bilayer) QD devices.

Result: Successfully extracts capacitive properties from experimental data, including relative lever arms and capacitive couplings. Bilayer germanium devices with more complex transitions (interlayer tunneling, distinct loading lines) serve as powerful testbed for automation methods.

Conclusion: The automated protocol enables rapid extraction of useful, nontrivial information about QD devices, addressing scalability challenges in quantum dot spin qubit characterization.

Abstract: As quantum dot (QD)-based spin qubits advance toward larger, more complex device architectures, rapid, automated device characterization and data analysis tools become critical. The orientation and spacing of transition lines in a charge stability diagram (CSD) contain a fingerprint of a QD device's capacitive environment, making these measurements useful tools for device characterization. However, manually interpreting these features is time-consuming, error-prone, and impractical at scale. Here, we present an automated protocol for extracting underlying capacitive properties from CSDs. Our method integrates machine learning, image processing, and object detection to identify and track charge transitions across large datasets without manual labeling. We demonstrate this method using experimentally measured data from a strained-germanium single-quantum-well (planar) and a strained-germanium double-quantum-well (bilayer) QD device. Unlike for planar QD devices, CSDs in bilayer germanium heterostructure exhibit a larger set of transitions, including interlayer tunneling and distinct loading lines for the vertically stacked QDs, making them a powerful testbed for automation methods. By analyzing the properties of many CSDs, we can statistically estimate physically relevant quantities, like relative lever arms and capacitive couplings. Thus, our protocol enables rapid extraction of useful, nontrivial information about QD devices.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [105] [A Chain-of-Thought Approach to Semantic Query Categorization in e-Commerce Taxonomies](https://arxiv.org/abs/2601.00510)
*Jetlir Duraj,Ishita Khan,Kilian Merkelbach,Mehran Elyasi*

Main category: cs.IR

TL;DR: The paper proposes a Chain-of-Thought approach combining tree-search with LLM semantic scoring for query categorization in e-commerce taxonomies, outperforming embedding-based methods and enabling taxonomy problem detection.


<details>
  <summary>Details</summary>
Motivation: Accurate query categorization in e-commerce taxonomies is crucial for search relevance and inventory navigation, but existing methods need improvement for practical applications.

Method: Novel Chain-of-Thought paradigm that combines simple tree-search with LLM semantic scoring for hierarchical query categorization.

Result: CoT approach performs better than embedding-based query category predictions on human-judged pairs and relevance tests, and can detect problems within hierarchical taxonomies.

Conclusion: The CoT approach provides effective query categorization and taxonomy validation, with scalable LLM-based alternatives proposed for handling millions of queries.

Abstract: Search in e-Commerce is powered at the core by a structured representation of the inventory, often formulated as a category taxonomy. An important capability in e-Commerce with hierarchical taxonomies is to select a set of relevant leaf categories that are semantically aligned with a given user query. In this scope, we address a fundamental problem of search query categorization in real-world e-Commerce taxonomies. A correct categorization of a query not only provides a way to zoom into the correct inventory space, but opens the door to multiple intent understanding capabilities for a query. A practical and accurate solution to this problem has many applications in e-commerce, including constraining retrieved items and improving the relevance of the search results. For this task, we explore a novel Chain-of-Thought (CoT) paradigm that combines simple tree-search with LLM semantic scoring. Assessing its classification performance on human-judged query-category pairs, relevance tests, and LLM-based reference methods, we find that the CoT approach performs better than a benchmark that uses embedding-based query category predictions. We show how the CoT approach can detect problems within a hierarchical taxonomy. Finally, we also propose LLM-based approaches for query-categorization of the same spirit, but which scale better at the range of millions of queries.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [106] [DefVINS: Visual-Inertial Odometry for Deformable Scenes](https://arxiv.org/abs/2601.00702)
*Samuel Cerezo,Javier Civera*

Main category: cs.RO

TL;DR: DefVINS: A VIO framework that separates rigid IMU-anchored state from non-rigid deformation using embedded deformation graphs, with observability-aware activation of non-rigid degrees of freedom.


<details>
  <summary>Details</summary>
Motivation: Classical VIO assumes rigidity, which fails in deformable scenes causing over-fitting to local non-rigid motion or severe drift when deformation dominates visual parallax.

Method: Separates rigid IMU-anchored state from non-rigid warp represented by embedded deformation graph. Uses standard VIO initialization, then progressively activates non-rigid degrees of freedom as estimation becomes well-conditioned. Includes observability analysis and conditioning-based activation strategy.

Result: Ablation studies show benefits of combining inertial constraints with observability-aware deformation activation, resulting in improved robustness under non-rigid environments.

Conclusion: DefVINS successfully addresses VIO challenges in deformable scenes through explicit separation of rigid and non-rigid components with observability-aware activation strategies.

Abstract: Deformable scenes violate the rigidity assumptions underpinning classical visual-inertial odometry (VIO), often leading to over-fitting to local non-rigid motion or severe drift when deformation dominates visual parallax. We introduce DefVINS, a visual-inertial odometry framework that explicitly separates a rigid, IMU-anchored state from a non--rigid warp represented by an embedded deformation graph. The system is initialized using a standard VIO procedure that fixes gravity, velocity, and IMU biases, after which non-rigid degrees of freedom are activated progressively as the estimation becomes well conditioned. An observability analysis is included to characterize how inertial measurements constrain the rigid motion and render otherwise unobservable modes identifiable in the presence of deformation. This analysis motivates the use of IMU anchoring and informs a conditioning-based activation strategy that prevents ill-posed updates under poor excitation. Ablation studies demonstrate the benefits of combining inertial constraints with observability-aware deformation activation, resulting in improved robustness under non-rigid environments.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [107] [Next Generation Intelligent Low-Altitude Economy Deployments: The O-RAN Perspective](https://arxiv.org/abs/2601.00257)
*Aly Sabri Abdalla,Vuk Marojevic*

Main category: eess.SY

TL;DR: O-RAN-enabled framework for low-altitude economy applications using AI-driven orchestration of UAV swarms in complex environments.


<details>
  <summary>Details</summary>
Motivation: Current LAE applications face challenges in real-time, resilient orchestration of aerial nodes in signal-constrained environments with limited AI integration for mission-specific needs.

Method: Proposes O-RAN-enabled LAE framework leveraging disaggregated RAN architecture, open interfaces, and RAN intelligent controllers (RICs) for closed-loop AI-optimized operations. Uses semantic-aware rApp as terrain interpreter and reinforcement learning-enabled xApp for real-time trajectory planning.

Result: Evaluates feasibility and performance of proposed architecture through semantic-aware rApp and RL-based xApp for LAE swarm trajectory planning. Surveys UAV testbed capabilities for LAE research.

Conclusion: Presents critical research challenges and standardization needs for O-RAN-enabled LAE frameworks, highlighting the importance of AI-driven orchestration for mission-critical low-altitude operations.

Abstract: Despite the growing interest in low-altitude economy (LAE) applications, including UAV-based logistics and emergency response, fundamental challenges remain in orchestrating such missions over complex, signal-constrained environments. These include the absence of real-time, resilient, and context-aware orchestration of aerial nodes with limited integration of artificial intelligence (AI) specialized for LAE missions. This paper introduces an open radio access network (O-RAN)-enabled LAE framework that leverages seamless coordination between the disaggregated RAN architecture, open interfaces, and RAN intelligent controllers (RICs) to facilitate closed-loop, AI-optimized, and mission-critical LAE operations. We evaluate the feasibility and performance of the proposed architecture via a semantic-aware rApp that acts as a terrain interpreter, offering semantic guidance to a reinforcement learning-enabled xApp, which performs real-time trajectory planning for LAE swarm nodes. We survey the capabilities of UAV testbeds that can be leveraged for LAE research, and present critical research challenges and standardization needs.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [108] [Neural Brain Fields: A NeRF-Inspired Approach for Generating Nonexistent EEG Electrodes](https://arxiv.org/abs/2601.00012)
*Shahar Ain Kedem,Itamar Zimerman,Eliya Nachmani*

Main category: eess.SP

TL;DR: A NeRF-inspired method for EEG processing that trains a neural network on single EEG samples to create fixed-size weight vectors encoding entire signals, enabling continuous visualization, reconstruction, and simulation of electrode data.


<details>
  <summary>Details</summary>
Motivation: EEG data presents unique challenges: variable length recordings, low signal-to-noise ratios, inter-participant variability, temporal drift, and limited clean datasets. Current deep learning methods struggle to effectively process EEG signals, creating an important open research problem.

Method: Inspired by Neural Radiance Fields (NeRF), the method draws an analogy between NeRF's discrete images from different viewpoints and EEG electrodes at different scalp locations. A neural network is trained on a single EEG sample in a NeRF-style manner to produce a fixed-size weight vector that encodes the entire signal, enabling rendering of EEG signals at unseen time steps and spatial electrode positions.

Result: The approach enables continuous visualization of brain activity at any desired resolution (including ultra-high resolution), reconstruction of raw EEG signals, and effective simulation of nonexistent electrode data in EEG recordings. The reconstructed signals can be fed into standard EEG processing networks to improve performance.

Conclusion: This NeRF-inspired method provides a novel approach to EEG processing that addresses key challenges in the field, offering continuous representation, reconstruction capabilities, and data augmentation through electrode simulation, potentially improving downstream EEG analysis tasks.

Abstract: Electroencephalography (EEG) data present unique modeling challenges because recordings vary in length, exhibit very low signal to noise ratios, differ significantly across participants, drift over time within sessions, and are rarely available in large and clean datasets. Consequently, developing deep learning methods that can effectively process EEG signals remains an open and important research problem. To tackle this problem, this work presents a new method inspired by Neural Radiance Fields (NeRF). In computer vision, NeRF techniques train a neural network to memorize the appearance of a 3D scene and then uses its learned parameters to render and edit the scene from any viewpoint. We draw an analogy between the discrete images captured from different viewpoints used to learn a continuous 3D scene in NeRF, and EEG electrodes positioned at different locations on the scalp, which are used to infer the underlying representation of continuous neural activity. Building on this connection, we show that a neural network can be trained on a single EEG sample in a NeRF style manner to produce a fixed size and informative weight vector that encodes the entire signal. Moreover, via this representation we can render the EEG signal at previously unseen time steps and spatial electrode positions. We demonstrate that this approach enables continuous visualization of brain activity at any desired resolution, including ultra high resolution, and reconstruction of raw EEG signals. Finally, our empirical analysis shows that this method can effectively simulate nonexistent electrodes data in EEG recordings, allowing the reconstructed signal to be fed into standard EEG processing networks to improve performance.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [109] [Learning Speech Representations with Variational Predictive Coding](https://arxiv.org/abs/2601.00100)
*Sung-Lin Yeh,Peter Bell,Hao Tang*

Main category: eess.AS

TL;DR: The paper reveals that predictive coding under a variational view is the underlying principle behind HuBERT's success, enabling improvements to parameterization and optimization that boost performance on multiple speech tasks.


<details>
  <summary>Details</summary>
Motivation: Despite HuBERT being the best known objective for learning speech representations, its development has stalled due to lack of an underlying principle. The authors aim to identify this principle to enable further improvements.

Method: The paper shows that predictive coding under a variational view is the principle behind HuBERT. This formulation allows for improvements in parameterization and optimization, leading to two simple modifications that enhance the HuBERT objective.

Result: The improved pre-training brings significant performance gains on four downstream tasks: phone classification, f0 tracking, speaker recognition, and automatic speech recognition.

Conclusion: The predictive coding interpretation provides a unifying framework for HuBERT and connects it to other objectives (APC, CPC, wav2vec, BEST-RQ), highlighting its importance for advancing speech representation learning.

Abstract: Despite being the best known objective for learning speech representations, the HuBERT objective has not been further developed and improved. We argue that it is the lack of an underlying principle that stalls the development, and, in this paper, we show that predictive coding under a variational view is the principle behind the HuBERT objective. Due to its generality, our formulation provides opportunities to improve parameterization and optimization, and we show two simple modifications that bring immediate improvements to the HuBERT objective. In addition, the predictive coding formulation has tight connections to various other objectives, such as APC, CPC, wav2vec, and BEST-RQ. Empirically, the improvement in pre-training brings significant improvements to four downstream tasks: phone classification, f0 tracking, speaker recognition, and automatic speech recognition, highlighting the importance of the predictive coding interpretation.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [110] [The Trojan in the Vocabulary: Stealthy Sabotage of LLM Composition](https://arxiv.org/abs/2601.00065)
*Xiaoze Liu,Weichen Yu,Matt Fredrikson,Xiaoqian Wang,Jing Gao*

Main category: cs.LG

TL;DR: Researchers demonstrate a "breaker token" attack where a single malicious token inserted into a donor model remains inert in that model but becomes highly destructive when transplanted into a base model, exploiting tokenizer alignment vulnerabilities in modular AI composition.


<details>
  <summary>Details</summary>
Motivation: As the open-weight LLM ecosystem increasingly relies on model composition techniques (weight merging, speculative decoding, vocabulary expansion), tokenizer transplant becomes essential for interoperability. However, this critical step introduces a supply-chain vulnerability that can be exploited to sabotage composed models.

Method: The attack engineers a single "breaker token" that appears functionally inert in a donor model but reliably reconstructs into a high-salience malicious feature after transplant. This exploits the geometry of coefficient reuse to create an asymmetric realizability gap. The attack is formalized as a dual-objective optimization problem and instantiated using a sparse solver, achieving training-free spectral mimicry to evade outlier detection.

Result: The attack successfully sabotages the base model's generation while leaving the donor model's utility statistically indistinguishable from nominal behavior. The malicious token demonstrates structural persistence against fine-tuning and weight merging, highlighting a hidden risk in modular AI composition pipelines.

Conclusion: Tokenizer transplant, while essential for model interoperability, introduces a supply-chain vulnerability that can be exploited through carefully engineered "breaker tokens." This attack reveals hidden risks in the pipeline of modular AI composition that persist despite standard safety measures like fine-tuning and weight merging.

Abstract: The open-weight LLM ecosystem is increasingly defined by model composition techniques (such as weight merging, speculative decoding, and vocabulary expansion) that remix capabilities from diverse sources. A critical prerequisite for applying these methods across different model families is tokenizer transplant, which aligns incompatible vocabularies to a shared embedding space. We demonstrate that this essential interoperability step introduces a supply-chain vulnerability: we engineer a single "breaker token" that is functionally inert in a donor model yet reliably reconstructs into a high-salience malicious feature after transplant into a base model. By exploiting the geometry of coefficient reuse, our attack creates an asymmetric realizability gap that sabotages the base model's generation while leaving the donor's utility statistically indistinguishable from nominal behavior. We formalize this as a dual-objective optimization problem and instantiate the attack using a sparse solver. Empirically, the attack is training-free and achieves spectral mimicry to evade outlier detection, while demonstrating structural persistence against fine-tuning and weight merging, highlighting a hidden risk in the pipeline of modular AI composition. Code is available at https://github.com/xz-liu/tokenforge

</details>


### [111] [Deep Delta Learning](https://arxiv.org/abs/2601.00417)
*Yifan Zhang,Yifeng Liu,Mengdi Wang,Quanquan Gu*

Main category: cs.LG

TL;DR: Deep Delta Learning (DDL) replaces standard additive residual connections with learnable geometric transformations that dynamically modulate identity shortcuts, enabling more complex state transitions while maintaining stable training.


<details>
  <summary>Details</summary>
Motivation: Standard residual networks use strictly additive identity shortcuts, which impose a limited inductive bias that restricts the network's ability to model complex state transitions and non-monotonic dynamics.

Method: Introduces Delta Operator - a rank-1 perturbation of the identity matrix parameterized by a reflection direction vector and gating scalar. This modulates the identity shortcut with data-dependent geometric transformations, enabling dynamic interpolation between identity mapping, orthogonal projection, and geometric reflection.

Result: The method provides explicit control over layer-wise transition operator spectrum, allowing modeling of complex non-monotonic dynamics while preserving stable training characteristics of gated residual architectures through synchronous rank-1 injection.

Conclusion: DDL generalizes residual connections beyond additive bias, enabling more expressive feature transformations while maintaining training stability, offering a principled approach to modeling complex state transitions in deep networks.

Abstract: The efficacy of deep residual networks is fundamentally predicated on the identity shortcut connection. While this mechanism effectively mitigates the vanishing gradient problem, it imposes a strictly additive inductive bias on feature transformations, thereby limiting the network's capacity to model complex state transitions. In this paper, we introduce Deep Delta Learning (DDL), a novel architecture that generalizes the standard residual connection by modulating the identity shortcut with a learnable, data-dependent geometric transformation. This transformation, termed the Delta Operator, constitutes a rank-1 perturbation of the identity matrix, parameterized by a reflection direction vector $\mathbf{k}(\mathbf{X})$ and a gating scalar $β(\mathbf{X})$. We provide a spectral analysis of this operator, demonstrating that the gate $β(\mathbf{X})$ enables dynamic interpolation between identity mapping, orthogonal projection, and geometric reflection. Furthermore, we restructure the residual update as a synchronous rank-1 injection, where the gate acts as a dynamic step size governing both the erasure of old information and the writing of new features. This unification empowers the network to explicitly control the spectrum of its layer-wise transition operator, enabling the modeling of complex, non-monotonic dynamics while preserving the stable training characteristics of gated residual architectures.

</details>


### [112] [TeleDoCTR: Domain-Specific and Contextual Troubleshooting for Telecommunications](https://arxiv.org/abs/2601.00691)
*Mohamed Trabelsi,Huseyin Uzunalioglu*

Main category: cs.LG

TL;DR: TeleDoCTR is a telecom-specific troubleshooting system that automates ticket classification, retrieval of similar historical tickets, and generation of fault analysis reports to improve efficiency in telecom ticket resolution.


<details>
  <summary>Details</summary>
Motivation: Telecom troubleshooting is highly complex and time-consuming due to diverse tickets, specialized domain knowledge requirements, and the need for experts to manually interpret content, consult documentation, and search historical records, which delays issue resolution and reduces operational efficiency.

Method: TeleDoCTR integrates domain-specific ranking and generative models to automate three key troubleshooting steps: 1) routing tickets to appropriate expert teams (classification), 2) retrieving contextually and semantically similar historical tickets (retrieval), and 3) generating detailed fault analysis reports with issue description, root cause, and potential solutions (generation).

Result: The system was evaluated on real-world telecom infrastructure data and demonstrated superior performance over existing state-of-the-art methods, significantly enhancing both accuracy and efficiency of the troubleshooting process.

Conclusion: TeleDoCTR effectively addresses the challenges of telecom ticket troubleshooting by automating key workflow steps, reducing human-intensive efforts, and improving overall operational efficiency through domain-specific contextual modeling.

Abstract: Ticket troubleshooting refers to the process of analyzing and resolving problems that are reported through a ticketing system. In large organizations offering a wide range of services, this task is highly complex due to the diversity of submitted tickets and the need for specialized domain knowledge. In particular, troubleshooting in telecommunications (telecom) is a very time-consuming task as it requires experts to interpret ticket content, consult documentation, and search historical records to identify appropriate resolutions. This human-intensive approach not only delays issue resolution but also hinders overall operational efficiency. To enhance the effectiveness and efficiency of ticket troubleshooting in telecom, we propose TeleDoCTR, a novel telecom-related, domain-specific, and contextual troubleshooting system tailored for end-to-end ticket resolution in telecom. TeleDoCTR integrates both domain-specific ranking and generative models to automate key steps of the troubleshooting workflow which are: routing tickets to the appropriate expert team responsible for resolving the ticket (classification task), retrieving contextually and semantically similar historical tickets (retrieval task), and generating a detailed fault analysis report outlining the issue, root cause, and potential solutions (generation task). We evaluate TeleDoCTR on a real-world dataset from a telecom infrastructure and demonstrate that it achieves superior performance over existing state-of-the-art methods, significantly enhancing the accuracy and efficiency of the troubleshooting process.

</details>


### [113] [Memory Bank Compression for Continual Adaptation of Large Language Models](https://arxiv.org/abs/2601.00756)
*Thomas Katraouras,Dimitrios Rafailidis*

Main category: cs.LG

TL;DR: MBC proposes a memory compression method for LLM continual learning that reduces memory bank size to 0.3% of baselines while maintaining accuracy through codebook optimization and online resetting mechanisms.


<details>
  <summary>Details</summary>
Motivation: LLMs need continual learning to stay updated with evolving data, but current memory-augmented approaches suffer from constantly growing memory banks in real-world scenarios with large-scale data streams.

Method: MBC compresses memory bank via codebook optimization strategy during online adaptation learning, uses online resetting mechanism to prevent codebook collapse, and employs Key-Value Low-Rank Adaptation in attention layers for efficient memory utilization.

Result: Experiments show MBC reduces memory bank size to 0.3% compared to most competitive baseline while maintaining high retention accuracy during online adaptation learning.

Conclusion: MBC provides an efficient solution for continual learning in LLMs by addressing the memory growth problem through compression techniques while preserving knowledge retention capabilities.

Abstract: Large Language Models (LLMs) have become a mainstay for many everyday applications. However, as data evolve their knowledge quickly becomes outdated. Continual learning aims to update LLMs with new information without erasing previously acquired knowledge. Although methods such as full fine-tuning can incorporate new data, they are computationally expensive and prone to catastrophic forgetting, where prior knowledge is overwritten. Memory-augmented approaches address this by equipping LLMs with a memory bank, that is an external memory module which stores information for future use. However, these methods face a critical limitation, in particular, the memory bank constantly grows in the real-world scenario when large-scale data streams arrive. In this paper, we propose MBC, a model that compresses the memory bank through a codebook optimization strategy during online adaptation learning. To ensure stable learning, we also introduce an online resetting mechanism that prevents codebook collapse. In addition, we employ Key-Value Low-Rank Adaptation in the attention layers of the LLM, enabling efficient utilization of the compressed memory representations. Experiments with benchmark question-answering datasets demonstrate that MBC reduces the memory bank size to 0.3% when compared against the most competitive baseline, while maintaining high retention accuracy during online adaptation learning. Our code is publicly available at https://github.com/Thomkat/MBC.

</details>


### [114] [Geometry of Reason: Spectral Signatures of Valid Mathematical Reasoning](https://arxiv.org/abs/2601.00791)
*Valentin Noël*

Main category: cs.LG

TL;DR: Training-free method using spectral analysis of attention patterns to detect valid mathematical reasoning in LLMs, achieving 85-96% accuracy across multiple models without any training.


<details>
  <summary>Details</summary>
Motivation: Need for reliable methods to verify mathematical reasoning in LLMs without requiring training data or fine-tuning, addressing hallucination detection and AI safety monitoring.

Method: Treat attention matrices as adjacency matrices of dynamic graphs over tokens, extract four spectral diagnostics: Fiedler value (algebraic connectivity), high-frequency energy ratio (HFER), graph signal smoothness, and spectral entropy.

Result: Method achieves effect sizes up to Cohen's d=3.30 (p<10^-116), 85.0-95.6% classification accuracy across 7 transformer models from 4 architectural families, with calibrated thresholds reaching 93-95% accuracy.

Conclusion: Spectral graph analysis provides principled framework for reasoning verification, detects logical coherence rather than compiler acceptance, and reveals architectural dependencies in attention mechanisms.

Abstract: We present a training-free method for detecting valid mathematical reasoning in large language models through spectral analysis of attention patterns. By treating attention matrices as adjacency matrices of dynamic graphs over tokens, we extract four interpretable spectral diagnostics, the Fiedler value (algebraic connectivity), high-frequency energy ratio (HFER), graph signal smoothness, and spectral entropy, that exhibit statistically significant differences between valid and invalid mathematical proofs. Experiments across seven transformer models from four independent architectural families (Meta Llama, Alibaba Qwen, Microsoft Phi, and Mistral AI) demonstrate that this spectral signature produces effect sizes up to Cohen's $d = 3.30$ ($p < 10^{-116}$), enabling 85.0--95.6\% classification accuracy under rigorous evaluation, with calibrated thresholds reaching 93--95\% on the full dataset. The method requires no training data, fine-tuning, or learned classifiers: a single threshold on a spectral metric suffices for high accuracy. Through systematic label correction, we discover that the spectral method detects logical coherence rather than compiler acceptance, identifying mathematically valid proofs that formal verifiers reject due to technical failures. We further identify an architectural dependency: Mistral-7B's Sliding Window Attention shifts the discriminative signal from HFER to late-layer Smoothness ($d = 2.09$, $p_{\text{MW}} = 1.16 \times 10^{-48}$), revealing that attention mechanism design affects which spectral features capture reasoning validity. These findings establish spectral graph analysis as a principled framework for reasoning verification with immediate applications to hallucination detection and AI safety monitoring.

</details>


### [115] [Optimized Hybrid Feature Engineering for Resource-Efficient Arrhythmia Detection in ECG Signals: An Optimization Framework](https://arxiv.org/abs/2601.00192)
*Moirangthem Tiken Singh,Manibhushan Yaikhom*

Main category: cs.LG

TL;DR: Proposes a resource-efficient data-centric framework for arrhythmia detection on edge devices using hybrid wavelet-graph features and ultra-lightweight linear classifiers.


<details>
  <summary>Details</summary>
Motivation: Cardiovascular diseases require continuous monitoring via IoMT, but current deep learning approaches have prohibitive computational overhead for resource-constrained edge devices.

Method: Integrates time-frequency wavelet decompositions with graph-theoretic structural descriptors (PageRank centrality), refines features using mutual information and recursive elimination, and uses interpretable linear classifiers.

Result: Achieves 98.44% diagnostic accuracy with 8.54 KB model footprint, 0.46 μs classification latency within 52 ms per-beat pipeline, outperforming compressed models like KD-Light (25 KB, 96.32% accuracy).

Conclusion: The framework provides order-of-magnitude efficiency gains over existing approaches, enabling real-time arrhythmia detection on battery-less cardiac sensors.

Abstract: Cardiovascular diseases, particularly arrhythmias, remain a leading global cause of mortality, necessitating continuous monitoring via the Internet of Medical Things (IoMT). However, state-of-the-art deep learning approaches often impose prohibitive computational overheads, rendering them unsuitable for resource-constrained edge devices. This study proposes a resource-efficient, data-centric framework that prioritizes feature engineering over complexity. Our optimized pipeline makes the complex, high-dimensional arrhythmia data linearly separable. This is achieved by integrating time-frequency wavelet decompositions with graph-theoretic structural descriptors, such as PageRank centrality. This hybrid feature space, combining wavelet decompositions and graph-theoretic descriptors, is then refined using mutual information and recursive elimination, enabling interpretable, ultra-lightweight linear classifiers. Validation on the MIT-BIH and INCART datasets yields 98.44% diagnostic accuracy with an 8.54 KB model footprint. The system achieves 0.46 $μ$s classification inference latency within a 52 ms per-beat pipeline, ensuring real-time operation. These outcomes provide an order-of-magnitude efficiency gain over compressed models, such as KD-Light (25 KB, 96.32% accuracy), advancing battery-less cardiac sensors.

</details>


### [116] [E-GRPO: High Entropy Steps Drive Effective Reinforcement Learning for Flow Models](https://arxiv.org/abs/2601.00423)
*Shengjun Zhang,Zhang Zhang,Chensheng Dai,Yueqi Duan*

Main category: cs.LG

TL;DR: E-GRPO: Entropy-aware Group Relative Policy Optimization for flow matching models that increases entropy of SDE sampling steps by merging consecutive low-entropy steps into high-entropy steps, using multi-step group normalized advantages.


<details>
  <summary>Details</summary>
Motivation: Existing methods for human preference alignment in flow matching models suffer from sparse and ambiguous reward signals when optimizing over multiple denoising steps. High entropy steps enable more efficient exploration while low entropy steps result in undistinguished roll-outs.

Method: Proposes E-GRPO which merges consecutive low entropy steps into one high entropy step for SDE sampling, while applying ODE sampling on other steps. Introduces multi-step group normalized advantage that computes group-relative advantages within samples sharing the same consolidated SDE denoising step.

Result: Experimental results on different reward settings demonstrate the effectiveness of the proposed methods.

Conclusion: E-GRPO addresses the sparse reward problem in flow matching models by entropy-aware step consolidation and group-relative advantage computation, improving exploration efficiency in human preference alignment.

Abstract: Recent reinforcement learning has enhanced the flow matching models on human preference alignment. While stochastic sampling enables the exploration of denoising directions, existing methods which optimize over multiple denoising steps suffer from sparse and ambiguous reward signals. We observe that the high entropy steps enable more efficient and effective exploration while the low entropy steps result in undistinguished roll-outs. To this end, we propose E-GRPO, an entropy aware Group Relative Policy Optimization to increase the entropy of SDE sampling steps. Since the integration of stochastic differential equations suffer from ambiguous reward signals due to stochasticity from multiple steps, we specifically merge consecutive low entropy steps to formulate one high entropy step for SDE sampling, while applying ODE sampling on other steps. Building upon this, we introduce multi-step group normalized advantage, which computes group-relative advantages within samples sharing the same consolidated SDE denoising step. Experimental results on different reward settings have demonstrated the effectiveness of our methods.

</details>


### [117] [Avatar Forcing: Real-Time Interactive Head Avatar Generation for Natural Conversation](https://arxiv.org/abs/2601.00664)
*Taekyung Ki,Sangwon Jang,Jaehyeong Jo,Jaehong Yoon,Sung Ju Hwang*

Main category: cs.LG

TL;DR: Avatar Forcing enables real-time interactive talking head avatars using diffusion forcing and preference optimization for expressive reactions without labeled data.


<details>
  <summary>Details</summary>
Motivation: Current talking head generation models lack true interactivity and emotional engagement, producing one-way responses rather than real-time interactive communication. The paper aims to create avatars that can respond instantly to both verbal and non-verbal cues like speech, nods, and laughter.

Method: Proposes Avatar Forcing framework using diffusion forcing to model real-time user-avatar interactions with low latency. Introduces direct preference optimization method that uses synthetic losing samples created by dropping user conditions, enabling label-free learning of expressive interactions.

Result: Achieves real-time interaction with low latency (~500ms), 6.8X speedup compared to baseline, and produces reactive/expressive avatar motion preferred over 80% against baseline.

Conclusion: Avatar Forcing successfully addresses key challenges in interactive avatar generation by enabling real-time processing of multimodal inputs and label-free learning of expressive reactions, creating more engaging virtual communication experiences.

Abstract: Talking head generation creates lifelike avatars from static portraits for virtual communication and content creation. However, current models do not yet convey the feeling of truly interactive communication, often generating one-way responses that lack emotional engagement. We identify two key challenges toward truly interactive avatars: generating motion in real-time under causal constraints and learning expressive, vibrant reactions without additional labeled data. To address these challenges, we propose Avatar Forcing, a new framework for interactive head avatar generation that models real-time user-avatar interactions through diffusion forcing. This design allows the avatar to process real-time multimodal inputs, including the user's audio and motion, with low latency for instant reactions to both verbal and non-verbal cues such as speech, nods, and laughter. Furthermore, we introduce a direct preference optimization method that leverages synthetic losing samples constructed by dropping user conditions, enabling label-free learning of expressive interaction. Experimental results demonstrate that our framework enables real-time interaction with low latency (approximately 500ms), achieving 6.8X speedup compared to the baseline, and produces reactive and expressive avatar motion, which is preferred over 80% against the baseline.

</details>


### [118] [FedHypeVAE: Federated Learning with Hypernetwork Generated Conditional VAEs for Differentially Private Embedding Sharing](https://arxiv.org/abs/2601.00785)
*Sunny Gupta,Amit Sethi*

Main category: cs.LG

TL;DR: FedHypeVAE: A differentially private, hypernetwork-driven framework for synthesizing embedding-level data in federated learning, addressing non-IID client heterogeneity while providing formal privacy guarantees against gradient leakage.


<details>
  <summary>Details</summary>
Motivation: Existing federated data sharing methods struggle with non-IID client heterogeneity and offer limited formal protection against gradient leakage. There's a need for a framework that can synthesize embedding-level data across decentralized clients while ensuring privacy and handling distributional differences.

Method: Uses a conditional VAE backbone with client-aware decoders and class-conditional priors generated by a shared hypernetwork from private, trainable client codes. The hypernetwork is optimized under differential privacy with noise-perturbed, clipped gradients. Includes local MMD alignment between real/synthetic embeddings and Lipschitz regularization on hypernetwork outputs for stability under non-IID conditions.

Result: FedHypeVAE enables domain-agnostic synthesis using neutral meta-codes and controllable multi-domain coverage through mixtures of meta-codes. It unifies personalization, privacy, and distribution alignment at the generator level for privacy-preserving data synthesis in federated settings.

Conclusion: FedHypeVAE establishes a principled foundation for privacy-preserving data synthesis in federated learning by addressing key challenges of non-IID heterogeneity and gradient leakage through a differentially private hypernetwork architecture with personalized generative capabilities.

Abstract: Federated data sharing promises utility without centralizing raw data, yet existing embedding-level generators struggle under non-IID client heterogeneity and provide limited formal protection against gradient leakage. We propose FedHypeVAE, a differentially private, hypernetwork-driven framework for synthesizing embedding-level data across decentralized clients. Building on a conditional VAE backbone, we replace the single global decoder and fixed latent prior with client-aware decoders and class-conditional priors generated by a shared hypernetwork from private, trainable client codes. This bi-level design personalizes the generative layerrather than the downstream modelwhile decoupling local data from communicated parameters. The shared hypernetwork is optimized under differential privacy, ensuring that only noise-perturbed, clipped gradients are aggregated across clients. A local MMD alignment between real and synthetic embeddings and a Lipschitz regularizer on hypernetwork outputs further enhance stability and distributional coherence under non-IID conditions. After training, a neutral meta-code enables domain agnostic synthesis, while mixtures of meta-codes provide controllable multi-domain coverage. FedHypeVAE unifies personalization, privacy, and distribution alignment at the generator level, establishing a principled foundation for privacy-preserving data synthesis in federated settings. Code: github.com/sunnyinAI/FedHypeVAE

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [119] [Deep Learning Approach for the Diagnosis of Pediatric Pneumonia Using Chest X-ray Imaging](https://arxiv.org/abs/2601.00041)
*Fatemeh Hosseinabadi,Mohammad Mojtaba Rohani*

Main category: eess.IV

TL;DR: Deep learning models (ResNetRS, RegNet, EfficientNetV2) applied to pediatric pneumonia detection from chest X-rays, with RegNet achieving best performance at 92.4% accuracy.


<details>
  <summary>Details</summary>
Motivation: Pediatric pneumonia is a major global health issue with high morbidity and mortality. Accurate diagnosis is challenging due to limited radiological expertise and the complexity of pediatric imaging, creating a need for automated diagnostic tools.

Method: Used transfer learning with three CNN architectures (ResNetRS, RegNet, EfficientNetV2) pretrained on ImageNet. Fine-tuned models on a curated subset of 1,000 pediatric chest X-ray images from a larger public dataset (5,856 images). Images were preprocessed and labeled for binary classification (pneumonia vs normal).

Result: RegNet performed best with 92.4% accuracy and 90.1% sensitivity. ResNetRS achieved 91.9% accuracy and 89.3% sensitivity. EfficientNetV2 showed 88.5% accuracy and 88.1% sensitivity.

Conclusion: CNN-based transfer learning is effective for automated pediatric pneumonia detection from chest X-rays. RegNet demonstrated superior performance, suggesting potential for clinical application to assist in timely diagnosis where radiological expertise is limited.

Abstract: Pediatric pneumonia remains a leading cause of morbidity and mortality in children worldwide. Timely and accurate diagnosis is critical but often challenged by limited radiological expertise and the physiological and procedural complexity of pediatric imaging. This study investigates the performance of state-of-the-art convolutional neural network (CNN) architectures ResNetRS, RegNet, and EfficientNetV2 using transfer learning for the automated classification of pediatric chest Xray images as either pneumonia or normal.A curated subset of 1,000 chest X-ray images was extracted from a publicly available dataset originally comprising 5,856 pediatric images. All images were preprocessed and labeled for binary classification. Each model was fine-tuned using pretrained ImageNet weights and evaluated based on accuracy and sensitivity. RegNet achieved the highest classification performance with an accuracy of 92.4 and a sensitivity of 90.1, followed by ResNetRS (accuracy: 91.9, sensitivity: 89.3) and EfficientNetV2 (accuracy: 88.5, sensitivity: 88.1).

</details>


### [120] [The Impact of Lesion Focus on the Performance of AI-Based Melanoma Classification](https://arxiv.org/abs/2601.00355)
*Tanay Donde*

Main category: eess.IV

TL;DR: Models with better lesion attention alignment achieve higher diagnostic performance in melanoma classification, suggesting interpretable AI can improve medical diagnostics.


<details>
  <summary>Details</summary>
Motivation: Melanoma is deadly but early detection improves outcomes. Current CNN models for melanoma classification suffer from inconsistent focus on lesion areas, reducing diagnostic reliability.

Method: Used multiple explainability and sensitivity analysis approaches to study lesion attention. Analyzed masked images, bounding box detection, and transfer learning to investigate attention alignment with lesion areas.

Result: Models with higher focus on lesion areas achieved better diagnostic performance (precision, recall, F1-score). Attention alignment correlated with improved classification metrics.

Conclusion: Interpretable AI has potential in medical diagnostics. Study provides foundation for developing more accurate and trustworthy melanoma classification models through better attention alignment.

Abstract: Melanoma is the most lethal subtype of skin cancer, and early and accurate detection of this disease can greatly improve patients' outcomes. Although machine learning models, especially convolutional neural networks (CNNs), have shown great potential in automating melanoma classification, their diagnostic reliability still suffers due to inconsistent focus on lesion areas. In this study, we analyze the relationship between lesion attention and diagnostic performance, involving masked images, bounding box detection, and transfer learning. We used multiple explainability and sensitivity analysis approaches to investigate how well models aligned their attention with lesion areas and how this alignment correlated with precision, recall, and F1-score. Results showed that models with a higher focus on lesion areas achieved better diagnostic performance, suggesting the potential of interpretable AI in medical diagnostics. This study provides a foundation for developing more accurate and trustworthy melanoma classification models in the future.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [121] [Overlooked Safety Vulnerability in LLMs: Malicious Intelligent Optimization Algorithm Request and its Jailbreak](https://arxiv.org/abs/2601.00213)
*Haoran Gu,Handing Wang,Yi Mei,Mengjie Zhang,Yaochu Jin*

Main category: cs.CR

TL;DR: LLMs are highly vulnerable to malicious algorithm design attacks, with 83.59% average attack success rate and near-complete failure against specialized jailbreak methods, highlighting critical safety gaps in automated algorithm generation.


<details>
  <summary>Details</summary>
Motivation: While LLM safety has been studied for general usage, code generation, and agent applications, vulnerabilities in automated algorithm design remain underexplored, particularly for optimization algorithms used in complex decision-making scenarios where misuse could have serious consequences.

Method: Created MalOptBench (60 malicious optimization algorithm requests) and developed MOBjailbreak, a specialized jailbreak method for algorithm design. Evaluated 13 mainstream LLMs including GPT-5 and DeepSeek-V3.1, and tested state-of-the-art plug-and-play defenses.

Result: Most LLMs are highly susceptible: 83.59% average attack success rate, 4.28/5 harmfulness score on original prompts, and near-complete failure under MOBjailbreak. Existing defenses are only marginally effective and prone to exaggerated safety behaviors.

Conclusion: There is an urgent need for stronger alignment techniques to safeguard LLMs against misuse in algorithm design, as current models and defenses are inadequate for this specific safety vulnerability.

Abstract: The widespread deployment of large language models (LLMs) has raised growing concerns about their misuse risks and associated safety issues. While prior studies have examined the safety of LLMs in general usage, code generation, and agent-based applications, their vulnerabilities in automated algorithm design remain underexplored. To fill this gap, this study investigates this overlooked safety vulnerability, with a particular focus on intelligent optimization algorithm design, given its prevalent use in complex decision-making scenarios. We introduce MalOptBench, a benchmark consisting of 60 malicious optimization algorithm requests, and propose MOBjailbreak, a jailbreak method tailored for this scenario. Through extensive evaluation of 13 mainstream LLMs including the latest GPT-5 and DeepSeek-V3.1, we reveal that most models remain highly susceptible to such attacks, with an average attack success rate of 83.59% and an average harmfulness score of 4.28 out of 5 on original harmful prompts, and near-complete failure under MOBjailbreak. Furthermore, we assess state-of-the-art plug-and-play defenses that can be applied to closed-source models, and find that they are only marginally effective against MOBjailbreak and prone to exaggerated safety behaviors. These findings highlight the urgent need for stronger alignment techniques to safeguard LLMs against misuse in algorithm design.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [122] [Investigating the Viability of Employing Multi-modal Large Language Models in the Context of Audio Deepfake Detection](https://arxiv.org/abs/2601.00777)
*Akanksha Chuchra,Shukesh Reddy,Sudeepta Mishra,Abhijit Das,Abhinav Dhall*

Main category: cs.SD

TL;DR: MLLMs show potential for audio deepfake detection when combining audio inputs with multi-prompt text queries, but require task-specific training and struggle with out-of-domain generalization.


<details>
  <summary>Details</summary>
Motivation: While VLMs and MLLMs have shown strong performance for image/video deepfake detection, their application to audio deepfake detection remains largely unexplored, creating a research gap to investigate multimodal approaches for audio authenticity verification.

Method: Combines audio inputs with text prompts (text-aware, context-rich, question-answer based with binary decisions) to enable feature-guided reasoning. Evaluates two MLLMs (Qwen2-Audio-7B-Instruct and SALMONN) in zero-shot and fine-tuned modes using multi-prompt approach.

Result: Models perform poorly without task-specific training and struggle to generalize to out-of-domain data. However, they achieve good performance on in-domain data with minimal supervision, showing promising potential for audio deepfake detection when combining audio with multi-prompt approach.

Conclusion: Combining audio inputs with multi-prompt text queries represents a viable approach for audio deepfake detection using MLLMs, though task-specific training is necessary and out-of-domain generalization remains a challenge.

Abstract: While Vision-Language Models (VLMs) and Multimodal Large Language Models (MLLMs) have shown strong generalisation in detecting image and video deepfakes, their use for audio deepfake detection remains largely unexplored. In this work, we aim to explore the potential of MLLMs for audio deepfake detection. Combining audio inputs with a range of text prompts as queries to find out the viability of MLLMs to learn robust representations across modalities for audio deepfake detection. Therefore, we attempt to explore text-aware and context-rich, question-answer based prompts with binary decisions. We hypothesise that such a feature-guided reasoning will help in facilitating deeper multimodal understanding and enable robust feature learning for audio deepfake detection. We evaluate the performance of two MLLMs, Qwen2-Audio-7B-Instruct and SALMONN, in two evaluation modes: (a) zero-shot and (b) fine-tuned. Our experiments demonstrate that combining audio with a multi-prompt approach could be a viable way forward for audio deepfake detection. Our experiments show that the models perform poorly without task-specific training and struggle to generalise to out-of-domain data. However, they achieve good performance on in-domain data with minimal supervision, indicating promising potential for audio deepfake detection.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [123] [StockBot 2.0: Vanilla LSTMs Outperform Transformer-based Forecasting for Stock Prices](https://arxiv.org/abs/2601.00197)
*Shaswat Mohanty*

Main category: cs.CE

TL;DR: Enhanced StockBot architecture shows vanilla LSTM outperforms attention-based and transformer models for financial forecasting, highlighting recurrent models' robustness in data-limited scenarios.


<details>
  <summary>Details</summary>
Motivation: Financial market forecasting is challenging due to complex temporal dependencies, non-linear dynamics, and high volatility. The paper aims to systematically evaluate modern time-series forecasting models to determine which architecture performs best for stock prediction tasks.

Method: The researchers present an enhanced StockBot architecture that systematically evaluates attention-based, convolutional, and recurrent time-series forecasting models within a unified experimental setting. They compare these modern approaches against their earlier recurrent neural network framework, using a common set of default hyperparameters for fair comparison.

Result: Despite the flexibility of attention-based and transformer-inspired models, a carefully constructed vanilla LSTM consistently achieves superior predictive accuracy and more stable buy/sell decision-making. The LSTM demonstrates better performance when trained under common default hyperparameters without extensive tuning.

Conclusion: Recurrent sequence models (particularly LSTM) show robustness and data efficiency for financial time-series forecasting, especially in data-limited scenarios with single-day discretization. The results emphasize the importance of architectural inductive bias over model complexity when data is limited.

Abstract: Accurate forecasting of financial markets remains a long-standing challenge due to complex temporal and often latent dependencies, non-linear dynamics, and high volatility. Building on our earlier recurrent neural network framework, we present an enhanced StockBot architecture that systematically evaluates modern attention-based, convolutional, and recurrent time-series forecasting models within a unified experimental setting. While attention-based and transformer-inspired models offer increased modeling flexibility, extensive empirical evaluation reveals that a carefully constructed vanilla LSTM consistently achieves superior predictive accuracy and more stable buy/sell decision-making when trained under a common set of default hyperparameters. These results highlight the robustness and data efficiency of recurrent sequence models for financial time-series forecasting, particularly in the absence of extensive hyperparameter tuning or the availability of sufficient data when discretized to single-day intervals. Additionally, these results underscore the importance of architectural inductive bias in data-limited market prediction tasks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [124] [Reasoning in Action: MCTS-Driven Knowledge Retrieval for Large Language Models](https://arxiv.org/abs/2601.00003)
*Shuqi Liu,Bowei He,Chen Ma,Linqi Song*

Main category: cs.AI

TL;DR: A reasoning-aware knowledge retrieval method for LLMs that uses coarse-to-fine retrieval with Monte Carlo Tree Search to find knowledge aligned with conversation logic rather than just semantic similarity.


<details>
  <summary>Details</summary>
Motivation: LLMs typically improve performance through either retrieval of similar information or reasoning enhancement, but struggle to effectively integrate both strategies. Current retrieval methods focus on surface-level semantic similarity rather than alignment with the logical structure of conversations.

Method: Two-phase coarse-to-fine approach: 1) Identify contextually relevant sub-region of knowledge base where all sentences relate to the topic, 2) Refine search within sub-region to extract knowledge specifically relevant to reasoning process. Uses Monte Carlo Tree Search-inspired method to navigate knowledge sentences using common keywords.

Result: Experiments on two multi-turn dialogue datasets show the approach aligns more closely with human conversation reasoning, significantly enhances diversity of retrieved knowledge, and produces more informative and creative responses.

Conclusion: The reasoning-aware knowledge retrieval method effectively integrates retrieval and reasoning strategies, moving beyond semantic similarity to capture logical conversation structure, resulting in improved LLM performance in multi-turn dialogues.

Abstract: Large language models (LLMs) typically enhance their performance through either the retrieval of semantically similar information or the improvement of their reasoning capabilities. However, a significant challenge remains in effectively integrating both retrieval and reasoning strategies to optimize LLM performance. In this paper, we introduce a reasoning-aware knowledge retrieval method that enriches LLMs with information aligned to the logical structure of conversations, moving beyond surface-level semantic similarity. We follow a coarse-to-fine approach for knowledge retrieval. First, we identify a contextually relevant sub-region of the knowledge base, ensuring that all sentences within it are relevant to the context topic. Next, we refine our search within this sub-region to extract knowledge that is specifically relevant to the reasoning process. Throughout both phases, we employ the Monte Carlo Tree Search-inspired search method to effectively navigate through knowledge sentences using common keywords. Experiments on two multi-turn dialogue datasets demonstrate that our knowledge retrieval approach not only aligns more closely with the underlying reasoning in human conversations but also significantly enhances the diversity of the retrieved knowledge, resulting in more informative and creative responses.

</details>


### [125] [Finetuning Large Language Models for Automated Depression Screening in Nigerian Pidgin English: GENSCORE Pilot Study](https://arxiv.org/abs/2601.00004)
*Isaac Iyinoluwa Olufadewa,Miracle Ayomikun Adesina,Ezekiel Ayodeji Oladejo,Uthman Babatunde Usman,Owen Kolade Adeniyi,Matthew Tolulope Olawoyin*

Main category: cs.AI

TL;DR: Fine-tuned LLMs for automated depression screening in Nigerian Pidgin, with GPT-4.1 achieving 94.5% accuracy in PHQ-9 severity scoring.


<details>
  <summary>Details</summary>
Motivation: Depression screening in Nigeria faces barriers: limited clinician access, stigma, and language barriers. Traditional tools like PHQ-9 were validated in high-income countries and may be linguistically/culturally inaccessible for Nigerian communities using Pidgin and 520+ local languages.

Method: Collected 432 Pidgin-language audio responses from Nigerian young adults (18-40) to PHQ-9-aligned prompts. Performed transcription, preprocessing, annotation (semantic labeling, slang/idiom interpretation, PHQ-9 scoring). Fine-tuned three LLMs (Phi-3-mini-4k-instruct, Gemma-3-4B-it, GPT-4.1) on annotated dataset. Evaluated quantitatively (accuracy, precision, semantic alignment) and qualitatively (clarity, relevance, cultural appropriateness).

Result: GPT-4.1 achieved highest quantitative performance with 94.5% accuracy in PHQ-9 severity scoring prediction, outperforming Gemma-3-4B-it and Phi-3-mini-4k-instruct. Qualitatively, GPT-4.1 produced most culturally appropriate, clear, and contextually relevant responses.

Conclusion: AI-mediated depression screening can serve underserved Nigerian communities. This work provides foundation for deploying conversational mental-health tools in linguistically diverse, resource-constrained environments.

Abstract: Depression is a major contributor to the mental-health burden in Nigeria, yet screening coverage remains limited due to low access to clinicians, stigma, and language barriers. Traditional tools like the Patient Health Questionnaire-9 (PHQ-9) were validated in high-income countries but may be linguistically or culturally inaccessible for low- and middle-income countries and communities such as Nigeria where people communicate in Nigerian Pidgin and more than 520 local languages. This study presents a novel approach to automated depression screening using fine-tuned large language models (LLMs) adapted for conversational Nigerian Pidgin. We collected a dataset of 432 Pidgin-language audio responses from Nigerian young adults aged 18-40 to prompts assessing psychological experiences aligned with PHQ-9 items, performed transcription, rigorous preprocessing and annotation, including semantic labeling, slang and idiom interpretation, and PHQ-9 severity scoring. Three LLMs - Phi-3-mini-4k-instruct, Gemma-3-4B-it, and GPT-4.1 - were fine-tuned on this annotated dataset, and their performance was evaluated quantitatively (accuracy, precision and semantic alignment) and qualitatively (clarity, relevance, and cultural appropriateness). GPT-4.1 achieved the highest quantitative performance, with 94.5% accuracy in PHQ-9 severity scoring prediction, outperforming Gemma-3-4B-it and Phi-3-mini-4k-instruct. Qualitatively, GPT-4.1 also produced the most culturally appropriate, clear, and contextually relevant responses. AI-mediated depression screening for underserved Nigerian communities. This work provides a foundation for deploying conversational mental-health tools in linguistically diverse, resource-constrained environments.

</details>


### [126] [The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs](https://arxiv.org/abs/2601.00097)
*Akash Kumar Panda,Olaoluwa Adigun,Bart Kosko*

Main category: cs.AI

TL;DR: LLM agent extracts causal feedback fuzzy cognitive maps from text, creating bidirectional system where FCM equilibria drive LLM to fetch more text, which modifies FCM structure in feedback loop.


<details>
  <summary>Details</summary>
Motivation: To develop an autonomous agentic system that can extract and evolve causal knowledge from text through bidirectional interaction between LLM agents and dynamical FCM systems.

Method: Three-step LLM agent process: 1) extract key nouns/noun phrases from text, 2) identify FCM concept nodes from those, 3) infer fuzzy causal edges between nodes. Tested on Kissinger AI essay, compared with human-generated FCMs.

Result: Generated FCMs converged to same equilibrium limit cycles as human-generated FCMs despite structural differences. Mixed FCM from Gemini and ChatGPT agents absorbed dominant equilibria but also created new equilibria for better approximation.

Conclusion: LLM agents can effectively extract causal FCMs from text, creating bidirectional autonomous systems where FCM dynamics guide text processing and text modifies FCM structure in feedback loop.

Abstract: We design a large-language-model (LLM) agent that extracts causal feedback fuzzy cognitive maps (FCMs) from raw text. The causal learning or extraction process is agentic both because of the LLM's semi-autonomy and because ultimately the FCM dynamical system's equilibria drive the LLM agents to fetch and process causal text. The fetched text can in principle modify the adaptive FCM causal structure and so modify the source of its quasi-autonomy--its equilibrium limit cycles and fixed-point attractors. This bidirectional process endows the evolving FCM dynamical system with a degree of autonomy while still staying on its agentic leash. We show in particular that a sequence of three finely tuned system instructions guide an LLM agent as it systematically extracts key nouns and noun phrases from text, as it extracts FCM concept nodes from among those nouns and noun phrases, and then as it extracts or infers partial or fuzzy causal edges between those FCM nodes. We test this FCM generation on a recent essay about the promise of AI from the late diplomat and political theorist Henry Kissinger and his colleagues. This three-step process produced FCM dynamical systems that converged to the same equilibrium limit cycles as did the human-generated FCMs even though the human-generated FCM differed in the number of nodes and edges. A final FCM mixed generated FCMs from separate Gemini and ChatGPT LLM agents. The mixed FCM absorbed the equilibria of its dominant mixture component but also created new equilibria of its own to better approximate the underlying causal dynamical system.

</details>


### [127] [The Illusion of Insight in Reasoning Models](https://arxiv.org/abs/2601.00514)
*Liv G. d'Aliberti,Manoel Horta Ribeiro*

Main category: cs.AI

TL;DR: Mid-reasoning shifts in LLMs are rare, don't improve with training, and seldom boost accuracy - they're symptoms of unstable inference rather than genuine "Aha!" moments.


<details>
  <summary>Details</summary>
Motivation: To investigate whether reasoning models truly have "Aha!" moments - sudden mid-trace realizations that lead to accurate outputs - and whether these intrinsic reasoning shifts actually improve performance.

Method: Analyzed 1M+ reasoning traces across hundreds of training checkpoints, three reasoning domains, multiple decoding temperatures and model architectures. Instrumented training runs to detect mid-reasoning shifts and studied their effects.

Result: Reasoning shifts are rare, don't become more frequent with training, and seldom improve accuracy. Their effect varies with model uncertainty. Artificially triggering extrinsic shifts under high entropy reliably improves accuracy.

Conclusion: Mid-reasoning shifts are symptoms of unstable inference behavior rather than an intrinsic mechanism for self-correction, contradicting prior perceptions of model insight.

Abstract: Do reasoning models have "Aha!" moments? Prior work suggests that models like DeepSeek-R1-Zero undergo sudden mid-trace realizations that lead to accurate outputs, implying an intrinsic capacity for self-correction. Yet, it remains unclear whether such intrinsic shifts in reasoning strategy actually improve performance. Here, we study mid-reasoning shifts and instrument training runs to detect them. Our analysis spans 1M+ reasoning traces, hundreds of training checkpoints, three reasoning domains, and multiple decoding temperatures and model architectures. We find that reasoning shifts are rare, do not become more frequent with training, and seldom improve accuracy, indicating that they do not correspond to prior perceptions of model insight. However, their effect varies with model uncertainty. Building on this finding, we show that artificially triggering extrinsic shifts under high entropy reliably improves accuracy. Our results show that mid-reasoning shifts are symptoms of unstable inference behavior rather than an intrinsic mechanism for self-correction.

</details>


### [128] [From Clay to Code: Typological and Material Reasoning in AI Interpretations of Iranian Pigeon Towers](https://arxiv.org/abs/2601.00029)
*Abolhassan Pishahang,Maryam Badiei*

Main category: cs.AI

TL;DR: AI systems can visually replicate vernacular architectural forms like Iranian pigeon towers but fail to understand the material and climatic reasoning behind them, revealing a gap between visual resemblance and architectural intelligence.


<details>
  <summary>Details</summary>
Motivation: To investigate how generative AI systems interpret and reconstruct the architectural intelligence embedded in vernacular forms, specifically examining whether AI can understand the functional, material, and environmental reasoning behind traditional designs beyond mere visual reproduction.

Method: Used Iranian pigeon towers as a case study, testing three diffusion models (Midjourney v6, DALL-E 3, and DreamStudio/SDXL) across three prompt stages: referential (with reference images), adaptive (modified prompts), and speculative (creative prompts). Evaluated outputs using a five-criteria framework assessing typology, materiality, environment, realism, and cultural specificity.

Result: AI reliably reproduces geometric patterns but misinterprets material and climatic reasoning. Reference imagery improves realism but limits creativity, while creative prompts generate inventive but culturally ambiguous outcomes. The study reveals a clear boundary between visual resemblance and architectural reasoning in AI systems.

Conclusion: Generative AI can visually replicate vernacular forms but lacks understanding of the architectural intelligence behind them. The research establishes computational vernacular reasoning as a framework for analyzing how AI perceives, distorts, and reimagines traditional design intelligence, highlighting the gap between visual reproduction and true architectural comprehension.

Abstract: This study investigates how generative AI systems interpret the architectural intelligence embedded in vernacular form. Using the Iranian pigeon tower as a case study, the research tests three diffusion models, Midjourney v6, DALL-E 3, and DreamStudio based on Stable Diffusion XL (SDXL), across three prompt stages: referential, adaptive, and speculative. A five-criteria evaluation framework assesses how each system reconstructs typology, materiality, environment, realism, and cultural specificity. Results show that AI reliably reproduces geometric patterns but misreads material and climatic reasoning. Reference imagery improves realism yet limits creativity, while freedom from reference generates inventive but culturally ambiguous outcomes. The findings define a boundary between visual resemblance and architectural reasoning, positioning computational vernacular reasoning as a framework for analyzing how AI perceives, distorts, and reimagines traditional design intelligence.

</details>


### [129] [Explicit Abstention Knobs for Predictable Reliability in Video Question Answering](https://arxiv.org/abs/2601.00138)
*Jorge Ortiz*

Main category: cs.AI

TL;DR: Confidence-based abstention provides reliable error rate control for VLMs in video QA, but this control degrades under distribution shift.


<details>
  <summary>Details</summary>
Motivation: High-stakes deployment of vision-language models requires selective prediction where systems abstain when uncertain to avoid costly errors. Need to investigate whether confidence-based abstention provides reliable control over error rates in video question answering and whether that control remains robust under distribution shift.

Method: Using NExT-QA dataset and Gemini 2.0 Flash model, analyze confidence thresholding for abstention. Sweep threshold epsilon to produce risk-coverage tradeoffs and evaluate control under distribution shift.

Result: First, confidence thresholding provides mechanistic control in-distribution, producing smooth risk-coverage tradeoffs and reducing error rates. Second, this control degrades under distribution shift.

Conclusion: While confidence-based abstention works well in-distribution for error rate control in video QA, it's not robust to distribution shifts, highlighting the need for more reliable uncertainty estimation methods for safe deployment.

Abstract: High-stakes deployment of vision-language models (VLMs) requires selective prediction, where systems abstain when uncertain rather than risk costly errors. We investigate whether confidence-based abstention provides reliable control over error rates in video question answering, and whether that control remains robust under distribution shift. Using NExT-QA and Gemini 2.0 Flash, we establish two findings. First, confidence thresholding provides mechanistic control in-distribution. Sweeping threshold epsilon produces smooth risk-coverage tradeoffs, reducing error rates f

</details>
